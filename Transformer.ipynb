{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義 Transforme rModel\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, num_heads):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, 1, batch_first=True)\n",
    "        self.transformer = Transformer(\n",
    "            d_model=hidden_dim,\n",
    "            #d_model=input_dim,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        #self.fc = nn.Linear(BATCH_SIZE*input_dim, output_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "    \n",
    "        # batch_size, _ = src.shape[0], src.shape[1]\n",
    "        # h_0 = torch.randn(1, batch_size,  self.hidden_dim).to(device)\n",
    "        # c_0 = torch.randn(1, batch_size,  self.hidden_dim).to(device)\n",
    "        # src, _ = self.lstm(src, (h_0, c_0))\n",
    "        src = self.embedding(src)\n",
    "        # #print('lstm後的大小:',src.shape)\n",
    "        output = self.transformer(src, src)\n",
    "        #print('T後的大小:',output.shape)\n",
    "        output = self.fc(output)\n",
    "        #output = self.fc(output)\n",
    "        #print('最終大小:',output.shape)\n",
    "        output = output[:, -1, :]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型參數\n",
    "input_dim = 10 # 輸入詞彙表大小\n",
    "hidden_dim = 32  # 隱藏層維度\n",
    "output_dim = 1  # 輸出維度，輸出維度為1，代表預測的下一個數\n",
    "num_layers = 4  # Transformer Encoder/Decoder 層數\n",
    "num_heads = 8  # Attention heads \n",
    "\n",
    "\n",
    "\n",
    "# 創建 Transformer\n",
    "model = TransformerModel(input_dim, hidden_dim, output_dim, num_layers, num_heads)\n",
    "model.to(device)\n",
    "\n",
    "# 定義損失函數和優化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-2, weight_decay=1e-6)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(final_seq, batch_size):\n",
    "    \"\"\"\n",
    "    Batches the sequence data using PyTorch DataLoader.\n",
    "\n",
    "    Args:\n",
    "        final_seq: A list of tuples containing sequence input data and target data.\n",
    "        batch_size: The desired batch size.\n",
    "\n",
    "    Returns:\n",
    "        A DataLoader object containing the batched sequence data.\n",
    "\n",
    "    \"\"\"\n",
    "    final_seq = DataLoader(dataset=final_seq, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=False)\n",
    "\n",
    "    return final_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成 l * w * h 維度的資料\n",
    "# l : batch_size\n",
    "# w : sequence length\n",
    "# h : amounts of features \n",
    "# 以下以 30 * 6 * 1 做示範\n",
    "def data_generated(beg, num):\n",
    "    final_seq = []\n",
    "    for i in range(num):\n",
    "        end = beg + 30\n",
    "        q_tensors = [torch.tensor([i]*10, dtype=torch.float32) for i in range(beg, end)]\n",
    "        q_tensors = torch.stack(q_tensors)\n",
    "        a_tensors = torch.tensor([end], dtype=torch.float32) \n",
    "        final_seq.append((q_tensors, a_tensors))\n",
    "        beg += 1\n",
    "    print('final_seq : 資料類型={}, 列數={}'.format(type(final_seq), len(final_seq)))\n",
    "    print('final_seq[0] : 資料類型={}, 列數={}'.format(type(final_seq[0]), len(final_seq[0])))\n",
    "    print('final_seq[0][0] : 資料類型={}, 內容數={}'.format(type(final_seq[0][0]), final_seq[0][0].shape))\n",
    "    print('final_seq[0][1] : 資料類型={}, 內容數={}'.format(type(final_seq[0][1]), final_seq[0][1].shape))\n",
    "    print(final_seq[0][0])\n",
    "    print(final_seq[0][1])\n",
    "    data = batch_data(final_seq, 30)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_seq : 資料類型=<class 'list'>, 列數=571\n",
      "final_seq[0] : 資料類型=<class 'tuple'>, 列數=2\n",
      "final_seq[0][0] : 資料類型=<class 'torch.Tensor'>, 內容數=torch.Size([30, 10])\n",
      "final_seq[0][1] : 資料類型=<class 'torch.Tensor'>, 內容數=torch.Size([1])\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.],\n",
      "        [ 3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.],\n",
      "        [ 4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.],\n",
      "        [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
      "        [ 6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.],\n",
      "        [ 7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.],\n",
      "        [ 8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.],\n",
      "        [ 9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.],\n",
      "        [10., 10., 10., 10., 10., 10., 10., 10., 10., 10.],\n",
      "        [11., 11., 11., 11., 11., 11., 11., 11., 11., 11.],\n",
      "        [12., 12., 12., 12., 12., 12., 12., 12., 12., 12.],\n",
      "        [13., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
      "        [14., 14., 14., 14., 14., 14., 14., 14., 14., 14.],\n",
      "        [15., 15., 15., 15., 15., 15., 15., 15., 15., 15.],\n",
      "        [16., 16., 16., 16., 16., 16., 16., 16., 16., 16.],\n",
      "        [17., 17., 17., 17., 17., 17., 17., 17., 17., 17.],\n",
      "        [18., 18., 18., 18., 18., 18., 18., 18., 18., 18.],\n",
      "        [19., 19., 19., 19., 19., 19., 19., 19., 19., 19.],\n",
      "        [20., 20., 20., 20., 20., 20., 20., 20., 20., 20.],\n",
      "        [21., 21., 21., 21., 21., 21., 21., 21., 21., 21.],\n",
      "        [22., 22., 22., 22., 22., 22., 22., 22., 22., 22.],\n",
      "        [23., 23., 23., 23., 23., 23., 23., 23., 23., 23.],\n",
      "        [24., 24., 24., 24., 24., 24., 24., 24., 24., 24.],\n",
      "        [25., 25., 25., 25., 25., 25., 25., 25., 25., 25.],\n",
      "        [26., 26., 26., 26., 26., 26., 26., 26., 26., 26.],\n",
      "        [27., 27., 27., 27., 27., 27., 27., 27., 27., 27.],\n",
      "        [28., 28., 28., 28., 28., 28., 28., 28., 28., 28.],\n",
      "        [29., 29., 29., 29., 29., 29., 29., 29., 29., 29.]])\n",
      "tensor([30.])\n"
     ]
    }
   ],
   "source": [
    "data = data_generated(0, 571)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_seq : 資料類型=<class 'list'>, 列數=6000\n",
      "final_seq[0] : 資料類型=<class 'tuple'>, 列數=2\n",
      "final_seq[0][0] : 資料類型=<class 'torch.Tensor'>, 內容數=torch.Size([30, 10])\n",
      "final_seq[0][1] : 資料類型=<class 'torch.Tensor'>, 內容數=torch.Size([1])\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.],\n",
      "        [ 3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.],\n",
      "        [ 4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.],\n",
      "        [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
      "        [ 6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.],\n",
      "        [ 7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.],\n",
      "        [ 8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.],\n",
      "        [ 9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.],\n",
      "        [10., 10., 10., 10., 10., 10., 10., 10., 10., 10.],\n",
      "        [11., 11., 11., 11., 11., 11., 11., 11., 11., 11.],\n",
      "        [12., 12., 12., 12., 12., 12., 12., 12., 12., 12.],\n",
      "        [13., 13., 13., 13., 13., 13., 13., 13., 13., 13.],\n",
      "        [14., 14., 14., 14., 14., 14., 14., 14., 14., 14.],\n",
      "        [15., 15., 15., 15., 15., 15., 15., 15., 15., 15.],\n",
      "        [16., 16., 16., 16., 16., 16., 16., 16., 16., 16.],\n",
      "        [17., 17., 17., 17., 17., 17., 17., 17., 17., 17.],\n",
      "        [18., 18., 18., 18., 18., 18., 18., 18., 18., 18.],\n",
      "        [19., 19., 19., 19., 19., 19., 19., 19., 19., 19.],\n",
      "        [20., 20., 20., 20., 20., 20., 20., 20., 20., 20.],\n",
      "        [21., 21., 21., 21., 21., 21., 21., 21., 21., 21.],\n",
      "        [22., 22., 22., 22., 22., 22., 22., 22., 22., 22.],\n",
      "        [23., 23., 23., 23., 23., 23., 23., 23., 23., 23.],\n",
      "        [24., 24., 24., 24., 24., 24., 24., 24., 24., 24.],\n",
      "        [25., 25., 25., 25., 25., 25., 25., 25., 25., 25.],\n",
      "        [26., 26., 26., 26., 26., 26., 26., 26., 26., 26.],\n",
      "        [27., 27., 27., 27., 27., 27., 27., 27., 27., 27.],\n",
      "        [28., 28., 28., 28., 28., 28., 28., 28., 28., 28.],\n",
      "        [29., 29., 29., 29., 29., 29., 29., 29., 29., 29.]])\n",
      "tensor([30.])\n",
      "final_seq : 資料類型=<class 'list'>, 列數=60\n",
      "final_seq[0] : 資料類型=<class 'tuple'>, 列數=2\n",
      "final_seq[0][0] : 資料類型=<class 'torch.Tensor'>, 內容數=torch.Size([30, 10])\n",
      "final_seq[0][1] : 資料類型=<class 'torch.Tensor'>, 內容數=torch.Size([1])\n",
      "tensor([[600., 600., 600., 600., 600., 600., 600., 600., 600., 600.],\n",
      "        [601., 601., 601., 601., 601., 601., 601., 601., 601., 601.],\n",
      "        [602., 602., 602., 602., 602., 602., 602., 602., 602., 602.],\n",
      "        [603., 603., 603., 603., 603., 603., 603., 603., 603., 603.],\n",
      "        [604., 604., 604., 604., 604., 604., 604., 604., 604., 604.],\n",
      "        [605., 605., 605., 605., 605., 605., 605., 605., 605., 605.],\n",
      "        [606., 606., 606., 606., 606., 606., 606., 606., 606., 606.],\n",
      "        [607., 607., 607., 607., 607., 607., 607., 607., 607., 607.],\n",
      "        [608., 608., 608., 608., 608., 608., 608., 608., 608., 608.],\n",
      "        [609., 609., 609., 609., 609., 609., 609., 609., 609., 609.],\n",
      "        [610., 610., 610., 610., 610., 610., 610., 610., 610., 610.],\n",
      "        [611., 611., 611., 611., 611., 611., 611., 611., 611., 611.],\n",
      "        [612., 612., 612., 612., 612., 612., 612., 612., 612., 612.],\n",
      "        [613., 613., 613., 613., 613., 613., 613., 613., 613., 613.],\n",
      "        [614., 614., 614., 614., 614., 614., 614., 614., 614., 614.],\n",
      "        [615., 615., 615., 615., 615., 615., 615., 615., 615., 615.],\n",
      "        [616., 616., 616., 616., 616., 616., 616., 616., 616., 616.],\n",
      "        [617., 617., 617., 617., 617., 617., 617., 617., 617., 617.],\n",
      "        [618., 618., 618., 618., 618., 618., 618., 618., 618., 618.],\n",
      "        [619., 619., 619., 619., 619., 619., 619., 619., 619., 619.],\n",
      "        [620., 620., 620., 620., 620., 620., 620., 620., 620., 620.],\n",
      "        [621., 621., 621., 621., 621., 621., 621., 621., 621., 621.],\n",
      "        [622., 622., 622., 622., 622., 622., 622., 622., 622., 622.],\n",
      "        [623., 623., 623., 623., 623., 623., 623., 623., 623., 623.],\n",
      "        [624., 624., 624., 624., 624., 624., 624., 624., 624., 624.],\n",
      "        [625., 625., 625., 625., 625., 625., 625., 625., 625., 625.],\n",
      "        [626., 626., 626., 626., 626., 626., 626., 626., 626., 626.],\n",
      "        [627., 627., 627., 627., 627., 627., 627., 627., 627., 627.],\n",
      "        [628., 628., 628., 628., 628., 628., 628., 628., 628., 628.],\n",
      "        [629., 629., 629., 629., 629., 629., 629., 629., 629., 629.]])\n",
      "tensor([630.])\n",
      "final_seq : 資料類型=<class 'list'>, 列數=60\n",
      "final_seq[0] : 資料類型=<class 'tuple'>, 列數=2\n",
      "final_seq[0][0] : 資料類型=<class 'torch.Tensor'>, 內容數=torch.Size([30, 10])\n",
      "final_seq[0][1] : 資料類型=<class 'torch.Tensor'>, 內容數=torch.Size([1])\n",
      "tensor([[700., 700., 700., 700., 700., 700., 700., 700., 700., 700.],\n",
      "        [701., 701., 701., 701., 701., 701., 701., 701., 701., 701.],\n",
      "        [702., 702., 702., 702., 702., 702., 702., 702., 702., 702.],\n",
      "        [703., 703., 703., 703., 703., 703., 703., 703., 703., 703.],\n",
      "        [704., 704., 704., 704., 704., 704., 704., 704., 704., 704.],\n",
      "        [705., 705., 705., 705., 705., 705., 705., 705., 705., 705.],\n",
      "        [706., 706., 706., 706., 706., 706., 706., 706., 706., 706.],\n",
      "        [707., 707., 707., 707., 707., 707., 707., 707., 707., 707.],\n",
      "        [708., 708., 708., 708., 708., 708., 708., 708., 708., 708.],\n",
      "        [709., 709., 709., 709., 709., 709., 709., 709., 709., 709.],\n",
      "        [710., 710., 710., 710., 710., 710., 710., 710., 710., 710.],\n",
      "        [711., 711., 711., 711., 711., 711., 711., 711., 711., 711.],\n",
      "        [712., 712., 712., 712., 712., 712., 712., 712., 712., 712.],\n",
      "        [713., 713., 713., 713., 713., 713., 713., 713., 713., 713.],\n",
      "        [714., 714., 714., 714., 714., 714., 714., 714., 714., 714.],\n",
      "        [715., 715., 715., 715., 715., 715., 715., 715., 715., 715.],\n",
      "        [716., 716., 716., 716., 716., 716., 716., 716., 716., 716.],\n",
      "        [717., 717., 717., 717., 717., 717., 717., 717., 717., 717.],\n",
      "        [718., 718., 718., 718., 718., 718., 718., 718., 718., 718.],\n",
      "        [719., 719., 719., 719., 719., 719., 719., 719., 719., 719.],\n",
      "        [720., 720., 720., 720., 720., 720., 720., 720., 720., 720.],\n",
      "        [721., 721., 721., 721., 721., 721., 721., 721., 721., 721.],\n",
      "        [722., 722., 722., 722., 722., 722., 722., 722., 722., 722.],\n",
      "        [723., 723., 723., 723., 723., 723., 723., 723., 723., 723.],\n",
      "        [724., 724., 724., 724., 724., 724., 724., 724., 724., 724.],\n",
      "        [725., 725., 725., 725., 725., 725., 725., 725., 725., 725.],\n",
      "        [726., 726., 726., 726., 726., 726., 726., 726., 726., 726.],\n",
      "        [727., 727., 727., 727., 727., 727., 727., 727., 727., 727.],\n",
      "        [728., 728., 728., 728., 728., 728., 728., 728., 728., 728.],\n",
      "        [729., 729., 729., 729., 729., 729., 729., 729., 729., 729.]])\n",
      "tensor([730.])\n"
     ]
    }
   ],
   "source": [
    "# 生成訓練資料\n",
    "train_data = data_generated(0, 6000)\n",
    "\n",
    "# 生成驗證資料\n",
    "valid_data = data_generated(600, 60)\n",
    "\n",
    "# 生成測試資料\n",
    "test_data = data_generated(700, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 生成訓練資料\n",
    "# train_data = []\n",
    "# for i in range(1000): \n",
    "#     sequence = torch.arange(i, i+6).float() # 輸入等差數列\n",
    "#     target = torch.tensor([sequence[-1] + 1])  # 預測下一個值，等於最後一個+1\n",
    "#     sequence = sequence.unsqueeze(0)\n",
    "#     sequence = torch.cat([sequence, sequence], dim=0)\n",
    "#     train_data.append((sequence, target))\n",
    "\n",
    "# # 生成驗證資料\n",
    "# valid_data = []\n",
    "# for i in range(1000,1100):\n",
    "#     sequence = torch.arange(i, i+6).float()  # 輸入等差數列\n",
    "#     target = torch.tensor([sequence[-1] + 1])  # 預測下一個值，等於最後一個+1\n",
    "#     sequence = sequence.unsqueeze(0)\n",
    "#     sequence = torch.cat([sequence, sequence], dim=0)\n",
    "#     valid_data.append((sequence, target))\n",
    "\n",
    "# # 生成測試資料\n",
    "# test_data = []\n",
    "# for i in range(1100,1200):\n",
    "#     sequence = torch.arange(i, i+6).float()  # 輸入等差數列\n",
    "#     target = torch.tensor([sequence[-1] + 1])  # 預測下一個值，等於最後一個+1\n",
    "#     sequence = sequence.unsqueeze(0)\n",
    "#     sequence = torch.cat([sequence, sequence], dim=0)\n",
    "#     test_data.append((sequence, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_seq = train_data\n",
    "# print('final_seq : 資料類型={}, 列數={}'.format(type(final_seq), len(final_seq)))\n",
    "# print('final_seq[0] : 資料類型={}, 列數={}'.format(type(final_seq[0]), len(final_seq[0])))\n",
    "# print('final_seq[0][0] : 資料類型={}, 內容數={}'.format(type(final_seq[0][0]), final_seq[0][0].shape))\n",
    "# print('final_seq[0][1] : 資料類型={}, 內容數={}'.format(type(final_seq[0][1]), final_seq[0][1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_loss(model, val_data, loss_function):\n",
    "    \"\"\"\n",
    "    Computes the average validation loss for a given model and validation data.\n",
    "\n",
    "    Args:\n",
    "        model: The model for which to compute the validation loss.\n",
    "        val_data: The validation data (a DataLoader object).\n",
    "        loss_function: The loss function to compute the loss.\n",
    "\n",
    "    Returns:\n",
    "        The average validation loss.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    with torch.no_grad():\n",
    "        for seq, label in val_data:\n",
    "            try:\n",
    "                seq, label = seq.to(device), label.to(device)\n",
    "                y_pred = model(seq)\n",
    "                loss = loss_function(y_pred[0].view(-1), label)\n",
    "                val_loss.append(loss.item())\n",
    "            except:\n",
    "                seq, label = seq.to(device), label.to(device)\n",
    "                print(seq.shape)\n",
    "                print(seq.dtype)\n",
    "                print(seq.type())\n",
    "                y_pred = model(seq, seq)\n",
    "                loss = loss_function(y_pred[0].view(-1), label)\n",
    "                val_loss.append(loss.item())\n",
    "\n",
    "    return np.mean(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 000 train_loss 12074676.44768921 val_loss 400266.31250000\n",
      "epoch 001 train_loss 11960094.27997147 val_loss 378570.57812500\n",
      "epoch 002 train_loss 11842904.11299591 val_loss 353652.87500000\n",
      "epoch 003 train_loss 11869225.46492020 val_loss 359658.18750000\n",
      "epoch 004 train_loss 11761792.34649231 val_loss 338333.09375000\n",
      "epoch 005 train_loss 11819682.65396008 val_loss 349824.26562500\n",
      "epoch 006 train_loss 11756057.96716782 val_loss 336118.26562500\n",
      "epoch 007 train_loss 11625261.99595879 val_loss 309568.70312500\n",
      "epoch 008 train_loss 11498380.60675171 val_loss 287263.06250000\n",
      "epoch 009 train_loss 11383166.48093475 val_loss 266835.79687500\n",
      "epoch 010 train_loss 11272849.43181175 val_loss 247692.67968750\n",
      "epoch 011 train_loss 11165650.62938538 val_loss 229587.26562500\n",
      "epoch 012 train_loss 11060740.82353668 val_loss 212388.34375000\n",
      "epoch 013 train_loss 10957655.14553104 val_loss 196016.84375000\n",
      "epoch 014 train_loss 10856104.97951588 val_loss 180420.74218750\n",
      "epoch 015 train_loss 10755898.80525978 val_loss 165563.78125000\n",
      "epoch 016 train_loss 10656903.32578804 val_loss 151419.60937500\n",
      "epoch 017 train_loss 10559021.93544365 val_loss 137968.28125000\n",
      "epoch 018 train_loss 10462183.21677235 val_loss 125194.08593750\n",
      "epoch 019 train_loss 10366332.19666557 val_loss 113084.54687500\n",
      "epoch 020 train_loss 10365855.05921909 val_loss 113391.83203125\n",
      "epoch 021 train_loss 10277365.00914253 val_loss 102696.89843750\n",
      "epoch 022 train_loss 10189845.37119740 val_loss 92564.09375000\n",
      "epoch 023 train_loss 10103115.94520904 val_loss 82986.25390625\n",
      "epoch 024 train_loss 10190956.23283771 val_loss 93014.67187500\n",
      "epoch 025 train_loss 10110391.98868118 val_loss 84093.98437500\n",
      "epoch 026 train_loss 10277511.45153053 val_loss 103543.79687500\n",
      "epoch 027 train_loss 10204800.46433067 val_loss 95066.58593750\n",
      "epoch 028 train_loss 10132792.97463097 val_loss 86983.08203125\n",
      "epoch 029 train_loss 10061407.11037827 val_loss 79285.87500000\n",
      "epoch 030 train_loss 10243559.67658043 val_loss 100002.37890625\n",
      "epoch 031 train_loss 10179694.86914413 val_loss 92680.02343750\n",
      "epoch 032 train_loss 10116632.17453354 val_loss 85662.14843750\n",
      "epoch 033 train_loss 10054062.20462593 val_loss 78942.82031250\n",
      "epoch 034 train_loss 9991958.92264462 val_loss 72517.23242188\n",
      "epoch 035 train_loss 9930299.41786598 val_loss 66381.23437500\n",
      "epoch 036 train_loss 9869066.20297584 val_loss 60531.30859375\n",
      "epoch 037 train_loss 10198279.47428307 val_loss 94740.76171875\n",
      "epoch 038 train_loss 10134376.19889793 val_loss 87591.78125000\n",
      "epoch 039 train_loss 10071308.02988075 val_loss 80754.54296875\n",
      "epoch 040 train_loss 10008784.40334499 val_loss 74221.54296875\n",
      "epoch 041 train_loss 9946767.55366043 val_loss 67986.43359375\n",
      "epoch 042 train_loss 9827524.96179314 val_loss 54086.76953125\n",
      "epoch 043 train_loss 9770405.25854569 val_loss 50936.64648438\n",
      "epoch 044 train_loss 9694684.82620506 val_loss 44713.20312500\n",
      "epoch 045 train_loss 9622103.56918838 val_loss 39045.86718750\n",
      "epoch 046 train_loss 9551403.59865166 val_loss 33850.39843750\n",
      "epoch 047 train_loss 9482055.03331085 val_loss 29083.46191406\n",
      "epoch 048 train_loss 9413772.45522400 val_loss 24719.06347656\n",
      "epoch 049 train_loss 9346378.50625160 val_loss 20740.01562500\n",
      "epoch 050 train_loss 9279760.70635368 val_loss 17134.29931641\n",
      "epoch 051 train_loss 9522272.92326847 val_loss 31025.27343750\n",
      "epoch 052 train_loss 9436112.88914345 val_loss 25828.90332031\n",
      "epoch 053 train_loss 9424862.69335781 val_loss 25599.43847656\n",
      "epoch 054 train_loss 9363898.39760170 val_loss 21921.44433594\n",
      "epoch 055 train_loss 9303557.67706268 val_loss 18546.39794922\n",
      "epoch 056 train_loss 9243750.81191429 val_loss 15468.97314453\n",
      "epoch 057 train_loss 9184443.75783104 val_loss 12684.66992188\n",
      "epoch 058 train_loss 10136526.47166496 val_loss 87509.05078125\n",
      "epoch 059 train_loss 10037492.16489410 val_loss 75452.33593750\n",
      "epoch 060 train_loss 9946513.10636246 val_loss 67009.25390625\n",
      "epoch 061 train_loss 9865835.37740581 val_loss 59479.31445312\n",
      "epoch 062 train_loss 10217347.13563835 val_loss 96248.64843750\n",
      "epoch 063 train_loss 11292093.34507729 val_loss 252782.12500000\n",
      "epoch 064 train_loss 11206585.13198338 val_loss 238284.13281250\n",
      "epoch 065 train_loss 11123744.13406280 val_loss 224463.25781250\n",
      "epoch 066 train_loss 11694120.61074707 val_loss 328046.59375000\n",
      "epoch 067 train_loss 11608804.98304207 val_loss 312159.95312500\n",
      "epoch 068 train_loss 11539324.69163597 val_loss 299128.78125000\n",
      "epoch 069 train_loss 11498335.22384949 val_loss 292204.29687500\n",
      "epoch 070 train_loss 11437883.28273056 val_loss 281108.71875000\n",
      "epoch 071 train_loss 11377854.16905262 val_loss 270261.60937500\n",
      "epoch 072 train_loss 11318213.36181305 val_loss 259656.44531250\n",
      "epoch 073 train_loss 11258908.63875443 val_loss 249285.76562500\n",
      "epoch 074 train_loss 11161369.45694721 val_loss 229837.94531250\n",
      "epoch 075 train_loss 11075464.82642181 val_loss 216865.52343750\n",
      "epoch 076 train_loss 10961774.37023766 val_loss 196318.13281250\n",
      "epoch 077 train_loss 10863075.37581585 val_loss 182353.81250000\n",
      "epoch 078 train_loss 10776525.86061592 val_loss 169710.92968750\n",
      "Epoch 00079: reducing learning rate of group 0 to 5.0000e-03.\n",
      "epoch 079 train_loss 10808214.86034210 val_loss 177907.12500000\n",
      "epoch 080 train_loss 10774165.02975052 val_loss 172824.91406250\n",
      "epoch 081 train_loss 10740436.86246437 val_loss 167831.32812500\n",
      "epoch 082 train_loss 10698148.93341660 val_loss 160852.79687500\n",
      "epoch 083 train_loss 10638620.36721748 val_loss 151606.63281250\n",
      "epoch 084 train_loss 10569221.11814468 val_loss 141489.13281250\n",
      "epoch 085 train_loss 10629905.22664345 val_loss 150511.00000000\n",
      "epoch 086 train_loss 10576597.22113243 val_loss 143321.28906250\n",
      "epoch 087 train_loss 10526088.76127701 val_loss 136563.85546875\n",
      "epoch 088 train_loss 10529460.60921093 val_loss 136015.95703125\n",
      "epoch 089 train_loss 10468266.14987217 val_loss 128440.73828125\n",
      "epoch 090 train_loss 10496162.55983673 val_loss 132443.62109375\n",
      "epoch 091 train_loss 10445749.53874115 val_loss 125924.15625000\n",
      "epoch 092 train_loss 10396810.66126450 val_loss 119691.00781250\n",
      "epoch 093 train_loss 10348828.75614151 val_loss 113700.98046875\n",
      "epoch 094 train_loss 10877495.32913071 val_loss 184982.07812500\n",
      "epoch 095 train_loss 10803269.05646523 val_loss 175042.90625000\n",
      "epoch 096 train_loss 10781033.73902626 val_loss 172516.97656250\n",
      "epoch 097 train_loss 10740471.11699181 val_loss 166792.36718750\n",
      "epoch 098 train_loss 10691844.79826981 val_loss 159754.97656250\n",
      "epoch 099 train_loss 10643757.73992249 val_loss 152918.38281250\n",
      "Epoch 00100: reducing learning rate of group 0 to 2.5000e-03.\n",
      "epoch 100 train_loss 10608690.97348144 val_loss 149574.57031250\n",
      "epoch 101 train_loss 10585015.23924362 val_loss 146279.74218750\n",
      "epoch 102 train_loss 10561454.01627113 val_loss 143031.37500000\n",
      "epoch 103 train_loss 10537991.62194412 val_loss 139827.25781250\n",
      "epoch 104 train_loss 10514619.25214561 val_loss 136666.21875000\n",
      "epoch 105 train_loss 10491329.13661247 val_loss 133547.06250000\n",
      "epoch 106 train_loss 10453782.35519730 val_loss 127691.93359375\n",
      "epoch 107 train_loss 10438314.95928757 val_loss 126079.30468750\n",
      "epoch 108 train_loss 10426639.25577110 val_loss 124876.69140625\n",
      "epoch 109 train_loss 10638198.69672890 val_loss 153699.78906250\n",
      "epoch 110 train_loss 10614246.17305710 val_loss 150492.21093750\n",
      "epoch 111 train_loss 10590805.15900192 val_loss 147053.02343750\n",
      "epoch 112 train_loss 10521001.02961716 val_loss 137743.61328125\n",
      "epoch 113 train_loss 10498995.88223389 val_loss 134502.95312500\n",
      "epoch 114 train_loss 10476996.08920586 val_loss 131780.79687500\n",
      "epoch 115 train_loss 10441242.58688034 val_loss 126161.68750000\n",
      "epoch 116 train_loss 10407959.03706177 val_loss 122106.72265625\n",
      "epoch 117 train_loss 10433943.23370850 val_loss 126956.38281250\n",
      "epoch 118 train_loss 10207929.07922089 val_loss 97750.98828125\n",
      "epoch 119 train_loss 10208057.90110718 val_loss 95571.68750000\n",
      "epoch 120 train_loss 10214179.39612167 val_loss 101233.85937500\n",
      "Epoch 00121: reducing learning rate of group 0 to 1.2500e-03.\n",
      "epoch 121 train_loss 10195679.60230827 val_loss 100374.94140625\n",
      "epoch 122 train_loss 10184222.95962822 val_loss 99115.39062500\n",
      "epoch 123 train_loss 10170983.95061928 val_loss 92345.48046875\n",
      "epoch 124 train_loss 10156431.27786835 val_loss 92155.34765625\n",
      "epoch 125 train_loss 10143255.15261597 val_loss 91724.19531250\n",
      "epoch 126 train_loss 10129683.12950745 val_loss 90204.81640625\n",
      "epoch 127 train_loss 10115824.00892700 val_loss 88793.69140625\n",
      "epoch 128 train_loss 10105063.57965103 val_loss 90738.38281250\n",
      "epoch 129 train_loss 10092208.76802673 val_loss 90557.87890625\n",
      "epoch 130 train_loss 10080127.40679550 val_loss 79600.98046875\n",
      "epoch 131 train_loss 10419104.71553543 val_loss 125051.38281250\n",
      "epoch 132 train_loss 10402165.92154396 val_loss 127939.07031250\n",
      "epoch 133 train_loss 10387929.97842983 val_loss 116626.74609375\n",
      "epoch 134 train_loss 10374806.48075462 val_loss 119588.63671875\n",
      "epoch 135 train_loss 10360534.51241623 val_loss 118656.42578125\n",
      "epoch 136 train_loss 10347933.33526527 val_loss 115328.05468750\n",
      "epoch 137 train_loss 10332921.27926910 val_loss 114172.98046875\n",
      "epoch 138 train_loss 10320062.10377235 val_loss 111021.14843750\n",
      "epoch 139 train_loss 10306950.31052040 val_loss 114895.85937500\n",
      "epoch 140 train_loss 10295074.74592125 val_loss 109735.17968750\n",
      "epoch 141 train_loss 11066363.81145977 val_loss 219991.42187500\n",
      "Epoch 00142: reducing learning rate of group 0 to 6.2500e-04.\n",
      "epoch 142 train_loss 11054362.16750382 val_loss 218777.03125000\n",
      "epoch 143 train_loss 11047163.89829002 val_loss 217611.39062500\n",
      "epoch 144 train_loss 11040165.66246170 val_loss 216472.82031250\n",
      "epoch 145 train_loss 11033284.91134808 val_loss 215352.44531250\n",
      "epoch 146 train_loss 11026484.07124641 val_loss 214245.63281250\n",
      "epoch 147 train_loss 11019741.60012764 val_loss 213149.53125000\n",
      "epoch 148 train_loss 11013043.33897533 val_loss 212062.09375000\n",
      "epoch 149 train_loss 11006379.77959045 val_loss 210982.10156250\n",
      "epoch 150 train_loss 10999744.00737450 val_loss 209908.47656250\n",
      "epoch 151 train_loss 10993131.01202858 val_loss 208840.49218750\n",
      "epoch 152 train_loss 10986536.65088180 val_loss 207777.50000000\n",
      "epoch 153 train_loss 10979957.85515289 val_loss 206719.12500000\n",
      "epoch 154 train_loss 10973392.44948830 val_loss 205665.04687500\n",
      "epoch 155 train_loss 10966837.99421440 val_loss 204614.79687500\n",
      "epoch 156 train_loss 10960293.14133347 val_loss 203568.35156250\n",
      "epoch 157 train_loss 10953757.23242859 val_loss 202525.43750000\n",
      "epoch 158 train_loss 10947228.93703674 val_loss 201485.93750000\n",
      "epoch 159 train_loss 10940707.46877533 val_loss 200449.72656250\n",
      "epoch 160 train_loss 10934192.19927841 val_loss 199416.75000000\n",
      "epoch 161 train_loss 10927682.77962700 val_loss 198386.85937500\n",
      "epoch 162 train_loss 10921178.41091965 val_loss 197360.00781250\n",
      "Epoch 00163: reducing learning rate of group 0 to 3.1250e-04.\n",
      "epoch 163 train_loss 10916397.16480972 val_loss 196847.73437500\n",
      "epoch 164 train_loss 10913148.56550629 val_loss 196336.18750000\n",
      "epoch 165 train_loss 10909900.95589447 val_loss 195825.33593750\n",
      "epoch 166 train_loss 10906654.45135899 val_loss 195315.21093750\n",
      "epoch 167 train_loss 10903408.87235592 val_loss 194805.78906250\n",
      "epoch 168 train_loss 10900164.22428352 val_loss 194297.10937500\n",
      "epoch 169 train_loss 10896920.52125923 val_loss 193789.08593750\n",
      "epoch 170 train_loss 10893677.72740665 val_loss 193281.77343750\n",
      "epoch 171 train_loss 10890435.92877121 val_loss 192775.19531250\n",
      "epoch 172 train_loss 10887194.84807587 val_loss 192269.33593750\n",
      "epoch 173 train_loss 10883954.78484177 val_loss 191764.07812500\n",
      "epoch 174 train_loss 10880715.38001316 val_loss 191259.59375000\n",
      "epoch 175 train_loss 10877476.74694260 val_loss 190755.75000000\n",
      "epoch 176 train_loss 10874238.93315289 val_loss 190252.57812500\n",
      "epoch 177 train_loss 10871002.09317329 val_loss 189750.14062500\n",
      "epoch 178 train_loss 10867764.77365814 val_loss 189248.39843750\n",
      "epoch 179 train_loss 11070382.06383549 val_loss 221620.49218750\n",
      "epoch 180 train_loss 11066041.04987129 val_loss 220968.82812500\n",
      "epoch 181 train_loss 11062187.51044575 val_loss 220340.73437500\n",
      "epoch 182 train_loss 11058426.51722919 val_loss 219724.28906250\n",
      "epoch 183 train_loss 11054716.30323532 val_loss 219115.17187500\n",
      "Epoch 00184: reducing learning rate of group 0 to 1.5625e-04.\n",
      "epoch 184 train_loss 11052008.62675888 val_loss 218813.12500000\n",
      "epoch 185 train_loss 11050180.84959152 val_loss 218512.76562500\n",
      "epoch 186 train_loss 11048360.94075321 val_loss 218213.72656250\n",
      "epoch 187 train_loss 11046546.84124619 val_loss 217915.69531250\n",
      "epoch 188 train_loss 11044737.39361610 val_loss 217618.51562500\n",
      "epoch 189 train_loss 11042931.66099731 val_loss 217321.98437500\n",
      "epoch 190 train_loss 11041128.85408154 val_loss 217026.10937500\n",
      "epoch 191 train_loss 11039328.35206612 val_loss 216730.76562500\n",
      "epoch 192 train_loss 11037530.04888229 val_loss 216435.91406250\n",
      "epoch 193 train_loss 11035733.23266224 val_loss 216141.43750000\n",
      "epoch 194 train_loss 11033937.68078728 val_loss 215847.32031250\n",
      "epoch 195 train_loss 11032143.15268280 val_loss 215553.54687500\n",
      "epoch 196 train_loss 11030349.74937927 val_loss 215260.09375000\n",
      "epoch 197 train_loss 11028556.95248055 val_loss 214966.92187500\n",
      "epoch 198 train_loss 11026765.35726059 val_loss 214674.07031250\n",
      "epoch 199 train_loss 11024974.40567207 val_loss 214381.52343750\n",
      "epoch 200 train_loss 11023183.90700592 val_loss 214089.18750000\n",
      "epoch 201 train_loss 11021393.90164207 val_loss 213797.11718750\n",
      "epoch 202 train_loss 11019604.76949436 val_loss 213505.29687500\n",
      "epoch 203 train_loss 11017815.90287178 val_loss 213213.71093750\n",
      "epoch 204 train_loss 11016027.42585853 val_loss 212922.34375000\n",
      "Epoch 00205: reducing learning rate of group 0 to 7.8125e-05.\n",
      "epoch 205 train_loss 11014711.91918045 val_loss 212776.81250000\n",
      "epoch 206 train_loss 11013818.19083023 val_loss 212631.30468750\n",
      "epoch 207 train_loss 11012924.58488369 val_loss 212485.82812500\n",
      "epoch 208 train_loss 11012030.81767235 val_loss 212340.44531250\n",
      "epoch 209 train_loss 11011137.32846138 val_loss 212195.10937500\n",
      "epoch 210 train_loss 11010243.82008900 val_loss 212049.82812500\n",
      "epoch 211 train_loss 11009350.53835648 val_loss 211904.58593750\n",
      "epoch 212 train_loss 11008457.05320057 val_loss 211759.39843750\n",
      "epoch 213 train_loss 11007563.84917683 val_loss 211614.29687500\n",
      "epoch 214 train_loss 11006670.76404442 val_loss 211469.22656250\n",
      "epoch 215 train_loss 11005777.69335243 val_loss 211324.19531250\n",
      "epoch 216 train_loss 11004884.36957081 val_loss 211179.21875000\n",
      "epoch 217 train_loss 11003991.30675728 val_loss 211034.29687500\n",
      "epoch 218 train_loss 11003098.51720127 val_loss 210889.42968750\n",
      "epoch 219 train_loss 11002205.65299133 val_loss 210744.60937500\n",
      "epoch 220 train_loss 11001312.91003121 val_loss 210599.86718750\n",
      "epoch 221 train_loss 11000420.17067116 val_loss 210455.13281250\n",
      "epoch 222 train_loss 10999527.36840527 val_loss 210310.50781250\n",
      "epoch 223 train_loss 10998634.75030128 val_loss 210165.89062500\n",
      "epoch 224 train_loss 10997742.35632725 val_loss 210021.31250000\n",
      "epoch 225 train_loss 10996850.02451736 val_loss 209876.85156250\n",
      "Epoch 00226: reducing learning rate of group 0 to 3.9063e-05.\n",
      "epoch 226 train_loss 10996192.51285305 val_loss 209804.48437500\n",
      "epoch 227 train_loss 10995745.47524208 val_loss 209732.14843750\n",
      "epoch 228 train_loss 10995298.40351082 val_loss 209659.76562500\n",
      "epoch 229 train_loss 10994851.38233490 val_loss 209587.44531250\n",
      "epoch 230 train_loss 10994404.23990379 val_loss 209515.09375000\n",
      "epoch 231 train_loss 10993957.17975838 val_loss 209442.78906250\n",
      "epoch 232 train_loss 10993510.21718636 val_loss 209370.51562500\n",
      "epoch 233 train_loss 10993063.33750374 val_loss 209298.21093750\n",
      "epoch 234 train_loss 10992616.36351929 val_loss 209225.95312500\n",
      "epoch 235 train_loss 10992169.31743118 val_loss 209153.67187500\n",
      "epoch 236 train_loss 10991722.23056389 val_loss 209081.42968750\n",
      "epoch 237 train_loss 10991275.37219719 val_loss 209009.20312500\n",
      "epoch 238 train_loss 10990828.54779900 val_loss 208936.96093750\n",
      "epoch 239 train_loss 10990381.52805061 val_loss 208864.76562500\n",
      "epoch 240 train_loss 10989934.58378319 val_loss 208792.54687500\n",
      "epoch 241 train_loss 10989487.67185173 val_loss 208720.38281250\n",
      "epoch 242 train_loss 10989040.87717094 val_loss 208648.20312500\n",
      "epoch 243 train_loss 10988593.97429550 val_loss 208576.06250000\n",
      "epoch 244 train_loss 10988147.21130379 val_loss 208503.92968750\n",
      "epoch 245 train_loss 10987700.18930328 val_loss 208431.79687500\n",
      "epoch 246 train_loss 10987253.17502739 val_loss 208359.66406250\n",
      "Epoch 00247: reducing learning rate of group 0 to 1.9531e-05.\n",
      "epoch 247 train_loss 10986924.72326904 val_loss 208323.74218750\n",
      "epoch 248 train_loss 10986701.71717049 val_loss 208287.69531250\n",
      "epoch 249 train_loss 10986478.25338676 val_loss 208251.73437500\n",
      "epoch 250 train_loss 10986255.06653732 val_loss 208215.75781250\n",
      "epoch 251 train_loss 10986031.51765388 val_loss 208179.99218750\n",
      "epoch 252 train_loss 10985808.44803589 val_loss 208143.81250000\n",
      "epoch 253 train_loss 10985585.67061844 val_loss 208108.04687500\n",
      "epoch 254 train_loss 10985362.42520699 val_loss 208071.88281250\n",
      "epoch 255 train_loss 10985139.51536263 val_loss 208036.19531250\n",
      "epoch 256 train_loss 10984916.46373795 val_loss 207999.98437500\n",
      "epoch 257 train_loss 10984693.52351227 val_loss 207964.26562500\n",
      "epoch 258 train_loss 10984470.27104050 val_loss 207928.07031250\n",
      "epoch 259 train_loss 10984247.50071434 val_loss 207892.40625000\n",
      "epoch 260 train_loss 10984024.39979240 val_loss 207856.19531250\n",
      "epoch 261 train_loss 10983801.43689156 val_loss 207820.51562500\n",
      "epoch 262 train_loss 10983578.24563011 val_loss 207784.32031250\n",
      "epoch 263 train_loss 10983355.18363220 val_loss 207748.64843750\n",
      "epoch 264 train_loss 10983131.85378342 val_loss 207712.44531250\n",
      "epoch 265 train_loss 10982908.80247078 val_loss 207676.82031250\n",
      "epoch 266 train_loss 10982685.44197426 val_loss 207640.60937500\n",
      "epoch 267 train_loss 10982462.28440033 val_loss 207604.96093750\n",
      "Epoch 00268: reducing learning rate of group 0 to 9.7656e-06.\n",
      "epoch 268 train_loss 10982297.42226173 val_loss 207587.25781250\n",
      "epoch 269 train_loss 10982185.61601410 val_loss 207569.22656250\n",
      "epoch 270 train_loss 10982073.77351204 val_loss 207551.35937500\n",
      "epoch 271 train_loss 10981961.89398026 val_loss 207533.37500000\n",
      "epoch 272 train_loss 10981849.95005249 val_loss 207515.47656250\n",
      "epoch 273 train_loss 10981737.82581734 val_loss 207497.52343750\n",
      "epoch 274 train_loss 10981625.58450760 val_loss 207479.59375000\n",
      "epoch 275 train_loss 10981512.99927910 val_loss 207461.67187500\n",
      "epoch 276 train_loss 10981400.24603836 val_loss 207443.74218750\n",
      "epoch 277 train_loss 10981287.28911682 val_loss 207425.86718750\n",
      "epoch 278 train_loss 10981174.12427605 val_loss 207408.34375000\n",
      "epoch 279 train_loss 10981061.41795708 val_loss 207391.16406250\n",
      "epoch 280 train_loss 10980949.51939377 val_loss 207373.53906250\n",
      "epoch 281 train_loss 10980838.03770828 val_loss 207355.75000000\n",
      "epoch 282 train_loss 10980726.46505104 val_loss 207337.95312500\n",
      "epoch 283 train_loss 10980615.02300659 val_loss 207320.13281250\n",
      "epoch 284 train_loss 10980503.66575188 val_loss 207302.25781250\n",
      "epoch 285 train_loss 10980392.21544502 val_loss 207284.39843750\n",
      "epoch 286 train_loss 10980280.80989342 val_loss 207266.50000000\n",
      "epoch 287 train_loss 10980169.28818275 val_loss 207248.60937500\n",
      "epoch 288 train_loss 10980057.83364082 val_loss 207230.71093750\n",
      "Epoch 00289: reducing learning rate of group 0 to 4.8828e-06.\n",
      "epoch 289 train_loss 10979976.98226669 val_loss 207223.07812500\n",
      "epoch 290 train_loss 10979924.83257484 val_loss 207215.17187500\n",
      "epoch 291 train_loss 10979872.48081467 val_loss 207207.02343750\n",
      "epoch 292 train_loss 10979820.14601730 val_loss 207198.78906250\n",
      "epoch 293 train_loss 10979767.81293510 val_loss 207190.47656250\n",
      "epoch 294 train_loss 10979715.64644157 val_loss 207182.13281250\n",
      "epoch 295 train_loss 10979663.46939384 val_loss 207173.78125000\n",
      "epoch 296 train_loss 10979611.17902077 val_loss 207165.41406250\n",
      "epoch 297 train_loss 10979558.88905022 val_loss 207157.02343750\n",
      "epoch 298 train_loss 10979506.70281281 val_loss 207148.64062500\n",
      "epoch 299 train_loss 10979454.32277199 val_loss 207140.26562500\n",
      "epoch 300 train_loss 10979402.16087402 val_loss 207131.87500000\n",
      "epoch 301 train_loss 10979349.83687149 val_loss 207123.48437500\n",
      "epoch 302 train_loss 10979297.65835808 val_loss 207115.07031250\n",
      "epoch 303 train_loss 10979245.38166191 val_loss 207106.67968750\n",
      "epoch 304 train_loss 10979193.27257492 val_loss 207098.27343750\n",
      "epoch 305 train_loss 10979140.85730064 val_loss 207089.88281250\n",
      "epoch 306 train_loss 10979088.65309448 val_loss 207081.47656250\n",
      "epoch 307 train_loss 10979036.40415230 val_loss 207073.07812500\n",
      "epoch 308 train_loss 10978984.11464119 val_loss 207064.67187500\n",
      "epoch 309 train_loss 10978932.02092842 val_loss 207056.30468750\n",
      "Epoch 00310: reducing learning rate of group 0 to 2.4414e-06.\n",
      "epoch 310 train_loss 10978894.28202271 val_loss 207052.80468750\n",
      "epoch 311 train_loss 10978870.15109482 val_loss 207049.23437500\n",
      "epoch 312 train_loss 10978845.97411400 val_loss 207045.59375000\n",
      "epoch 313 train_loss 10978822.05333511 val_loss 207041.90625000\n",
      "epoch 314 train_loss 10978798.09297111 val_loss 207038.15625000\n",
      "epoch 315 train_loss 10978773.93177231 val_loss 207034.38281250\n",
      "epoch 316 train_loss 10978750.02882141 val_loss 207030.57812500\n",
      "epoch 317 train_loss 10978726.01105583 val_loss 207026.78906250\n",
      "epoch 318 train_loss 10978701.97695419 val_loss 207022.94531250\n",
      "epoch 319 train_loss 10978677.84929367 val_loss 207019.10156250\n",
      "epoch 320 train_loss 10978653.89725548 val_loss 207015.25781250\n",
      "epoch 321 train_loss 10978629.82842758 val_loss 207011.45312500\n",
      "epoch 322 train_loss 10978605.78225960 val_loss 207007.59375000\n",
      "epoch 323 train_loss 10978581.89859116 val_loss 207003.72656250\n",
      "epoch 324 train_loss 10978557.78776451 val_loss 206999.89843750\n",
      "epoch 325 train_loss 10978533.81754540 val_loss 206996.03125000\n",
      "epoch 326 train_loss 10978509.82390129 val_loss 206992.17968750\n",
      "epoch 327 train_loss 10978485.74148270 val_loss 206988.32812500\n",
      "epoch 328 train_loss 10978461.67983551 val_loss 206984.46093750\n",
      "epoch 329 train_loss 10978437.66249710 val_loss 206980.60937500\n",
      "epoch 330 train_loss 10978413.74927345 val_loss 206976.74218750\n",
      "Epoch 00331: reducing learning rate of group 0 to 1.2207e-06.\n",
      "epoch 331 train_loss 10978396.88811607 val_loss 206975.28906250\n",
      "epoch 332 train_loss 10978386.75072731 val_loss 206973.80468750\n",
      "epoch 333 train_loss 10978376.63682167 val_loss 206972.28906250\n",
      "epoch 334 train_loss 10978366.66437988 val_loss 206970.77343750\n",
      "epoch 335 train_loss 10978356.56162125 val_loss 206969.21875000\n",
      "epoch 336 train_loss 10978346.40823883 val_loss 206967.67968750\n",
      "epoch 337 train_loss 10978336.47037292 val_loss 206966.14062500\n",
      "epoch 338 train_loss 10978326.57846199 val_loss 206964.55468750\n",
      "epoch 339 train_loss 10978316.33843536 val_loss 206962.99218750\n",
      "epoch 340 train_loss 10978306.40834305 val_loss 206961.40625000\n",
      "epoch 341 train_loss 10978296.31502808 val_loss 206959.81250000\n",
      "epoch 342 train_loss 10978286.34562935 val_loss 206958.22656250\n",
      "epoch 343 train_loss 10978276.20173508 val_loss 206956.64843750\n",
      "epoch 344 train_loss 10978266.08847145 val_loss 206955.05468750\n",
      "epoch 345 train_loss 10978256.02143646 val_loss 206953.44531250\n",
      "epoch 346 train_loss 10978246.03496986 val_loss 206951.84375000\n",
      "epoch 347 train_loss 10978235.92350296 val_loss 206950.25781250\n",
      "epoch 348 train_loss 10978225.90378799 val_loss 206948.64843750\n",
      "epoch 349 train_loss 10978215.93548553 val_loss 206947.04687500\n",
      "epoch 350 train_loss 10978205.89589478 val_loss 206945.44531250\n",
      "epoch 351 train_loss 10978195.70621086 val_loss 206943.82031250\n",
      "Epoch 00352: reducing learning rate of group 0 to 6.1035e-07.\n",
      "epoch 352 train_loss 10978188.98111794 val_loss 206943.42187500\n",
      "epoch 353 train_loss 10978186.17531174 val_loss 206943.03125000\n",
      "epoch 354 train_loss 10978183.22695984 val_loss 206942.61718750\n",
      "epoch 355 train_loss 10978180.50923263 val_loss 206942.20312500\n",
      "epoch 356 train_loss 10978177.66855103 val_loss 206941.78125000\n",
      "epoch 357 train_loss 10978174.79842262 val_loss 206941.35156250\n",
      "epoch 358 train_loss 10978171.99946342 val_loss 206940.94531250\n",
      "epoch 359 train_loss 10978169.23555939 val_loss 206940.51562500\n",
      "epoch 360 train_loss 10978166.44700302 val_loss 206940.09375000\n",
      "epoch 361 train_loss 10978163.72301201 val_loss 206939.64062500\n",
      "epoch 362 train_loss 10978160.98041542 val_loss 206939.24218750\n",
      "epoch 363 train_loss 10978158.06148232 val_loss 206938.80468750\n",
      "epoch 364 train_loss 10978155.25056084 val_loss 206938.36718750\n",
      "epoch 365 train_loss 10978152.65064308 val_loss 206937.94531250\n",
      "epoch 366 train_loss 10978149.82387230 val_loss 206937.50781250\n",
      "epoch 367 train_loss 10978146.95536079 val_loss 206937.07031250\n",
      "epoch 368 train_loss 10978144.17457573 val_loss 206936.61718750\n",
      "epoch 369 train_loss 10978141.50337402 val_loss 206936.17187500\n",
      "epoch 370 train_loss 10978138.69669075 val_loss 206935.75000000\n",
      "epoch 371 train_loss 10978135.84641167 val_loss 206935.31250000\n",
      "epoch 372 train_loss 10978133.13447601 val_loss 206934.85937500\n",
      "Epoch 00373: reducing learning rate of group 0 to 3.0518e-07.\n",
      "epoch 373 train_loss 10978130.44718742 val_loss 206934.76562500\n",
      "epoch 374 train_loss 10978130.14537231 val_loss 206934.68750000\n",
      "epoch 375 train_loss 10978129.80584724 val_loss 206934.60156250\n",
      "epoch 376 train_loss 10978129.73023445 val_loss 206934.53125000\n",
      "epoch 377 train_loss 10978127.98514107 val_loss 206934.43750000\n",
      "epoch 378 train_loss 10978127.66520828 val_loss 206934.33593750\n",
      "epoch 379 train_loss 10978127.06399689 val_loss 206934.26562500\n",
      "epoch 380 train_loss 10978126.98448013 val_loss 206934.16406250\n",
      "epoch 381 train_loss 10978126.39551849 val_loss 206934.10156250\n",
      "epoch 382 train_loss 10978124.91785400 val_loss 206934.00000000\n",
      "epoch 383 train_loss 10978124.32532761 val_loss 206933.91406250\n",
      "epoch 384 train_loss 10978124.23534439 val_loss 206933.81250000\n",
      "epoch 385 train_loss 10978124.10932487 val_loss 206933.73437500\n",
      "epoch 386 train_loss 10978122.14332199 val_loss 206933.62500000\n",
      "epoch 387 train_loss 10978121.96872368 val_loss 206933.53906250\n",
      "epoch 388 train_loss 10978121.46045097 val_loss 206933.46875000\n",
      "epoch 389 train_loss 10978121.44027290 val_loss 206933.34375000\n",
      "epoch 390 train_loss 10978120.58187881 val_loss 206933.25781250\n",
      "epoch 391 train_loss 10978119.37074287 val_loss 206933.17968750\n",
      "epoch 392 train_loss 10978118.74544342 val_loss 206933.07812500\n",
      "epoch 393 train_loss 10978118.64700607 val_loss 206932.97656250\n",
      "Epoch 00394: reducing learning rate of group 0 to 1.5259e-07.\n",
      "epoch 394 train_loss 10978118.21269882 val_loss 206932.96093750\n",
      "epoch 395 train_loss 10978118.02883858 val_loss 206932.96093750\n",
      "epoch 396 train_loss 10978117.97592667 val_loss 206932.94531250\n",
      "epoch 397 train_loss 10978117.96695534 val_loss 206932.92968750\n",
      "epoch 398 train_loss 10978116.58102463 val_loss 206932.92187500\n",
      "epoch 399 train_loss 10978116.57722008 val_loss 206932.90625000\n",
      "epoch 400 train_loss 10978116.57216454 val_loss 206932.87500000\n",
      "epoch 401 train_loss 10978116.56867012 val_loss 206932.87500000\n",
      "epoch 402 train_loss 10978116.50041183 val_loss 206932.84375000\n",
      "epoch 403 train_loss 10978116.49320862 val_loss 206932.84375000\n",
      "epoch 404 train_loss 10978115.97675804 val_loss 206932.82031250\n",
      "epoch 405 train_loss 10978115.97288658 val_loss 206932.78125000\n",
      "epoch 406 train_loss 10978115.90380211 val_loss 206932.78125000\n",
      "epoch 407 train_loss 10978115.89244850 val_loss 206932.76562500\n",
      "epoch 408 train_loss 10978115.88733406 val_loss 206932.75000000\n",
      "epoch 409 train_loss 10978115.88265221 val_loss 206932.71875000\n",
      "epoch 410 train_loss 10978115.87670326 val_loss 206932.71093750\n",
      "epoch 411 train_loss 10978115.87318581 val_loss 206932.71093750\n",
      "epoch 412 train_loss 10978115.81266060 val_loss 206932.69531250\n",
      "epoch 413 train_loss 10978115.80391716 val_loss 206932.66406250\n",
      "epoch 414 train_loss 10978115.79801384 val_loss 206932.66406250\n",
      "Epoch 00415: reducing learning rate of group 0 to 7.6294e-08.\n",
      "epoch 415 train_loss 10978115.27458771 val_loss 206932.66406250\n",
      "epoch 416 train_loss 10978115.27338852 val_loss 206932.66406250\n",
      "epoch 417 train_loss 10978115.27286430 val_loss 206932.66406250\n",
      "epoch 418 train_loss 10978115.27236969 val_loss 206932.66406250\n",
      "epoch 419 train_loss 10978115.27201744 val_loss 206932.66406250\n",
      "epoch 420 train_loss 10978115.27122787 val_loss 206932.66406250\n",
      "epoch 421 train_loss 10978115.27036209 val_loss 206932.66406250\n",
      "epoch 422 train_loss 10978115.26996475 val_loss 206932.66406250\n",
      "epoch 423 train_loss 10978115.26954567 val_loss 206932.66406250\n",
      "epoch 424 train_loss 10978115.26879417 val_loss 206932.66406250\n",
      "epoch 425 train_loss 10978115.26788139 val_loss 206932.66406250\n",
      "epoch 426 train_loss 10978115.26744202 val_loss 206932.66406250\n",
      "epoch 427 train_loss 10978115.26717354 val_loss 206932.66406250\n",
      "epoch 428 train_loss 10978115.26615387 val_loss 206932.66406250\n",
      "epoch 429 train_loss 10978115.21242813 val_loss 206932.66406250\n",
      "epoch 430 train_loss 10978115.21217621 val_loss 206932.66406250\n",
      "epoch 431 train_loss 10978115.21184517 val_loss 206932.66406250\n",
      "epoch 432 train_loss 10978115.20244286 val_loss 206932.66406250\n",
      "epoch 433 train_loss 10978115.19920341 val_loss 206932.67968750\n",
      "epoch 434 train_loss 10978115.19878082 val_loss 206932.67968750\n",
      "epoch 435 train_loss 10978115.19844864 val_loss 206932.67968750\n",
      "Epoch 00436: reducing learning rate of group 0 to 3.8147e-08.\n",
      "epoch 436 train_loss 10978115.19077507 val_loss 206932.69531250\n",
      "epoch 437 train_loss 10978115.19066002 val_loss 206932.69531250\n",
      "epoch 438 train_loss 10978115.19049477 val_loss 206932.69531250\n",
      "epoch 439 train_loss 10978115.19020576 val_loss 206932.69531250\n",
      "epoch 440 train_loss 10978115.18997787 val_loss 206932.69531250\n",
      "epoch 441 train_loss 10978115.18983116 val_loss 206932.69531250\n",
      "epoch 442 train_loss 10978115.18956123 val_loss 206932.69531250\n",
      "epoch 443 train_loss 10978115.18937706 val_loss 206932.69531250\n",
      "epoch 444 train_loss 10978115.18918274 val_loss 206932.69531250\n",
      "epoch 445 train_loss 10978115.18926155 val_loss 206932.69531250\n",
      "epoch 446 train_loss 10978115.18896538 val_loss 206932.69531250\n",
      "epoch 447 train_loss 10978115.18888954 val_loss 206932.71093750\n",
      "epoch 448 train_loss 10978115.18861908 val_loss 206932.71093750\n",
      "epoch 449 train_loss 10978115.18836266 val_loss 206932.71093750\n",
      "epoch 450 train_loss 10978115.18826019 val_loss 206932.71093750\n",
      "epoch 451 train_loss 10978115.18810196 val_loss 206932.71093750\n",
      "epoch 452 train_loss 10978115.18800003 val_loss 206932.71093750\n",
      "epoch 453 train_loss 10978115.18777580 val_loss 206932.71093750\n",
      "epoch 454 train_loss 10978115.18765320 val_loss 206932.71093750\n",
      "epoch 455 train_loss 10978115.18738502 val_loss 206932.71093750\n",
      "epoch 456 train_loss 10978115.18730308 val_loss 206932.71093750\n",
      "Epoch 00457: reducing learning rate of group 0 to 1.9073e-08.\n",
      "epoch 457 train_loss 10978115.18351334 val_loss 206932.71093750\n",
      "epoch 458 train_loss 10978115.18339111 val_loss 206932.71093750\n",
      "epoch 459 train_loss 10978115.18325401 val_loss 206932.71093750\n",
      "epoch 460 train_loss 10978115.18313026 val_loss 206932.71093750\n",
      "epoch 461 train_loss 10978115.18302353 val_loss 206932.71093750\n",
      "epoch 462 train_loss 10978115.18317986 val_loss 206932.71093750\n",
      "epoch 463 train_loss 10978115.18301178 val_loss 206932.71093750\n",
      "epoch 464 train_loss 10978115.18287621 val_loss 206932.72656250\n",
      "epoch 465 train_loss 10978115.18282242 val_loss 206932.72656250\n",
      "epoch 466 train_loss 10978115.18265968 val_loss 206932.72656250\n",
      "epoch 467 train_loss 10978115.18264305 val_loss 206932.72656250\n",
      "epoch 468 train_loss 10978115.18248550 val_loss 206932.72656250\n",
      "epoch 469 train_loss 10978115.18242012 val_loss 206932.72656250\n",
      "epoch 470 train_loss 10978115.18239998 val_loss 206932.72656250\n",
      "epoch 471 train_loss 10978115.18224739 val_loss 206932.72656250\n",
      "epoch 472 train_loss 10978115.18214523 val_loss 206932.72656250\n",
      "epoch 473 train_loss 10978115.18199760 val_loss 206932.72656250\n",
      "epoch 474 train_loss 10978115.18208405 val_loss 206932.72656250\n",
      "epoch 475 train_loss 10978115.18186623 val_loss 206932.72656250\n",
      "epoch 476 train_loss 10978115.18183395 val_loss 206932.72656250\n",
      "epoch 477 train_loss 10978115.18182037 val_loss 206932.72656250\n",
      "epoch 478 train_loss 10978115.18163490 val_loss 206932.72656250\n",
      "epoch 479 train_loss 10978115.18154984 val_loss 206932.72656250\n",
      "epoch 480 train_loss 10978115.18139633 val_loss 206932.72656250\n",
      "epoch 481 train_loss 10978115.18140205 val_loss 206932.72656250\n",
      "epoch 482 train_loss 10978115.18128326 val_loss 206932.72656250\n",
      "epoch 483 train_loss 10978115.18117485 val_loss 206932.74218750\n",
      "epoch 484 train_loss 10978115.18102936 val_loss 206932.74218750\n",
      "epoch 485 train_loss 10978115.18104584 val_loss 206932.74218750\n",
      "epoch 486 train_loss 10978115.18090568 val_loss 206932.75000000\n",
      "epoch 487 train_loss 10978115.18073708 val_loss 206932.75000000\n",
      "epoch 488 train_loss 10978115.18062454 val_loss 206932.75000000\n",
      "epoch 489 train_loss 10978115.18048241 val_loss 206932.75000000\n",
      "epoch 490 train_loss 10978115.18045250 val_loss 206932.75000000\n",
      "epoch 491 train_loss 10978115.18038368 val_loss 206932.75000000\n",
      "epoch 492 train_loss 10978115.18021156 val_loss 206932.75000000\n",
      "epoch 493 train_loss 10978115.18014160 val_loss 206932.75000000\n",
      "epoch 494 train_loss 10978115.18005234 val_loss 206932.75000000\n",
      "epoch 495 train_loss 10978115.17989197 val_loss 206932.75000000\n",
      "epoch 496 train_loss 10978115.17992203 val_loss 206932.75000000\n",
      "epoch 497 train_loss 10978115.17975136 val_loss 206932.75000000\n",
      "epoch 498 train_loss 10978115.17971260 val_loss 206932.75000000\n",
      "epoch 499 train_loss 10978115.17959946 val_loss 206932.75000000\n",
      "epoch 500 train_loss 10978115.17945107 val_loss 206932.75000000\n",
      "epoch 501 train_loss 10978115.17928802 val_loss 206932.75000000\n",
      "epoch 502 train_loss 10978115.17917190 val_loss 206932.75000000\n",
      "epoch 503 train_loss 10978115.17909599 val_loss 206932.75000000\n",
      "epoch 504 train_loss 10978115.17901428 val_loss 206932.75000000\n",
      "epoch 505 train_loss 10978115.17892952 val_loss 206932.75000000\n",
      "epoch 506 train_loss 10978115.17879585 val_loss 206932.75000000\n",
      "epoch 507 train_loss 10978115.17878738 val_loss 206932.75000000\n",
      "epoch 508 train_loss 10978115.17883049 val_loss 206932.75000000\n",
      "epoch 509 train_loss 10978115.17893990 val_loss 206932.75000000\n",
      "epoch 510 train_loss 10978115.17880119 val_loss 206932.75000000\n",
      "epoch 511 train_loss 10978115.17865265 val_loss 206932.75000000\n",
      "epoch 512 train_loss 10978115.17857582 val_loss 206932.75000000\n",
      "epoch 513 train_loss 10978115.17854942 val_loss 206932.76562500\n",
      "epoch 514 train_loss 10978115.17844734 val_loss 206932.76562500\n",
      "epoch 515 train_loss 10978115.17833382 val_loss 206932.76562500\n",
      "epoch 516 train_loss 10978115.17821899 val_loss 206932.76562500\n",
      "epoch 517 train_loss 10978115.17808456 val_loss 206932.76562500\n",
      "epoch 518 train_loss 10978115.17796669 val_loss 206932.76562500\n",
      "epoch 519 train_loss 10978115.17790421 val_loss 206932.76562500\n",
      "epoch 520 train_loss 10978115.17774147 val_loss 206932.76562500\n",
      "epoch 521 train_loss 10978115.17760681 val_loss 206932.76562500\n",
      "epoch 522 train_loss 10978115.17762489 val_loss 206932.76562500\n",
      "epoch 523 train_loss 10978115.17753792 val_loss 206932.78125000\n",
      "epoch 524 train_loss 10978115.17741142 val_loss 206932.78125000\n",
      "epoch 525 train_loss 10978115.17728310 val_loss 206932.78125000\n",
      "epoch 526 train_loss 10978115.17721588 val_loss 206932.78125000\n",
      "epoch 527 train_loss 10978115.17704170 val_loss 206932.78125000\n",
      "epoch 528 train_loss 10978115.17690155 val_loss 206932.78125000\n",
      "epoch 529 train_loss 10978115.17682793 val_loss 206932.78125000\n",
      "epoch 530 train_loss 10978115.17664719 val_loss 206932.78125000\n",
      "epoch 531 train_loss 10978115.17679039 val_loss 206932.78125000\n",
      "epoch 532 train_loss 10978115.17663460 val_loss 206932.78125000\n",
      "epoch 533 train_loss 10978115.17649872 val_loss 206932.78125000\n",
      "epoch 534 train_loss 10978115.17640518 val_loss 206932.78125000\n",
      "epoch 535 train_loss 10978115.17632500 val_loss 206932.78125000\n",
      "epoch 536 train_loss 10978115.17614967 val_loss 206932.78125000\n",
      "epoch 537 train_loss 10978115.17607803 val_loss 206932.78125000\n",
      "epoch 538 train_loss 10978115.17602074 val_loss 206932.78125000\n",
      "epoch 539 train_loss 10978115.17606354 val_loss 206932.78125000\n",
      "epoch 540 train_loss 10978115.17591026 val_loss 206932.78125000\n",
      "epoch 541 train_loss 10978115.17582199 val_loss 206932.78125000\n",
      "epoch 542 train_loss 10978115.17570824 val_loss 206932.78125000\n",
      "epoch 543 train_loss 10978115.17555496 val_loss 206932.78125000\n",
      "epoch 544 train_loss 10978115.17554146 val_loss 206932.78125000\n",
      "epoch 545 train_loss 10978115.17557564 val_loss 206932.78125000\n",
      "epoch 546 train_loss 10978115.17564308 val_loss 206932.79687500\n",
      "epoch 547 train_loss 10978115.17557281 val_loss 206932.79687500\n",
      "epoch 548 train_loss 10978115.17562218 val_loss 206932.79687500\n",
      "epoch 549 train_loss 10978115.17550217 val_loss 206932.79687500\n",
      "epoch 550 train_loss 10978115.17539421 val_loss 206932.79687500\n",
      "epoch 551 train_loss 10978115.17529007 val_loss 206932.79687500\n",
      "epoch 552 train_loss 10978115.17521362 val_loss 206932.79687500\n",
      "epoch 553 train_loss 10978115.17515022 val_loss 206932.79687500\n",
      "epoch 554 train_loss 10978115.17505218 val_loss 206932.79687500\n",
      "epoch 555 train_loss 10978115.17493980 val_loss 206932.79687500\n",
      "epoch 556 train_loss 10978115.17488472 val_loss 206932.79687500\n",
      "epoch 557 train_loss 10978115.17474457 val_loss 206932.79687500\n",
      "epoch 558 train_loss 10978115.17462166 val_loss 206932.79687500\n",
      "epoch 559 train_loss 10978115.17453445 val_loss 206932.79687500\n",
      "epoch 560 train_loss 10978115.17439323 val_loss 206932.79687500\n",
      "epoch 561 train_loss 10978115.17442375 val_loss 206932.79687500\n",
      "epoch 562 train_loss 10978115.17430450 val_loss 206932.79687500\n",
      "epoch 563 train_loss 10978115.17414062 val_loss 206932.79687500\n",
      "epoch 564 train_loss 10978115.17401764 val_loss 206932.79687500\n",
      "epoch 565 train_loss 10978115.17400879 val_loss 206932.79687500\n",
      "epoch 566 train_loss 10978115.17393906 val_loss 206932.79687500\n",
      "epoch 567 train_loss 10978115.17379036 val_loss 206932.79687500\n",
      "epoch 568 train_loss 10978115.17363953 val_loss 206932.79687500\n",
      "epoch 569 train_loss 10978115.17358307 val_loss 206932.79687500\n",
      "epoch 570 train_loss 10978115.17343887 val_loss 206932.79687500\n",
      "epoch 571 train_loss 10978115.17331001 val_loss 206932.79687500\n",
      "epoch 572 train_loss 10978115.17333122 val_loss 206932.79687500\n",
      "epoch 573 train_loss 10978115.17317207 val_loss 206932.79687500\n",
      "epoch 574 train_loss 10978115.17305443 val_loss 206932.81250000\n",
      "epoch 575 train_loss 10978115.17297440 val_loss 206932.81250000\n",
      "epoch 576 train_loss 10978115.17285225 val_loss 206932.81250000\n",
      "epoch 577 train_loss 10978115.17269455 val_loss 206932.81250000\n",
      "epoch 578 train_loss 10978115.17259224 val_loss 206932.81250000\n",
      "epoch 579 train_loss 10978115.17279655 val_loss 206932.81250000\n",
      "epoch 580 train_loss 10978115.17262802 val_loss 206932.81250000\n",
      "epoch 581 train_loss 10978115.17255051 val_loss 206932.81250000\n",
      "epoch 582 train_loss 10978115.17255219 val_loss 206932.81250000\n",
      "epoch 583 train_loss 10978115.17256393 val_loss 206932.81250000\n",
      "epoch 584 train_loss 10978115.17242119 val_loss 206932.81250000\n",
      "epoch 585 train_loss 10978115.17236008 val_loss 206932.81250000\n",
      "epoch 586 train_loss 10978115.17229042 val_loss 206932.81250000\n",
      "epoch 587 train_loss 10978115.17215279 val_loss 206932.81250000\n",
      "epoch 588 train_loss 10978115.17217575 val_loss 206932.81250000\n",
      "epoch 589 train_loss 10978115.17201706 val_loss 206932.81250000\n",
      "epoch 590 train_loss 10978115.17197571 val_loss 206932.81250000\n",
      "epoch 591 train_loss 10978115.17189186 val_loss 206932.81250000\n",
      "epoch 592 train_loss 10978115.17181656 val_loss 206932.81250000\n",
      "epoch 593 train_loss 10978115.17170456 val_loss 206932.82812500\n",
      "epoch 594 train_loss 10978115.17159912 val_loss 206932.82812500\n",
      "epoch 595 train_loss 10978115.17172035 val_loss 206932.82812500\n",
      "epoch 596 train_loss 10978115.17159470 val_loss 206932.82812500\n",
      "epoch 597 train_loss 10978115.17146057 val_loss 206932.82812500\n",
      "epoch 598 train_loss 10978115.17139358 val_loss 206932.82812500\n",
      "epoch 599 train_loss 10978115.17129219 val_loss 206932.82812500\n",
      "epoch 600 train_loss 10978115.17119484 val_loss 206932.82812500\n",
      "epoch 601 train_loss 10978115.17111702 val_loss 206932.82812500\n",
      "epoch 602 train_loss 10978115.17096603 val_loss 206932.82812500\n",
      "epoch 603 train_loss 10978115.17090324 val_loss 206932.82812500\n",
      "epoch 604 train_loss 10978115.17080452 val_loss 206932.82812500\n",
      "epoch 605 train_loss 10978115.17066528 val_loss 206932.82812500\n",
      "epoch 606 train_loss 10978115.17050148 val_loss 206932.82812500\n",
      "epoch 607 train_loss 10978115.17048676 val_loss 206932.82812500\n",
      "epoch 608 train_loss 10978115.17040627 val_loss 206932.82812500\n",
      "epoch 609 train_loss 10978115.17024284 val_loss 206932.85156250\n",
      "epoch 610 train_loss 10978115.17020409 val_loss 206932.85156250\n",
      "epoch 611 train_loss 10978115.17013573 val_loss 206932.85156250\n",
      "epoch 612 train_loss 10978115.17003616 val_loss 206932.85156250\n",
      "epoch 613 train_loss 10978115.16995834 val_loss 206932.85156250\n",
      "epoch 614 train_loss 10978115.16984093 val_loss 206932.85156250\n",
      "epoch 615 train_loss 10978115.16970238 val_loss 206932.85156250\n",
      "epoch 616 train_loss 10978115.16956276 val_loss 206932.85156250\n",
      "epoch 617 train_loss 10978115.16945221 val_loss 206932.85156250\n",
      "epoch 618 train_loss 10978115.16934616 val_loss 206932.85156250\n",
      "epoch 619 train_loss 10978115.16918922 val_loss 206932.85156250\n",
      "epoch 620 train_loss 10978115.16909447 val_loss 206932.85156250\n",
      "epoch 621 train_loss 10978115.16904762 val_loss 206932.86718750\n",
      "epoch 622 train_loss 10978115.16893013 val_loss 206932.86718750\n",
      "epoch 623 train_loss 10978115.16902855 val_loss 206932.86718750\n",
      "epoch 624 train_loss 10978115.16896629 val_loss 206932.86718750\n",
      "epoch 625 train_loss 10978115.16880463 val_loss 206932.86718750\n",
      "epoch 626 train_loss 10978115.16872070 val_loss 206932.86718750\n",
      "epoch 627 train_loss 10978115.16865089 val_loss 206932.86718750\n",
      "epoch 628 train_loss 10978115.16857338 val_loss 206932.86718750\n",
      "epoch 629 train_loss 10978115.16852867 val_loss 206932.86718750\n",
      "epoch 630 train_loss 10978115.16843979 val_loss 206932.86718750\n",
      "epoch 631 train_loss 10978115.16836311 val_loss 206932.86718750\n",
      "epoch 632 train_loss 10978115.16825569 val_loss 206932.86718750\n",
      "epoch 633 train_loss 10978115.16820892 val_loss 206932.86718750\n",
      "epoch 634 train_loss 10978115.16805450 val_loss 206932.86718750\n",
      "epoch 635 train_loss 10978115.16805939 val_loss 206932.86718750\n",
      "epoch 636 train_loss 10978115.16798615 val_loss 206932.86718750\n",
      "epoch 637 train_loss 10978115.16791832 val_loss 206932.86718750\n",
      "epoch 638 train_loss 10978115.16775993 val_loss 206932.86718750\n",
      "epoch 639 train_loss 10978115.16764992 val_loss 206932.86718750\n",
      "epoch 640 train_loss 10978115.16758301 val_loss 206932.86718750\n",
      "epoch 641 train_loss 10978115.16742210 val_loss 206932.86718750\n",
      "epoch 642 train_loss 10978115.16733536 val_loss 206932.86718750\n",
      "epoch 643 train_loss 10978115.16735313 val_loss 206932.86718750\n",
      "epoch 644 train_loss 10978115.16723923 val_loss 206932.86718750\n",
      "epoch 645 train_loss 10978115.16721367 val_loss 206932.86718750\n",
      "epoch 646 train_loss 10978115.16708977 val_loss 206932.86718750\n",
      "epoch 647 train_loss 10978115.16704063 val_loss 206932.86718750\n",
      "epoch 648 train_loss 10978115.16692306 val_loss 206932.86718750\n",
      "epoch 649 train_loss 10978115.16674911 val_loss 206932.86718750\n",
      "epoch 650 train_loss 10978115.16673218 val_loss 206932.86718750\n",
      "epoch 651 train_loss 10978115.16659798 val_loss 206932.86718750\n",
      "epoch 652 train_loss 10978115.16654869 val_loss 206932.86718750\n",
      "epoch 653 train_loss 10978115.16640358 val_loss 206932.86718750\n",
      "epoch 654 train_loss 10978115.16629143 val_loss 206932.86718750\n",
      "epoch 655 train_loss 10978115.16631027 val_loss 206932.86718750\n",
      "epoch 656 train_loss 10978115.16623260 val_loss 206932.86718750\n",
      "epoch 657 train_loss 10978115.16614220 val_loss 206932.86718750\n",
      "epoch 658 train_loss 10978115.16602531 val_loss 206932.86718750\n",
      "epoch 659 train_loss 10978115.16588829 val_loss 206932.86718750\n",
      "epoch 660 train_loss 10978115.16580406 val_loss 206932.86718750\n",
      "epoch 661 train_loss 10978115.16584808 val_loss 206932.86718750\n",
      "epoch 662 train_loss 10978115.16569649 val_loss 206932.86718750\n",
      "epoch 663 train_loss 10978115.16572662 val_loss 206932.86718750\n",
      "epoch 664 train_loss 10978115.16564026 val_loss 206932.86718750\n",
      "epoch 665 train_loss 10978115.16549553 val_loss 206932.86718750\n",
      "epoch 666 train_loss 10978115.16551720 val_loss 206932.86718750\n",
      "epoch 667 train_loss 10978115.16535324 val_loss 206932.86718750\n",
      "epoch 668 train_loss 10978115.16599861 val_loss 206932.86718750\n",
      "epoch 669 train_loss 10978115.16598312 val_loss 206932.86718750\n",
      "epoch 670 train_loss 10978115.16583885 val_loss 206932.86718750\n",
      "epoch 671 train_loss 10978115.16570084 val_loss 206932.86718750\n",
      "epoch 672 train_loss 10978115.16563301 val_loss 206932.86718750\n",
      "epoch 673 train_loss 10978115.16546982 val_loss 206932.86718750\n",
      "epoch 674 train_loss 10978115.16543594 val_loss 206932.86718750\n",
      "epoch 675 train_loss 10978115.16540024 val_loss 206932.86718750\n",
      "epoch 676 train_loss 10978115.16527550 val_loss 206932.86718750\n",
      "epoch 677 train_loss 10978115.16515045 val_loss 206932.86718750\n",
      "epoch 678 train_loss 10978115.16505135 val_loss 206932.86718750\n",
      "epoch 679 train_loss 10978115.16494850 val_loss 206932.86718750\n",
      "epoch 680 train_loss 10978115.16485588 val_loss 206932.86718750\n",
      "epoch 681 train_loss 10978115.16491333 val_loss 206932.86718750\n",
      "epoch 682 train_loss 10978115.16479881 val_loss 206932.86718750\n",
      "epoch 683 train_loss 10978115.16463089 val_loss 206932.86718750\n",
      "epoch 684 train_loss 10978115.16454178 val_loss 206932.87500000\n",
      "epoch 685 train_loss 10978115.16448708 val_loss 206932.87500000\n",
      "epoch 686 train_loss 10978115.16439499 val_loss 206932.87500000\n",
      "epoch 687 train_loss 10978115.16424324 val_loss 206932.87500000\n",
      "epoch 688 train_loss 10978115.16414688 val_loss 206932.88281250\n",
      "epoch 689 train_loss 10978115.16402183 val_loss 206932.88281250\n",
      "epoch 690 train_loss 10978115.16398155 val_loss 206932.88281250\n",
      "epoch 691 train_loss 10978115.16404045 val_loss 206932.88281250\n",
      "epoch 692 train_loss 10978115.16392151 val_loss 206932.88281250\n",
      "epoch 693 train_loss 10978115.16395981 val_loss 206932.88281250\n",
      "epoch 694 train_loss 10978115.16382004 val_loss 206932.88281250\n",
      "epoch 695 train_loss 10978115.16379532 val_loss 206932.88281250\n",
      "epoch 696 train_loss 10978115.16363609 val_loss 206932.88281250\n",
      "epoch 697 train_loss 10978115.16355064 val_loss 206932.88281250\n",
      "epoch 698 train_loss 10978115.16352310 val_loss 206932.88281250\n",
      "epoch 699 train_loss 10978115.16338196 val_loss 206932.88281250\n",
      "epoch 700 train_loss 10978115.16328674 val_loss 206932.88281250\n",
      "epoch 701 train_loss 10978115.16318764 val_loss 206932.88281250\n",
      "epoch 702 train_loss 10978115.16308700 val_loss 206932.88281250\n",
      "epoch 703 train_loss 10978115.16319901 val_loss 206932.88281250\n",
      "epoch 704 train_loss 10978115.16307022 val_loss 206932.88281250\n",
      "epoch 705 train_loss 10978115.16300751 val_loss 206932.88281250\n",
      "epoch 706 train_loss 10978115.16293221 val_loss 206932.88281250\n",
      "epoch 707 train_loss 10978115.16301819 val_loss 206932.88281250\n",
      "epoch 708 train_loss 10978115.16292191 val_loss 206932.88281250\n",
      "epoch 709 train_loss 10978115.16286491 val_loss 206932.88281250\n",
      "epoch 710 train_loss 10978115.16275093 val_loss 206932.88281250\n",
      "epoch 711 train_loss 10978115.16262817 val_loss 206932.88281250\n",
      "epoch 712 train_loss 10978115.16251076 val_loss 206932.88281250\n",
      "epoch 713 train_loss 10978115.16240448 val_loss 206932.88281250\n",
      "epoch 714 train_loss 10978115.16227974 val_loss 206932.88281250\n",
      "epoch 715 train_loss 10978115.16219696 val_loss 206932.88281250\n",
      "epoch 716 train_loss 10978115.16206177 val_loss 206932.89843750\n",
      "epoch 717 train_loss 10978115.16195534 val_loss 206932.89843750\n",
      "epoch 718 train_loss 10978115.16191429 val_loss 206932.89843750\n",
      "epoch 719 train_loss 10978115.16179596 val_loss 206932.89843750\n",
      "epoch 720 train_loss 10978115.16173958 val_loss 206932.89843750\n",
      "epoch 721 train_loss 10978115.16164711 val_loss 206932.89843750\n",
      "epoch 722 train_loss 10978115.16155960 val_loss 206932.89843750\n",
      "epoch 723 train_loss 10978115.16148613 val_loss 206932.89843750\n",
      "epoch 724 train_loss 10978115.16135445 val_loss 206932.89843750\n",
      "epoch 725 train_loss 10978115.16133141 val_loss 206932.89843750\n",
      "epoch 726 train_loss 10978115.16113472 val_loss 206932.89843750\n",
      "epoch 727 train_loss 10978115.16105682 val_loss 206932.89843750\n",
      "epoch 728 train_loss 10978115.16089409 val_loss 206932.89843750\n",
      "epoch 729 train_loss 10978115.16079559 val_loss 206932.89843750\n",
      "epoch 730 train_loss 10978115.16066574 val_loss 206932.89843750\n",
      "epoch 731 train_loss 10978115.16049080 val_loss 206932.89843750\n",
      "epoch 732 train_loss 10978115.16042793 val_loss 206932.89843750\n",
      "epoch 733 train_loss 10978115.16036583 val_loss 206932.89843750\n",
      "epoch 734 train_loss 10978115.16036263 val_loss 206932.89843750\n",
      "epoch 735 train_loss 10978115.16020042 val_loss 206932.89843750\n",
      "epoch 736 train_loss 10978115.16018112 val_loss 206932.89843750\n",
      "epoch 737 train_loss 10978115.16003036 val_loss 206932.91406250\n",
      "epoch 738 train_loss 10978115.15991310 val_loss 206932.91406250\n",
      "epoch 739 train_loss 10978115.15987656 val_loss 206932.91406250\n",
      "epoch 740 train_loss 10978115.15976891 val_loss 206932.91406250\n",
      "epoch 741 train_loss 10978115.15969910 val_loss 206932.91406250\n",
      "epoch 742 train_loss 10978115.15958939 val_loss 206932.91406250\n",
      "epoch 743 train_loss 10978115.15947662 val_loss 206932.91406250\n",
      "epoch 744 train_loss 10978115.15935257 val_loss 206932.91406250\n",
      "epoch 745 train_loss 10978115.15931389 val_loss 206932.91406250\n",
      "epoch 746 train_loss 10978115.15924454 val_loss 206932.91406250\n",
      "epoch 747 train_loss 10978115.15921715 val_loss 206932.91406250\n",
      "epoch 748 train_loss 10978115.15908493 val_loss 206932.91406250\n",
      "epoch 749 train_loss 10978115.15902809 val_loss 206932.91406250\n",
      "epoch 750 train_loss 10978115.15896683 val_loss 206932.91406250\n",
      "epoch 751 train_loss 10978115.15884239 val_loss 206932.91406250\n",
      "epoch 752 train_loss 10978115.15870995 val_loss 206932.91406250\n",
      "epoch 753 train_loss 10978115.15859962 val_loss 206932.91406250\n",
      "epoch 754 train_loss 10978115.15849190 val_loss 206932.91406250\n",
      "epoch 755 train_loss 10978115.15840172 val_loss 206932.91406250\n",
      "epoch 756 train_loss 10978115.15828163 val_loss 206932.91406250\n",
      "epoch 757 train_loss 10978115.15817749 val_loss 206932.91406250\n",
      "epoch 758 train_loss 10978115.15803368 val_loss 206932.91406250\n",
      "epoch 759 train_loss 10978115.15807495 val_loss 206932.91406250\n",
      "epoch 760 train_loss 10978115.15804375 val_loss 206932.91406250\n",
      "epoch 761 train_loss 10978115.15796089 val_loss 206932.91406250\n",
      "epoch 762 train_loss 10978115.15786507 val_loss 206932.91406250\n",
      "epoch 763 train_loss 10978115.15783897 val_loss 206932.91406250\n",
      "epoch 764 train_loss 10978115.15779152 val_loss 206932.91406250\n",
      "epoch 765 train_loss 10978115.15763985 val_loss 206932.91406250\n",
      "epoch 766 train_loss 10978115.15757851 val_loss 206932.91406250\n",
      "epoch 767 train_loss 10978115.15742035 val_loss 206932.91406250\n",
      "epoch 768 train_loss 10978115.15738426 val_loss 206932.91406250\n",
      "epoch 769 train_loss 10978115.15726486 val_loss 206932.91406250\n",
      "epoch 770 train_loss 10978115.15713753 val_loss 206932.91406250\n",
      "epoch 771 train_loss 10978115.15699242 val_loss 206932.91406250\n",
      "epoch 772 train_loss 10978115.15688202 val_loss 206932.91406250\n",
      "epoch 773 train_loss 10978115.15700607 val_loss 206932.91406250\n",
      "epoch 774 train_loss 10978115.15707306 val_loss 206932.91406250\n",
      "epoch 775 train_loss 10978115.15696754 val_loss 206932.91406250\n",
      "epoch 776 train_loss 10978115.15686295 val_loss 206932.91406250\n",
      "epoch 777 train_loss 10978115.15677658 val_loss 206932.91406250\n",
      "epoch 778 train_loss 10978115.15668366 val_loss 206932.91406250\n",
      "epoch 779 train_loss 10978115.15675186 val_loss 206932.91406250\n",
      "epoch 780 train_loss 10978115.15662949 val_loss 206932.91406250\n",
      "epoch 781 train_loss 10978115.15651993 val_loss 206932.91406250\n",
      "epoch 782 train_loss 10978115.15639305 val_loss 206932.91406250\n",
      "epoch 783 train_loss 10978115.15626404 val_loss 206932.92968750\n",
      "epoch 784 train_loss 10978115.15616440 val_loss 206932.92968750\n",
      "epoch 785 train_loss 10978115.15605721 val_loss 206932.92968750\n",
      "epoch 786 train_loss 10978115.15600922 val_loss 206932.92968750\n",
      "epoch 787 train_loss 10978115.15588104 val_loss 206932.92968750\n",
      "epoch 788 train_loss 10978115.15574547 val_loss 206932.92968750\n",
      "epoch 789 train_loss 10978115.15561913 val_loss 206932.92968750\n",
      "epoch 790 train_loss 10978115.15559517 val_loss 206932.92968750\n",
      "epoch 791 train_loss 10978115.15547585 val_loss 206932.92968750\n",
      "epoch 792 train_loss 10978115.15543953 val_loss 206932.92968750\n",
      "epoch 793 train_loss 10978115.15529556 val_loss 206932.92968750\n",
      "epoch 794 train_loss 10978115.15522690 val_loss 206932.92968750\n",
      "epoch 795 train_loss 10978115.15513268 val_loss 206932.92968750\n",
      "epoch 796 train_loss 10978115.15505142 val_loss 206932.92968750\n",
      "epoch 797 train_loss 10978115.15492363 val_loss 206932.92968750\n",
      "epoch 798 train_loss 10978115.15487526 val_loss 206932.92968750\n",
      "epoch 799 train_loss 10978115.15481049 val_loss 206932.92968750\n",
      "epoch 800 train_loss 10978115.15473030 val_loss 206932.92968750\n",
      "epoch 801 train_loss 10978115.15458015 val_loss 206932.92968750\n",
      "epoch 802 train_loss 10978115.15448097 val_loss 206932.92968750\n",
      "epoch 803 train_loss 10978115.15438484 val_loss 206932.92968750\n",
      "epoch 804 train_loss 10978115.15426117 val_loss 206932.92968750\n",
      "epoch 805 train_loss 10978115.15412766 val_loss 206932.92968750\n",
      "epoch 806 train_loss 10978115.15403458 val_loss 206932.92968750\n",
      "epoch 807 train_loss 10978115.15402603 val_loss 206932.92968750\n",
      "epoch 808 train_loss 10978115.15391151 val_loss 206932.92968750\n",
      "epoch 809 train_loss 10978115.15380264 val_loss 206932.92968750\n",
      "epoch 810 train_loss 10978115.15370598 val_loss 206932.92968750\n",
      "epoch 811 train_loss 10978115.15356949 val_loss 206932.92968750\n",
      "epoch 812 train_loss 10978115.15354950 val_loss 206932.92968750\n",
      "epoch 813 train_loss 10978115.15351082 val_loss 206932.92968750\n",
      "epoch 814 train_loss 10978115.15335770 val_loss 206932.92968750\n",
      "epoch 815 train_loss 10978115.15327774 val_loss 206932.92968750\n",
      "epoch 816 train_loss 10978115.15322525 val_loss 206932.92968750\n",
      "epoch 817 train_loss 10978115.15318657 val_loss 206932.92968750\n",
      "epoch 818 train_loss 10978115.15313194 val_loss 206932.92968750\n",
      "epoch 819 train_loss 10978115.15300407 val_loss 206932.92968750\n",
      "epoch 820 train_loss 10978115.15289986 val_loss 206932.92968750\n",
      "epoch 821 train_loss 10978115.15277443 val_loss 206932.92968750\n",
      "epoch 822 train_loss 10978115.15293541 val_loss 206932.92968750\n",
      "epoch 823 train_loss 10978115.15286804 val_loss 206932.92968750\n",
      "epoch 824 train_loss 10978115.15275063 val_loss 206932.94531250\n",
      "epoch 825 train_loss 10978115.15260407 val_loss 206932.94531250\n",
      "epoch 826 train_loss 10978115.15248596 val_loss 206932.94531250\n",
      "epoch 827 train_loss 10978115.15234001 val_loss 206932.94531250\n",
      "epoch 828 train_loss 10978115.15223923 val_loss 206932.94531250\n",
      "epoch 829 train_loss 10978115.15210587 val_loss 206932.94531250\n",
      "epoch 830 train_loss 10978115.15199745 val_loss 206932.94531250\n",
      "epoch 831 train_loss 10978115.15193787 val_loss 206932.94531250\n",
      "epoch 832 train_loss 10978115.15191795 val_loss 206932.94531250\n",
      "epoch 833 train_loss 10978115.15178780 val_loss 206932.96093750\n",
      "epoch 834 train_loss 10978115.15173615 val_loss 206932.96093750\n",
      "epoch 835 train_loss 10978115.15162086 val_loss 206932.96093750\n",
      "epoch 836 train_loss 10978115.15147919 val_loss 206932.96093750\n",
      "epoch 837 train_loss 10978115.15135407 val_loss 206932.96093750\n",
      "epoch 838 train_loss 10978115.15125648 val_loss 206932.96093750\n",
      "epoch 839 train_loss 10978115.15114601 val_loss 206932.96093750\n",
      "epoch 840 train_loss 10978115.15106773 val_loss 206932.96093750\n",
      "epoch 841 train_loss 10978115.15095512 val_loss 206932.96093750\n",
      "epoch 842 train_loss 10978115.15082184 val_loss 206932.96093750\n",
      "epoch 843 train_loss 10978115.15091492 val_loss 206932.96093750\n",
      "epoch 844 train_loss 10978115.15074760 val_loss 206932.96093750\n",
      "epoch 845 train_loss 10978115.15069054 val_loss 206932.96093750\n",
      "epoch 846 train_loss 10978115.15054764 val_loss 206932.96093750\n",
      "epoch 847 train_loss 10978115.15042419 val_loss 206932.96093750\n",
      "epoch 848 train_loss 10978115.15037575 val_loss 206932.96093750\n",
      "epoch 849 train_loss 10978115.15028030 val_loss 206932.96093750\n",
      "epoch 850 train_loss 10978115.15026535 val_loss 206932.96093750\n",
      "epoch 851 train_loss 10978115.15012810 val_loss 206932.96093750\n",
      "epoch 852 train_loss 10978115.14999557 val_loss 206932.96093750\n",
      "epoch 853 train_loss 10978115.14990944 val_loss 206932.96093750\n",
      "epoch 854 train_loss 10978115.14976814 val_loss 206932.96093750\n",
      "epoch 855 train_loss 10978115.14965958 val_loss 206932.96093750\n",
      "epoch 856 train_loss 10978115.14974403 val_loss 206932.96093750\n",
      "epoch 857 train_loss 10978115.14961006 val_loss 206932.96093750\n",
      "epoch 858 train_loss 10978115.14959824 val_loss 206932.96093750\n",
      "epoch 859 train_loss 10978115.14952858 val_loss 206932.96093750\n",
      "epoch 860 train_loss 10978115.14943581 val_loss 206932.96093750\n",
      "epoch 861 train_loss 10978115.14933311 val_loss 206932.96093750\n",
      "epoch 862 train_loss 10978115.14925461 val_loss 206932.96093750\n",
      "epoch 863 train_loss 10978115.14922791 val_loss 206932.96093750\n",
      "epoch 864 train_loss 10978115.14916260 val_loss 206932.96093750\n",
      "epoch 865 train_loss 10978115.14911011 val_loss 206932.96093750\n",
      "epoch 866 train_loss 10978115.14897568 val_loss 206932.96093750\n",
      "epoch 867 train_loss 10978115.14885681 val_loss 206932.96093750\n",
      "epoch 868 train_loss 10978115.14881828 val_loss 206932.96093750\n",
      "epoch 869 train_loss 10978115.14881889 val_loss 206932.96093750\n",
      "epoch 870 train_loss 10978115.14872093 val_loss 206932.96093750\n",
      "epoch 871 train_loss 10978115.14860909 val_loss 206932.96093750\n",
      "epoch 872 train_loss 10978115.14846931 val_loss 206932.96093750\n",
      "epoch 873 train_loss 10978115.14835953 val_loss 206932.96093750\n",
      "epoch 874 train_loss 10978115.14827171 val_loss 206932.96093750\n",
      "epoch 875 train_loss 10978115.14818977 val_loss 206932.96093750\n",
      "epoch 876 train_loss 10978115.14805588 val_loss 206932.96093750\n",
      "epoch 877 train_loss 10978115.14818161 val_loss 206932.96093750\n",
      "epoch 878 train_loss 10978115.14807075 val_loss 206932.96093750\n",
      "epoch 879 train_loss 10978115.14798805 val_loss 206932.96093750\n",
      "epoch 880 train_loss 10978115.14798615 val_loss 206932.96093750\n",
      "epoch 881 train_loss 10978115.14789200 val_loss 206932.96093750\n",
      "epoch 882 train_loss 10978115.14775207 val_loss 206932.96093750\n",
      "epoch 883 train_loss 10978115.14768074 val_loss 206932.96093750\n",
      "epoch 884 train_loss 10978115.14761673 val_loss 206932.96093750\n",
      "epoch 885 train_loss 10978115.14768677 val_loss 206932.96093750\n",
      "epoch 886 train_loss 10978115.14753906 val_loss 206932.96093750\n",
      "epoch 887 train_loss 10978115.14750832 val_loss 206932.96093750\n",
      "epoch 888 train_loss 10978115.14737534 val_loss 206932.96093750\n",
      "epoch 889 train_loss 10978115.14730011 val_loss 206932.96093750\n",
      "epoch 890 train_loss 10978115.14722794 val_loss 206932.96093750\n",
      "epoch 891 train_loss 10978115.14712517 val_loss 206932.96093750\n",
      "epoch 892 train_loss 10978115.14702477 val_loss 206932.97656250\n",
      "epoch 893 train_loss 10978115.14692589 val_loss 206932.97656250\n",
      "epoch 894 train_loss 10978115.14682060 val_loss 206932.97656250\n",
      "epoch 895 train_loss 10978115.14673019 val_loss 206932.97656250\n",
      "epoch 896 train_loss 10978115.14659996 val_loss 206932.97656250\n",
      "epoch 897 train_loss 10978115.14648201 val_loss 206932.97656250\n",
      "epoch 898 train_loss 10978115.14638863 val_loss 206932.97656250\n",
      "epoch 899 train_loss 10978115.14622696 val_loss 206932.97656250\n",
      "epoch 900 train_loss 10978115.14614784 val_loss 206932.97656250\n",
      "epoch 901 train_loss 10978115.14611565 val_loss 206932.97656250\n",
      "epoch 902 train_loss 10978115.14599434 val_loss 206932.97656250\n",
      "epoch 903 train_loss 10978115.14586548 val_loss 206932.97656250\n",
      "epoch 904 train_loss 10978115.14582108 val_loss 206932.97656250\n",
      "epoch 905 train_loss 10978115.14581055 val_loss 206932.97656250\n",
      "epoch 906 train_loss 10978115.14569626 val_loss 206932.97656250\n",
      "epoch 907 train_loss 10978115.14562996 val_loss 206932.97656250\n",
      "epoch 908 train_loss 10978115.14552826 val_loss 206932.97656250\n",
      "epoch 909 train_loss 10978115.14541710 val_loss 206932.97656250\n",
      "epoch 910 train_loss 10978115.14533562 val_loss 206932.97656250\n",
      "epoch 911 train_loss 10978115.14528549 val_loss 206932.97656250\n",
      "epoch 912 train_loss 10978115.14521698 val_loss 206932.97656250\n",
      "epoch 913 train_loss 10978115.14509178 val_loss 206932.97656250\n",
      "epoch 914 train_loss 10978115.14497375 val_loss 206932.97656250\n",
      "epoch 915 train_loss 10978115.14489342 val_loss 206932.97656250\n",
      "epoch 916 train_loss 10978115.14479828 val_loss 206932.97656250\n",
      "epoch 917 train_loss 10978115.14478760 val_loss 206932.98437500\n",
      "epoch 918 train_loss 10978115.14465942 val_loss 206932.98437500\n",
      "epoch 919 train_loss 10978115.14454102 val_loss 206932.98437500\n",
      "epoch 920 train_loss 10978115.14443100 val_loss 206932.98437500\n",
      "epoch 921 train_loss 10978115.14432114 val_loss 206932.98437500\n",
      "epoch 922 train_loss 10978115.14424545 val_loss 206932.98437500\n",
      "epoch 923 train_loss 10978115.14413315 val_loss 206932.98437500\n",
      "epoch 924 train_loss 10978115.14406212 val_loss 206932.98437500\n",
      "epoch 925 train_loss 10978115.14394196 val_loss 206932.98437500\n",
      "epoch 926 train_loss 10978115.14384506 val_loss 206932.98437500\n",
      "epoch 927 train_loss 10978115.14377945 val_loss 206932.98437500\n",
      "epoch 928 train_loss 10978115.14367439 val_loss 206932.98437500\n",
      "epoch 929 train_loss 10978115.14355881 val_loss 206932.98437500\n",
      "epoch 930 train_loss 10978115.14346924 val_loss 206932.98437500\n",
      "epoch 931 train_loss 10978115.14345070 val_loss 206932.98437500\n",
      "epoch 932 train_loss 10978115.14333618 val_loss 206932.98437500\n",
      "epoch 933 train_loss 10978115.14325752 val_loss 206932.98437500\n",
      "epoch 934 train_loss 10978115.14321175 val_loss 206932.98437500\n",
      "epoch 935 train_loss 10978115.14319305 val_loss 206932.98437500\n",
      "epoch 936 train_loss 10978115.14310707 val_loss 206932.98437500\n",
      "epoch 937 train_loss 10978115.14304253 val_loss 206932.98437500\n",
      "epoch 938 train_loss 10978115.14293541 val_loss 206932.98437500\n",
      "epoch 939 train_loss 10978115.14282501 val_loss 206932.98437500\n",
      "epoch 940 train_loss 10978115.14276352 val_loss 206932.98437500\n",
      "epoch 941 train_loss 10978115.14265205 val_loss 206932.98437500\n",
      "epoch 942 train_loss 10978115.14256928 val_loss 206932.98437500\n",
      "epoch 943 train_loss 10978115.14247505 val_loss 206932.98437500\n",
      "epoch 944 train_loss 10978115.14247803 val_loss 206932.98437500\n",
      "epoch 945 train_loss 10978115.14236053 val_loss 206932.98437500\n",
      "epoch 946 train_loss 10978115.14223213 val_loss 206932.98437500\n",
      "epoch 947 train_loss 10978115.14211525 val_loss 206932.98437500\n",
      "epoch 948 train_loss 10978115.14207657 val_loss 206932.98437500\n",
      "epoch 949 train_loss 10978115.14193031 val_loss 206932.98437500\n",
      "epoch 950 train_loss 10978115.14182945 val_loss 206932.98437500\n",
      "epoch 951 train_loss 10978115.14172401 val_loss 206932.98437500\n",
      "epoch 952 train_loss 10978115.14161804 val_loss 206932.98437500\n",
      "epoch 953 train_loss 10978115.14152641 val_loss 206932.98437500\n",
      "epoch 954 train_loss 10978115.14146118 val_loss 206932.98437500\n",
      "epoch 955 train_loss 10978115.14140053 val_loss 206932.98437500\n",
      "epoch 956 train_loss 10978115.14129021 val_loss 206932.98437500\n",
      "epoch 957 train_loss 10978115.14117912 val_loss 206932.98437500\n",
      "epoch 958 train_loss 10978115.14105881 val_loss 206932.98437500\n",
      "epoch 959 train_loss 10978115.14097984 val_loss 206932.98437500\n",
      "epoch 960 train_loss 10978115.14087021 val_loss 206932.98437500\n",
      "epoch 961 train_loss 10978115.14080429 val_loss 206932.98437500\n",
      "epoch 962 train_loss 10978115.14070519 val_loss 206932.98437500\n",
      "epoch 963 train_loss 10978115.14060829 val_loss 206932.98437500\n",
      "epoch 964 train_loss 10978115.14056778 val_loss 206932.98437500\n",
      "epoch 965 train_loss 10978115.14048821 val_loss 206932.98437500\n",
      "epoch 966 train_loss 10978115.14037582 val_loss 206932.98437500\n",
      "epoch 967 train_loss 10978115.14025925 val_loss 206932.98437500\n",
      "epoch 968 train_loss 10978115.14014992 val_loss 206932.98437500\n",
      "epoch 969 train_loss 10978115.14011749 val_loss 206932.98437500\n",
      "epoch 970 train_loss 10978115.14001709 val_loss 206932.98437500\n",
      "epoch 971 train_loss 10978115.13993729 val_loss 206932.98437500\n",
      "epoch 972 train_loss 10978115.13983955 val_loss 206932.98437500\n",
      "epoch 973 train_loss 10978115.13974686 val_loss 206932.98437500\n",
      "epoch 974 train_loss 10978115.13969360 val_loss 206932.98437500\n",
      "epoch 975 train_loss 10978115.13962563 val_loss 206932.98437500\n",
      "epoch 976 train_loss 10978115.13951828 val_loss 206932.98437500\n",
      "epoch 977 train_loss 10978115.13942368 val_loss 206932.98437500\n",
      "epoch 978 train_loss 10978115.13934082 val_loss 206932.98437500\n",
      "epoch 979 train_loss 10978115.13927719 val_loss 206932.98437500\n",
      "epoch 980 train_loss 10978115.13915779 val_loss 206932.98437500\n",
      "epoch 981 train_loss 10978115.13911850 val_loss 206932.98437500\n",
      "epoch 982 train_loss 10978115.13909859 val_loss 206932.98437500\n",
      "epoch 983 train_loss 10978115.13898407 val_loss 206932.98437500\n",
      "epoch 984 train_loss 10978115.13887367 val_loss 206932.98437500\n",
      "epoch 985 train_loss 10978115.13879532 val_loss 206932.98437500\n",
      "epoch 986 train_loss 10978115.13867729 val_loss 206932.98437500\n",
      "epoch 987 train_loss 10978115.13854713 val_loss 206932.98437500\n",
      "epoch 988 train_loss 10978115.13853149 val_loss 206932.98437500\n",
      "epoch 989 train_loss 10978115.13847427 val_loss 206932.98437500\n",
      "epoch 990 train_loss 10978115.13836212 val_loss 206932.98437500\n",
      "epoch 991 train_loss 10978115.13824951 val_loss 206932.98437500\n",
      "epoch 992 train_loss 10978115.13818947 val_loss 206932.98437500\n",
      "epoch 993 train_loss 10978115.13807938 val_loss 206932.98437500\n",
      "epoch 994 train_loss 10978115.13800217 val_loss 206932.98437500\n",
      "epoch 995 train_loss 10978115.13787231 val_loss 206932.98437500\n",
      "epoch 996 train_loss 10978115.13779953 val_loss 206932.98437500\n",
      "epoch 997 train_loss 10978115.13772537 val_loss 206932.98437500\n",
      "epoch 998 train_loss 10978115.13764687 val_loss 206932.98437500\n",
      "epoch 999 train_loss 10978115.13753059 val_loss 206932.98437500\n",
      "epoch 1000 train_loss 10978115.13743736 val_loss 206932.98437500\n",
      "epoch 1001 train_loss 10978115.13735527 val_loss 206932.98437500\n",
      "epoch 1002 train_loss 10978115.13726196 val_loss 206932.98437500\n",
      "epoch 1003 train_loss 10978115.13715782 val_loss 206932.98437500\n",
      "epoch 1004 train_loss 10978115.13704323 val_loss 206932.98437500\n",
      "epoch 1005 train_loss 10978115.13694984 val_loss 206932.98437500\n",
      "epoch 1006 train_loss 10978115.13686127 val_loss 206932.98437500\n",
      "epoch 1007 train_loss 10978115.13678825 val_loss 206932.98437500\n",
      "epoch 1008 train_loss 10978115.13665451 val_loss 206932.98437500\n",
      "epoch 1009 train_loss 10978115.13660141 val_loss 206932.99218750\n",
      "epoch 1010 train_loss 10978115.13648483 val_loss 206932.99218750\n",
      "epoch 1011 train_loss 10978115.13638535 val_loss 206932.99218750\n",
      "epoch 1012 train_loss 10978115.13630371 val_loss 206932.99218750\n",
      "epoch 1013 train_loss 10978115.13618034 val_loss 206932.99218750\n",
      "epoch 1014 train_loss 10978115.13608330 val_loss 206932.99218750\n",
      "epoch 1015 train_loss 10978115.13602455 val_loss 206932.99218750\n",
      "epoch 1016 train_loss 10978115.13598030 val_loss 206932.99218750\n",
      "epoch 1017 train_loss 10978115.13590408 val_loss 206932.99218750\n",
      "epoch 1018 train_loss 10978115.13579323 val_loss 206932.99218750\n",
      "epoch 1019 train_loss 10978115.13567780 val_loss 206932.99218750\n",
      "epoch 1020 train_loss 10978115.13558510 val_loss 206932.99218750\n",
      "epoch 1021 train_loss 10978115.13548264 val_loss 206932.99218750\n",
      "epoch 1022 train_loss 10978115.13535835 val_loss 206932.99218750\n",
      "epoch 1023 train_loss 10978115.13523491 val_loss 206932.99218750\n",
      "epoch 1024 train_loss 10978115.13518013 val_loss 206932.99218750\n",
      "epoch 1025 train_loss 10978115.13518005 val_loss 206932.99218750\n",
      "epoch 1026 train_loss 10978115.13508080 val_loss 206932.99218750\n",
      "epoch 1027 train_loss 10978115.13501877 val_loss 206932.99218750\n",
      "epoch 1028 train_loss 10978115.13493866 val_loss 206932.99218750\n",
      "epoch 1029 train_loss 10978115.13486321 val_loss 206932.99218750\n",
      "epoch 1030 train_loss 10978115.13475815 val_loss 206932.99218750\n",
      "epoch 1031 train_loss 10978115.13466370 val_loss 206932.99218750\n",
      "epoch 1032 train_loss 10978115.13456512 val_loss 206932.99218750\n",
      "epoch 1033 train_loss 10978115.13448357 val_loss 206932.99218750\n",
      "epoch 1034 train_loss 10978115.13438034 val_loss 206932.99218750\n",
      "epoch 1035 train_loss 10978115.13427452 val_loss 206932.99218750\n",
      "epoch 1036 train_loss 10978115.13418854 val_loss 206932.99218750\n",
      "epoch 1037 train_loss 10978115.13415840 val_loss 206932.99218750\n",
      "epoch 1038 train_loss 10978115.13410164 val_loss 206932.99218750\n",
      "epoch 1039 train_loss 10978115.13407875 val_loss 206932.99218750\n",
      "epoch 1040 train_loss 10978115.13401856 val_loss 206932.99218750\n",
      "epoch 1041 train_loss 10978115.13396874 val_loss 206932.99218750\n",
      "epoch 1042 train_loss 10978115.13383705 val_loss 206932.99218750\n",
      "epoch 1043 train_loss 10978115.13373222 val_loss 206932.99218750\n",
      "epoch 1044 train_loss 10978115.13362335 val_loss 206932.99218750\n",
      "epoch 1045 train_loss 10978115.13352539 val_loss 206932.99218750\n",
      "epoch 1046 train_loss 10978115.13342384 val_loss 206932.99218750\n",
      "epoch 1047 train_loss 10978115.13355759 val_loss 206932.99218750\n",
      "epoch 1048 train_loss 10978115.13348373 val_loss 206932.99218750\n",
      "epoch 1049 train_loss 10978115.13342300 val_loss 206932.99218750\n",
      "epoch 1050 train_loss 10978115.13334442 val_loss 206932.99218750\n",
      "epoch 1051 train_loss 10978115.13328568 val_loss 206932.99218750\n",
      "epoch 1052 train_loss 10978115.13317093 val_loss 206932.99218750\n",
      "epoch 1053 train_loss 10978115.13307251 val_loss 206932.99218750\n",
      "epoch 1054 train_loss 10978115.13297615 val_loss 206932.99218750\n",
      "epoch 1055 train_loss 10978115.13289619 val_loss 206932.99218750\n",
      "epoch 1056 train_loss 10978115.13288429 val_loss 206932.99218750\n",
      "epoch 1057 train_loss 10978115.13278343 val_loss 206932.99218750\n",
      "epoch 1058 train_loss 10978115.13267372 val_loss 206932.99218750\n",
      "epoch 1059 train_loss 10978115.13259430 val_loss 206932.99218750\n",
      "epoch 1060 train_loss 10978115.13247902 val_loss 206932.99218750\n",
      "epoch 1061 train_loss 10978115.13244637 val_loss 206932.99218750\n",
      "epoch 1062 train_loss 10978115.13248054 val_loss 206932.99218750\n",
      "epoch 1063 train_loss 10978115.13237953 val_loss 206932.99218750\n",
      "epoch 1064 train_loss 10978115.13233231 val_loss 206932.99218750\n",
      "epoch 1065 train_loss 10978115.13222633 val_loss 206932.99218750\n",
      "epoch 1066 train_loss 10978115.13211670 val_loss 206932.99218750\n",
      "epoch 1067 train_loss 10978115.13200195 val_loss 206932.99218750\n",
      "epoch 1068 train_loss 10978115.13190277 val_loss 206932.99218750\n",
      "epoch 1069 train_loss 10978115.13179909 val_loss 206932.99218750\n",
      "epoch 1070 train_loss 10978115.13172256 val_loss 206932.99218750\n",
      "epoch 1071 train_loss 10978115.13165779 val_loss 206932.99218750\n",
      "epoch 1072 train_loss 10978115.13171242 val_loss 206932.99218750\n",
      "epoch 1073 train_loss 10978115.13160644 val_loss 206932.99218750\n",
      "epoch 1074 train_loss 10978115.13160118 val_loss 206932.99218750\n",
      "epoch 1075 train_loss 10978115.13150169 val_loss 206932.99218750\n",
      "epoch 1076 train_loss 10978115.13144554 val_loss 206932.99218750\n",
      "epoch 1077 train_loss 10978115.13136284 val_loss 206932.99218750\n",
      "epoch 1078 train_loss 10978115.13126617 val_loss 206932.99218750\n",
      "epoch 1079 train_loss 10978115.13121460 val_loss 206932.99218750\n",
      "epoch 1080 train_loss 10978115.13109352 val_loss 206932.99218750\n",
      "epoch 1081 train_loss 10978115.13101059 val_loss 206932.99218750\n",
      "epoch 1082 train_loss 10978115.13088936 val_loss 206932.99218750\n",
      "epoch 1083 train_loss 10978115.13079025 val_loss 206932.99218750\n",
      "epoch 1084 train_loss 10978115.13067307 val_loss 206932.99218750\n",
      "epoch 1085 train_loss 10978115.13058502 val_loss 206932.99218750\n",
      "epoch 1086 train_loss 10978115.13055946 val_loss 206932.99218750\n",
      "epoch 1087 train_loss 10978115.13046989 val_loss 206932.99218750\n",
      "epoch 1088 train_loss 10978115.13038109 val_loss 206932.99218750\n",
      "epoch 1089 train_loss 10978115.13029068 val_loss 206932.99218750\n",
      "epoch 1090 train_loss 10978115.13021706 val_loss 206932.99218750\n",
      "epoch 1091 train_loss 10978115.13014313 val_loss 206932.99218750\n",
      "epoch 1092 train_loss 10978115.13006966 val_loss 206932.99218750\n",
      "epoch 1093 train_loss 10978115.12999931 val_loss 206932.99218750\n",
      "epoch 1094 train_loss 10978115.12987946 val_loss 206932.99218750\n",
      "epoch 1095 train_loss 10978115.12977638 val_loss 206932.99218750\n",
      "epoch 1096 train_loss 10978115.12968468 val_loss 206932.99218750\n",
      "epoch 1097 train_loss 10978115.12960838 val_loss 206932.99218750\n",
      "epoch 1098 train_loss 10978115.12948707 val_loss 206932.99218750\n",
      "epoch 1099 train_loss 10978115.12937775 val_loss 206932.99218750\n",
      "epoch 1100 train_loss 10978115.12927406 val_loss 206932.99218750\n",
      "epoch 1101 train_loss 10978115.12916153 val_loss 206932.99218750\n",
      "epoch 1102 train_loss 10978115.12908943 val_loss 206932.99218750\n",
      "epoch 1103 train_loss 10978115.12898361 val_loss 206932.99218750\n",
      "epoch 1104 train_loss 10978115.12893883 val_loss 206932.99218750\n",
      "epoch 1105 train_loss 10978115.12888077 val_loss 206932.99218750\n",
      "epoch 1106 train_loss 10978115.12878754 val_loss 206932.99218750\n",
      "epoch 1107 train_loss 10978115.12870377 val_loss 206932.99218750\n",
      "epoch 1108 train_loss 10978115.12858978 val_loss 206932.99218750\n",
      "epoch 1109 train_loss 10978115.12853622 val_loss 206932.99218750\n",
      "epoch 1110 train_loss 10978115.12844467 val_loss 206932.99218750\n",
      "epoch 1111 train_loss 10978115.12838104 val_loss 206932.99218750\n",
      "epoch 1112 train_loss 10978115.12828339 val_loss 206932.99218750\n",
      "epoch 1113 train_loss 10978115.12819427 val_loss 206932.99218750\n",
      "epoch 1114 train_loss 10978115.12816856 val_loss 206932.99218750\n",
      "epoch 1115 train_loss 10978115.12810021 val_loss 206932.99218750\n",
      "epoch 1116 train_loss 10978115.12798653 val_loss 206932.99218750\n",
      "epoch 1117 train_loss 10978115.12788132 val_loss 206932.99218750\n",
      "epoch 1118 train_loss 10978115.12779655 val_loss 206932.99218750\n",
      "epoch 1119 train_loss 10978115.12770340 val_loss 206932.99218750\n",
      "epoch 1120 train_loss 10978115.12760460 val_loss 206932.99218750\n",
      "epoch 1121 train_loss 10978115.12753464 val_loss 206932.99218750\n",
      "epoch 1122 train_loss 10978115.12744102 val_loss 206932.99218750\n",
      "epoch 1123 train_loss 10978115.12733276 val_loss 206932.99218750\n",
      "epoch 1124 train_loss 10978115.12725563 val_loss 206932.99218750\n",
      "epoch 1125 train_loss 10978115.12714600 val_loss 206932.99218750\n",
      "epoch 1126 train_loss 10978115.12706299 val_loss 206932.99218750\n",
      "epoch 1127 train_loss 10978115.12695160 val_loss 206932.99218750\n",
      "epoch 1128 train_loss 10978115.12685516 val_loss 206932.99218750\n",
      "epoch 1129 train_loss 10978115.12675674 val_loss 206932.99218750\n",
      "epoch 1130 train_loss 10978115.12667419 val_loss 206932.99218750\n",
      "epoch 1131 train_loss 10978115.12662605 val_loss 206932.99218750\n",
      "epoch 1132 train_loss 10978115.12649757 val_loss 206932.99218750\n",
      "epoch 1133 train_loss 10978115.12641182 val_loss 206932.99218750\n",
      "epoch 1134 train_loss 10978115.12630646 val_loss 206932.99218750\n",
      "epoch 1135 train_loss 10978115.12623886 val_loss 206932.99218750\n",
      "epoch 1136 train_loss 10978115.12617096 val_loss 206932.99218750\n",
      "epoch 1137 train_loss 10978115.12607948 val_loss 206932.99218750\n",
      "epoch 1138 train_loss 10978115.12599838 val_loss 206932.99218750\n",
      "epoch 1139 train_loss 10978115.12596489 val_loss 206932.99218750\n",
      "epoch 1140 train_loss 10978115.12587990 val_loss 206932.99218750\n",
      "epoch 1141 train_loss 10978115.12578911 val_loss 206932.99218750\n",
      "epoch 1142 train_loss 10978115.12568344 val_loss 206932.99218750\n",
      "epoch 1143 train_loss 10978115.12556107 val_loss 206932.99218750\n",
      "epoch 1144 train_loss 10978115.12551941 val_loss 206932.99218750\n",
      "epoch 1145 train_loss 10978115.12542076 val_loss 206932.99218750\n",
      "epoch 1146 train_loss 10978115.12533874 val_loss 206932.99218750\n",
      "epoch 1147 train_loss 10978115.12523842 val_loss 206932.99218750\n",
      "epoch 1148 train_loss 10978115.12513794 val_loss 206932.99218750\n",
      "epoch 1149 train_loss 10978115.12502602 val_loss 206932.99218750\n",
      "epoch 1150 train_loss 10978115.12500671 val_loss 206932.99218750\n",
      "epoch 1151 train_loss 10978115.12491722 val_loss 206933.00781250\n",
      "epoch 1152 train_loss 10978115.12481392 val_loss 206933.00781250\n",
      "epoch 1153 train_loss 10978115.12472900 val_loss 206933.00781250\n",
      "epoch 1154 train_loss 10978115.12464935 val_loss 206933.00781250\n",
      "epoch 1155 train_loss 10978115.12452675 val_loss 206933.00781250\n",
      "epoch 1156 train_loss 10978115.12442223 val_loss 206933.00781250\n",
      "epoch 1157 train_loss 10978115.12433228 val_loss 206933.00781250\n",
      "epoch 1158 train_loss 10978115.12429382 val_loss 206933.00781250\n",
      "epoch 1159 train_loss 10978115.12424408 val_loss 206933.00781250\n",
      "epoch 1160 train_loss 10978115.12414223 val_loss 206933.00781250\n",
      "epoch 1161 train_loss 10978115.12403748 val_loss 206933.00781250\n",
      "epoch 1162 train_loss 10978115.12393326 val_loss 206933.00781250\n",
      "epoch 1163 train_loss 10978115.12389832 val_loss 206933.00781250\n",
      "epoch 1164 train_loss 10978115.12381905 val_loss 206933.00781250\n",
      "epoch 1165 train_loss 10978115.12370957 val_loss 206933.00781250\n",
      "epoch 1166 train_loss 10978115.12362465 val_loss 206933.00781250\n",
      "epoch 1167 train_loss 10978115.12355003 val_loss 206933.00781250\n",
      "epoch 1168 train_loss 10978115.12343567 val_loss 206933.00781250\n",
      "epoch 1169 train_loss 10978115.12334999 val_loss 206933.00781250\n",
      "epoch 1170 train_loss 10978115.12324020 val_loss 206933.00781250\n",
      "epoch 1171 train_loss 10978115.12315201 val_loss 206933.00781250\n",
      "epoch 1172 train_loss 10978115.12302132 val_loss 206933.00781250\n",
      "epoch 1173 train_loss 10978115.12294365 val_loss 206933.00781250\n",
      "epoch 1174 train_loss 10978115.12284714 val_loss 206933.00781250\n",
      "epoch 1175 train_loss 10978115.12275375 val_loss 206933.00781250\n",
      "epoch 1176 train_loss 10978115.12274170 val_loss 206933.00781250\n",
      "epoch 1177 train_loss 10978115.12267937 val_loss 206933.00781250\n",
      "epoch 1178 train_loss 10978115.12260696 val_loss 206933.00781250\n",
      "epoch 1179 train_loss 10978115.12251343 val_loss 206933.00781250\n",
      "epoch 1180 train_loss 10978115.12239853 val_loss 206933.00781250\n",
      "epoch 1181 train_loss 10978115.12230423 val_loss 206933.00781250\n",
      "epoch 1182 train_loss 10978115.12220795 val_loss 206933.00781250\n",
      "epoch 1183 train_loss 10978115.12212746 val_loss 206933.00781250\n",
      "epoch 1184 train_loss 10978115.12202736 val_loss 206933.00781250\n",
      "epoch 1185 train_loss 10978115.12192009 val_loss 206933.00781250\n",
      "epoch 1186 train_loss 10978115.12190445 val_loss 206933.00781250\n",
      "epoch 1187 train_loss 10978115.12179985 val_loss 206933.00781250\n",
      "epoch 1188 train_loss 10978115.12167488 val_loss 206933.00781250\n",
      "epoch 1189 train_loss 10978115.12163719 val_loss 206933.00781250\n",
      "epoch 1190 train_loss 10978115.12154190 val_loss 206933.00781250\n",
      "epoch 1191 train_loss 10978115.12144905 val_loss 206933.00781250\n",
      "epoch 1192 train_loss 10978115.12135658 val_loss 206933.00781250\n",
      "epoch 1193 train_loss 10978115.12126717 val_loss 206933.00781250\n",
      "epoch 1194 train_loss 10978115.12116692 val_loss 206933.00781250\n",
      "epoch 1195 train_loss 10978115.12106026 val_loss 206933.00781250\n",
      "epoch 1196 train_loss 10978115.12096855 val_loss 206933.00781250\n",
      "epoch 1197 train_loss 10978115.12099785 val_loss 206933.00781250\n",
      "epoch 1198 train_loss 10978115.12088287 val_loss 206933.00781250\n",
      "epoch 1199 train_loss 10978115.12078270 val_loss 206933.00781250\n",
      "epoch 1200 train_loss 10978115.12067780 val_loss 206933.00781250\n",
      "epoch 1201 train_loss 10978115.12062676 val_loss 206933.00781250\n",
      "epoch 1202 train_loss 10978115.12053116 val_loss 206933.00781250\n",
      "epoch 1203 train_loss 10978115.12045196 val_loss 206933.00781250\n",
      "epoch 1204 train_loss 10978115.12038704 val_loss 206933.00781250\n",
      "epoch 1205 train_loss 10978115.12029205 val_loss 206933.00781250\n",
      "epoch 1206 train_loss 10978115.12027046 val_loss 206933.00781250\n",
      "epoch 1207 train_loss 10978115.12021584 val_loss 206933.00781250\n",
      "epoch 1208 train_loss 10978115.12008644 val_loss 206933.00781250\n",
      "epoch 1209 train_loss 10978115.12002525 val_loss 206933.00781250\n",
      "epoch 1210 train_loss 10978115.11994698 val_loss 206933.00781250\n",
      "epoch 1211 train_loss 10978115.11984566 val_loss 206933.00781250\n",
      "epoch 1212 train_loss 10978115.11973137 val_loss 206933.00781250\n",
      "epoch 1213 train_loss 10978115.11963036 val_loss 206933.00781250\n",
      "epoch 1214 train_loss 10978115.11955605 val_loss 206933.00781250\n",
      "epoch 1215 train_loss 10978115.11953896 val_loss 206933.00781250\n",
      "epoch 1216 train_loss 10978115.11940842 val_loss 206933.00781250\n",
      "epoch 1217 train_loss 10978115.11935783 val_loss 206933.00781250\n",
      "epoch 1218 train_loss 10978115.11927025 val_loss 206933.00781250\n",
      "epoch 1219 train_loss 10978115.11916176 val_loss 206933.00781250\n",
      "epoch 1220 train_loss 10978115.11905983 val_loss 206933.00781250\n",
      "epoch 1221 train_loss 10978115.11895432 val_loss 206933.00781250\n",
      "epoch 1222 train_loss 10978115.11887093 val_loss 206933.00781250\n",
      "epoch 1223 train_loss 10978115.11887093 val_loss 206933.00781250\n",
      "epoch 1224 train_loss 10978115.11876534 val_loss 206933.00781250\n",
      "epoch 1225 train_loss 10978115.11866920 val_loss 206933.00781250\n",
      "epoch 1226 train_loss 10978115.11858429 val_loss 206933.00781250\n",
      "epoch 1227 train_loss 10978115.11848076 val_loss 206933.00781250\n",
      "epoch 1228 train_loss 10978115.11838837 val_loss 206933.00781250\n",
      "epoch 1229 train_loss 10978115.11825340 val_loss 206933.00781250\n",
      "epoch 1230 train_loss 10978115.11815979 val_loss 206933.00781250\n",
      "epoch 1231 train_loss 10978115.11806290 val_loss 206933.00781250\n",
      "epoch 1232 train_loss 10978115.11799576 val_loss 206933.00781250\n",
      "epoch 1233 train_loss 10978115.11789879 val_loss 206933.00781250\n",
      "epoch 1234 train_loss 10978115.11780968 val_loss 206933.00781250\n",
      "epoch 1235 train_loss 10978115.11771462 val_loss 206933.00781250\n",
      "epoch 1236 train_loss 10978115.11765388 val_loss 206933.00781250\n",
      "epoch 1237 train_loss 10978115.11758209 val_loss 206933.00781250\n",
      "epoch 1238 train_loss 10978115.11755074 val_loss 206933.00781250\n",
      "epoch 1239 train_loss 10978115.11757187 val_loss 206933.00781250\n",
      "epoch 1240 train_loss 10978115.11748466 val_loss 206933.00781250\n",
      "epoch 1241 train_loss 10978115.11736313 val_loss 206933.00781250\n",
      "epoch 1242 train_loss 10978115.11728172 val_loss 206933.00781250\n",
      "epoch 1243 train_loss 10978115.11716110 val_loss 206933.00781250\n",
      "epoch 1244 train_loss 10978115.11708672 val_loss 206933.00781250\n",
      "epoch 1245 train_loss 10978115.11700195 val_loss 206933.00781250\n",
      "epoch 1246 train_loss 10978115.11694084 val_loss 206933.00781250\n",
      "epoch 1247 train_loss 10978115.11688110 val_loss 206933.00781250\n",
      "epoch 1248 train_loss 10978115.11674728 val_loss 206933.00781250\n",
      "epoch 1249 train_loss 10978115.11666115 val_loss 206933.00781250\n",
      "epoch 1250 train_loss 10978115.11662445 val_loss 206933.00781250\n",
      "epoch 1251 train_loss 10978115.11657509 val_loss 206933.00781250\n",
      "epoch 1252 train_loss 10978115.11647400 val_loss 206933.00781250\n",
      "epoch 1253 train_loss 10978115.11639854 val_loss 206933.02343750\n",
      "epoch 1254 train_loss 10978115.11626595 val_loss 206933.02343750\n",
      "epoch 1255 train_loss 10978115.11616074 val_loss 206933.02343750\n",
      "epoch 1256 train_loss 10978115.11607025 val_loss 206933.02343750\n",
      "epoch 1257 train_loss 10978115.11596199 val_loss 206933.02343750\n",
      "epoch 1258 train_loss 10978115.11592438 val_loss 206933.02343750\n",
      "epoch 1259 train_loss 10978115.11580032 val_loss 206933.02343750\n",
      "epoch 1260 train_loss 10978115.11571007 val_loss 206933.02343750\n",
      "epoch 1261 train_loss 10978115.11565529 val_loss 206933.02343750\n",
      "epoch 1262 train_loss 10978115.11556343 val_loss 206933.02343750\n",
      "epoch 1263 train_loss 10978115.11547005 val_loss 206933.02343750\n",
      "epoch 1264 train_loss 10978115.11536003 val_loss 206933.02343750\n",
      "epoch 1265 train_loss 10978115.11524521 val_loss 206933.02343750\n",
      "epoch 1266 train_loss 10978115.11517250 val_loss 206933.02343750\n",
      "epoch 1267 train_loss 10978115.11510391 val_loss 206933.02343750\n",
      "epoch 1268 train_loss 10978115.11502602 val_loss 206933.02343750\n",
      "epoch 1269 train_loss 10978115.11493652 val_loss 206933.02343750\n",
      "epoch 1270 train_loss 10978115.11481071 val_loss 206933.02343750\n",
      "epoch 1271 train_loss 10978115.11474174 val_loss 206933.02343750\n",
      "epoch 1272 train_loss 10978115.11470589 val_loss 206933.02343750\n",
      "epoch 1273 train_loss 10978115.11460899 val_loss 206933.02343750\n",
      "epoch 1274 train_loss 10978115.11451202 val_loss 206933.02343750\n",
      "epoch 1275 train_loss 10978115.11441589 val_loss 206933.02343750\n",
      "epoch 1276 train_loss 10978115.11433777 val_loss 206933.02343750\n",
      "epoch 1277 train_loss 10978115.11420845 val_loss 206933.02343750\n",
      "epoch 1278 train_loss 10978115.11427277 val_loss 206933.02343750\n",
      "epoch 1279 train_loss 10978115.11421669 val_loss 206933.02343750\n",
      "epoch 1280 train_loss 10978115.11413925 val_loss 206933.02343750\n",
      "epoch 1281 train_loss 10978115.11403923 val_loss 206933.02343750\n",
      "epoch 1282 train_loss 10978115.11399681 val_loss 206933.02343750\n",
      "epoch 1283 train_loss 10978115.11404656 val_loss 206933.02343750\n",
      "epoch 1284 train_loss 10978115.11397499 val_loss 206933.02343750\n",
      "epoch 1285 train_loss 10978115.11388412 val_loss 206933.02343750\n",
      "epoch 1286 train_loss 10978115.11378250 val_loss 206933.02343750\n",
      "epoch 1287 train_loss 10978115.11367111 val_loss 206933.02343750\n",
      "epoch 1288 train_loss 10978115.11356102 val_loss 206933.02343750\n",
      "epoch 1289 train_loss 10978115.11349213 val_loss 206933.02343750\n",
      "epoch 1290 train_loss 10978115.11338943 val_loss 206933.02343750\n",
      "epoch 1291 train_loss 10978115.11328834 val_loss 206933.02343750\n",
      "epoch 1292 train_loss 10978115.11319786 val_loss 206933.02343750\n",
      "epoch 1293 train_loss 10978115.11308632 val_loss 206933.02343750\n",
      "epoch 1294 train_loss 10978115.11306046 val_loss 206933.02343750\n",
      "epoch 1295 train_loss 10978115.11295486 val_loss 206933.02343750\n",
      "epoch 1296 train_loss 10978115.11291016 val_loss 206933.02343750\n",
      "epoch 1297 train_loss 10978115.11280441 val_loss 206933.02343750\n",
      "epoch 1298 train_loss 10978115.11272293 val_loss 206933.02343750\n",
      "epoch 1299 train_loss 10978115.11261734 val_loss 206933.02343750\n",
      "epoch 1300 train_loss 10978115.11255745 val_loss 206933.02343750\n",
      "epoch 1301 train_loss 10978115.11247932 val_loss 206933.02343750\n",
      "epoch 1302 train_loss 10978115.11241318 val_loss 206933.02343750\n",
      "epoch 1303 train_loss 10978115.11230286 val_loss 206933.02343750\n",
      "epoch 1304 train_loss 10978115.11219681 val_loss 206933.02343750\n",
      "epoch 1305 train_loss 10978115.11211601 val_loss 206933.02343750\n",
      "epoch 1306 train_loss 10978115.11204765 val_loss 206933.02343750\n",
      "epoch 1307 train_loss 10978115.11193321 val_loss 206933.02343750\n",
      "epoch 1308 train_loss 10978115.11186989 val_loss 206933.02343750\n",
      "epoch 1309 train_loss 10978115.11180939 val_loss 206933.02343750\n",
      "epoch 1310 train_loss 10978115.11169754 val_loss 206933.02343750\n",
      "epoch 1311 train_loss 10978115.11160957 val_loss 206933.02343750\n",
      "epoch 1312 train_loss 10978115.11153023 val_loss 206933.02343750\n",
      "epoch 1313 train_loss 10978115.11145584 val_loss 206933.02343750\n",
      "epoch 1314 train_loss 10978115.11135094 val_loss 206933.02343750\n",
      "epoch 1315 train_loss 10978115.11126060 val_loss 206933.02343750\n",
      "epoch 1316 train_loss 10978115.11119499 val_loss 206933.02343750\n",
      "epoch 1317 train_loss 10978115.11110542 val_loss 206933.02343750\n",
      "epoch 1318 train_loss 10978115.11100502 val_loss 206933.02343750\n",
      "epoch 1319 train_loss 10978115.11089783 val_loss 206933.02343750\n",
      "epoch 1320 train_loss 10978115.11081428 val_loss 206933.02343750\n",
      "epoch 1321 train_loss 10978115.11069527 val_loss 206933.02343750\n",
      "epoch 1322 train_loss 10978115.11059845 val_loss 206933.02343750\n",
      "epoch 1323 train_loss 10978115.11053390 val_loss 206933.02343750\n",
      "epoch 1324 train_loss 10978115.11042839 val_loss 206933.02343750\n",
      "epoch 1325 train_loss 10978115.11034996 val_loss 206933.02343750\n",
      "epoch 1326 train_loss 10978115.11023308 val_loss 206933.02343750\n",
      "epoch 1327 train_loss 10978115.11014984 val_loss 206933.02343750\n",
      "epoch 1328 train_loss 10978115.11006432 val_loss 206933.02343750\n",
      "epoch 1329 train_loss 10978115.11000435 val_loss 206933.02343750\n",
      "epoch 1330 train_loss 10978115.10994377 val_loss 206933.02343750\n",
      "epoch 1331 train_loss 10978115.10984634 val_loss 206933.02343750\n",
      "epoch 1332 train_loss 10978115.10973190 val_loss 206933.02343750\n",
      "epoch 1333 train_loss 10978115.10964355 val_loss 206933.02343750\n",
      "epoch 1334 train_loss 10978115.10957054 val_loss 206933.02343750\n",
      "epoch 1335 train_loss 10978115.10949112 val_loss 206933.02343750\n",
      "epoch 1336 train_loss 10978115.10939110 val_loss 206933.02343750\n",
      "epoch 1337 train_loss 10978115.10930100 val_loss 206933.02343750\n",
      "epoch 1338 train_loss 10978115.10922821 val_loss 206933.02343750\n",
      "epoch 1339 train_loss 10978115.10922882 val_loss 206933.02343750\n",
      "epoch 1340 train_loss 10978115.10910820 val_loss 206933.02343750\n",
      "epoch 1341 train_loss 10978115.10901962 val_loss 206933.02343750\n",
      "epoch 1342 train_loss 10978115.10893166 val_loss 206933.02343750\n",
      "epoch 1343 train_loss 10978115.10884102 val_loss 206933.02343750\n",
      "epoch 1344 train_loss 10978115.10876137 val_loss 206933.02343750\n",
      "epoch 1345 train_loss 10978115.10870842 val_loss 206933.02343750\n",
      "epoch 1346 train_loss 10978115.10858765 val_loss 206933.02343750\n",
      "epoch 1347 train_loss 10978115.10848244 val_loss 206933.02343750\n",
      "epoch 1348 train_loss 10978115.10837952 val_loss 206933.02343750\n",
      "epoch 1349 train_loss 10978115.10827385 val_loss 206933.02343750\n",
      "epoch 1350 train_loss 10978115.10821144 val_loss 206933.02343750\n",
      "epoch 1351 train_loss 10978115.10811340 val_loss 206933.02343750\n",
      "epoch 1352 train_loss 10978115.10802910 val_loss 206933.02343750\n",
      "epoch 1353 train_loss 10978115.10790970 val_loss 206933.02343750\n",
      "epoch 1354 train_loss 10978115.10781235 val_loss 206933.02343750\n",
      "epoch 1355 train_loss 10978115.10777863 val_loss 206933.02343750\n",
      "epoch 1356 train_loss 10978115.10772034 val_loss 206933.02343750\n",
      "epoch 1357 train_loss 10978115.10767449 val_loss 206933.02343750\n",
      "epoch 1358 train_loss 10978115.10756973 val_loss 206933.02343750\n",
      "epoch 1359 train_loss 10978115.10746605 val_loss 206933.02343750\n",
      "epoch 1360 train_loss 10978115.10735893 val_loss 206933.02343750\n",
      "epoch 1361 train_loss 10978115.10724640 val_loss 206933.02343750\n",
      "epoch 1362 train_loss 10978115.10716103 val_loss 206933.02343750\n",
      "epoch 1363 train_loss 10978115.10707397 val_loss 206933.02343750\n",
      "epoch 1364 train_loss 10978115.10700096 val_loss 206933.02343750\n",
      "epoch 1365 train_loss 10978115.10690079 val_loss 206933.02343750\n",
      "epoch 1366 train_loss 10978115.10680664 val_loss 206933.02343750\n",
      "epoch 1367 train_loss 10978115.10669327 val_loss 206933.02343750\n",
      "epoch 1368 train_loss 10978115.10659470 val_loss 206933.02343750\n",
      "epoch 1369 train_loss 10978115.10651650 val_loss 206933.02343750\n",
      "epoch 1370 train_loss 10978115.10645203 val_loss 206933.02343750\n",
      "epoch 1371 train_loss 10978115.10633690 val_loss 206933.02343750\n",
      "epoch 1372 train_loss 10978115.10625107 val_loss 206933.02343750\n",
      "epoch 1373 train_loss 10978115.10616783 val_loss 206933.02343750\n",
      "epoch 1374 train_loss 10978115.10607475 val_loss 206933.02343750\n",
      "epoch 1375 train_loss 10978115.10598663 val_loss 206933.02343750\n",
      "epoch 1376 train_loss 10978115.10589790 val_loss 206933.02343750\n",
      "epoch 1377 train_loss 10978115.10578156 val_loss 206933.02343750\n",
      "epoch 1378 train_loss 10978115.10570206 val_loss 206933.02343750\n",
      "epoch 1379 train_loss 10978115.10559120 val_loss 206933.02343750\n",
      "epoch 1380 train_loss 10978115.10555443 val_loss 206933.02343750\n",
      "epoch 1381 train_loss 10978115.10544792 val_loss 206933.02343750\n",
      "epoch 1382 train_loss 10978115.10535873 val_loss 206933.02343750\n",
      "epoch 1383 train_loss 10978115.10524689 val_loss 206933.02343750\n",
      "epoch 1384 train_loss 10978115.10513725 val_loss 206933.02343750\n",
      "epoch 1385 train_loss 10978115.10508202 val_loss 206933.02343750\n",
      "epoch 1386 train_loss 10978115.10497795 val_loss 206933.02343750\n",
      "epoch 1387 train_loss 10978115.10488052 val_loss 206933.02343750\n",
      "epoch 1388 train_loss 10978115.10475441 val_loss 206933.02343750\n",
      "epoch 1389 train_loss 10978115.10468224 val_loss 206933.02343750\n",
      "epoch 1390 train_loss 10978115.10465187 val_loss 206933.02343750\n",
      "epoch 1391 train_loss 10978115.10458359 val_loss 206933.02343750\n",
      "epoch 1392 train_loss 10978115.10452255 val_loss 206933.02343750\n",
      "epoch 1393 train_loss 10978115.10440361 val_loss 206933.02343750\n",
      "epoch 1394 train_loss 10978115.10434448 val_loss 206933.02343750\n",
      "epoch 1395 train_loss 10978115.10424706 val_loss 206933.02343750\n",
      "epoch 1396 train_loss 10978115.10415962 val_loss 206933.02343750\n",
      "epoch 1397 train_loss 10978115.10413422 val_loss 206933.02343750\n",
      "epoch 1398 train_loss 10978115.10408943 val_loss 206933.02343750\n",
      "epoch 1399 train_loss 10978115.10398834 val_loss 206933.02343750\n",
      "epoch 1400 train_loss 10978115.10388603 val_loss 206933.02343750\n",
      "epoch 1401 train_loss 10978115.10378113 val_loss 206933.02343750\n",
      "epoch 1402 train_loss 10978115.10367630 val_loss 206933.02343750\n",
      "epoch 1403 train_loss 10978115.10358292 val_loss 206933.02343750\n",
      "epoch 1404 train_loss 10978115.10346764 val_loss 206933.02343750\n",
      "epoch 1405 train_loss 10978115.10341347 val_loss 206933.02343750\n",
      "epoch 1406 train_loss 10978115.10332100 val_loss 206933.02343750\n",
      "epoch 1407 train_loss 10978115.10321808 val_loss 206933.02343750\n",
      "epoch 1408 train_loss 10978115.10311317 val_loss 206933.02343750\n",
      "epoch 1409 train_loss 10978115.10302925 val_loss 206933.02343750\n",
      "epoch 1410 train_loss 10978115.10294930 val_loss 206933.02343750\n",
      "epoch 1411 train_loss 10978115.10284203 val_loss 206933.02343750\n",
      "epoch 1412 train_loss 10978115.10275085 val_loss 206933.02343750\n",
      "epoch 1413 train_loss 10978115.10265694 val_loss 206933.02343750\n",
      "epoch 1414 train_loss 10978115.10290581 val_loss 206933.04687500\n",
      "epoch 1415 train_loss 10978115.10283371 val_loss 206933.04687500\n",
      "epoch 1416 train_loss 10978115.10273376 val_loss 206933.04687500\n",
      "epoch 1417 train_loss 10978115.10264923 val_loss 206933.04687500\n",
      "epoch 1418 train_loss 10978115.10254822 val_loss 206933.04687500\n",
      "epoch 1419 train_loss 10978115.10244797 val_loss 206933.04687500\n",
      "epoch 1420 train_loss 10978115.10236229 val_loss 206933.04687500\n",
      "epoch 1421 train_loss 10978115.10227020 val_loss 206933.04687500\n",
      "epoch 1422 train_loss 10978115.10216133 val_loss 206933.04687500\n",
      "epoch 1423 train_loss 10978115.10207512 val_loss 206933.04687500\n",
      "epoch 1424 train_loss 10978115.10198029 val_loss 206933.04687500\n",
      "epoch 1425 train_loss 10978115.10188850 val_loss 206933.04687500\n",
      "epoch 1426 train_loss 10978115.10179527 val_loss 206933.04687500\n",
      "epoch 1427 train_loss 10978115.10169777 val_loss 206933.04687500\n",
      "epoch 1428 train_loss 10978115.10166893 val_loss 206933.04687500\n",
      "epoch 1429 train_loss 10978115.10160599 val_loss 206933.04687500\n",
      "epoch 1430 train_loss 10978115.10154007 val_loss 206933.04687500\n",
      "epoch 1431 train_loss 10978115.10144089 val_loss 206933.04687500\n",
      "epoch 1432 train_loss 10978115.10138023 val_loss 206933.04687500\n",
      "epoch 1433 train_loss 10978115.10131111 val_loss 206933.04687500\n",
      "epoch 1434 train_loss 10978115.10123947 val_loss 206933.04687500\n",
      "epoch 1435 train_loss 10978115.10111717 val_loss 206933.04687500\n",
      "epoch 1436 train_loss 10978115.10102989 val_loss 206933.04687500\n",
      "epoch 1437 train_loss 10978115.10093514 val_loss 206933.04687500\n",
      "epoch 1438 train_loss 10978115.10083336 val_loss 206933.04687500\n",
      "epoch 1439 train_loss 10978115.10072968 val_loss 206933.04687500\n",
      "epoch 1440 train_loss 10978115.10062676 val_loss 206933.04687500\n",
      "epoch 1441 train_loss 10978115.10057617 val_loss 206933.04687500\n",
      "epoch 1442 train_loss 10978115.10048958 val_loss 206933.04687500\n",
      "epoch 1443 train_loss 10978115.10042191 val_loss 206933.04687500\n",
      "epoch 1444 train_loss 10978115.10031509 val_loss 206933.04687500\n",
      "epoch 1445 train_loss 10978115.10021477 val_loss 206933.04687500\n",
      "epoch 1446 train_loss 10978115.10015221 val_loss 206933.04687500\n",
      "epoch 1447 train_loss 10978115.10003990 val_loss 206933.04687500\n",
      "epoch 1448 train_loss 10978115.09996155 val_loss 206933.04687500\n",
      "epoch 1449 train_loss 10978115.09983543 val_loss 206933.04687500\n",
      "epoch 1450 train_loss 10978115.09976585 val_loss 206933.04687500\n",
      "epoch 1451 train_loss 10978115.09970680 val_loss 206933.04687500\n",
      "epoch 1452 train_loss 10978115.09959991 val_loss 206933.04687500\n",
      "epoch 1453 train_loss 10978115.09949699 val_loss 206933.04687500\n",
      "epoch 1454 train_loss 10978115.09946411 val_loss 206933.04687500\n",
      "epoch 1455 train_loss 10978115.09935905 val_loss 206933.04687500\n",
      "epoch 1456 train_loss 10978115.09928352 val_loss 206933.04687500\n",
      "epoch 1457 train_loss 10978115.09919365 val_loss 206933.04687500\n",
      "epoch 1458 train_loss 10978115.09911339 val_loss 206933.04687500\n",
      "epoch 1459 train_loss 10978115.09898468 val_loss 206933.04687500\n",
      "epoch 1460 train_loss 10978115.09889534 val_loss 206933.04687500\n",
      "epoch 1461 train_loss 10978115.09881271 val_loss 206933.04687500\n",
      "epoch 1462 train_loss 10978115.09871582 val_loss 206933.04687500\n",
      "epoch 1463 train_loss 10978115.09863350 val_loss 206933.04687500\n",
      "epoch 1464 train_loss 10978115.09855072 val_loss 206933.04687500\n",
      "epoch 1465 train_loss 10978115.09847679 val_loss 206933.04687500\n",
      "epoch 1466 train_loss 10978115.09835243 val_loss 206933.04687500\n",
      "epoch 1467 train_loss 10978115.09825676 val_loss 206933.04687500\n",
      "epoch 1468 train_loss 10978115.09818764 val_loss 206933.04687500\n",
      "epoch 1469 train_loss 10978115.09812286 val_loss 206933.04687500\n",
      "epoch 1470 train_loss 10978115.09803955 val_loss 206933.04687500\n",
      "epoch 1471 train_loss 10978115.09794113 val_loss 206933.04687500\n",
      "epoch 1472 train_loss 10978115.09784004 val_loss 206933.04687500\n",
      "epoch 1473 train_loss 10978115.09775352 val_loss 206933.04687500\n",
      "epoch 1474 train_loss 10978115.09764419 val_loss 206933.04687500\n",
      "epoch 1475 train_loss 10978115.09760414 val_loss 206933.04687500\n",
      "epoch 1476 train_loss 10978115.09751389 val_loss 206933.04687500\n",
      "epoch 1477 train_loss 10978115.09743652 val_loss 206933.04687500\n",
      "epoch 1478 train_loss 10978115.09736473 val_loss 206933.04687500\n",
      "epoch 1479 train_loss 10978115.09724426 val_loss 206933.04687500\n",
      "epoch 1480 train_loss 10978115.09715103 val_loss 206933.04687500\n",
      "epoch 1481 train_loss 10978115.09712013 val_loss 206933.04687500\n",
      "epoch 1482 train_loss 10978115.09703461 val_loss 206933.04687500\n",
      "epoch 1483 train_loss 10978115.09692421 val_loss 206933.04687500\n",
      "epoch 1484 train_loss 10978115.09681892 val_loss 206933.04687500\n",
      "epoch 1485 train_loss 10978115.09675346 val_loss 206933.04687500\n",
      "epoch 1486 train_loss 10978115.09665016 val_loss 206933.04687500\n",
      "epoch 1487 train_loss 10978115.09655159 val_loss 206933.04687500\n",
      "epoch 1488 train_loss 10978115.09647468 val_loss 206933.04687500\n",
      "epoch 1489 train_loss 10978115.09637512 val_loss 206933.04687500\n",
      "epoch 1490 train_loss 10978115.09634071 val_loss 206933.04687500\n",
      "epoch 1491 train_loss 10978115.09624138 val_loss 206933.04687500\n",
      "epoch 1492 train_loss 10978115.09614723 val_loss 206933.04687500\n",
      "epoch 1493 train_loss 10978115.09610931 val_loss 206933.04687500\n",
      "epoch 1494 train_loss 10978115.09600121 val_loss 206933.04687500\n",
      "epoch 1495 train_loss 10978115.09592651 val_loss 206933.04687500\n",
      "epoch 1496 train_loss 10978115.09583519 val_loss 206933.04687500\n",
      "epoch 1497 train_loss 10978115.09574867 val_loss 206933.04687500\n",
      "epoch 1498 train_loss 10978115.09563156 val_loss 206933.04687500\n",
      "epoch 1499 train_loss 10978115.09554405 val_loss 206933.04687500\n",
      "epoch 1500 train_loss 10978115.09546707 val_loss 206933.04687500\n",
      "epoch 1501 train_loss 10978115.09542847 val_loss 206933.04687500\n",
      "epoch 1502 train_loss 10978115.09532944 val_loss 206933.04687500\n",
      "epoch 1503 train_loss 10978115.09521843 val_loss 206933.04687500\n",
      "epoch 1504 train_loss 10978115.09514824 val_loss 206933.04687500\n",
      "epoch 1505 train_loss 10978115.09505150 val_loss 206933.04687500\n",
      "epoch 1506 train_loss 10978115.09494781 val_loss 206933.04687500\n",
      "epoch 1507 train_loss 10978115.09488159 val_loss 206933.04687500\n",
      "epoch 1508 train_loss 10978115.09483971 val_loss 206933.04687500\n",
      "epoch 1509 train_loss 10978115.09472481 val_loss 206933.04687500\n",
      "epoch 1510 train_loss 10978115.09462006 val_loss 206933.04687500\n",
      "epoch 1511 train_loss 10978115.09452721 val_loss 206933.04687500\n",
      "epoch 1512 train_loss 10978115.09444756 val_loss 206933.04687500\n",
      "epoch 1513 train_loss 10978115.09435150 val_loss 206933.04687500\n",
      "epoch 1514 train_loss 10978115.09425453 val_loss 206933.04687500\n",
      "epoch 1515 train_loss 10978115.09418358 val_loss 206933.04687500\n",
      "epoch 1516 train_loss 10978115.09409706 val_loss 206933.04687500\n",
      "epoch 1517 train_loss 10978115.09405083 val_loss 206933.04687500\n",
      "epoch 1518 train_loss 10978115.09397079 val_loss 206933.04687500\n",
      "epoch 1519 train_loss 10978115.09386803 val_loss 206933.04687500\n",
      "epoch 1520 train_loss 10978115.09378563 val_loss 206933.04687500\n",
      "epoch 1521 train_loss 10978115.09370575 val_loss 206933.04687500\n",
      "epoch 1522 train_loss 10978115.09364288 val_loss 206933.04687500\n",
      "epoch 1523 train_loss 10978115.09355141 val_loss 206933.04687500\n",
      "epoch 1524 train_loss 10978115.09350472 val_loss 206933.04687500\n",
      "epoch 1525 train_loss 10978115.09344803 val_loss 206933.04687500\n",
      "epoch 1526 train_loss 10978115.09334282 val_loss 206933.04687500\n",
      "epoch 1527 train_loss 10978115.09323448 val_loss 206933.04687500\n",
      "epoch 1528 train_loss 10978115.09322670 val_loss 206933.04687500\n",
      "epoch 1529 train_loss 10978115.09312149 val_loss 206933.04687500\n",
      "epoch 1530 train_loss 10978115.09301292 val_loss 206933.04687500\n",
      "epoch 1531 train_loss 10978115.09291840 val_loss 206933.04687500\n",
      "epoch 1532 train_loss 10978115.09283401 val_loss 206933.04687500\n",
      "epoch 1533 train_loss 10978115.09277023 val_loss 206933.04687500\n",
      "epoch 1534 train_loss 10978115.09266029 val_loss 206933.04687500\n",
      "epoch 1535 train_loss 10978115.09254188 val_loss 206933.04687500\n",
      "epoch 1536 train_loss 10978115.09246483 val_loss 206933.04687500\n",
      "epoch 1537 train_loss 10978115.09235413 val_loss 206933.04687500\n",
      "epoch 1538 train_loss 10978115.09230354 val_loss 206933.04687500\n",
      "epoch 1539 train_loss 10978115.09222305 val_loss 206933.04687500\n",
      "epoch 1540 train_loss 10978115.09214233 val_loss 206933.04687500\n",
      "epoch 1541 train_loss 10978115.09206367 val_loss 206933.04687500\n",
      "epoch 1542 train_loss 10978115.09195465 val_loss 206933.04687500\n",
      "epoch 1543 train_loss 10978115.09188705 val_loss 206933.04687500\n",
      "epoch 1544 train_loss 10978115.09178192 val_loss 206933.04687500\n",
      "epoch 1545 train_loss 10978115.09168884 val_loss 206933.04687500\n",
      "epoch 1546 train_loss 10978115.09158501 val_loss 206933.04687500\n",
      "epoch 1547 train_loss 10978115.09147552 val_loss 206933.04687500\n",
      "epoch 1548 train_loss 10978115.09141838 val_loss 206933.04687500\n",
      "epoch 1549 train_loss 10978115.09132736 val_loss 206933.04687500\n",
      "epoch 1550 train_loss 10978115.09121628 val_loss 206933.04687500\n",
      "epoch 1551 train_loss 10978115.09119942 val_loss 206933.04687500\n",
      "epoch 1552 train_loss 10978115.09109177 val_loss 206933.04687500\n",
      "epoch 1553 train_loss 10978115.09102669 val_loss 206933.04687500\n",
      "epoch 1554 train_loss 10978115.09100792 val_loss 206933.04687500\n",
      "epoch 1555 train_loss 10978115.09090225 val_loss 206933.04687500\n",
      "epoch 1556 train_loss 10978115.09084602 val_loss 206933.04687500\n",
      "epoch 1557 train_loss 10978115.09075371 val_loss 206933.04687500\n",
      "epoch 1558 train_loss 10978115.09066284 val_loss 206933.04687500\n",
      "epoch 1559 train_loss 10978115.09058014 val_loss 206933.04687500\n",
      "epoch 1560 train_loss 10978115.09047752 val_loss 206933.04687500\n",
      "epoch 1561 train_loss 10978115.09040726 val_loss 206933.04687500\n",
      "epoch 1562 train_loss 10978115.09029488 val_loss 206933.04687500\n",
      "epoch 1563 train_loss 10978115.09020554 val_loss 206933.04687500\n",
      "epoch 1564 train_loss 10978115.09013527 val_loss 206933.04687500\n",
      "epoch 1565 train_loss 10978115.09003319 val_loss 206933.04687500\n",
      "epoch 1566 train_loss 10978115.08994568 val_loss 206933.04687500\n",
      "epoch 1567 train_loss 10978115.08984314 val_loss 206933.04687500\n",
      "epoch 1568 train_loss 10978115.08974815 val_loss 206933.04687500\n",
      "epoch 1569 train_loss 10978115.08965027 val_loss 206933.04687500\n",
      "epoch 1570 train_loss 10978115.08956596 val_loss 206933.04687500\n",
      "epoch 1571 train_loss 10978115.08948105 val_loss 206933.04687500\n",
      "epoch 1572 train_loss 10978115.08936058 val_loss 206933.04687500\n",
      "epoch 1573 train_loss 10978115.08928703 val_loss 206933.04687500\n",
      "epoch 1574 train_loss 10978115.08925552 val_loss 206933.04687500\n",
      "epoch 1575 train_loss 10978115.08921257 val_loss 206933.04687500\n",
      "epoch 1576 train_loss 10978115.08913483 val_loss 206933.04687500\n",
      "epoch 1577 train_loss 10978115.08904106 val_loss 206933.04687500\n",
      "epoch 1578 train_loss 10978115.08898186 val_loss 206933.04687500\n",
      "epoch 1579 train_loss 10978115.08891708 val_loss 206933.04687500\n",
      "epoch 1580 train_loss 10978115.08882286 val_loss 206933.04687500\n",
      "epoch 1581 train_loss 10978115.08877815 val_loss 206933.04687500\n",
      "epoch 1582 train_loss 10978115.08867485 val_loss 206933.04687500\n",
      "epoch 1583 train_loss 10978115.08856491 val_loss 206933.04687500\n",
      "epoch 1584 train_loss 10978115.08847755 val_loss 206933.04687500\n",
      "epoch 1585 train_loss 10978115.08842979 val_loss 206933.04687500\n",
      "epoch 1586 train_loss 10978115.08836372 val_loss 206933.04687500\n",
      "epoch 1587 train_loss 10978115.08824989 val_loss 206933.04687500\n",
      "epoch 1588 train_loss 10978115.08816345 val_loss 206933.04687500\n",
      "epoch 1589 train_loss 10978115.08808006 val_loss 206933.04687500\n",
      "epoch 1590 train_loss 10978115.08798561 val_loss 206933.04687500\n",
      "epoch 1591 train_loss 10978115.08789467 val_loss 206933.04687500\n",
      "epoch 1592 train_loss 10978115.08778908 val_loss 206933.04687500\n",
      "epoch 1593 train_loss 10978115.08777580 val_loss 206933.04687500\n",
      "epoch 1594 train_loss 10978115.08768394 val_loss 206933.04687500\n",
      "epoch 1595 train_loss 10978115.08760857 val_loss 206933.04687500\n",
      "epoch 1596 train_loss 10978115.08753777 val_loss 206933.04687500\n",
      "epoch 1597 train_loss 10978115.08743271 val_loss 206933.04687500\n",
      "epoch 1598 train_loss 10978115.08733833 val_loss 206933.04687500\n",
      "epoch 1599 train_loss 10978115.08722267 val_loss 206933.04687500\n",
      "epoch 1600 train_loss 10978115.08714340 val_loss 206933.04687500\n",
      "epoch 1601 train_loss 10978115.08706634 val_loss 206933.04687500\n",
      "epoch 1602 train_loss 10978115.08698509 val_loss 206933.04687500\n",
      "epoch 1603 train_loss 10978115.08687324 val_loss 206933.04687500\n",
      "epoch 1604 train_loss 10978115.08678528 val_loss 206933.04687500\n",
      "epoch 1605 train_loss 10978115.08667869 val_loss 206933.04687500\n",
      "epoch 1606 train_loss 10978115.08659233 val_loss 206933.04687500\n",
      "epoch 1607 train_loss 10978115.08657127 val_loss 206933.04687500\n",
      "epoch 1608 train_loss 10978115.08649948 val_loss 206933.04687500\n",
      "epoch 1609 train_loss 10978115.08640320 val_loss 206933.04687500\n",
      "epoch 1610 train_loss 10978115.08630325 val_loss 206933.04687500\n",
      "epoch 1611 train_loss 10978115.08620331 val_loss 206933.04687500\n",
      "epoch 1612 train_loss 10978115.08608040 val_loss 206933.04687500\n",
      "epoch 1613 train_loss 10978115.08600914 val_loss 206933.04687500\n",
      "epoch 1614 train_loss 10978115.08593094 val_loss 206933.04687500\n",
      "epoch 1615 train_loss 10978115.08582726 val_loss 206933.04687500\n",
      "epoch 1616 train_loss 10978115.08575943 val_loss 206933.04687500\n",
      "epoch 1617 train_loss 10978115.08566734 val_loss 206933.04687500\n",
      "epoch 1618 train_loss 10978115.08557304 val_loss 206933.04687500\n",
      "epoch 1619 train_loss 10978115.08548248 val_loss 206933.04687500\n",
      "epoch 1620 train_loss 10978115.08537827 val_loss 206933.04687500\n",
      "epoch 1621 train_loss 10978115.08529015 val_loss 206933.04687500\n",
      "epoch 1622 train_loss 10978115.08522140 val_loss 206933.04687500\n",
      "epoch 1623 train_loss 10978115.08512321 val_loss 206933.04687500\n",
      "epoch 1624 train_loss 10978115.08502258 val_loss 206933.04687500\n",
      "epoch 1625 train_loss 10978115.08492477 val_loss 206933.04687500\n",
      "epoch 1626 train_loss 10978115.08484894 val_loss 206933.04687500\n",
      "epoch 1627 train_loss 10978115.08480751 val_loss 206933.04687500\n",
      "epoch 1628 train_loss 10978115.08470039 val_loss 206933.04687500\n",
      "epoch 1629 train_loss 10978115.08459846 val_loss 206933.04687500\n",
      "epoch 1630 train_loss 10978115.08455009 val_loss 206933.04687500\n",
      "epoch 1631 train_loss 10978115.08447380 val_loss 206933.04687500\n",
      "epoch 1632 train_loss 10978115.08437225 val_loss 206933.04687500\n",
      "epoch 1633 train_loss 10978115.08431602 val_loss 206933.04687500\n",
      "epoch 1634 train_loss 10978115.08423714 val_loss 206933.04687500\n",
      "epoch 1635 train_loss 10978115.08412354 val_loss 206933.04687500\n",
      "epoch 1636 train_loss 10978115.08406380 val_loss 206933.04687500\n",
      "epoch 1637 train_loss 10978115.08396790 val_loss 206933.04687500\n",
      "epoch 1638 train_loss 10978115.08385963 val_loss 206933.04687500\n",
      "epoch 1639 train_loss 10978115.08382843 val_loss 206933.04687500\n",
      "epoch 1640 train_loss 10978115.08373863 val_loss 206933.04687500\n",
      "epoch 1641 train_loss 10978115.08363617 val_loss 206933.04687500\n",
      "epoch 1642 train_loss 10978115.08358841 val_loss 206933.04687500\n",
      "epoch 1643 train_loss 10978115.08348488 val_loss 206933.04687500\n",
      "epoch 1644 train_loss 10978115.08342613 val_loss 206933.04687500\n",
      "epoch 1645 train_loss 10978115.08331726 val_loss 206933.04687500\n",
      "epoch 1646 train_loss 10978115.08323563 val_loss 206933.04687500\n",
      "epoch 1647 train_loss 10978115.08313988 val_loss 206933.04687500\n",
      "epoch 1648 train_loss 10978115.08304985 val_loss 206933.04687500\n",
      "epoch 1649 train_loss 10978115.08298271 val_loss 206933.04687500\n",
      "epoch 1650 train_loss 10978115.08290085 val_loss 206933.04687500\n",
      "epoch 1651 train_loss 10978115.08279365 val_loss 206933.04687500\n",
      "epoch 1652 train_loss 10978115.08272133 val_loss 206933.04687500\n",
      "epoch 1653 train_loss 10978115.08261253 val_loss 206933.04687500\n",
      "epoch 1654 train_loss 10978115.08252480 val_loss 206933.04687500\n",
      "epoch 1655 train_loss 10978115.08241829 val_loss 206933.04687500\n",
      "epoch 1656 train_loss 10978115.08232910 val_loss 206933.04687500\n",
      "epoch 1657 train_loss 10978115.08226700 val_loss 206933.04687500\n",
      "epoch 1658 train_loss 10978115.08218247 val_loss 206933.04687500\n",
      "epoch 1659 train_loss 10978115.08208855 val_loss 206933.04687500\n",
      "epoch 1660 train_loss 10978115.08204979 val_loss 206933.04687500\n",
      "epoch 1661 train_loss 10978115.08196175 val_loss 206933.04687500\n",
      "epoch 1662 train_loss 10978115.08186615 val_loss 206933.04687500\n",
      "epoch 1663 train_loss 10978115.08182083 val_loss 206933.04687500\n",
      "epoch 1664 train_loss 10978115.08173088 val_loss 206933.04687500\n",
      "epoch 1665 train_loss 10978115.08161919 val_loss 206933.04687500\n",
      "epoch 1666 train_loss 10978115.08150765 val_loss 206933.04687500\n",
      "epoch 1667 train_loss 10978115.08143463 val_loss 206933.04687500\n",
      "epoch 1668 train_loss 10978115.08134857 val_loss 206933.04687500\n",
      "epoch 1669 train_loss 10978115.08125969 val_loss 206933.04687500\n",
      "epoch 1670 train_loss 10978115.08114510 val_loss 206933.04687500\n",
      "epoch 1671 train_loss 10978115.08105820 val_loss 206933.04687500\n",
      "epoch 1672 train_loss 10978115.08096222 val_loss 206933.04687500\n",
      "epoch 1673 train_loss 10978115.08085701 val_loss 206933.04687500\n",
      "epoch 1674 train_loss 10978115.08076531 val_loss 206933.04687500\n",
      "epoch 1675 train_loss 10978115.08067772 val_loss 206933.04687500\n",
      "epoch 1676 train_loss 10978115.08060822 val_loss 206933.04687500\n",
      "epoch 1677 train_loss 10978115.08053253 val_loss 206933.04687500\n",
      "epoch 1678 train_loss 10978115.08044716 val_loss 206933.04687500\n",
      "epoch 1679 train_loss 10978115.08036354 val_loss 206933.04687500\n",
      "epoch 1680 train_loss 10978115.08024315 val_loss 206933.04687500\n",
      "epoch 1681 train_loss 10978115.08017281 val_loss 206933.04687500\n",
      "epoch 1682 train_loss 10978115.08008789 val_loss 206933.04687500\n",
      "epoch 1683 train_loss 10978115.08001419 val_loss 206933.04687500\n",
      "epoch 1684 train_loss 10978115.07991180 val_loss 206933.04687500\n",
      "epoch 1685 train_loss 10978115.07984573 val_loss 206933.04687500\n",
      "epoch 1686 train_loss 10978115.07979134 val_loss 206933.04687500\n",
      "epoch 1687 train_loss 10978115.07968025 val_loss 206933.04687500\n",
      "epoch 1688 train_loss 10978115.07960464 val_loss 206933.04687500\n",
      "epoch 1689 train_loss 10978115.07948982 val_loss 206933.04687500\n",
      "epoch 1690 train_loss 10978115.07939903 val_loss 206933.04687500\n",
      "epoch 1691 train_loss 10978115.07930466 val_loss 206933.04687500\n",
      "epoch 1692 train_loss 10978115.07923340 val_loss 206933.04687500\n",
      "epoch 1693 train_loss 10978115.07914719 val_loss 206933.04687500\n",
      "epoch 1694 train_loss 10978115.07909576 val_loss 206933.04687500\n",
      "epoch 1695 train_loss 10978115.07899834 val_loss 206933.04687500\n",
      "epoch 1696 train_loss 10978115.07890877 val_loss 206933.04687500\n",
      "epoch 1697 train_loss 10978115.07880005 val_loss 206933.04687500\n",
      "epoch 1698 train_loss 10978115.07871193 val_loss 206933.04687500\n",
      "epoch 1699 train_loss 10978115.07862473 val_loss 206933.04687500\n",
      "epoch 1700 train_loss 10978115.07853683 val_loss 206933.04687500\n",
      "epoch 1701 train_loss 10978115.07846924 val_loss 206933.04687500\n",
      "epoch 1702 train_loss 10978115.07840248 val_loss 206933.04687500\n",
      "epoch 1703 train_loss 10978115.07830002 val_loss 206933.04687500\n",
      "epoch 1704 train_loss 10978115.07820786 val_loss 206933.04687500\n",
      "epoch 1705 train_loss 10978115.07809578 val_loss 206933.04687500\n",
      "epoch 1706 train_loss 10978115.07800407 val_loss 206933.04687500\n",
      "epoch 1707 train_loss 10978115.07795593 val_loss 206933.04687500\n",
      "epoch 1708 train_loss 10978115.07786598 val_loss 206933.04687500\n",
      "epoch 1709 train_loss 10978115.07777222 val_loss 206933.04687500\n",
      "epoch 1710 train_loss 10978115.07767738 val_loss 206933.04687500\n",
      "epoch 1711 train_loss 10978115.07758522 val_loss 206933.04687500\n",
      "epoch 1712 train_loss 10978115.07748673 val_loss 206933.04687500\n",
      "epoch 1713 train_loss 10978115.07738808 val_loss 206933.04687500\n",
      "epoch 1714 train_loss 10978115.07729576 val_loss 206933.04687500\n",
      "epoch 1715 train_loss 10978115.07719810 val_loss 206933.04687500\n",
      "epoch 1716 train_loss 10978115.07711479 val_loss 206933.04687500\n",
      "epoch 1717 train_loss 10978115.07702713 val_loss 206933.04687500\n",
      "epoch 1718 train_loss 10978115.07690857 val_loss 206933.04687500\n",
      "epoch 1719 train_loss 10978115.07681938 val_loss 206933.04687500\n",
      "epoch 1720 train_loss 10978115.07673042 val_loss 206933.04687500\n",
      "epoch 1721 train_loss 10978115.07666046 val_loss 206933.04687500\n",
      "epoch 1722 train_loss 10978115.07654930 val_loss 206933.04687500\n",
      "epoch 1723 train_loss 10978115.07648064 val_loss 206933.04687500\n",
      "epoch 1724 train_loss 10978115.07643295 val_loss 206933.04687500\n",
      "epoch 1725 train_loss 10978115.07632057 val_loss 206933.04687500\n",
      "epoch 1726 train_loss 10978115.07624504 val_loss 206933.04687500\n",
      "epoch 1727 train_loss 10978115.07618790 val_loss 206933.04687500\n",
      "epoch 1728 train_loss 10978115.07609695 val_loss 206933.04687500\n",
      "epoch 1729 train_loss 10978115.07598427 val_loss 206933.04687500\n",
      "epoch 1730 train_loss 10978115.07590027 val_loss 206933.04687500\n",
      "epoch 1731 train_loss 10978115.07582916 val_loss 206933.04687500\n",
      "epoch 1732 train_loss 10978115.07571304 val_loss 206933.04687500\n",
      "epoch 1733 train_loss 10978115.07564896 val_loss 206933.04687500\n",
      "epoch 1734 train_loss 10978115.07556694 val_loss 206933.04687500\n",
      "epoch 1735 train_loss 10978115.07549400 val_loss 206933.04687500\n",
      "epoch 1736 train_loss 10978115.07542076 val_loss 206933.04687500\n",
      "epoch 1737 train_loss 10978115.07532631 val_loss 206933.04687500\n",
      "epoch 1738 train_loss 10978115.07525055 val_loss 206933.04687500\n",
      "epoch 1739 train_loss 10978115.07513901 val_loss 206933.04687500\n",
      "epoch 1740 train_loss 10978115.07504776 val_loss 206933.04687500\n",
      "epoch 1741 train_loss 10978115.07494904 val_loss 206933.04687500\n",
      "epoch 1742 train_loss 10978115.07485725 val_loss 206933.04687500\n",
      "epoch 1743 train_loss 10978115.07475556 val_loss 206933.04687500\n",
      "epoch 1744 train_loss 10978115.07467796 val_loss 206933.04687500\n",
      "epoch 1745 train_loss 10978115.07458275 val_loss 206933.04687500\n",
      "epoch 1746 train_loss 10978115.07447273 val_loss 206933.04687500\n",
      "epoch 1747 train_loss 10978115.07451332 val_loss 206933.04687500\n",
      "epoch 1748 train_loss 10978115.07442627 val_loss 206933.04687500\n",
      "epoch 1749 train_loss 10978115.07432716 val_loss 206933.04687500\n",
      "epoch 1750 train_loss 10978115.07427025 val_loss 206933.04687500\n",
      "epoch 1751 train_loss 10978115.07417526 val_loss 206933.04687500\n",
      "epoch 1752 train_loss 10978115.07410149 val_loss 206933.04687500\n",
      "epoch 1753 train_loss 10978115.07399872 val_loss 206933.04687500\n",
      "epoch 1754 train_loss 10978115.07390579 val_loss 206933.04687500\n",
      "epoch 1755 train_loss 10978115.07379883 val_loss 206933.04687500\n",
      "epoch 1756 train_loss 10978115.07369263 val_loss 206933.04687500\n",
      "epoch 1757 train_loss 10978115.07361069 val_loss 206933.04687500\n",
      "epoch 1758 train_loss 10978115.07353806 val_loss 206933.04687500\n",
      "epoch 1759 train_loss 10978115.07345032 val_loss 206933.04687500\n",
      "epoch 1760 train_loss 10978115.07336533 val_loss 206933.04687500\n",
      "epoch 1761 train_loss 10978115.07331108 val_loss 206933.04687500\n",
      "epoch 1762 train_loss 10978115.07322617 val_loss 206933.04687500\n",
      "epoch 1763 train_loss 10978115.07313614 val_loss 206933.04687500\n",
      "epoch 1764 train_loss 10978115.07305305 val_loss 206933.04687500\n",
      "epoch 1765 train_loss 10978115.07301331 val_loss 206933.04687500\n",
      "epoch 1766 train_loss 10978115.07291840 val_loss 206933.04687500\n",
      "epoch 1767 train_loss 10978115.07281334 val_loss 206933.04687500\n",
      "epoch 1768 train_loss 10978115.07273331 val_loss 206933.04687500\n",
      "epoch 1769 train_loss 10978115.07264076 val_loss 206933.04687500\n",
      "epoch 1770 train_loss 10978115.07255440 val_loss 206933.04687500\n",
      "epoch 1771 train_loss 10978115.07244362 val_loss 206933.04687500\n",
      "epoch 1772 train_loss 10978115.07234383 val_loss 206933.04687500\n",
      "epoch 1773 train_loss 10978115.07226433 val_loss 206933.04687500\n",
      "epoch 1774 train_loss 10978115.07217468 val_loss 206933.04687500\n",
      "epoch 1775 train_loss 10978115.07204948 val_loss 206933.04687500\n",
      "epoch 1776 train_loss 10978115.07196907 val_loss 206933.04687500\n",
      "epoch 1777 train_loss 10978115.07190430 val_loss 206933.04687500\n",
      "epoch 1778 train_loss 10978115.07180992 val_loss 206933.04687500\n",
      "epoch 1779 train_loss 10978115.07170692 val_loss 206933.04687500\n",
      "epoch 1780 train_loss 10978115.07161133 val_loss 206933.04687500\n",
      "epoch 1781 train_loss 10978115.07152374 val_loss 206933.04687500\n",
      "epoch 1782 train_loss 10978115.07151802 val_loss 206933.04687500\n",
      "epoch 1783 train_loss 10978115.07140732 val_loss 206933.04687500\n",
      "epoch 1784 train_loss 10978115.07131554 val_loss 206933.04687500\n",
      "epoch 1785 train_loss 10978115.07120308 val_loss 206933.04687500\n",
      "epoch 1786 train_loss 10978115.07113220 val_loss 206933.04687500\n",
      "epoch 1787 train_loss 10978115.07104820 val_loss 206933.04687500\n",
      "epoch 1788 train_loss 10978115.07096527 val_loss 206933.04687500\n",
      "epoch 1789 train_loss 10978115.07086395 val_loss 206933.04687500\n",
      "epoch 1790 train_loss 10978115.07079529 val_loss 206933.04687500\n",
      "epoch 1791 train_loss 10978115.07071838 val_loss 206933.04687500\n",
      "epoch 1792 train_loss 10978115.07060776 val_loss 206933.04687500\n",
      "epoch 1793 train_loss 10978115.07052803 val_loss 206933.04687500\n",
      "epoch 1794 train_loss 10978115.07043632 val_loss 206933.04687500\n",
      "epoch 1795 train_loss 10978115.07034348 val_loss 206933.04687500\n",
      "epoch 1796 train_loss 10978115.07024879 val_loss 206933.04687500\n",
      "epoch 1797 train_loss 10978115.07014580 val_loss 206933.04687500\n",
      "epoch 1798 train_loss 10978115.07004425 val_loss 206933.04687500\n",
      "epoch 1799 train_loss 10978115.06994797 val_loss 206933.04687500\n",
      "epoch 1800 train_loss 10978115.06986427 val_loss 206933.04687500\n",
      "epoch 1801 train_loss 10978115.06984482 val_loss 206933.04687500\n",
      "epoch 1802 train_loss 10978115.06973389 val_loss 206933.04687500\n",
      "epoch 1803 train_loss 10978115.06966667 val_loss 206933.04687500\n",
      "epoch 1804 train_loss 10978115.06957199 val_loss 206933.04687500\n",
      "epoch 1805 train_loss 10978115.06951569 val_loss 206933.04687500\n",
      "epoch 1806 train_loss 10978115.06940414 val_loss 206933.04687500\n",
      "epoch 1807 train_loss 10978115.06934494 val_loss 206933.04687500\n",
      "epoch 1808 train_loss 10978115.06924065 val_loss 206933.04687500\n",
      "epoch 1809 train_loss 10978115.06915123 val_loss 206933.04687500\n",
      "epoch 1810 train_loss 10978115.06906998 val_loss 206933.04687500\n",
      "epoch 1811 train_loss 10978115.06899193 val_loss 206933.04687500\n",
      "epoch 1812 train_loss 10978115.06889748 val_loss 206933.04687500\n",
      "epoch 1813 train_loss 10978115.06886650 val_loss 206933.04687500\n",
      "epoch 1814 train_loss 10978115.06875397 val_loss 206933.04687500\n",
      "epoch 1815 train_loss 10978115.06871010 val_loss 206933.04687500\n",
      "epoch 1816 train_loss 10978115.06863747 val_loss 206933.04687500\n",
      "epoch 1817 train_loss 10978115.06857948 val_loss 206933.04687500\n",
      "epoch 1818 train_loss 10978115.06848000 val_loss 206933.04687500\n",
      "epoch 1819 train_loss 10978115.06839195 val_loss 206933.04687500\n",
      "epoch 1820 train_loss 10978115.06831429 val_loss 206933.04687500\n",
      "epoch 1821 train_loss 10978115.06821793 val_loss 206933.04687500\n",
      "epoch 1822 train_loss 10978115.06811707 val_loss 206933.04687500\n",
      "epoch 1823 train_loss 10978115.06801125 val_loss 206933.04687500\n",
      "epoch 1824 train_loss 10978115.06793297 val_loss 206933.04687500\n",
      "epoch 1825 train_loss 10978115.06784347 val_loss 206933.04687500\n",
      "epoch 1826 train_loss 10978115.06774162 val_loss 206933.04687500\n",
      "epoch 1827 train_loss 10978115.06764122 val_loss 206933.04687500\n",
      "epoch 1828 train_loss 10978115.06755386 val_loss 206933.04687500\n",
      "epoch 1829 train_loss 10978115.06746376 val_loss 206933.04687500\n",
      "epoch 1830 train_loss 10978115.06737656 val_loss 206933.04687500\n",
      "epoch 1831 train_loss 10978115.06726105 val_loss 206933.04687500\n",
      "epoch 1832 train_loss 10978115.06719322 val_loss 206933.04687500\n",
      "epoch 1833 train_loss 10978115.06716873 val_loss 206933.04687500\n",
      "epoch 1834 train_loss 10978115.06707962 val_loss 206933.04687500\n",
      "epoch 1835 train_loss 10978115.06696938 val_loss 206933.04687500\n",
      "epoch 1836 train_loss 10978115.06688339 val_loss 206933.04687500\n",
      "epoch 1837 train_loss 10978115.06677017 val_loss 206933.04687500\n",
      "epoch 1838 train_loss 10978115.06667778 val_loss 206933.04687500\n",
      "epoch 1839 train_loss 10978115.06659462 val_loss 206933.04687500\n",
      "epoch 1840 train_loss 10978115.06650055 val_loss 206933.04687500\n",
      "epoch 1841 train_loss 10978115.06640259 val_loss 206933.04687500\n",
      "epoch 1842 train_loss 10978115.06632622 val_loss 206933.04687500\n",
      "epoch 1843 train_loss 10978115.06625381 val_loss 206933.04687500\n",
      "epoch 1844 train_loss 10978115.06621559 val_loss 206933.04687500\n",
      "epoch 1845 train_loss 10978115.06612602 val_loss 206933.05468750\n",
      "epoch 1846 train_loss 10978115.06606995 val_loss 206933.05468750\n",
      "epoch 1847 train_loss 10978115.06597611 val_loss 206933.05468750\n",
      "epoch 1848 train_loss 10978115.06586479 val_loss 206933.05468750\n",
      "epoch 1849 train_loss 10978115.06578941 val_loss 206933.05468750\n",
      "epoch 1850 train_loss 10978115.06571037 val_loss 206933.05468750\n",
      "epoch 1851 train_loss 10978115.06561928 val_loss 206933.05468750\n",
      "epoch 1852 train_loss 10978115.06551796 val_loss 206933.05468750\n",
      "epoch 1853 train_loss 10978115.06544823 val_loss 206933.05468750\n",
      "epoch 1854 train_loss 10978115.06535507 val_loss 206933.05468750\n",
      "epoch 1855 train_loss 10978115.06531723 val_loss 206933.05468750\n",
      "epoch 1856 train_loss 10978115.06523407 val_loss 206933.05468750\n",
      "epoch 1857 train_loss 10978115.06512146 val_loss 206933.05468750\n",
      "epoch 1858 train_loss 10978115.06506348 val_loss 206933.05468750\n",
      "epoch 1859 train_loss 10978115.06495545 val_loss 206933.05468750\n",
      "epoch 1860 train_loss 10978115.06487038 val_loss 206933.05468750\n",
      "epoch 1861 train_loss 10978115.06475914 val_loss 206933.05468750\n",
      "epoch 1862 train_loss 10978115.06466324 val_loss 206933.05468750\n",
      "epoch 1863 train_loss 10978115.06461746 val_loss 206933.05468750\n",
      "epoch 1864 train_loss 10978115.06451065 val_loss 206933.05468750\n",
      "epoch 1865 train_loss 10978115.06442154 val_loss 206933.05468750\n",
      "epoch 1866 train_loss 10978115.06434067 val_loss 206933.05468750\n",
      "epoch 1867 train_loss 10978115.06424957 val_loss 206933.05468750\n",
      "epoch 1868 train_loss 10978115.06416916 val_loss 206933.05468750\n",
      "epoch 1869 train_loss 10978115.06406120 val_loss 206933.05468750\n",
      "epoch 1870 train_loss 10978115.06397659 val_loss 206933.05468750\n",
      "epoch 1871 train_loss 10978115.06386337 val_loss 206933.05468750\n",
      "epoch 1872 train_loss 10978115.06376755 val_loss 206933.05468750\n",
      "epoch 1873 train_loss 10978115.06368584 val_loss 206933.05468750\n",
      "epoch 1874 train_loss 10978115.06359383 val_loss 206933.05468750\n",
      "epoch 1875 train_loss 10978115.06351952 val_loss 206933.05468750\n",
      "epoch 1876 train_loss 10978115.06344185 val_loss 206933.05468750\n",
      "epoch 1877 train_loss 10978115.06335052 val_loss 206933.05468750\n",
      "epoch 1878 train_loss 10978115.06325584 val_loss 206933.05468750\n",
      "epoch 1879 train_loss 10978115.06322929 val_loss 206933.05468750\n",
      "epoch 1880 train_loss 10978115.06321640 val_loss 206933.05468750\n",
      "epoch 1881 train_loss 10978115.06312889 val_loss 206933.05468750\n",
      "epoch 1882 train_loss 10978115.06304504 val_loss 206933.05468750\n",
      "epoch 1883 train_loss 10978115.06294281 val_loss 206933.05468750\n",
      "epoch 1884 train_loss 10978115.06284889 val_loss 206933.05468750\n",
      "epoch 1885 train_loss 10978115.06276985 val_loss 206933.05468750\n",
      "epoch 1886 train_loss 10978115.06268051 val_loss 206933.05468750\n",
      "epoch 1887 train_loss 10978115.06257774 val_loss 206933.05468750\n",
      "epoch 1888 train_loss 10978115.06250099 val_loss 206933.05468750\n",
      "epoch 1889 train_loss 10978115.06240082 val_loss 206933.05468750\n",
      "epoch 1890 train_loss 10978115.06230873 val_loss 206933.05468750\n",
      "epoch 1891 train_loss 10978115.06234093 val_loss 206933.05468750\n",
      "epoch 1892 train_loss 10978115.06223694 val_loss 206933.05468750\n",
      "epoch 1893 train_loss 10978115.06219124 val_loss 206933.05468750\n",
      "epoch 1894 train_loss 10978115.06207985 val_loss 206933.05468750\n",
      "epoch 1895 train_loss 10978115.06205139 val_loss 206933.05468750\n",
      "epoch 1896 train_loss 10978115.06195045 val_loss 206933.05468750\n",
      "epoch 1897 train_loss 10978115.06184952 val_loss 206933.05468750\n",
      "epoch 1898 train_loss 10978115.06177071 val_loss 206933.05468750\n",
      "epoch 1899 train_loss 10978115.06167122 val_loss 206933.05468750\n",
      "epoch 1900 train_loss 10978115.06157631 val_loss 206933.05468750\n",
      "epoch 1901 train_loss 10978115.06149635 val_loss 206933.05468750\n",
      "epoch 1902 train_loss 10978115.06139381 val_loss 206933.05468750\n",
      "epoch 1903 train_loss 10978115.06130669 val_loss 206933.05468750\n",
      "epoch 1904 train_loss 10978115.06118042 val_loss 206933.05468750\n",
      "epoch 1905 train_loss 10978115.06109673 val_loss 206933.05468750\n",
      "epoch 1906 train_loss 10978115.06101875 val_loss 206933.05468750\n",
      "epoch 1907 train_loss 10978115.06094742 val_loss 206933.05468750\n",
      "epoch 1908 train_loss 10978115.06082802 val_loss 206933.05468750\n",
      "epoch 1909 train_loss 10978115.06073784 val_loss 206933.05468750\n",
      "epoch 1910 train_loss 10978115.06066338 val_loss 206933.05468750\n",
      "epoch 1911 train_loss 10978115.06058556 val_loss 206933.05468750\n",
      "epoch 1912 train_loss 10978115.06045349 val_loss 206933.05468750\n",
      "epoch 1913 train_loss 10978115.06038681 val_loss 206933.05468750\n",
      "epoch 1914 train_loss 10978115.06030113 val_loss 206933.05468750\n",
      "epoch 1915 train_loss 10978115.06020454 val_loss 206933.05468750\n",
      "epoch 1916 train_loss 10978115.06009788 val_loss 206933.05468750\n",
      "epoch 1917 train_loss 10978115.06000648 val_loss 206933.05468750\n",
      "epoch 1918 train_loss 10978115.05990837 val_loss 206933.05468750\n",
      "epoch 1919 train_loss 10978115.05981155 val_loss 206933.05468750\n",
      "epoch 1920 train_loss 10978115.05976051 val_loss 206933.05468750\n",
      "epoch 1921 train_loss 10978115.05965202 val_loss 206933.05468750\n",
      "epoch 1922 train_loss 10978115.05956627 val_loss 206933.05468750\n",
      "epoch 1923 train_loss 10978115.05951981 val_loss 206933.05468750\n",
      "epoch 1924 train_loss 10978115.05942497 val_loss 206933.05468750\n",
      "epoch 1925 train_loss 10978115.05932449 val_loss 206933.05468750\n",
      "epoch 1926 train_loss 10978115.05921356 val_loss 206933.05468750\n",
      "epoch 1927 train_loss 10978115.05911804 val_loss 206933.05468750\n",
      "epoch 1928 train_loss 10978115.05904579 val_loss 206933.05468750\n",
      "epoch 1929 train_loss 10978115.05894257 val_loss 206933.05468750\n",
      "epoch 1930 train_loss 10978115.05885551 val_loss 206933.05468750\n",
      "epoch 1931 train_loss 10978115.05876564 val_loss 206933.05468750\n",
      "epoch 1932 train_loss 10978115.05865944 val_loss 206933.05468750\n",
      "epoch 1933 train_loss 10978115.05856911 val_loss 206933.05468750\n",
      "epoch 1934 train_loss 10978115.05854149 val_loss 206933.07031250\n",
      "epoch 1935 train_loss 10978115.05847656 val_loss 206933.07031250\n",
      "epoch 1936 train_loss 10978115.05837486 val_loss 206933.07031250\n",
      "epoch 1937 train_loss 10978115.05833923 val_loss 206933.07031250\n",
      "epoch 1938 train_loss 10978115.05831848 val_loss 206933.07031250\n",
      "epoch 1939 train_loss 10978115.05824059 val_loss 206933.07031250\n",
      "epoch 1940 train_loss 10978115.05817398 val_loss 206933.07031250\n",
      "epoch 1941 train_loss 10978115.05808724 val_loss 206933.07031250\n",
      "epoch 1942 train_loss 10978115.05799583 val_loss 206933.07031250\n",
      "epoch 1943 train_loss 10978115.05787521 val_loss 206933.07031250\n",
      "epoch 1944 train_loss 10978115.05778870 val_loss 206933.07031250\n",
      "epoch 1945 train_loss 10978115.05771049 val_loss 206933.07031250\n",
      "epoch 1946 train_loss 10978115.05760902 val_loss 206933.07031250\n",
      "epoch 1947 train_loss 10978115.05752884 val_loss 206933.07031250\n",
      "epoch 1948 train_loss 10978115.05746452 val_loss 206933.07031250\n",
      "epoch 1949 train_loss 10978115.05737000 val_loss 206933.07031250\n",
      "epoch 1950 train_loss 10978115.05726196 val_loss 206933.07031250\n",
      "epoch 1951 train_loss 10978115.05716682 val_loss 206933.07031250\n",
      "epoch 1952 train_loss 10978115.05706833 val_loss 206933.07031250\n",
      "epoch 1953 train_loss 10978115.05699722 val_loss 206933.07031250\n",
      "epoch 1954 train_loss 10978115.05691200 val_loss 206933.07031250\n",
      "epoch 1955 train_loss 10978115.05683456 val_loss 206933.07031250\n",
      "epoch 1956 train_loss 10978115.05675430 val_loss 206933.07031250\n",
      "epoch 1957 train_loss 10978115.05664940 val_loss 206933.07031250\n",
      "epoch 1958 train_loss 10978115.05655998 val_loss 206933.07031250\n",
      "epoch 1959 train_loss 10978115.05646889 val_loss 206933.07031250\n",
      "epoch 1960 train_loss 10978115.05640510 val_loss 206933.07031250\n",
      "epoch 1961 train_loss 10978115.05631218 val_loss 206933.07031250\n",
      "epoch 1962 train_loss 10978115.05622513 val_loss 206933.07031250\n",
      "epoch 1963 train_loss 10978115.05612961 val_loss 206933.07031250\n",
      "epoch 1964 train_loss 10978115.05604042 val_loss 206933.07031250\n",
      "epoch 1965 train_loss 10978115.05596237 val_loss 206933.07031250\n",
      "epoch 1966 train_loss 10978115.05587463 val_loss 206933.07031250\n",
      "epoch 1967 train_loss 10978115.05576355 val_loss 206933.07031250\n",
      "epoch 1968 train_loss 10978115.05566589 val_loss 206933.07031250\n",
      "epoch 1969 train_loss 10978115.05561790 val_loss 206933.07031250\n",
      "epoch 1970 train_loss 10978115.05553268 val_loss 206933.07031250\n",
      "epoch 1971 train_loss 10978115.05545052 val_loss 206933.07031250\n",
      "epoch 1972 train_loss 10978115.05534790 val_loss 206933.07031250\n",
      "epoch 1973 train_loss 10978115.05535301 val_loss 206933.07031250\n",
      "epoch 1974 train_loss 10978115.05525330 val_loss 206933.07031250\n",
      "epoch 1975 train_loss 10978115.05515602 val_loss 206933.07031250\n",
      "epoch 1976 train_loss 10978115.05509407 val_loss 206933.07031250\n",
      "epoch 1977 train_loss 10978115.05500183 val_loss 206933.07031250\n",
      "epoch 1978 train_loss 10978115.05489723 val_loss 206933.07031250\n",
      "epoch 1979 train_loss 10978115.05480835 val_loss 206933.07031250\n",
      "epoch 1980 train_loss 10978115.05472084 val_loss 206933.07031250\n",
      "epoch 1981 train_loss 10978115.05468170 val_loss 206933.07031250\n",
      "epoch 1982 train_loss 10978115.05458489 val_loss 206933.07031250\n",
      "epoch 1983 train_loss 10978115.05452507 val_loss 206933.07031250\n",
      "epoch 1984 train_loss 10978115.05447952 val_loss 206933.07031250\n",
      "epoch 1985 train_loss 10978115.05437920 val_loss 206933.07031250\n",
      "epoch 1986 train_loss 10978115.05430153 val_loss 206933.07031250\n",
      "epoch 1987 train_loss 10978115.05419212 val_loss 206933.07031250\n",
      "epoch 1988 train_loss 10978115.05410790 val_loss 206933.07031250\n",
      "epoch 1989 train_loss 10978115.05401939 val_loss 206933.07031250\n",
      "epoch 1990 train_loss 10978115.05391205 val_loss 206933.07031250\n",
      "epoch 1991 train_loss 10978115.05383034 val_loss 206933.07031250\n",
      "epoch 1992 train_loss 10978115.05375778 val_loss 206933.07031250\n",
      "epoch 1993 train_loss 10978115.05371422 val_loss 206933.07031250\n",
      "epoch 1994 train_loss 10978115.05361656 val_loss 206933.07031250\n",
      "epoch 1995 train_loss 10978115.05352394 val_loss 206933.07031250\n",
      "epoch 1996 train_loss 10978115.05345345 val_loss 206933.07031250\n",
      "epoch 1997 train_loss 10978115.05336403 val_loss 206933.07031250\n",
      "epoch 1998 train_loss 10978115.05328117 val_loss 206933.07031250\n",
      "epoch 1999 train_loss 10978115.05318497 val_loss 206933.07031250\n",
      "epoch 2000 train_loss 10978115.05310532 val_loss 206933.07031250\n",
      "epoch 2001 train_loss 10978115.05303734 val_loss 206933.07031250\n",
      "epoch 2002 train_loss 10978115.05293190 val_loss 206933.07031250\n",
      "epoch 2003 train_loss 10978115.05290878 val_loss 206933.07031250\n",
      "epoch 2004 train_loss 10978115.05279533 val_loss 206933.07031250\n",
      "epoch 2005 train_loss 10978115.05272491 val_loss 206933.07031250\n",
      "epoch 2006 train_loss 10978115.05262711 val_loss 206933.07031250\n",
      "epoch 2007 train_loss 10978115.05253509 val_loss 206933.07031250\n",
      "epoch 2008 train_loss 10978115.05243775 val_loss 206933.07031250\n",
      "epoch 2009 train_loss 10978115.05234657 val_loss 206933.07031250\n",
      "epoch 2010 train_loss 10978115.05228470 val_loss 206933.07031250\n",
      "epoch 2011 train_loss 10978115.05218933 val_loss 206933.07031250\n",
      "epoch 2012 train_loss 10978115.05207977 val_loss 206933.07031250\n",
      "epoch 2013 train_loss 10978115.05201210 val_loss 206933.07031250\n",
      "epoch 2014 train_loss 10978115.05189064 val_loss 206933.07031250\n",
      "epoch 2015 train_loss 10978115.05180344 val_loss 206933.07031250\n",
      "epoch 2016 train_loss 10978115.05173302 val_loss 206933.07031250\n",
      "epoch 2017 train_loss 10978115.05163063 val_loss 206933.07031250\n",
      "epoch 2018 train_loss 10978115.05153458 val_loss 206933.07031250\n",
      "epoch 2019 train_loss 10978115.05144508 val_loss 206933.07031250\n",
      "epoch 2020 train_loss 10978115.05133720 val_loss 206933.07031250\n",
      "epoch 2021 train_loss 10978115.05131264 val_loss 206933.07031250\n",
      "epoch 2022 train_loss 10978115.05120613 val_loss 206933.07031250\n",
      "epoch 2023 train_loss 10978115.05110466 val_loss 206933.07031250\n",
      "epoch 2024 train_loss 10978115.05103119 val_loss 206933.07031250\n",
      "epoch 2025 train_loss 10978115.05093651 val_loss 206933.07031250\n",
      "epoch 2026 train_loss 10978115.05083542 val_loss 206933.07031250\n",
      "epoch 2027 train_loss 10978115.05074081 val_loss 206933.07031250\n",
      "epoch 2028 train_loss 10978115.05063934 val_loss 206933.07031250\n",
      "epoch 2029 train_loss 10978115.05054543 val_loss 206933.07031250\n",
      "epoch 2030 train_loss 10978115.05046188 val_loss 206933.07031250\n",
      "epoch 2031 train_loss 10978115.05036148 val_loss 206933.07031250\n",
      "epoch 2032 train_loss 10978115.05026649 val_loss 206933.07031250\n",
      "epoch 2033 train_loss 10978115.05017357 val_loss 206933.07031250\n",
      "epoch 2034 train_loss 10978115.05010147 val_loss 206933.07031250\n",
      "epoch 2035 train_loss 10978115.04999153 val_loss 206933.07031250\n",
      "epoch 2036 train_loss 10978115.04987946 val_loss 206933.07031250\n",
      "epoch 2037 train_loss 10978115.04981140 val_loss 206933.07031250\n",
      "epoch 2038 train_loss 10978115.04972008 val_loss 206933.07031250\n",
      "epoch 2039 train_loss 10978115.04961731 val_loss 206933.07031250\n",
      "epoch 2040 train_loss 10978115.04956505 val_loss 206933.07031250\n",
      "epoch 2041 train_loss 10978115.04947296 val_loss 206933.07031250\n",
      "epoch 2042 train_loss 10978115.04939514 val_loss 206933.07031250\n",
      "epoch 2043 train_loss 10978115.04931526 val_loss 206933.07031250\n",
      "epoch 2044 train_loss 10978115.04923103 val_loss 206933.07031250\n",
      "epoch 2045 train_loss 10978115.04914398 val_loss 206933.07031250\n",
      "epoch 2046 train_loss 10978115.04903763 val_loss 206933.07031250\n",
      "epoch 2047 train_loss 10978115.04899528 val_loss 206933.07031250\n",
      "epoch 2048 train_loss 10978115.04888779 val_loss 206933.07031250\n",
      "epoch 2049 train_loss 10978115.04881866 val_loss 206933.07031250\n",
      "epoch 2050 train_loss 10978115.04869469 val_loss 206933.07031250\n",
      "epoch 2051 train_loss 10978115.04862091 val_loss 206933.07031250\n",
      "epoch 2052 train_loss 10978115.04852066 val_loss 206933.07031250\n",
      "epoch 2053 train_loss 10978115.04842506 val_loss 206933.07031250\n",
      "epoch 2054 train_loss 10978115.04832748 val_loss 206933.07031250\n",
      "epoch 2055 train_loss 10978115.04830170 val_loss 206933.07031250\n",
      "epoch 2056 train_loss 10978115.04821526 val_loss 206933.07031250\n",
      "epoch 2057 train_loss 10978115.04812248 val_loss 206933.07031250\n",
      "epoch 2058 train_loss 10978115.04801163 val_loss 206933.07031250\n",
      "epoch 2059 train_loss 10978115.04791687 val_loss 206933.07031250\n",
      "epoch 2060 train_loss 10978115.04783524 val_loss 206933.07031250\n",
      "epoch 2061 train_loss 10978115.04777710 val_loss 206933.07031250\n",
      "epoch 2062 train_loss 10978115.04771751 val_loss 206933.07031250\n",
      "epoch 2063 train_loss 10978115.04762871 val_loss 206933.07031250\n",
      "epoch 2064 train_loss 10978115.04753235 val_loss 206933.07031250\n",
      "epoch 2065 train_loss 10978115.04741715 val_loss 206933.07031250\n",
      "epoch 2066 train_loss 10978115.04731842 val_loss 206933.07031250\n",
      "epoch 2067 train_loss 10978115.04726204 val_loss 206933.07031250\n",
      "epoch 2068 train_loss 10978115.04716835 val_loss 206933.07031250\n",
      "epoch 2069 train_loss 10978115.04710182 val_loss 206933.07031250\n",
      "epoch 2070 train_loss 10978115.04699417 val_loss 206933.07031250\n",
      "epoch 2071 train_loss 10978115.04690239 val_loss 206933.07031250\n",
      "epoch 2072 train_loss 10978115.04680931 val_loss 206933.07031250\n",
      "epoch 2073 train_loss 10978115.04670471 val_loss 206933.07031250\n",
      "epoch 2074 train_loss 10978115.04658737 val_loss 206933.07031250\n",
      "epoch 2075 train_loss 10978115.04650948 val_loss 206933.07031250\n",
      "epoch 2076 train_loss 10978115.04641548 val_loss 206933.07031250\n",
      "epoch 2077 train_loss 10978115.04631340 val_loss 206933.07031250\n",
      "epoch 2078 train_loss 10978115.04625145 val_loss 206933.07031250\n",
      "epoch 2079 train_loss 10978115.04616219 val_loss 206933.07031250\n",
      "epoch 2080 train_loss 10978115.04607803 val_loss 206933.07031250\n",
      "epoch 2081 train_loss 10978115.04596901 val_loss 206933.07031250\n",
      "epoch 2082 train_loss 10978115.04587929 val_loss 206933.07031250\n",
      "epoch 2083 train_loss 10978115.04576508 val_loss 206933.07031250\n",
      "epoch 2084 train_loss 10978115.04568031 val_loss 206933.07031250\n",
      "epoch 2085 train_loss 10978115.04558250 val_loss 206933.07031250\n",
      "epoch 2086 train_loss 10978115.04548950 val_loss 206933.07031250\n",
      "epoch 2087 train_loss 10978115.04561790 val_loss 206933.07031250\n",
      "epoch 2088 train_loss 10978115.04551766 val_loss 206933.07031250\n",
      "epoch 2089 train_loss 10978115.04542626 val_loss 206933.07031250\n",
      "epoch 2090 train_loss 10978115.04532898 val_loss 206933.07031250\n",
      "epoch 2091 train_loss 10978115.04525795 val_loss 206933.07031250\n",
      "epoch 2092 train_loss 10978115.04516037 val_loss 206933.07031250\n",
      "epoch 2093 train_loss 10978115.04508018 val_loss 206933.07031250\n",
      "epoch 2094 train_loss 10978115.04500511 val_loss 206933.07031250\n",
      "epoch 2095 train_loss 10978115.04489830 val_loss 206933.07031250\n",
      "epoch 2096 train_loss 10978115.04481499 val_loss 206933.07812500\n",
      "epoch 2097 train_loss 10978115.04470932 val_loss 206933.07812500\n",
      "epoch 2098 train_loss 10978115.04460159 val_loss 206933.07812500\n",
      "epoch 2099 train_loss 10978115.04451225 val_loss 206933.07812500\n",
      "epoch 2100 train_loss 10978115.04447273 val_loss 206933.07812500\n",
      "epoch 2101 train_loss 10978115.04438744 val_loss 206933.07812500\n",
      "epoch 2102 train_loss 10978115.04444412 val_loss 206933.07812500\n",
      "epoch 2103 train_loss 10978115.04435951 val_loss 206933.07812500\n",
      "epoch 2104 train_loss 10978115.04427216 val_loss 206933.07812500\n",
      "epoch 2105 train_loss 10978115.04416336 val_loss 206933.07812500\n",
      "epoch 2106 train_loss 10978115.04407723 val_loss 206933.07812500\n",
      "epoch 2107 train_loss 10978115.04397964 val_loss 206933.07812500\n",
      "epoch 2108 train_loss 10978115.04394341 val_loss 206933.07812500\n",
      "epoch 2109 train_loss 10978115.04383202 val_loss 206933.07812500\n",
      "epoch 2110 train_loss 10978115.04373688 val_loss 206933.07812500\n",
      "epoch 2111 train_loss 10978115.04364136 val_loss 206933.07812500\n",
      "epoch 2112 train_loss 10978115.04357987 val_loss 206933.07812500\n",
      "epoch 2113 train_loss 10978115.04349396 val_loss 206933.07812500\n",
      "epoch 2114 train_loss 10978115.04342606 val_loss 206933.07812500\n",
      "epoch 2115 train_loss 10978115.04338943 val_loss 206933.07812500\n",
      "epoch 2116 train_loss 10978115.04328911 val_loss 206933.07812500\n",
      "epoch 2117 train_loss 10978115.04320869 val_loss 206933.07812500\n",
      "epoch 2118 train_loss 10978115.04312027 val_loss 206933.07812500\n",
      "epoch 2119 train_loss 10978115.04303719 val_loss 206933.07812500\n",
      "epoch 2120 train_loss 10978115.04293045 val_loss 206933.07812500\n",
      "epoch 2121 train_loss 10978115.04284248 val_loss 206933.07812500\n",
      "epoch 2122 train_loss 10978115.04274040 val_loss 206933.07812500\n",
      "epoch 2123 train_loss 10978115.04265305 val_loss 206933.07812500\n",
      "epoch 2124 train_loss 10978115.04257393 val_loss 206933.07812500\n",
      "epoch 2125 train_loss 10978115.04249062 val_loss 206933.07812500\n",
      "epoch 2126 train_loss 10978115.04238113 val_loss 206933.07812500\n",
      "epoch 2127 train_loss 10978115.04231972 val_loss 206933.07812500\n",
      "epoch 2128 train_loss 10978115.04223000 val_loss 206933.07812500\n",
      "epoch 2129 train_loss 10978115.04214096 val_loss 206933.07812500\n",
      "epoch 2130 train_loss 10978115.04204704 val_loss 206933.07812500\n",
      "epoch 2131 train_loss 10978115.04197807 val_loss 206933.07812500\n",
      "epoch 2132 train_loss 10978115.04188507 val_loss 206933.07812500\n",
      "epoch 2133 train_loss 10978115.04179367 val_loss 206933.07812500\n",
      "epoch 2134 train_loss 10978115.04170647 val_loss 206933.07812500\n",
      "epoch 2135 train_loss 10978115.04162796 val_loss 206933.07812500\n",
      "epoch 2136 train_loss 10978115.04153671 val_loss 206933.07812500\n",
      "epoch 2137 train_loss 10978115.04141365 val_loss 206933.07812500\n",
      "epoch 2138 train_loss 10978115.04133148 val_loss 206933.07812500\n",
      "epoch 2139 train_loss 10978115.04128166 val_loss 206933.07812500\n",
      "epoch 2140 train_loss 10978115.04117447 val_loss 206933.07812500\n",
      "epoch 2141 train_loss 10978115.04114075 val_loss 206933.07812500\n",
      "epoch 2142 train_loss 10978115.04105225 val_loss 206933.07812500\n",
      "epoch 2143 train_loss 10978115.04094452 val_loss 206933.07812500\n",
      "epoch 2144 train_loss 10978115.04086288 val_loss 206933.07812500\n",
      "epoch 2145 train_loss 10978115.04075165 val_loss 206933.07812500\n",
      "epoch 2146 train_loss 10978115.04066429 val_loss 206933.07812500\n",
      "epoch 2147 train_loss 10978115.04060738 val_loss 206933.07812500\n",
      "epoch 2148 train_loss 10978115.04049393 val_loss 206933.07812500\n",
      "epoch 2149 train_loss 10978115.04040291 val_loss 206933.07812500\n",
      "epoch 2150 train_loss 10978115.04030800 val_loss 206933.07812500\n",
      "epoch 2151 train_loss 10978115.04021370 val_loss 206933.07812500\n",
      "epoch 2152 train_loss 10978115.04018013 val_loss 206933.07812500\n",
      "epoch 2153 train_loss 10978115.04010063 val_loss 206933.07812500\n",
      "epoch 2154 train_loss 10978115.04008636 val_loss 206933.07812500\n",
      "epoch 2155 train_loss 10978115.03997818 val_loss 206933.07812500\n",
      "epoch 2156 train_loss 10978115.03989685 val_loss 206933.07812500\n",
      "epoch 2157 train_loss 10978115.03980713 val_loss 206933.07812500\n",
      "epoch 2158 train_loss 10978115.03972504 val_loss 206933.07812500\n",
      "epoch 2159 train_loss 10978115.03961922 val_loss 206933.07812500\n",
      "epoch 2160 train_loss 10978115.03956451 val_loss 206933.07812500\n",
      "epoch 2161 train_loss 10978115.03947151 val_loss 206933.07812500\n",
      "epoch 2162 train_loss 10978115.03935822 val_loss 206933.07812500\n",
      "epoch 2163 train_loss 10978115.03924690 val_loss 206933.07812500\n",
      "epoch 2164 train_loss 10978115.03916367 val_loss 206933.07812500\n",
      "epoch 2165 train_loss 10978115.03906624 val_loss 206933.07812500\n",
      "epoch 2166 train_loss 10978115.03899033 val_loss 206933.07812500\n",
      "epoch 2167 train_loss 10978115.03889313 val_loss 206933.07812500\n",
      "epoch 2168 train_loss 10978115.03885872 val_loss 206933.07812500\n",
      "epoch 2169 train_loss 10978115.03877396 val_loss 206933.07812500\n",
      "epoch 2170 train_loss 10978115.03868423 val_loss 206933.07812500\n",
      "epoch 2171 train_loss 10978115.03860130 val_loss 206933.07812500\n",
      "epoch 2172 train_loss 10978115.03850197 val_loss 206933.07812500\n",
      "epoch 2173 train_loss 10978115.03841118 val_loss 206933.07812500\n",
      "epoch 2174 train_loss 10978115.03832298 val_loss 206933.07812500\n",
      "epoch 2175 train_loss 10978115.03822685 val_loss 206933.07812500\n",
      "epoch 2176 train_loss 10978115.03814026 val_loss 206933.07812500\n",
      "epoch 2177 train_loss 10978115.03804504 val_loss 206933.07812500\n",
      "epoch 2178 train_loss 10978115.03794106 val_loss 206933.07812500\n",
      "epoch 2179 train_loss 10978115.03790817 val_loss 206933.07812500\n",
      "epoch 2180 train_loss 10978115.03778953 val_loss 206933.07812500\n",
      "epoch 2181 train_loss 10978115.03770935 val_loss 206933.07812500\n",
      "epoch 2182 train_loss 10978115.03760506 val_loss 206933.07812500\n",
      "epoch 2183 train_loss 10978115.03752419 val_loss 206933.07812500\n",
      "epoch 2184 train_loss 10978115.03744591 val_loss 206933.07812500\n",
      "epoch 2185 train_loss 10978115.03738136 val_loss 206933.07812500\n",
      "epoch 2186 train_loss 10978115.03728889 val_loss 206933.07812500\n",
      "epoch 2187 train_loss 10978115.03720558 val_loss 206933.07812500\n",
      "epoch 2188 train_loss 10978115.03710480 val_loss 206933.07812500\n",
      "epoch 2189 train_loss 10978115.03701263 val_loss 206933.07812500\n",
      "epoch 2190 train_loss 10978115.03693184 val_loss 206933.07812500\n",
      "epoch 2191 train_loss 10978115.03691002 val_loss 206933.07812500\n",
      "epoch 2192 train_loss 10978115.03681702 val_loss 206933.07812500\n",
      "epoch 2193 train_loss 10978115.03673752 val_loss 206933.07812500\n",
      "epoch 2194 train_loss 10978115.03665634 val_loss 206933.07812500\n",
      "epoch 2195 train_loss 10978115.03655701 val_loss 206933.07812500\n",
      "epoch 2196 train_loss 10978115.03645241 val_loss 206933.07812500\n",
      "epoch 2197 train_loss 10978115.03638481 val_loss 206933.07812500\n",
      "epoch 2198 train_loss 10978115.03630707 val_loss 206933.07812500\n",
      "epoch 2199 train_loss 10978115.03621300 val_loss 206933.07812500\n",
      "epoch 2200 train_loss 10978115.03612244 val_loss 206933.07812500\n",
      "epoch 2201 train_loss 10978115.03601936 val_loss 206933.07812500\n",
      "epoch 2202 train_loss 10978115.03594536 val_loss 206933.07812500\n",
      "epoch 2203 train_loss 10978115.03587051 val_loss 206933.07812500\n",
      "epoch 2204 train_loss 10978115.03577164 val_loss 206933.07812500\n",
      "epoch 2205 train_loss 10978115.03569351 val_loss 206933.07812500\n",
      "epoch 2206 train_loss 10978115.03558235 val_loss 206933.07812500\n",
      "epoch 2207 train_loss 10978115.03552528 val_loss 206933.07812500\n",
      "epoch 2208 train_loss 10978115.03541634 val_loss 206933.07812500\n",
      "epoch 2209 train_loss 10978115.03532539 val_loss 206933.07812500\n",
      "epoch 2210 train_loss 10978115.03523956 val_loss 206933.07812500\n",
      "epoch 2211 train_loss 10978115.03513397 val_loss 206933.07812500\n",
      "epoch 2212 train_loss 10978115.03502884 val_loss 206933.07812500\n",
      "epoch 2213 train_loss 10978115.03495857 val_loss 206933.07812500\n",
      "epoch 2214 train_loss 10978115.03487701 val_loss 206933.07812500\n",
      "epoch 2215 train_loss 10978115.03476700 val_loss 206933.07812500\n",
      "epoch 2216 train_loss 10978115.03467148 val_loss 206933.07812500\n",
      "epoch 2217 train_loss 10978115.03460190 val_loss 206933.07812500\n",
      "epoch 2218 train_loss 10978115.03450180 val_loss 206933.07812500\n",
      "epoch 2219 train_loss 10978115.03445793 val_loss 206933.07812500\n",
      "epoch 2220 train_loss 10978115.03435509 val_loss 206933.07812500\n",
      "epoch 2221 train_loss 10978115.03426735 val_loss 206933.07812500\n",
      "epoch 2222 train_loss 10978115.03415520 val_loss 206933.07812500\n",
      "epoch 2223 train_loss 10978115.03412956 val_loss 206933.07812500\n",
      "epoch 2224 train_loss 10978115.03407989 val_loss 206933.07812500\n",
      "epoch 2225 train_loss 10978115.03399315 val_loss 206933.07812500\n",
      "epoch 2226 train_loss 10978115.03388672 val_loss 206933.07812500\n",
      "epoch 2227 train_loss 10978115.03381027 val_loss 206933.07812500\n",
      "epoch 2228 train_loss 10978115.03371903 val_loss 206933.07812500\n",
      "epoch 2229 train_loss 10978115.03365944 val_loss 206933.07812500\n",
      "epoch 2230 train_loss 10978115.03355866 val_loss 206933.07812500\n",
      "epoch 2231 train_loss 10978115.03346741 val_loss 206933.07812500\n",
      "epoch 2232 train_loss 10978115.03338577 val_loss 206933.07812500\n",
      "epoch 2233 train_loss 10978115.03328774 val_loss 206933.07812500\n",
      "epoch 2234 train_loss 10978115.03325256 val_loss 206933.07812500\n",
      "epoch 2235 train_loss 10978115.03315697 val_loss 206933.07812500\n",
      "epoch 2236 train_loss 10978115.03305306 val_loss 206933.07812500\n",
      "epoch 2237 train_loss 10978115.03297813 val_loss 206933.07812500\n",
      "epoch 2238 train_loss 10978115.03285866 val_loss 206933.07812500\n",
      "epoch 2239 train_loss 10978115.03277458 val_loss 206933.07812500\n",
      "epoch 2240 train_loss 10978115.03266319 val_loss 206933.07812500\n",
      "epoch 2241 train_loss 10978115.03257378 val_loss 206933.07812500\n",
      "epoch 2242 train_loss 10978115.03249718 val_loss 206933.07812500\n",
      "epoch 2243 train_loss 10978115.03240555 val_loss 206933.07812500\n",
      "epoch 2244 train_loss 10978115.03232948 val_loss 206933.07812500\n",
      "epoch 2245 train_loss 10978115.03224678 val_loss 206933.07812500\n",
      "epoch 2246 train_loss 10978115.03215286 val_loss 206933.07812500\n",
      "epoch 2247 train_loss 10978115.03202522 val_loss 206933.07812500\n",
      "epoch 2248 train_loss 10978115.03195442 val_loss 206933.07812500\n",
      "epoch 2249 train_loss 10978115.03187782 val_loss 206933.07812500\n",
      "epoch 2250 train_loss 10978115.03180939 val_loss 206933.07812500\n",
      "epoch 2251 train_loss 10978115.03172676 val_loss 206933.07812500\n",
      "epoch 2252 train_loss 10978115.03162872 val_loss 206933.07812500\n",
      "epoch 2253 train_loss 10978115.03155807 val_loss 206933.07812500\n",
      "epoch 2254 train_loss 10978115.03146584 val_loss 206933.07812500\n",
      "epoch 2255 train_loss 10978115.03134804 val_loss 206933.07812500\n",
      "epoch 2256 train_loss 10978115.03126038 val_loss 206933.07812500\n",
      "epoch 2257 train_loss 10978115.03115623 val_loss 206933.07812500\n",
      "epoch 2258 train_loss 10978115.03106140 val_loss 206933.07812500\n",
      "epoch 2259 train_loss 10978115.03097534 val_loss 206933.07812500\n",
      "epoch 2260 train_loss 10978115.03088814 val_loss 206933.07812500\n",
      "epoch 2261 train_loss 10978115.03081902 val_loss 206933.07812500\n",
      "epoch 2262 train_loss 10978115.03073357 val_loss 206933.07812500\n",
      "epoch 2263 train_loss 10978115.03063515 val_loss 206933.07812500\n",
      "epoch 2264 train_loss 10978115.03054474 val_loss 206933.07812500\n",
      "epoch 2265 train_loss 10978115.03045433 val_loss 206933.07812500\n",
      "epoch 2266 train_loss 10978115.03037392 val_loss 206933.07812500\n",
      "epoch 2267 train_loss 10978115.03027954 val_loss 206933.07812500\n",
      "epoch 2268 train_loss 10978115.03020782 val_loss 206933.07812500\n",
      "epoch 2269 train_loss 10978115.03010101 val_loss 206933.07812500\n",
      "epoch 2270 train_loss 10978115.03002724 val_loss 206933.07812500\n",
      "epoch 2271 train_loss 10978115.02994141 val_loss 206933.07812500\n",
      "epoch 2272 train_loss 10978115.02984985 val_loss 206933.07812500\n",
      "epoch 2273 train_loss 10978115.02978912 val_loss 206933.07812500\n",
      "epoch 2274 train_loss 10978115.02971329 val_loss 206933.07812500\n",
      "epoch 2275 train_loss 10978115.02962738 val_loss 206933.07812500\n",
      "epoch 2276 train_loss 10978115.02955551 val_loss 206933.07812500\n",
      "epoch 2277 train_loss 10978115.02944702 val_loss 206933.07812500\n",
      "epoch 2278 train_loss 10978115.02933136 val_loss 206933.07812500\n",
      "epoch 2279 train_loss 10978115.02923515 val_loss 206933.07812500\n",
      "epoch 2280 train_loss 10978115.02923836 val_loss 206933.07812500\n",
      "epoch 2281 train_loss 10978115.02914650 val_loss 206933.07812500\n",
      "epoch 2282 train_loss 10978115.02902260 val_loss 206933.07812500\n",
      "epoch 2283 train_loss 10978115.02900963 val_loss 206933.07812500\n",
      "epoch 2284 train_loss 10978115.02892181 val_loss 206933.07812500\n",
      "epoch 2285 train_loss 10978115.02882286 val_loss 206933.07812500\n",
      "epoch 2286 train_loss 10978115.02871643 val_loss 206933.07812500\n",
      "epoch 2287 train_loss 10978115.02863541 val_loss 206933.07812500\n",
      "epoch 2288 train_loss 10978115.02856133 val_loss 206933.07812500\n",
      "epoch 2289 train_loss 10978115.02846428 val_loss 206933.07812500\n",
      "epoch 2290 train_loss 10978115.02839714 val_loss 206933.07812500\n",
      "epoch 2291 train_loss 10978115.02829735 val_loss 206933.07812500\n",
      "epoch 2292 train_loss 10978115.02822731 val_loss 206933.07812500\n",
      "epoch 2293 train_loss 10978115.02812767 val_loss 206933.07812500\n",
      "epoch 2294 train_loss 10978115.02802048 val_loss 206933.07812500\n",
      "epoch 2295 train_loss 10978115.02792488 val_loss 206933.07812500\n",
      "epoch 2296 train_loss 10978115.02786369 val_loss 206933.07812500\n",
      "epoch 2297 train_loss 10978115.02777702 val_loss 206933.07812500\n",
      "epoch 2298 train_loss 10978115.02768623 val_loss 206933.07812500\n",
      "epoch 2299 train_loss 10978115.02759880 val_loss 206933.07812500\n",
      "epoch 2300 train_loss 10978115.02751129 val_loss 206933.07812500\n",
      "epoch 2301 train_loss 10978115.02743996 val_loss 206933.07812500\n",
      "epoch 2302 train_loss 10978115.02734833 val_loss 206933.07812500\n",
      "epoch 2303 train_loss 10978115.02723274 val_loss 206933.07812500\n",
      "epoch 2304 train_loss 10978115.02715874 val_loss 206933.07812500\n",
      "epoch 2305 train_loss 10978115.02706123 val_loss 206933.07812500\n",
      "epoch 2306 train_loss 10978115.02699768 val_loss 206933.07812500\n",
      "epoch 2307 train_loss 10978115.02688232 val_loss 206933.07812500\n",
      "epoch 2308 train_loss 10978115.02683113 val_loss 206933.07812500\n",
      "epoch 2309 train_loss 10978115.02674690 val_loss 206933.07812500\n",
      "epoch 2310 train_loss 10978115.02665283 val_loss 206933.07812500\n",
      "epoch 2311 train_loss 10978115.02657967 val_loss 206933.07812500\n",
      "epoch 2312 train_loss 10978115.02647179 val_loss 206933.07812500\n",
      "epoch 2313 train_loss 10978115.02637054 val_loss 206933.07812500\n",
      "epoch 2314 train_loss 10978115.02628914 val_loss 206933.07812500\n",
      "epoch 2315 train_loss 10978115.02621193 val_loss 206933.07812500\n",
      "epoch 2316 train_loss 10978115.02613602 val_loss 206933.07812500\n",
      "epoch 2317 train_loss 10978115.02602257 val_loss 206933.07812500\n",
      "epoch 2318 train_loss 10978115.02593620 val_loss 206933.07812500\n",
      "epoch 2319 train_loss 10978115.02584114 val_loss 206933.07812500\n",
      "epoch 2320 train_loss 10978115.02574524 val_loss 206933.07812500\n",
      "epoch 2321 train_loss 10978115.02565010 val_loss 206933.07812500\n",
      "epoch 2322 train_loss 10978115.02554604 val_loss 206933.07812500\n",
      "epoch 2323 train_loss 10978115.02546616 val_loss 206933.07812500\n",
      "epoch 2324 train_loss 10978115.02536697 val_loss 206933.07812500\n",
      "epoch 2325 train_loss 10978115.02528008 val_loss 206933.07812500\n",
      "epoch 2326 train_loss 10978115.02518883 val_loss 206933.07812500\n",
      "epoch 2327 train_loss 10978115.02509964 val_loss 206933.07812500\n",
      "epoch 2328 train_loss 10978115.02504112 val_loss 206933.07812500\n",
      "epoch 2329 train_loss 10978115.02494621 val_loss 206933.07812500\n",
      "epoch 2330 train_loss 10978115.02483017 val_loss 206933.07812500\n",
      "epoch 2331 train_loss 10978115.02475777 val_loss 206933.07812500\n",
      "epoch 2332 train_loss 10978115.02466225 val_loss 206933.07812500\n",
      "epoch 2333 train_loss 10978115.02457176 val_loss 206933.07812500\n",
      "epoch 2334 train_loss 10978115.02450012 val_loss 206933.07812500\n",
      "epoch 2335 train_loss 10978115.02439713 val_loss 206933.09375000\n",
      "epoch 2336 train_loss 10978115.02430290 val_loss 206933.09375000\n",
      "epoch 2337 train_loss 10978115.02424133 val_loss 206933.09375000\n",
      "epoch 2338 train_loss 10978115.02413460 val_loss 206933.09375000\n",
      "epoch 2339 train_loss 10978115.02405594 val_loss 206933.09375000\n",
      "epoch 2340 train_loss 10978115.02394463 val_loss 206933.09375000\n",
      "epoch 2341 train_loss 10978115.02386429 val_loss 206933.09375000\n",
      "epoch 2342 train_loss 10978115.02376160 val_loss 206933.09375000\n",
      "epoch 2343 train_loss 10978115.02366600 val_loss 206933.09375000\n",
      "epoch 2344 train_loss 10978115.02358482 val_loss 206933.09375000\n",
      "epoch 2345 train_loss 10978115.02350838 val_loss 206933.09375000\n",
      "epoch 2346 train_loss 10978115.02339729 val_loss 206933.09375000\n",
      "epoch 2347 train_loss 10978115.02338394 val_loss 206933.09375000\n",
      "epoch 2348 train_loss 10978115.02328377 val_loss 206933.09375000\n",
      "epoch 2349 train_loss 10978115.02318108 val_loss 206933.09375000\n",
      "epoch 2350 train_loss 10978115.02308464 val_loss 206933.09375000\n",
      "epoch 2351 train_loss 10978115.02300964 val_loss 206933.09375000\n",
      "epoch 2352 train_loss 10978115.02294022 val_loss 206933.09375000\n",
      "epoch 2353 train_loss 10978115.02282318 val_loss 206933.09375000\n",
      "epoch 2354 train_loss 10978115.02274292 val_loss 206933.09375000\n",
      "epoch 2355 train_loss 10978115.02264725 val_loss 206933.09375000\n",
      "epoch 2356 train_loss 10978115.02255707 val_loss 206933.09375000\n",
      "epoch 2357 train_loss 10978115.02248161 val_loss 206933.09375000\n",
      "epoch 2358 train_loss 10978115.02237266 val_loss 206933.09375000\n",
      "epoch 2359 train_loss 10978115.02227165 val_loss 206933.09375000\n",
      "epoch 2360 train_loss 10978115.02219673 val_loss 206933.09375000\n",
      "epoch 2361 train_loss 10978115.02209480 val_loss 206933.09375000\n",
      "epoch 2362 train_loss 10978115.02206375 val_loss 206933.09375000\n",
      "epoch 2363 train_loss 10978115.02194412 val_loss 206933.09375000\n",
      "epoch 2364 train_loss 10978115.02185455 val_loss 206933.09375000\n",
      "epoch 2365 train_loss 10978115.02178207 val_loss 206933.09375000\n",
      "epoch 2366 train_loss 10978115.02174614 val_loss 206933.09375000\n",
      "epoch 2367 train_loss 10978115.02171547 val_loss 206933.09375000\n",
      "epoch 2368 train_loss 10978115.02162125 val_loss 206933.09375000\n",
      "epoch 2369 train_loss 10978115.02152519 val_loss 206933.09375000\n",
      "epoch 2370 train_loss 10978115.02144836 val_loss 206933.09375000\n",
      "epoch 2371 train_loss 10978115.02134300 val_loss 206933.09375000\n",
      "epoch 2372 train_loss 10978115.02124443 val_loss 206933.09375000\n",
      "epoch 2373 train_loss 10978115.02114250 val_loss 206933.09375000\n",
      "epoch 2374 train_loss 10978115.02108627 val_loss 206933.09375000\n",
      "epoch 2375 train_loss 10978115.02101280 val_loss 206933.09375000\n",
      "epoch 2376 train_loss 10978115.02092171 val_loss 206933.09375000\n",
      "epoch 2377 train_loss 10978115.02083412 val_loss 206933.09375000\n",
      "epoch 2378 train_loss 10978115.02073166 val_loss 206933.09375000\n",
      "epoch 2379 train_loss 10978115.02063515 val_loss 206933.09375000\n",
      "epoch 2380 train_loss 10978115.02054268 val_loss 206933.09375000\n",
      "epoch 2381 train_loss 10978115.02046333 val_loss 206933.09375000\n",
      "epoch 2382 train_loss 10978115.02042076 val_loss 206933.09375000\n",
      "epoch 2383 train_loss 10978115.02035843 val_loss 206933.09375000\n",
      "epoch 2384 train_loss 10978115.02026154 val_loss 206933.09375000\n",
      "epoch 2385 train_loss 10978115.02017387 val_loss 206933.09375000\n",
      "epoch 2386 train_loss 10978115.02008339 val_loss 206933.09375000\n",
      "epoch 2387 train_loss 10978115.02000252 val_loss 206933.09375000\n",
      "epoch 2388 train_loss 10978115.01998413 val_loss 206933.09375000\n",
      "epoch 2389 train_loss 10978115.01992271 val_loss 206933.09375000\n",
      "epoch 2390 train_loss 10978115.01983612 val_loss 206933.09375000\n",
      "epoch 2391 train_loss 10978115.01978241 val_loss 206933.09375000\n",
      "epoch 2392 train_loss 10978115.01967911 val_loss 206933.09375000\n",
      "epoch 2393 train_loss 10978115.01960098 val_loss 206933.09375000\n",
      "epoch 2394 train_loss 10978115.01952255 val_loss 206933.09375000\n",
      "epoch 2395 train_loss 10978115.01942734 val_loss 206933.09375000\n",
      "epoch 2396 train_loss 10978115.01930923 val_loss 206933.09375000\n",
      "epoch 2397 train_loss 10978115.01929535 val_loss 206933.09375000\n",
      "epoch 2398 train_loss 10978115.01921776 val_loss 206933.09375000\n",
      "epoch 2399 train_loss 10978115.01912491 val_loss 206933.09375000\n",
      "epoch 2400 train_loss 10978115.01903603 val_loss 206933.09375000\n",
      "epoch 2401 train_loss 10978115.01894066 val_loss 206933.09375000\n",
      "epoch 2402 train_loss 10978115.01884254 val_loss 206933.09375000\n",
      "epoch 2403 train_loss 10978115.01877274 val_loss 206933.09375000\n",
      "epoch 2404 train_loss 10978115.01868622 val_loss 206933.09375000\n",
      "epoch 2405 train_loss 10978115.01863548 val_loss 206933.09375000\n",
      "epoch 2406 train_loss 10978115.01853607 val_loss 206933.09375000\n",
      "epoch 2407 train_loss 10978115.01843338 val_loss 206933.09375000\n",
      "epoch 2408 train_loss 10978115.01834526 val_loss 206933.09375000\n",
      "epoch 2409 train_loss 10978115.01825943 val_loss 206933.09375000\n",
      "epoch 2410 train_loss 10978115.01815498 val_loss 206933.09375000\n",
      "epoch 2411 train_loss 10978115.01810646 val_loss 206933.09375000\n",
      "epoch 2412 train_loss 10978115.01801674 val_loss 206933.09375000\n",
      "epoch 2413 train_loss 10978115.01794014 val_loss 206933.09375000\n",
      "epoch 2414 train_loss 10978115.01784088 val_loss 206933.09375000\n",
      "epoch 2415 train_loss 10978115.01775474 val_loss 206933.09375000\n",
      "epoch 2416 train_loss 10978115.01765320 val_loss 206933.09375000\n",
      "epoch 2417 train_loss 10978115.01756859 val_loss 206933.09375000\n",
      "epoch 2418 train_loss 10978115.01746345 val_loss 206933.09375000\n",
      "epoch 2419 train_loss 10978115.01737549 val_loss 206933.09375000\n",
      "epoch 2420 train_loss 10978115.01729797 val_loss 206933.09375000\n",
      "epoch 2421 train_loss 10978115.01718376 val_loss 206933.09375000\n",
      "epoch 2422 train_loss 10978115.01708534 val_loss 206933.09375000\n",
      "epoch 2423 train_loss 10978115.01703972 val_loss 206933.09375000\n",
      "epoch 2424 train_loss 10978115.01692368 val_loss 206933.09375000\n",
      "epoch 2425 train_loss 10978115.01686165 val_loss 206933.09375000\n",
      "epoch 2426 train_loss 10978115.01676483 val_loss 206933.09375000\n",
      "epoch 2427 train_loss 10978115.01668945 val_loss 206933.09375000\n",
      "epoch 2428 train_loss 10978115.01662407 val_loss 206933.09375000\n",
      "epoch 2429 train_loss 10978115.01654282 val_loss 206933.09375000\n",
      "epoch 2430 train_loss 10978115.01643822 val_loss 206933.09375000\n",
      "epoch 2431 train_loss 10978115.01646278 val_loss 206933.09375000\n",
      "epoch 2432 train_loss 10978115.01633575 val_loss 206933.09375000\n",
      "epoch 2433 train_loss 10978115.01624771 val_loss 206933.09375000\n",
      "epoch 2434 train_loss 10978115.01616379 val_loss 206933.09375000\n",
      "epoch 2435 train_loss 10978115.01605873 val_loss 206933.09375000\n",
      "epoch 2436 train_loss 10978115.01597206 val_loss 206933.09375000\n",
      "epoch 2437 train_loss 10978115.01587692 val_loss 206933.09375000\n",
      "epoch 2438 train_loss 10978115.01578392 val_loss 206933.09375000\n",
      "epoch 2439 train_loss 10978115.01570228 val_loss 206933.09375000\n",
      "epoch 2440 train_loss 10978115.01561401 val_loss 206933.09375000\n",
      "epoch 2441 train_loss 10978115.01556229 val_loss 206933.09375000\n",
      "epoch 2442 train_loss 10978115.01546562 val_loss 206933.09375000\n",
      "epoch 2443 train_loss 10978115.01539726 val_loss 206933.09375000\n",
      "epoch 2444 train_loss 10978115.01529488 val_loss 206933.09375000\n",
      "epoch 2445 train_loss 10978115.01521904 val_loss 206933.09375000\n",
      "epoch 2446 train_loss 10978115.01510155 val_loss 206933.09375000\n",
      "epoch 2447 train_loss 10978115.01501877 val_loss 206933.09375000\n",
      "epoch 2448 train_loss 10978115.01492233 val_loss 206933.09375000\n",
      "epoch 2449 train_loss 10978115.01481888 val_loss 206933.09375000\n",
      "epoch 2450 train_loss 10978115.01473061 val_loss 206933.09375000\n",
      "epoch 2451 train_loss 10978115.01465263 val_loss 206933.09375000\n",
      "epoch 2452 train_loss 10978115.01457138 val_loss 206933.09375000\n",
      "epoch 2453 train_loss 10978115.01451248 val_loss 206933.09375000\n",
      "epoch 2454 train_loss 10978115.01442184 val_loss 206933.09375000\n",
      "epoch 2455 train_loss 10978115.01433815 val_loss 206933.09375000\n",
      "epoch 2456 train_loss 10978115.01424965 val_loss 206933.09375000\n",
      "epoch 2457 train_loss 10978115.01414368 val_loss 206933.09375000\n",
      "epoch 2458 train_loss 10978115.01404701 val_loss 206933.09375000\n",
      "epoch 2459 train_loss 10978115.01396439 val_loss 206933.09375000\n",
      "epoch 2460 train_loss 10978115.01386574 val_loss 206933.09375000\n",
      "epoch 2461 train_loss 10978115.01377518 val_loss 206933.09375000\n",
      "epoch 2462 train_loss 10978115.01367668 val_loss 206933.09375000\n",
      "epoch 2463 train_loss 10978115.01361656 val_loss 206933.09375000\n",
      "epoch 2464 train_loss 10978115.01356430 val_loss 206933.09375000\n",
      "epoch 2465 train_loss 10978115.01347382 val_loss 206933.09375000\n",
      "epoch 2466 train_loss 10978115.01338226 val_loss 206933.09375000\n",
      "epoch 2467 train_loss 10978115.01331711 val_loss 206933.09375000\n",
      "epoch 2468 train_loss 10978115.01320045 val_loss 206933.09375000\n",
      "epoch 2469 train_loss 10978115.01315659 val_loss 206933.09375000\n",
      "epoch 2470 train_loss 10978115.01309181 val_loss 206933.09375000\n",
      "epoch 2471 train_loss 10978115.01298927 val_loss 206933.09375000\n",
      "epoch 2472 train_loss 10978115.01289993 val_loss 206933.09375000\n",
      "epoch 2473 train_loss 10978115.01281403 val_loss 206933.09375000\n",
      "epoch 2474 train_loss 10978115.01271462 val_loss 206933.09375000\n",
      "epoch 2475 train_loss 10978115.01261200 val_loss 206933.09375000\n",
      "epoch 2476 train_loss 10978115.01251724 val_loss 206933.09375000\n",
      "epoch 2477 train_loss 10978115.01243759 val_loss 206933.09375000\n",
      "epoch 2478 train_loss 10978115.01232758 val_loss 206933.09375000\n",
      "epoch 2479 train_loss 10978115.01224731 val_loss 206933.09375000\n",
      "epoch 2480 train_loss 10978115.01217941 val_loss 206933.09375000\n",
      "epoch 2481 train_loss 10978115.01212265 val_loss 206933.09375000\n",
      "epoch 2482 train_loss 10978115.01203415 val_loss 206933.09375000\n",
      "epoch 2483 train_loss 10978115.01196137 val_loss 206933.09375000\n",
      "epoch 2484 train_loss 10978115.01186943 val_loss 206933.09375000\n",
      "epoch 2485 train_loss 10978115.01177147 val_loss 206933.09375000\n",
      "epoch 2486 train_loss 10978115.01169846 val_loss 206933.09375000\n",
      "epoch 2487 train_loss 10978115.01159851 val_loss 206933.09375000\n",
      "epoch 2488 train_loss 10978115.01150200 val_loss 206933.09375000\n",
      "epoch 2489 train_loss 10978115.01138039 val_loss 206933.09375000\n",
      "epoch 2490 train_loss 10978115.01130531 val_loss 206933.09375000\n",
      "epoch 2491 train_loss 10978115.01124985 val_loss 206933.09375000\n",
      "epoch 2492 train_loss 10978115.01118179 val_loss 206933.09375000\n",
      "epoch 2493 train_loss 10978115.01108215 val_loss 206933.09375000\n",
      "epoch 2494 train_loss 10978115.01098396 val_loss 206933.09375000\n",
      "epoch 2495 train_loss 10978115.01090233 val_loss 206933.09375000\n",
      "epoch 2496 train_loss 10978115.01079971 val_loss 206933.09375000\n",
      "epoch 2497 train_loss 10978115.01071289 val_loss 206933.09375000\n",
      "epoch 2498 train_loss 10978115.01062645 val_loss 206933.09375000\n",
      "epoch 2499 train_loss 10978115.01056114 val_loss 206933.09375000\n",
      "epoch 2500 train_loss 10978115.01046349 val_loss 206933.09375000\n",
      "epoch 2501 train_loss 10978115.01037674 val_loss 206933.09375000\n",
      "epoch 2502 train_loss 10978115.01030769 val_loss 206933.09375000\n",
      "epoch 2503 train_loss 10978115.01019951 val_loss 206933.09375000\n",
      "epoch 2504 train_loss 10978115.01010620 val_loss 206933.09375000\n",
      "epoch 2505 train_loss 10978115.01003860 val_loss 206933.09375000\n",
      "epoch 2506 train_loss 10978115.00996849 val_loss 206933.09375000\n",
      "epoch 2507 train_loss 10978115.00986969 val_loss 206933.09375000\n",
      "epoch 2508 train_loss 10978115.00976395 val_loss 206933.09375000\n",
      "epoch 2509 train_loss 10978115.00967415 val_loss 206933.09375000\n",
      "epoch 2510 train_loss 10978115.00957420 val_loss 206933.09375000\n",
      "epoch 2511 train_loss 10978115.00948296 val_loss 206933.09375000\n",
      "epoch 2512 train_loss 10978115.00938492 val_loss 206933.09375000\n",
      "epoch 2513 train_loss 10978115.00928764 val_loss 206933.09375000\n",
      "epoch 2514 train_loss 10978115.00918907 val_loss 206933.09375000\n",
      "epoch 2515 train_loss 10978115.00909988 val_loss 206933.09375000\n",
      "epoch 2516 train_loss 10978115.00901108 val_loss 206933.09375000\n",
      "epoch 2517 train_loss 10978115.00891663 val_loss 206933.09375000\n",
      "epoch 2518 train_loss 10978115.00884895 val_loss 206933.09375000\n",
      "epoch 2519 train_loss 10978115.00876267 val_loss 206933.09375000\n",
      "epoch 2520 train_loss 10978115.00867546 val_loss 206933.09375000\n",
      "epoch 2521 train_loss 10978115.00860580 val_loss 206933.09375000\n",
      "epoch 2522 train_loss 10978115.00848785 val_loss 206933.09375000\n",
      "epoch 2523 train_loss 10978115.00838646 val_loss 206933.09375000\n",
      "epoch 2524 train_loss 10978115.00829674 val_loss 206933.09375000\n",
      "epoch 2525 train_loss 10978115.00819031 val_loss 206933.09375000\n",
      "epoch 2526 train_loss 10978115.00809692 val_loss 206933.09375000\n",
      "epoch 2527 train_loss 10978115.00803909 val_loss 206933.09375000\n",
      "epoch 2528 train_loss 10978115.00796372 val_loss 206933.09375000\n",
      "epoch 2529 train_loss 10978115.00788551 val_loss 206933.09375000\n",
      "epoch 2530 train_loss 10978115.00779297 val_loss 206933.09375000\n",
      "epoch 2531 train_loss 10978115.00770554 val_loss 206933.09375000\n",
      "epoch 2532 train_loss 10978115.00760750 val_loss 206933.09375000\n",
      "epoch 2533 train_loss 10978115.00751434 val_loss 206933.09375000\n",
      "epoch 2534 train_loss 10978115.00741211 val_loss 206933.09375000\n",
      "epoch 2535 train_loss 10978115.00733177 val_loss 206933.09375000\n",
      "epoch 2536 train_loss 10978115.00723137 val_loss 206933.09375000\n",
      "epoch 2537 train_loss 10978115.00716316 val_loss 206933.09375000\n",
      "epoch 2538 train_loss 10978115.00705978 val_loss 206933.09375000\n",
      "epoch 2539 train_loss 10978115.00697105 val_loss 206933.09375000\n",
      "epoch 2540 train_loss 10978115.00688805 val_loss 206933.09375000\n",
      "epoch 2541 train_loss 10978115.00681656 val_loss 206933.09375000\n",
      "epoch 2542 train_loss 10978115.00673584 val_loss 206933.09375000\n",
      "epoch 2543 train_loss 10978115.00662399 val_loss 206933.09375000\n",
      "epoch 2544 train_loss 10978115.00654236 val_loss 206933.09375000\n",
      "epoch 2545 train_loss 10978115.00643318 val_loss 206933.09375000\n",
      "epoch 2546 train_loss 10978115.00637123 val_loss 206933.09375000\n",
      "epoch 2547 train_loss 10978115.00625923 val_loss 206933.09375000\n",
      "epoch 2548 train_loss 10978115.00617714 val_loss 206933.09375000\n",
      "epoch 2549 train_loss 10978115.00606743 val_loss 206933.09375000\n",
      "epoch 2550 train_loss 10978115.00597824 val_loss 206933.09375000\n",
      "epoch 2551 train_loss 10978115.00588852 val_loss 206933.09375000\n",
      "epoch 2552 train_loss 10978115.00583260 val_loss 206933.09375000\n",
      "epoch 2553 train_loss 10978115.00574425 val_loss 206933.09375000\n",
      "epoch 2554 train_loss 10978115.00561478 val_loss 206933.09375000\n",
      "epoch 2555 train_loss 10978115.00553238 val_loss 206933.09375000\n",
      "epoch 2556 train_loss 10978115.00544350 val_loss 206933.09375000\n",
      "epoch 2557 train_loss 10978115.00534523 val_loss 206933.09375000\n",
      "epoch 2558 train_loss 10978115.00527268 val_loss 206933.09375000\n",
      "epoch 2559 train_loss 10978115.00516815 val_loss 206933.09375000\n",
      "epoch 2560 train_loss 10978115.00516190 val_loss 206933.09375000\n",
      "epoch 2561 train_loss 10978115.00506859 val_loss 206933.09375000\n",
      "epoch 2562 train_loss 10978115.00499428 val_loss 206933.09375000\n",
      "epoch 2563 train_loss 10978115.00490196 val_loss 206933.09375000\n",
      "epoch 2564 train_loss 10978115.00482925 val_loss 206933.09375000\n",
      "epoch 2565 train_loss 10978115.00472794 val_loss 206933.09375000\n",
      "epoch 2566 train_loss 10978115.00465828 val_loss 206933.09375000\n",
      "epoch 2567 train_loss 10978115.00458076 val_loss 206933.09375000\n",
      "epoch 2568 train_loss 10978115.00447258 val_loss 206933.09375000\n",
      "epoch 2569 train_loss 10978115.00438621 val_loss 206933.09375000\n",
      "epoch 2570 train_loss 10978115.00428848 val_loss 206933.09375000\n",
      "epoch 2571 train_loss 10978115.00421287 val_loss 206933.09375000\n",
      "epoch 2572 train_loss 10978115.00412682 val_loss 206933.09375000\n",
      "epoch 2573 train_loss 10978115.00402954 val_loss 206933.09375000\n",
      "epoch 2574 train_loss 10978115.00406189 val_loss 206933.09375000\n",
      "epoch 2575 train_loss 10978115.00397995 val_loss 206933.09375000\n",
      "epoch 2576 train_loss 10978115.00388008 val_loss 206933.09375000\n",
      "epoch 2577 train_loss 10978115.00378952 val_loss 206933.09375000\n",
      "epoch 2578 train_loss 10978115.00370178 val_loss 206933.09375000\n",
      "epoch 2579 train_loss 10978115.00361290 val_loss 206933.09375000\n",
      "epoch 2580 train_loss 10978115.00350456 val_loss 206933.09375000\n",
      "epoch 2581 train_loss 10978115.00342316 val_loss 206933.09375000\n",
      "epoch 2582 train_loss 10978115.00331039 val_loss 206933.09375000\n",
      "epoch 2583 train_loss 10978115.00322868 val_loss 206933.09375000\n",
      "epoch 2584 train_loss 10978115.00315437 val_loss 206933.09375000\n",
      "epoch 2585 train_loss 10978115.00308701 val_loss 206933.09375000\n",
      "epoch 2586 train_loss 10978115.00297928 val_loss 206933.09375000\n",
      "epoch 2587 train_loss 10978115.00289177 val_loss 206933.09375000\n",
      "epoch 2588 train_loss 10978115.00279190 val_loss 206933.09375000\n",
      "epoch 2589 train_loss 10978115.00270523 val_loss 206933.09375000\n",
      "epoch 2590 train_loss 10978115.00263268 val_loss 206933.09375000\n",
      "epoch 2591 train_loss 10978115.00257393 val_loss 206933.09375000\n",
      "epoch 2592 train_loss 10978115.00248642 val_loss 206933.09375000\n",
      "epoch 2593 train_loss 10978115.00238266 val_loss 206933.09375000\n",
      "epoch 2594 train_loss 10978115.00229347 val_loss 206933.09375000\n",
      "epoch 2595 train_loss 10978115.00219025 val_loss 206933.09375000\n",
      "epoch 2596 train_loss 10978115.00211548 val_loss 206933.09375000\n",
      "epoch 2597 train_loss 10978115.00202125 val_loss 206933.09375000\n",
      "epoch 2598 train_loss 10978115.00202736 val_loss 206933.09375000\n",
      "epoch 2599 train_loss 10978115.00198013 val_loss 206933.09375000\n",
      "epoch 2600 train_loss 10978115.00189858 val_loss 206933.09375000\n",
      "epoch 2601 train_loss 10978115.00179192 val_loss 206933.09375000\n",
      "epoch 2602 train_loss 10978115.00169205 val_loss 206933.09375000\n",
      "epoch 2603 train_loss 10978115.00159744 val_loss 206933.09375000\n",
      "epoch 2604 train_loss 10978115.00147858 val_loss 206933.09375000\n",
      "epoch 2605 train_loss 10978115.00139488 val_loss 206933.09375000\n",
      "epoch 2606 train_loss 10978115.00132935 val_loss 206933.09375000\n",
      "epoch 2607 train_loss 10978115.00123573 val_loss 206933.09375000\n",
      "epoch 2608 train_loss 10978115.00115875 val_loss 206933.09375000\n",
      "epoch 2609 train_loss 10978115.00106544 val_loss 206933.09375000\n",
      "epoch 2610 train_loss 10978115.00103813 val_loss 206933.09375000\n",
      "epoch 2611 train_loss 10978115.00097893 val_loss 206933.09375000\n",
      "epoch 2612 train_loss 10978115.00085991 val_loss 206933.09375000\n",
      "epoch 2613 train_loss 10978115.00081734 val_loss 206933.09375000\n",
      "epoch 2614 train_loss 10978115.00080017 val_loss 206933.09375000\n",
      "epoch 2615 train_loss 10978115.00068932 val_loss 206933.09375000\n",
      "epoch 2616 train_loss 10978115.00061203 val_loss 206933.09375000\n",
      "epoch 2617 train_loss 10978115.00051865 val_loss 206933.09375000\n",
      "epoch 2618 train_loss 10978115.00041344 val_loss 206933.09375000\n",
      "epoch 2619 train_loss 10978115.00032562 val_loss 206933.09375000\n",
      "epoch 2620 train_loss 10978115.00023071 val_loss 206933.09375000\n",
      "epoch 2621 train_loss 10978115.00014023 val_loss 206933.09375000\n",
      "epoch 2622 train_loss 10978115.00009575 val_loss 206933.09375000\n",
      "epoch 2623 train_loss 10978115.00002426 val_loss 206933.09375000\n",
      "epoch 2624 train_loss 10978114.99994011 val_loss 206933.09375000\n",
      "epoch 2625 train_loss 10978114.99988396 val_loss 206933.09375000\n",
      "epoch 2626 train_loss 10978114.99977035 val_loss 206933.09375000\n",
      "epoch 2627 train_loss 10978114.99968056 val_loss 206933.09375000\n",
      "epoch 2628 train_loss 10978114.99959495 val_loss 206933.09375000\n",
      "epoch 2629 train_loss 10978114.99952843 val_loss 206933.09375000\n",
      "epoch 2630 train_loss 10978114.99944756 val_loss 206933.09375000\n",
      "epoch 2631 train_loss 10978114.99934540 val_loss 206933.09375000\n",
      "epoch 2632 train_loss 10978114.99926239 val_loss 206933.09375000\n",
      "epoch 2633 train_loss 10978114.99917687 val_loss 206933.09375000\n",
      "epoch 2634 train_loss 10978114.99908638 val_loss 206933.09375000\n",
      "epoch 2635 train_loss 10978114.99899437 val_loss 206933.09375000\n",
      "epoch 2636 train_loss 10978114.99893852 val_loss 206933.09375000\n",
      "epoch 2637 train_loss 10978114.99885429 val_loss 206933.09375000\n",
      "epoch 2638 train_loss 10978114.99875092 val_loss 206933.09375000\n",
      "epoch 2639 train_loss 10978114.99866493 val_loss 206933.09375000\n",
      "epoch 2640 train_loss 10978114.99856789 val_loss 206933.09375000\n",
      "epoch 2641 train_loss 10978114.99846977 val_loss 206933.09375000\n",
      "epoch 2642 train_loss 10978114.99837433 val_loss 206933.09375000\n",
      "epoch 2643 train_loss 10978114.99830345 val_loss 206933.09375000\n",
      "epoch 2644 train_loss 10978114.99821388 val_loss 206933.09375000\n",
      "epoch 2645 train_loss 10978114.99809952 val_loss 206933.09375000\n",
      "epoch 2646 train_loss 10978114.99803970 val_loss 206933.09375000\n",
      "epoch 2647 train_loss 10978114.99796677 val_loss 206933.09375000\n",
      "epoch 2648 train_loss 10978114.99786102 val_loss 206933.09375000\n",
      "epoch 2649 train_loss 10978114.99777420 val_loss 206933.09375000\n",
      "epoch 2650 train_loss 10978114.99768204 val_loss 206933.09375000\n",
      "epoch 2651 train_loss 10978114.99758934 val_loss 206933.09375000\n",
      "epoch 2652 train_loss 10978114.99751434 val_loss 206933.09375000\n",
      "epoch 2653 train_loss 10978114.99741295 val_loss 206933.09375000\n",
      "epoch 2654 train_loss 10978114.99732628 val_loss 206933.09375000\n",
      "epoch 2655 train_loss 10978114.99723290 val_loss 206933.09375000\n",
      "epoch 2656 train_loss 10978114.99714073 val_loss 206933.09375000\n",
      "epoch 2657 train_loss 10978114.99705017 val_loss 206933.09375000\n",
      "epoch 2658 train_loss 10978114.99695221 val_loss 206933.09375000\n",
      "epoch 2659 train_loss 10978114.99685455 val_loss 206933.09375000\n",
      "epoch 2660 train_loss 10978114.99677971 val_loss 206933.09375000\n",
      "epoch 2661 train_loss 10978114.99668579 val_loss 206933.09375000\n",
      "epoch 2662 train_loss 10978114.99657173 val_loss 206933.09375000\n",
      "epoch 2663 train_loss 10978114.99651215 val_loss 206933.09375000\n",
      "epoch 2664 train_loss 10978114.99641396 val_loss 206933.09375000\n",
      "epoch 2665 train_loss 10978114.99631378 val_loss 206933.09375000\n",
      "epoch 2666 train_loss 10978114.99627708 val_loss 206933.09375000\n",
      "epoch 2667 train_loss 10978114.99618050 val_loss 206933.09375000\n",
      "epoch 2668 train_loss 10978114.99611656 val_loss 206933.09375000\n",
      "epoch 2669 train_loss 10978114.99600540 val_loss 206933.09375000\n",
      "epoch 2670 train_loss 10978114.99590637 val_loss 206933.09375000\n",
      "epoch 2671 train_loss 10978114.99583672 val_loss 206933.09375000\n",
      "epoch 2672 train_loss 10978114.99573372 val_loss 206933.09375000\n",
      "epoch 2673 train_loss 10978114.99563049 val_loss 206933.09375000\n",
      "epoch 2674 train_loss 10978114.99556778 val_loss 206933.09375000\n",
      "epoch 2675 train_loss 10978114.99548851 val_loss 206933.09375000\n",
      "epoch 2676 train_loss 10978114.99538025 val_loss 206933.09375000\n",
      "epoch 2677 train_loss 10978114.99529373 val_loss 206933.09375000\n",
      "epoch 2678 train_loss 10978114.99521713 val_loss 206933.09375000\n",
      "epoch 2679 train_loss 10978114.99510361 val_loss 206933.09375000\n",
      "epoch 2680 train_loss 10978114.99501061 val_loss 206933.09375000\n",
      "epoch 2681 train_loss 10978114.99491562 val_loss 206933.09375000\n",
      "epoch 2682 train_loss 10978114.99484001 val_loss 206933.09375000\n",
      "epoch 2683 train_loss 10978114.99473923 val_loss 206933.09375000\n",
      "epoch 2684 train_loss 10978114.99464684 val_loss 206933.09375000\n",
      "epoch 2685 train_loss 10978114.99458214 val_loss 206933.09375000\n",
      "epoch 2686 train_loss 10978114.99449379 val_loss 206933.09375000\n",
      "epoch 2687 train_loss 10978114.99439545 val_loss 206933.09375000\n",
      "epoch 2688 train_loss 10978114.99431053 val_loss 206933.09375000\n",
      "epoch 2689 train_loss 10978114.99424416 val_loss 206933.09375000\n",
      "epoch 2690 train_loss 10978114.99412903 val_loss 206933.09375000\n",
      "epoch 2691 train_loss 10978114.99405266 val_loss 206933.09375000\n",
      "epoch 2692 train_loss 10978114.99394539 val_loss 206933.09375000\n",
      "epoch 2693 train_loss 10978114.99384583 val_loss 206933.09375000\n",
      "epoch 2694 train_loss 10978114.99374939 val_loss 206933.09375000\n",
      "epoch 2695 train_loss 10978114.99364929 val_loss 206933.09375000\n",
      "epoch 2696 train_loss 10978114.99356796 val_loss 206933.09375000\n",
      "epoch 2697 train_loss 10978114.99346565 val_loss 206933.09375000\n",
      "epoch 2698 train_loss 10978114.99338066 val_loss 206933.09375000\n",
      "epoch 2699 train_loss 10978114.99332260 val_loss 206933.09375000\n",
      "epoch 2700 train_loss 10978114.99323860 val_loss 206933.09375000\n",
      "epoch 2701 train_loss 10978114.99315979 val_loss 206933.09375000\n",
      "epoch 2702 train_loss 10978114.99306229 val_loss 206933.09375000\n",
      "epoch 2703 train_loss 10978114.99294472 val_loss 206933.09375000\n",
      "epoch 2704 train_loss 10978114.99289467 val_loss 206933.09375000\n",
      "epoch 2705 train_loss 10978114.99279808 val_loss 206933.09375000\n",
      "epoch 2706 train_loss 10978114.99270019 val_loss 206933.09375000\n",
      "epoch 2707 train_loss 10978114.99261101 val_loss 206933.09375000\n",
      "epoch 2708 train_loss 10978114.99254181 val_loss 206933.09375000\n",
      "epoch 2709 train_loss 10978114.99253464 val_loss 206933.09375000\n",
      "epoch 2710 train_loss 10978114.99245308 val_loss 206933.09375000\n",
      "epoch 2711 train_loss 10978114.99235603 val_loss 206933.09375000\n",
      "epoch 2712 train_loss 10978114.99225449 val_loss 206933.09375000\n",
      "epoch 2713 train_loss 10978114.99218330 val_loss 206933.09375000\n",
      "epoch 2714 train_loss 10978114.99208153 val_loss 206933.09375000\n",
      "epoch 2715 train_loss 10978114.99199051 val_loss 206933.09375000\n",
      "epoch 2716 train_loss 10978114.99190277 val_loss 206933.09375000\n",
      "epoch 2717 train_loss 10978114.99181168 val_loss 206933.09375000\n",
      "epoch 2718 train_loss 10978114.99171623 val_loss 206933.09375000\n",
      "epoch 2719 train_loss 10978114.99161423 val_loss 206933.09375000\n",
      "epoch 2720 train_loss 10978114.99151840 val_loss 206933.09375000\n",
      "epoch 2721 train_loss 10978114.99143044 val_loss 206933.09375000\n",
      "epoch 2722 train_loss 10978114.99135536 val_loss 206933.09375000\n",
      "epoch 2723 train_loss 10978114.99126358 val_loss 206933.09375000\n",
      "epoch 2724 train_loss 10978114.99116776 val_loss 206933.09375000\n",
      "epoch 2725 train_loss 10978114.99108688 val_loss 206933.09375000\n",
      "epoch 2726 train_loss 10978114.99098358 val_loss 206933.09375000\n",
      "epoch 2727 train_loss 10978114.99089142 val_loss 206933.09375000\n",
      "epoch 2728 train_loss 10978114.99079979 val_loss 206933.09375000\n",
      "epoch 2729 train_loss 10978114.99070747 val_loss 206933.09375000\n",
      "epoch 2730 train_loss 10978114.99061386 val_loss 206933.09375000\n",
      "epoch 2731 train_loss 10978114.99051544 val_loss 206933.09375000\n",
      "epoch 2732 train_loss 10978114.99042542 val_loss 206933.09375000\n",
      "epoch 2733 train_loss 10978114.99033089 val_loss 206933.09375000\n",
      "epoch 2734 train_loss 10978114.99032440 val_loss 206933.09375000\n",
      "epoch 2735 train_loss 10978114.99024262 val_loss 206933.09375000\n",
      "epoch 2736 train_loss 10978114.99014946 val_loss 206933.09375000\n",
      "epoch 2737 train_loss 10978114.99005524 val_loss 206933.09375000\n",
      "epoch 2738 train_loss 10978114.98999885 val_loss 206933.09375000\n",
      "epoch 2739 train_loss 10978114.98992454 val_loss 206933.09375000\n",
      "epoch 2740 train_loss 10978114.98986328 val_loss 206933.09375000\n",
      "epoch 2741 train_loss 10978114.98977226 val_loss 206933.09375000\n",
      "epoch 2742 train_loss 10978114.98967217 val_loss 206933.09375000\n",
      "epoch 2743 train_loss 10978114.98956009 val_loss 206933.10937500\n",
      "epoch 2744 train_loss 10978114.98947395 val_loss 206933.10937500\n",
      "epoch 2745 train_loss 10978114.98940857 val_loss 206933.10937500\n",
      "epoch 2746 train_loss 10978114.98932083 val_loss 206933.10937500\n",
      "epoch 2747 train_loss 10978114.98922523 val_loss 206933.10937500\n",
      "epoch 2748 train_loss 10978114.98911804 val_loss 206933.10937500\n",
      "epoch 2749 train_loss 10978114.98903664 val_loss 206933.10937500\n",
      "epoch 2750 train_loss 10978114.98895012 val_loss 206933.10937500\n",
      "epoch 2751 train_loss 10978114.98889923 val_loss 206933.10937500\n",
      "epoch 2752 train_loss 10978114.98879105 val_loss 206933.10937500\n",
      "epoch 2753 train_loss 10978114.98870140 val_loss 206933.10937500\n",
      "epoch 2754 train_loss 10978114.98861114 val_loss 206933.10937500\n",
      "epoch 2755 train_loss 10978114.98855720 val_loss 206933.10937500\n",
      "epoch 2756 train_loss 10978114.98845985 val_loss 206933.10937500\n",
      "epoch 2757 train_loss 10978114.98835457 val_loss 206933.10937500\n",
      "epoch 2758 train_loss 10978114.98830849 val_loss 206933.10937500\n",
      "epoch 2759 train_loss 10978114.98821274 val_loss 206933.10937500\n",
      "epoch 2760 train_loss 10978114.98811134 val_loss 206933.10937500\n",
      "epoch 2761 train_loss 10978114.98802925 val_loss 206933.10937500\n",
      "epoch 2762 train_loss 10978114.98791298 val_loss 206933.10937500\n",
      "epoch 2763 train_loss 10978114.98783569 val_loss 206933.10937500\n",
      "epoch 2764 train_loss 10978114.98774933 val_loss 206933.10937500\n",
      "epoch 2765 train_loss 10978114.98766289 val_loss 206933.10937500\n",
      "epoch 2766 train_loss 10978114.98756187 val_loss 206933.10937500\n",
      "epoch 2767 train_loss 10978114.98747505 val_loss 206933.10937500\n",
      "epoch 2768 train_loss 10978114.98740212 val_loss 206933.10937500\n",
      "epoch 2769 train_loss 10978114.98735565 val_loss 206933.10937500\n",
      "epoch 2770 train_loss 10978114.98725273 val_loss 206933.10937500\n",
      "epoch 2771 train_loss 10978114.98716202 val_loss 206933.10937500\n",
      "epoch 2772 train_loss 10978114.98706413 val_loss 206933.10937500\n",
      "epoch 2773 train_loss 10978114.98696648 val_loss 206933.10937500\n",
      "epoch 2774 train_loss 10978114.98687996 val_loss 206933.10937500\n",
      "epoch 2775 train_loss 10978114.98680496 val_loss 206933.10937500\n",
      "epoch 2776 train_loss 10978114.98669136 val_loss 206933.10937500\n",
      "epoch 2777 train_loss 10978114.98660576 val_loss 206933.10937500\n",
      "epoch 2778 train_loss 10978114.98654671 val_loss 206933.10937500\n",
      "epoch 2779 train_loss 10978114.98644348 val_loss 206933.10937500\n",
      "epoch 2780 train_loss 10978114.98633965 val_loss 206933.10937500\n",
      "epoch 2781 train_loss 10978114.98628197 val_loss 206933.10937500\n",
      "epoch 2782 train_loss 10978114.98617500 val_loss 206933.10937500\n",
      "epoch 2783 train_loss 10978114.98607429 val_loss 206933.10937500\n",
      "epoch 2784 train_loss 10978114.98600388 val_loss 206933.10937500\n",
      "epoch 2785 train_loss 10978114.98590355 val_loss 206933.10937500\n",
      "epoch 2786 train_loss 10978114.98581055 val_loss 206933.10937500\n",
      "epoch 2787 train_loss 10978114.98573471 val_loss 206933.10937500\n",
      "epoch 2788 train_loss 10978114.98565102 val_loss 206933.10937500\n",
      "epoch 2789 train_loss 10978114.98556610 val_loss 206933.10937500\n",
      "epoch 2790 train_loss 10978114.98546272 val_loss 206933.10937500\n",
      "epoch 2791 train_loss 10978114.98536034 val_loss 206933.10937500\n",
      "epoch 2792 train_loss 10978114.98527435 val_loss 206933.10937500\n",
      "epoch 2793 train_loss 10978114.98519753 val_loss 206933.10937500\n",
      "epoch 2794 train_loss 10978114.98510033 val_loss 206933.10937500\n",
      "epoch 2795 train_loss 10978114.98500092 val_loss 206933.10937500\n",
      "epoch 2796 train_loss 10978114.98491218 val_loss 206933.10937500\n",
      "epoch 2797 train_loss 10978114.98483177 val_loss 206933.10937500\n",
      "epoch 2798 train_loss 10978114.98472015 val_loss 206933.10937500\n",
      "epoch 2799 train_loss 10978114.98463226 val_loss 206933.10937500\n",
      "epoch 2800 train_loss 10978114.98453102 val_loss 206933.10937500\n",
      "epoch 2801 train_loss 10978114.98446564 val_loss 206933.10937500\n",
      "epoch 2802 train_loss 10978114.98438164 val_loss 206933.10937500\n",
      "epoch 2803 train_loss 10978114.98432526 val_loss 206933.10937500\n",
      "epoch 2804 train_loss 10978114.98423195 val_loss 206933.10937500\n",
      "epoch 2805 train_loss 10978114.98415009 val_loss 206933.10937500\n",
      "epoch 2806 train_loss 10978114.98405731 val_loss 206933.10937500\n",
      "epoch 2807 train_loss 10978114.98400017 val_loss 206933.10937500\n",
      "epoch 2808 train_loss 10978114.98388367 val_loss 206933.10937500\n",
      "epoch 2809 train_loss 10978114.98379997 val_loss 206933.10937500\n",
      "epoch 2810 train_loss 10978114.98386269 val_loss 206933.10937500\n",
      "epoch 2811 train_loss 10978114.98378616 val_loss 206933.10937500\n",
      "epoch 2812 train_loss 10978114.98370895 val_loss 206933.10937500\n",
      "epoch 2813 train_loss 10978114.98361832 val_loss 206933.10937500\n",
      "epoch 2814 train_loss 10978114.98352707 val_loss 206933.10937500\n",
      "epoch 2815 train_loss 10978114.98345657 val_loss 206933.10937500\n",
      "epoch 2816 train_loss 10978114.98356117 val_loss 206933.10937500\n",
      "epoch 2817 train_loss 10978114.98346176 val_loss 206933.10937500\n",
      "epoch 2818 train_loss 10978114.98339294 val_loss 206933.10937500\n",
      "epoch 2819 train_loss 10978114.98333504 val_loss 206933.10937500\n",
      "epoch 2820 train_loss 10978114.98322868 val_loss 206933.10937500\n",
      "epoch 2821 train_loss 10978114.98313843 val_loss 206933.10937500\n",
      "epoch 2822 train_loss 10978114.98303154 val_loss 206933.10937500\n",
      "epoch 2823 train_loss 10978114.98294533 val_loss 206933.10937500\n",
      "epoch 2824 train_loss 10978114.98283333 val_loss 206933.10937500\n",
      "epoch 2825 train_loss 10978114.98277863 val_loss 206933.10937500\n",
      "epoch 2826 train_loss 10978114.98269707 val_loss 206933.10937500\n",
      "epoch 2827 train_loss 10978114.98259674 val_loss 206933.10937500\n",
      "epoch 2828 train_loss 10978114.98259506 val_loss 206933.10937500\n",
      "epoch 2829 train_loss 10978114.98251930 val_loss 206933.10937500\n",
      "epoch 2830 train_loss 10978114.98242149 val_loss 206933.10937500\n",
      "epoch 2831 train_loss 10978114.98232254 val_loss 206933.10937500\n",
      "epoch 2832 train_loss 10978114.98222977 val_loss 206933.10937500\n",
      "epoch 2833 train_loss 10978114.98212525 val_loss 206933.10937500\n",
      "epoch 2834 train_loss 10978114.98204865 val_loss 206933.10937500\n",
      "epoch 2835 train_loss 10978114.98194076 val_loss 206933.10937500\n",
      "epoch 2836 train_loss 10978114.98184273 val_loss 206933.10937500\n",
      "epoch 2837 train_loss 10978114.98174080 val_loss 206933.10937500\n",
      "epoch 2838 train_loss 10978114.98165207 val_loss 206933.10937500\n",
      "epoch 2839 train_loss 10978114.98156456 val_loss 206933.10937500\n",
      "epoch 2840 train_loss 10978114.98150871 val_loss 206933.10937500\n",
      "epoch 2841 train_loss 10978114.98140602 val_loss 206933.10937500\n",
      "epoch 2842 train_loss 10978114.98132805 val_loss 206933.10937500\n",
      "epoch 2843 train_loss 10978114.98124046 val_loss 206933.10937500\n",
      "epoch 2844 train_loss 10978114.98114174 val_loss 206933.10937500\n",
      "epoch 2845 train_loss 10978114.98106094 val_loss 206933.10937500\n",
      "epoch 2846 train_loss 10978114.98095970 val_loss 206933.10937500\n",
      "epoch 2847 train_loss 10978114.98088020 val_loss 206933.10937500\n",
      "epoch 2848 train_loss 10978114.98078613 val_loss 206933.10937500\n",
      "epoch 2849 train_loss 10978114.98067642 val_loss 206933.10937500\n",
      "epoch 2850 train_loss 10978114.98059349 val_loss 206933.10937500\n",
      "epoch 2851 train_loss 10978114.98050926 val_loss 206933.10937500\n",
      "epoch 2852 train_loss 10978114.98040283 val_loss 206933.10937500\n",
      "epoch 2853 train_loss 10978114.98031219 val_loss 206933.10937500\n",
      "epoch 2854 train_loss 10978114.98026833 val_loss 206933.10937500\n",
      "epoch 2855 train_loss 10978114.98018730 val_loss 206933.10937500\n",
      "epoch 2856 train_loss 10978114.98008392 val_loss 206933.10937500\n",
      "epoch 2857 train_loss 10978114.97999657 val_loss 206933.10937500\n",
      "epoch 2858 train_loss 10978114.97990685 val_loss 206933.10937500\n",
      "epoch 2859 train_loss 10978114.97981842 val_loss 206933.10937500\n",
      "epoch 2860 train_loss 10978114.97977722 val_loss 206933.10937500\n",
      "epoch 2861 train_loss 10978114.97967735 val_loss 206933.10937500\n",
      "epoch 2862 train_loss 10978114.97958077 val_loss 206933.10937500\n",
      "epoch 2863 train_loss 10978114.97952301 val_loss 206933.10937500\n",
      "epoch 2864 train_loss 10978114.97943634 val_loss 206933.10937500\n",
      "epoch 2865 train_loss 10978114.97933815 val_loss 206933.10937500\n",
      "epoch 2866 train_loss 10978114.97925743 val_loss 206933.10937500\n",
      "epoch 2867 train_loss 10978114.97915420 val_loss 206933.10937500\n",
      "epoch 2868 train_loss 10978114.97905548 val_loss 206933.10937500\n",
      "epoch 2869 train_loss 10978114.97898048 val_loss 206933.10937500\n",
      "epoch 2870 train_loss 10978114.97887710 val_loss 206933.10937500\n",
      "epoch 2871 train_loss 10978114.97877655 val_loss 206933.10937500\n",
      "epoch 2872 train_loss 10978114.97871323 val_loss 206933.10937500\n",
      "epoch 2873 train_loss 10978114.97861504 val_loss 206933.10937500\n",
      "epoch 2874 train_loss 10978114.97852570 val_loss 206933.10937500\n",
      "epoch 2875 train_loss 10978114.97842529 val_loss 206933.10937500\n",
      "epoch 2876 train_loss 10978114.97834457 val_loss 206933.10937500\n",
      "epoch 2877 train_loss 10978114.97825165 val_loss 206933.10937500\n",
      "epoch 2878 train_loss 10978114.97815704 val_loss 206933.10937500\n",
      "epoch 2879 train_loss 10978114.97810532 val_loss 206933.10937500\n",
      "epoch 2880 train_loss 10978114.97800484 val_loss 206933.10937500\n",
      "epoch 2881 train_loss 10978114.97793434 val_loss 206933.10937500\n",
      "epoch 2882 train_loss 10978114.97783310 val_loss 206933.10937500\n",
      "epoch 2883 train_loss 10978114.97773033 val_loss 206933.10937500\n",
      "epoch 2884 train_loss 10978114.97763763 val_loss 206933.10937500\n",
      "epoch 2885 train_loss 10978114.97754662 val_loss 206933.10937500\n",
      "epoch 2886 train_loss 10978114.97745232 val_loss 206933.10937500\n",
      "epoch 2887 train_loss 10978114.97737328 val_loss 206933.10937500\n",
      "epoch 2888 train_loss 10978114.97728111 val_loss 206933.10937500\n",
      "epoch 2889 train_loss 10978114.97718025 val_loss 206933.10937500\n",
      "epoch 2890 train_loss 10978114.97707024 val_loss 206933.10937500\n",
      "epoch 2891 train_loss 10978114.97698448 val_loss 206933.10937500\n",
      "epoch 2892 train_loss 10978114.97688721 val_loss 206933.10937500\n",
      "epoch 2893 train_loss 10978114.97680374 val_loss 206933.10937500\n",
      "epoch 2894 train_loss 10978114.97672936 val_loss 206933.10937500\n",
      "epoch 2895 train_loss 10978114.97665657 val_loss 206933.10937500\n",
      "epoch 2896 train_loss 10978114.97654175 val_loss 206933.10937500\n",
      "epoch 2897 train_loss 10978114.97645927 val_loss 206933.10937500\n",
      "epoch 2898 train_loss 10978114.97636421 val_loss 206933.10937500\n",
      "epoch 2899 train_loss 10978114.97626740 val_loss 206933.10937500\n",
      "epoch 2900 train_loss 10978114.97619080 val_loss 206933.10937500\n",
      "epoch 2901 train_loss 10978114.97612587 val_loss 206933.10937500\n",
      "epoch 2902 train_loss 10978114.97602814 val_loss 206933.10937500\n",
      "epoch 2903 train_loss 10978114.97608627 val_loss 206933.10937500\n",
      "epoch 2904 train_loss 10978114.97600174 val_loss 206933.10937500\n",
      "epoch 2905 train_loss 10978114.97590950 val_loss 206933.10937500\n",
      "epoch 2906 train_loss 10978114.97581749 val_loss 206933.10937500\n",
      "epoch 2907 train_loss 10978114.97572632 val_loss 206933.10937500\n",
      "epoch 2908 train_loss 10978114.97562782 val_loss 206933.10937500\n",
      "epoch 2909 train_loss 10978114.97557816 val_loss 206933.10937500\n",
      "epoch 2910 train_loss 10978114.97549980 val_loss 206933.10937500\n",
      "epoch 2911 train_loss 10978114.97536621 val_loss 206933.10937500\n",
      "epoch 2912 train_loss 10978114.97532127 val_loss 206933.10937500\n",
      "epoch 2913 train_loss 10978114.97524887 val_loss 206933.10937500\n",
      "epoch 2914 train_loss 10978114.97516769 val_loss 206933.10937500\n",
      "epoch 2915 train_loss 10978114.97507767 val_loss 206933.10937500\n",
      "epoch 2916 train_loss 10978114.97498474 val_loss 206933.10937500\n",
      "epoch 2917 train_loss 10978114.97489410 val_loss 206933.10937500\n",
      "epoch 2918 train_loss 10978114.97480957 val_loss 206933.10937500\n",
      "epoch 2919 train_loss 10978114.97472649 val_loss 206933.10937500\n",
      "epoch 2920 train_loss 10978114.97464081 val_loss 206933.10937500\n",
      "epoch 2921 train_loss 10978114.97456986 val_loss 206933.10937500\n",
      "epoch 2922 train_loss 10978114.97448448 val_loss 206933.10937500\n",
      "epoch 2923 train_loss 10978114.97438492 val_loss 206933.10937500\n",
      "epoch 2924 train_loss 10978114.97433105 val_loss 206933.10937500\n",
      "epoch 2925 train_loss 10978114.97424149 val_loss 206933.10937500\n",
      "epoch 2926 train_loss 10978114.97415360 val_loss 206933.10937500\n",
      "epoch 2927 train_loss 10978114.97405807 val_loss 206933.10937500\n",
      "epoch 2928 train_loss 10978114.97395645 val_loss 206933.10937500\n",
      "epoch 2929 train_loss 10978114.97386246 val_loss 206933.10937500\n",
      "epoch 2930 train_loss 10978114.97378418 val_loss 206933.10937500\n",
      "epoch 2931 train_loss 10978114.97373314 val_loss 206933.10937500\n",
      "epoch 2932 train_loss 10978114.97362755 val_loss 206933.10937500\n",
      "epoch 2933 train_loss 10978114.97361336 val_loss 206933.10937500\n",
      "epoch 2934 train_loss 10978114.97352714 val_loss 206933.10937500\n",
      "epoch 2935 train_loss 10978114.97343010 val_loss 206933.10937500\n",
      "epoch 2936 train_loss 10978114.97337334 val_loss 206933.10937500\n",
      "epoch 2937 train_loss 10978114.97331032 val_loss 206933.10937500\n",
      "epoch 2938 train_loss 10978114.97320839 val_loss 206933.10937500\n",
      "epoch 2939 train_loss 10978114.97310486 val_loss 206933.10937500\n",
      "epoch 2940 train_loss 10978114.97305344 val_loss 206933.10937500\n",
      "epoch 2941 train_loss 10978114.97296234 val_loss 206933.10937500\n",
      "epoch 2942 train_loss 10978114.97287811 val_loss 206933.10937500\n",
      "epoch 2943 train_loss 10978114.97277512 val_loss 206933.10937500\n",
      "epoch 2944 train_loss 10978114.97269157 val_loss 206933.10937500\n",
      "epoch 2945 train_loss 10978114.97259834 val_loss 206933.10937500\n",
      "epoch 2946 train_loss 10978114.97253220 val_loss 206933.10937500\n",
      "epoch 2947 train_loss 10978114.97244644 val_loss 206933.10937500\n",
      "epoch 2948 train_loss 10978114.97235146 val_loss 206933.10937500\n",
      "epoch 2949 train_loss 10978114.97226875 val_loss 206933.10937500\n",
      "epoch 2950 train_loss 10978114.97218048 val_loss 206933.10937500\n",
      "epoch 2951 train_loss 10978114.97208153 val_loss 206933.10937500\n",
      "epoch 2952 train_loss 10978114.97198387 val_loss 206933.10937500\n",
      "epoch 2953 train_loss 10978114.97190125 val_loss 206933.10937500\n",
      "epoch 2954 train_loss 10978114.97181045 val_loss 206933.10937500\n",
      "epoch 2955 train_loss 10978114.97171593 val_loss 206933.10937500\n",
      "epoch 2956 train_loss 10978114.97163704 val_loss 206933.10937500\n",
      "epoch 2957 train_loss 10978114.97157120 val_loss 206933.10937500\n",
      "epoch 2958 train_loss 10978114.97151451 val_loss 206933.10937500\n",
      "epoch 2959 train_loss 10978114.97142502 val_loss 206933.10937500\n",
      "epoch 2960 train_loss 10978114.97135338 val_loss 206933.10937500\n",
      "epoch 2961 train_loss 10978114.97123688 val_loss 206933.10937500\n",
      "epoch 2962 train_loss 10978114.97117592 val_loss 206933.10937500\n",
      "epoch 2963 train_loss 10978114.97106819 val_loss 206933.10937500\n",
      "epoch 2964 train_loss 10978114.97096657 val_loss 206933.10937500\n",
      "epoch 2965 train_loss 10978114.97088615 val_loss 206933.10937500\n",
      "epoch 2966 train_loss 10978114.97079567 val_loss 206933.10937500\n",
      "epoch 2967 train_loss 10978114.97070045 val_loss 206933.10937500\n",
      "epoch 2968 train_loss 10978114.97062164 val_loss 206933.10937500\n",
      "epoch 2969 train_loss 10978114.97052849 val_loss 206933.10937500\n",
      "epoch 2970 train_loss 10978114.97043861 val_loss 206933.10937500\n",
      "epoch 2971 train_loss 10978114.97037186 val_loss 206933.10937500\n",
      "epoch 2972 train_loss 10978114.97029175 val_loss 206933.10937500\n",
      "epoch 2973 train_loss 10978114.97021538 val_loss 206933.10937500\n",
      "epoch 2974 train_loss 10978114.97010521 val_loss 206933.10937500\n",
      "epoch 2975 train_loss 10978114.97001114 val_loss 206933.10937500\n",
      "epoch 2976 train_loss 10978114.96991043 val_loss 206933.10937500\n",
      "epoch 2977 train_loss 10978114.96984024 val_loss 206933.10937500\n",
      "epoch 2978 train_loss 10978114.96978943 val_loss 206933.10937500\n",
      "epoch 2979 train_loss 10978114.96971413 val_loss 206933.10937500\n",
      "epoch 2980 train_loss 10978114.96962235 val_loss 206933.10937500\n",
      "epoch 2981 train_loss 10978114.96967918 val_loss 206933.10937500\n",
      "epoch 2982 train_loss 10978114.96958893 val_loss 206933.10937500\n",
      "epoch 2983 train_loss 10978114.96964607 val_loss 206933.10937500\n",
      "epoch 2984 train_loss 10978114.96957146 val_loss 206933.10937500\n",
      "epoch 2985 train_loss 10978114.96947365 val_loss 206933.10937500\n",
      "epoch 2986 train_loss 10978114.96936401 val_loss 206933.10937500\n",
      "epoch 2987 train_loss 10978114.96927071 val_loss 206933.10937500\n",
      "epoch 2988 train_loss 10978114.96926491 val_loss 206933.10937500\n",
      "epoch 2989 train_loss 10978114.96918366 val_loss 206933.10937500\n",
      "epoch 2990 train_loss 10978114.96908730 val_loss 206933.10937500\n",
      "epoch 2991 train_loss 10978114.96900467 val_loss 206933.10937500\n",
      "epoch 2992 train_loss 10978114.96893013 val_loss 206933.10937500\n",
      "epoch 2993 train_loss 10978114.96881188 val_loss 206933.10937500\n",
      "epoch 2994 train_loss 10978114.96873581 val_loss 206933.10937500\n",
      "epoch 2995 train_loss 10978114.96864418 val_loss 206933.10937500\n",
      "epoch 2996 train_loss 10978114.96855545 val_loss 206933.10937500\n",
      "epoch 2997 train_loss 10978114.96846062 val_loss 206933.10937500\n",
      "epoch 2998 train_loss 10978114.96838226 val_loss 206933.10937500\n",
      "epoch 2999 train_loss 10978114.96831970 val_loss 206933.10937500\n",
      "epoch 3000 train_loss 10978114.96829056 val_loss 206933.10937500\n",
      "epoch 3001 train_loss 10978114.96819771 val_loss 206933.10937500\n",
      "epoch 3002 train_loss 10978114.96809753 val_loss 206933.10937500\n",
      "epoch 3003 train_loss 10978114.96804420 val_loss 206933.10937500\n",
      "epoch 3004 train_loss 10978114.96795929 val_loss 206933.10937500\n",
      "epoch 3005 train_loss 10978114.96785744 val_loss 206933.10937500\n",
      "epoch 3006 train_loss 10978114.96779106 val_loss 206933.10937500\n",
      "epoch 3007 train_loss 10978114.96770424 val_loss 206933.10937500\n",
      "epoch 3008 train_loss 10978114.96758438 val_loss 206933.10937500\n",
      "epoch 3009 train_loss 10978114.96750755 val_loss 206933.10937500\n",
      "epoch 3010 train_loss 10978114.96742920 val_loss 206933.10937500\n",
      "epoch 3011 train_loss 10978114.96732277 val_loss 206933.10937500\n",
      "epoch 3012 train_loss 10978114.96725166 val_loss 206933.10937500\n",
      "epoch 3013 train_loss 10978114.96724907 val_loss 206933.10937500\n",
      "epoch 3014 train_loss 10978114.96709694 val_loss 206933.10937500\n",
      "epoch 3015 train_loss 10978114.96706245 val_loss 206933.10937500\n",
      "epoch 3016 train_loss 10978114.96697090 val_loss 206933.10937500\n",
      "epoch 3017 train_loss 10978114.96689438 val_loss 206933.10937500\n",
      "epoch 3018 train_loss 10978114.96679901 val_loss 206933.10937500\n",
      "epoch 3019 train_loss 10978114.96669601 val_loss 206933.10937500\n",
      "epoch 3020 train_loss 10978114.96661125 val_loss 206933.10937500\n",
      "epoch 3021 train_loss 10978114.96653511 val_loss 206933.10937500\n",
      "epoch 3022 train_loss 10978114.96642960 val_loss 206933.10937500\n",
      "epoch 3023 train_loss 10978114.96633034 val_loss 206933.10937500\n",
      "epoch 3024 train_loss 10978114.96623840 val_loss 206933.10937500\n",
      "epoch 3025 train_loss 10978114.96613983 val_loss 206933.10937500\n",
      "epoch 3026 train_loss 10978114.96607254 val_loss 206933.10937500\n",
      "epoch 3027 train_loss 10978114.96596352 val_loss 206933.10937500\n",
      "epoch 3028 train_loss 10978114.96587837 val_loss 206933.10937500\n",
      "epoch 3029 train_loss 10978114.96578133 val_loss 206933.10937500\n",
      "epoch 3030 train_loss 10978114.96570236 val_loss 206933.10937500\n",
      "epoch 3031 train_loss 10978114.96561562 val_loss 206933.10937500\n",
      "epoch 3032 train_loss 10978114.96554726 val_loss 206933.10937500\n",
      "epoch 3033 train_loss 10978114.96545807 val_loss 206933.10937500\n",
      "epoch 3034 train_loss 10978114.96535835 val_loss 206933.10937500\n",
      "epoch 3035 train_loss 10978114.96526871 val_loss 206933.10937500\n",
      "epoch 3036 train_loss 10978114.96519630 val_loss 206933.10937500\n",
      "epoch 3037 train_loss 10978114.96512710 val_loss 206933.10937500\n",
      "epoch 3038 train_loss 10978114.96504150 val_loss 206933.10937500\n",
      "epoch 3039 train_loss 10978114.96494698 val_loss 206933.10937500\n",
      "epoch 3040 train_loss 10978114.96485260 val_loss 206933.10937500\n",
      "epoch 3041 train_loss 10978114.96474388 val_loss 206933.10937500\n",
      "epoch 3042 train_loss 10978114.96467056 val_loss 206933.10937500\n",
      "epoch 3043 train_loss 10978114.96457260 val_loss 206933.10937500\n",
      "epoch 3044 train_loss 10978114.96449432 val_loss 206933.10937500\n",
      "epoch 3045 train_loss 10978114.96443581 val_loss 206933.10937500\n",
      "epoch 3046 train_loss 10978114.96435936 val_loss 206933.10937500\n",
      "epoch 3047 train_loss 10978114.96428993 val_loss 206933.10937500\n",
      "epoch 3048 train_loss 10978114.96419868 val_loss 206933.10937500\n",
      "epoch 3049 train_loss 10978114.96411583 val_loss 206933.10937500\n",
      "epoch 3050 train_loss 10978114.96402130 val_loss 206933.10937500\n",
      "epoch 3051 train_loss 10978114.96390587 val_loss 206933.10937500\n",
      "epoch 3052 train_loss 10978114.96382866 val_loss 206933.10937500\n",
      "epoch 3053 train_loss 10978114.96373352 val_loss 206933.10937500\n",
      "epoch 3054 train_loss 10978114.96365372 val_loss 206933.10937500\n",
      "epoch 3055 train_loss 10978114.96356293 val_loss 206933.10937500\n",
      "epoch 3056 train_loss 10978114.96347206 val_loss 206933.10937500\n",
      "epoch 3057 train_loss 10978114.96338295 val_loss 206933.10937500\n",
      "epoch 3058 train_loss 10978114.96328796 val_loss 206933.10937500\n",
      "epoch 3059 train_loss 10978114.96322128 val_loss 206933.10937500\n",
      "epoch 3060 train_loss 10978114.96315613 val_loss 206933.10937500\n",
      "epoch 3061 train_loss 10978114.96307129 val_loss 206933.10937500\n",
      "epoch 3062 train_loss 10978114.96295761 val_loss 206933.10937500\n",
      "epoch 3063 train_loss 10978114.96292450 val_loss 206933.10937500\n",
      "epoch 3064 train_loss 10978114.96284782 val_loss 206933.10937500\n",
      "epoch 3065 train_loss 10978114.96273842 val_loss 206933.10937500\n",
      "epoch 3066 train_loss 10978114.96265839 val_loss 206933.10937500\n",
      "epoch 3067 train_loss 10978114.96255882 val_loss 206933.10937500\n",
      "epoch 3068 train_loss 10978114.96247269 val_loss 206933.10937500\n",
      "epoch 3069 train_loss 10978114.96237007 val_loss 206933.10937500\n",
      "epoch 3070 train_loss 10978114.96234757 val_loss 206933.10937500\n",
      "epoch 3071 train_loss 10978114.96227654 val_loss 206933.10937500\n",
      "epoch 3072 train_loss 10978114.96216843 val_loss 206933.10937500\n",
      "epoch 3073 train_loss 10978114.96207199 val_loss 206933.10937500\n",
      "epoch 3074 train_loss 10978114.96198341 val_loss 206933.10937500\n",
      "epoch 3075 train_loss 10978114.96188568 val_loss 206933.10937500\n",
      "epoch 3076 train_loss 10978114.96179001 val_loss 206933.10937500\n",
      "epoch 3077 train_loss 10978114.96171814 val_loss 206933.10937500\n",
      "epoch 3078 train_loss 10978114.96161812 val_loss 206933.10937500\n",
      "epoch 3079 train_loss 10978114.96152161 val_loss 206933.10937500\n",
      "epoch 3080 train_loss 10978114.96146950 val_loss 206933.10937500\n",
      "epoch 3081 train_loss 10978114.96137505 val_loss 206933.10937500\n",
      "epoch 3082 train_loss 10978114.96128433 val_loss 206933.10937500\n",
      "epoch 3083 train_loss 10978114.96119934 val_loss 206933.10937500\n",
      "epoch 3084 train_loss 10978114.96109558 val_loss 206933.10937500\n",
      "epoch 3085 train_loss 10978114.96100021 val_loss 206933.10937500\n",
      "epoch 3086 train_loss 10978114.96090355 val_loss 206933.10937500\n",
      "epoch 3087 train_loss 10978114.96081635 val_loss 206933.10937500\n",
      "epoch 3088 train_loss 10978114.96076469 val_loss 206933.10937500\n",
      "epoch 3089 train_loss 10978114.96068138 val_loss 206933.10937500\n",
      "epoch 3090 train_loss 10978114.96060554 val_loss 206933.10937500\n",
      "epoch 3091 train_loss 10978114.96050934 val_loss 206933.10937500\n",
      "epoch 3092 train_loss 10978114.96045128 val_loss 206933.10937500\n",
      "epoch 3093 train_loss 10978114.96035561 val_loss 206933.10937500\n",
      "epoch 3094 train_loss 10978114.96025093 val_loss 206933.10937500\n",
      "epoch 3095 train_loss 10978114.96017159 val_loss 206933.10937500\n",
      "epoch 3096 train_loss 10978114.96009148 val_loss 206933.10937500\n",
      "epoch 3097 train_loss 10978114.96000259 val_loss 206933.10937500\n",
      "epoch 3098 train_loss 10978114.95990624 val_loss 206933.10937500\n",
      "epoch 3099 train_loss 10978114.95982010 val_loss 206933.10937500\n",
      "epoch 3100 train_loss 10978114.95972191 val_loss 206933.10937500\n",
      "epoch 3101 train_loss 10978114.95965805 val_loss 206933.10937500\n",
      "epoch 3102 train_loss 10978114.95956375 val_loss 206933.10937500\n",
      "epoch 3103 train_loss 10978114.95946045 val_loss 206933.10937500\n",
      "epoch 3104 train_loss 10978114.95938202 val_loss 206933.10937500\n",
      "epoch 3105 train_loss 10978114.95927490 val_loss 206933.10937500\n",
      "epoch 3106 train_loss 10978114.95918579 val_loss 206933.10937500\n",
      "epoch 3107 train_loss 10978114.95909576 val_loss 206933.10937500\n",
      "epoch 3108 train_loss 10978114.95902557 val_loss 206933.10937500\n",
      "epoch 3109 train_loss 10978114.95896416 val_loss 206933.10937500\n",
      "epoch 3110 train_loss 10978114.95887261 val_loss 206933.10937500\n",
      "epoch 3111 train_loss 10978114.95880562 val_loss 206933.10937500\n",
      "epoch 3112 train_loss 10978114.95870789 val_loss 206933.10937500\n",
      "epoch 3113 train_loss 10978114.95859917 val_loss 206933.10937500\n",
      "epoch 3114 train_loss 10978114.95853035 val_loss 206933.10937500\n",
      "epoch 3115 train_loss 10978114.95842110 val_loss 206933.10937500\n",
      "epoch 3116 train_loss 10978114.95834450 val_loss 206933.10937500\n",
      "epoch 3117 train_loss 10978114.95825447 val_loss 206933.10937500\n",
      "epoch 3118 train_loss 10978114.95817253 val_loss 206933.10937500\n",
      "epoch 3119 train_loss 10978114.95807571 val_loss 206933.10937500\n",
      "epoch 3120 train_loss 10978114.95797058 val_loss 206933.10937500\n",
      "epoch 3121 train_loss 10978114.95788475 val_loss 206933.10937500\n",
      "epoch 3122 train_loss 10978114.95783882 val_loss 206933.10937500\n",
      "epoch 3123 train_loss 10978114.95773659 val_loss 206933.10937500\n",
      "epoch 3124 train_loss 10978114.95764641 val_loss 206933.10937500\n",
      "epoch 3125 train_loss 10978114.95753395 val_loss 206933.10937500\n",
      "epoch 3126 train_loss 10978114.95745682 val_loss 206933.10937500\n",
      "epoch 3127 train_loss 10978114.95735344 val_loss 206933.10937500\n",
      "epoch 3128 train_loss 10978114.95725906 val_loss 206933.10937500\n",
      "epoch 3129 train_loss 10978114.95720009 val_loss 206933.10937500\n",
      "epoch 3130 train_loss 10978114.95709480 val_loss 206933.10937500\n",
      "epoch 3131 train_loss 10978114.95699577 val_loss 206933.10937500\n",
      "epoch 3132 train_loss 10978114.95691933 val_loss 206933.10937500\n",
      "epoch 3133 train_loss 10978114.95683342 val_loss 206933.12500000\n",
      "epoch 3134 train_loss 10978114.95674942 val_loss 206933.12500000\n",
      "epoch 3135 train_loss 10978114.95667046 val_loss 206933.12500000\n",
      "epoch 3136 train_loss 10978114.95658478 val_loss 206933.12500000\n",
      "epoch 3137 train_loss 10978114.95647888 val_loss 206933.12500000\n",
      "epoch 3138 train_loss 10978114.95646866 val_loss 206933.12500000\n",
      "epoch 3139 train_loss 10978114.95636604 val_loss 206933.12500000\n",
      "epoch 3140 train_loss 10978114.95627571 val_loss 206933.12500000\n",
      "epoch 3141 train_loss 10978114.95618347 val_loss 206933.12500000\n",
      "epoch 3142 train_loss 10978114.95609398 val_loss 206933.12500000\n",
      "epoch 3143 train_loss 10978114.95600952 val_loss 206933.12500000\n",
      "epoch 3144 train_loss 10978114.95594673 val_loss 206933.12500000\n",
      "epoch 3145 train_loss 10978114.95592720 val_loss 206933.12500000\n",
      "epoch 3146 train_loss 10978114.95585220 val_loss 206933.12500000\n",
      "epoch 3147 train_loss 10978114.95575844 val_loss 206933.12500000\n",
      "epoch 3148 train_loss 10978114.95566330 val_loss 206933.12500000\n",
      "epoch 3149 train_loss 10978114.95560463 val_loss 206933.12500000\n",
      "epoch 3150 train_loss 10978114.95549637 val_loss 206933.12500000\n",
      "epoch 3151 train_loss 10978114.95540428 val_loss 206933.12500000\n",
      "epoch 3152 train_loss 10978114.95531998 val_loss 206933.12500000\n",
      "epoch 3153 train_loss 10978114.95522484 val_loss 206933.12500000\n",
      "epoch 3154 train_loss 10978114.95513847 val_loss 206933.12500000\n",
      "epoch 3155 train_loss 10978114.95506081 val_loss 206933.12500000\n",
      "epoch 3156 train_loss 10978114.95494888 val_loss 206933.12500000\n",
      "epoch 3157 train_loss 10978114.95496620 val_loss 206933.12500000\n",
      "epoch 3158 train_loss 10978114.95485695 val_loss 206933.12500000\n",
      "epoch 3159 train_loss 10978114.95477303 val_loss 206933.12500000\n",
      "epoch 3160 train_loss 10978114.95469658 val_loss 206933.12500000\n",
      "epoch 3161 train_loss 10978114.95459297 val_loss 206933.12500000\n",
      "epoch 3162 train_loss 10978114.95448738 val_loss 206933.12500000\n",
      "epoch 3163 train_loss 10978114.95441093 val_loss 206933.12500000\n",
      "epoch 3164 train_loss 10978114.95431709 val_loss 206933.12500000\n",
      "epoch 3165 train_loss 10978114.95424271 val_loss 206933.12500000\n",
      "epoch 3166 train_loss 10978114.95414154 val_loss 206933.12500000\n",
      "epoch 3167 train_loss 10978114.95403931 val_loss 206933.12500000\n",
      "epoch 3168 train_loss 10978114.95396095 val_loss 206933.12500000\n",
      "epoch 3169 train_loss 10978114.95386742 val_loss 206933.12500000\n",
      "epoch 3170 train_loss 10978114.95378044 val_loss 206933.12500000\n",
      "epoch 3171 train_loss 10978114.95369164 val_loss 206933.12500000\n",
      "epoch 3172 train_loss 10978114.95358841 val_loss 206933.12500000\n",
      "epoch 3173 train_loss 10978114.95351189 val_loss 206933.12500000\n",
      "epoch 3174 train_loss 10978114.95342392 val_loss 206933.12500000\n",
      "epoch 3175 train_loss 10978114.95336434 val_loss 206933.12500000\n",
      "epoch 3176 train_loss 10978114.95332527 val_loss 206933.12500000\n",
      "epoch 3177 train_loss 10978114.95318619 val_loss 206933.12500000\n",
      "epoch 3178 train_loss 10978114.95316032 val_loss 206933.12500000\n",
      "epoch 3179 train_loss 10978114.95306892 val_loss 206933.12500000\n",
      "epoch 3180 train_loss 10978114.95299080 val_loss 206933.12500000\n",
      "epoch 3181 train_loss 10978114.95287872 val_loss 206933.12500000\n",
      "epoch 3182 train_loss 10978114.95280785 val_loss 206933.12500000\n",
      "epoch 3183 train_loss 10978114.95271675 val_loss 206933.12500000\n",
      "epoch 3184 train_loss 10978114.95261566 val_loss 206933.12500000\n",
      "epoch 3185 train_loss 10978114.95252129 val_loss 206933.12500000\n",
      "epoch 3186 train_loss 10978114.95241997 val_loss 206933.12500000\n",
      "epoch 3187 train_loss 10978114.95233803 val_loss 206933.12500000\n",
      "epoch 3188 train_loss 10978114.95224930 val_loss 206933.12500000\n",
      "epoch 3189 train_loss 10978114.95217178 val_loss 206933.12500000\n",
      "epoch 3190 train_loss 10978114.95208443 val_loss 206933.12500000\n",
      "epoch 3191 train_loss 10978114.95201584 val_loss 206933.12500000\n",
      "epoch 3192 train_loss 10978114.95190636 val_loss 206933.12500000\n",
      "epoch 3193 train_loss 10978114.95181717 val_loss 206933.12500000\n",
      "epoch 3194 train_loss 10978114.95172859 val_loss 206933.12500000\n",
      "epoch 3195 train_loss 10978114.95164314 val_loss 206933.12500000\n",
      "epoch 3196 train_loss 10978114.95155304 val_loss 206933.12500000\n",
      "epoch 3197 train_loss 10978114.95145653 val_loss 206933.12500000\n",
      "epoch 3198 train_loss 10978114.95136970 val_loss 206933.12500000\n",
      "epoch 3199 train_loss 10978114.95126312 val_loss 206933.12500000\n",
      "epoch 3200 train_loss 10978114.95118095 val_loss 206933.12500000\n",
      "epoch 3201 train_loss 10978114.95108208 val_loss 206933.12500000\n",
      "epoch 3202 train_loss 10978114.95098831 val_loss 206933.12500000\n",
      "epoch 3203 train_loss 10978114.95093399 val_loss 206933.12500000\n",
      "epoch 3204 train_loss 10978114.95083283 val_loss 206933.12500000\n",
      "epoch 3205 train_loss 10978114.95074150 val_loss 206933.12500000\n",
      "epoch 3206 train_loss 10978114.95064133 val_loss 206933.12500000\n",
      "epoch 3207 train_loss 10978114.95056587 val_loss 206933.12500000\n",
      "epoch 3208 train_loss 10978114.95048057 val_loss 206933.12500000\n",
      "epoch 3209 train_loss 10978114.95038605 val_loss 206933.12500000\n",
      "epoch 3210 train_loss 10978114.95028999 val_loss 206933.12500000\n",
      "epoch 3211 train_loss 10978114.95020180 val_loss 206933.12500000\n",
      "epoch 3212 train_loss 10978114.95018082 val_loss 206933.12500000\n",
      "epoch 3213 train_loss 10978114.95011223 val_loss 206933.12500000\n",
      "epoch 3214 train_loss 10978114.94999695 val_loss 206933.12500000\n",
      "epoch 3215 train_loss 10978114.94991188 val_loss 206933.12500000\n",
      "epoch 3216 train_loss 10978114.94982208 val_loss 206933.12500000\n",
      "epoch 3217 train_loss 10978114.94971535 val_loss 206933.12500000\n",
      "epoch 3218 train_loss 10978114.94964249 val_loss 206933.12500000\n",
      "epoch 3219 train_loss 10978114.94955223 val_loss 206933.12500000\n",
      "epoch 3220 train_loss 10978114.94946365 val_loss 206933.12500000\n",
      "epoch 3221 train_loss 10978114.94937103 val_loss 206933.12500000\n",
      "epoch 3222 train_loss 10978114.94929077 val_loss 206933.12500000\n",
      "epoch 3223 train_loss 10978114.94921341 val_loss 206933.12500000\n",
      "epoch 3224 train_loss 10978114.94909920 val_loss 206933.12500000\n",
      "epoch 3225 train_loss 10978114.94902389 val_loss 206933.12500000\n",
      "epoch 3226 train_loss 10978114.94894676 val_loss 206933.12500000\n",
      "epoch 3227 train_loss 10978114.94886124 val_loss 206933.12500000\n",
      "epoch 3228 train_loss 10978114.94874847 val_loss 206933.12500000\n",
      "epoch 3229 train_loss 10978114.94865242 val_loss 206933.12500000\n",
      "epoch 3230 train_loss 10978114.94859100 val_loss 206933.12500000\n",
      "epoch 3231 train_loss 10978114.94851257 val_loss 206933.12500000\n",
      "epoch 3232 train_loss 10978114.94844460 val_loss 206933.12500000\n",
      "epoch 3233 train_loss 10978114.94834274 val_loss 206933.12500000\n",
      "epoch 3234 train_loss 10978114.94826645 val_loss 206933.12500000\n",
      "epoch 3235 train_loss 10978114.94816681 val_loss 206933.12500000\n",
      "epoch 3236 train_loss 10978114.94807640 val_loss 206933.12500000\n",
      "epoch 3237 train_loss 10978114.94797920 val_loss 206933.12500000\n",
      "epoch 3238 train_loss 10978114.94789772 val_loss 206933.12500000\n",
      "epoch 3239 train_loss 10978114.94783218 val_loss 206933.12500000\n",
      "epoch 3240 train_loss 10978114.94779335 val_loss 206933.12500000\n",
      "epoch 3241 train_loss 10978114.94769890 val_loss 206933.12500000\n",
      "epoch 3242 train_loss 10978114.94758865 val_loss 206933.12500000\n",
      "epoch 3243 train_loss 10978114.94749863 val_loss 206933.12500000\n",
      "epoch 3244 train_loss 10978114.94741936 val_loss 206933.12500000\n",
      "epoch 3245 train_loss 10978114.94735298 val_loss 206933.12500000\n",
      "epoch 3246 train_loss 10978114.94725830 val_loss 206933.12500000\n",
      "epoch 3247 train_loss 10978114.94718803 val_loss 206933.12500000\n",
      "epoch 3248 train_loss 10978114.94710869 val_loss 206933.12500000\n",
      "epoch 3249 train_loss 10978114.94705284 val_loss 206933.12500000\n",
      "epoch 3250 train_loss 10978114.94696846 val_loss 206933.12500000\n",
      "epoch 3251 train_loss 10978114.94686813 val_loss 206933.12500000\n",
      "epoch 3252 train_loss 10978114.94677048 val_loss 206933.12500000\n",
      "epoch 3253 train_loss 10978114.94666984 val_loss 206933.12500000\n",
      "epoch 3254 train_loss 10978114.94660011 val_loss 206933.12500000\n",
      "epoch 3255 train_loss 10978114.94653992 val_loss 206933.12500000\n",
      "epoch 3256 train_loss 10978114.94644127 val_loss 206933.12500000\n",
      "epoch 3257 train_loss 10978114.94633080 val_loss 206933.12500000\n",
      "epoch 3258 train_loss 10978114.94624184 val_loss 206933.12500000\n",
      "epoch 3259 train_loss 10978114.94614532 val_loss 206933.12500000\n",
      "epoch 3260 train_loss 10978114.94606018 val_loss 206933.12500000\n",
      "epoch 3261 train_loss 10978114.94596588 val_loss 206933.12500000\n",
      "epoch 3262 train_loss 10978114.94586914 val_loss 206933.12500000\n",
      "epoch 3263 train_loss 10978114.94577660 val_loss 206933.12500000\n",
      "epoch 3264 train_loss 10978114.94567276 val_loss 206933.12500000\n",
      "epoch 3265 train_loss 10978114.94555679 val_loss 206933.12500000\n",
      "epoch 3266 train_loss 10978114.94548904 val_loss 206933.12500000\n",
      "epoch 3267 train_loss 10978114.94545494 val_loss 206933.12500000\n",
      "epoch 3268 train_loss 10978114.94536453 val_loss 206933.12500000\n",
      "epoch 3269 train_loss 10978114.94526604 val_loss 206933.12500000\n",
      "epoch 3270 train_loss 10978114.94516762 val_loss 206933.12500000\n",
      "epoch 3271 train_loss 10978114.94512497 val_loss 206933.12500000\n",
      "epoch 3272 train_loss 10978114.94506287 val_loss 206933.12500000\n",
      "epoch 3273 train_loss 10978114.94498192 val_loss 206933.12500000\n",
      "epoch 3274 train_loss 10978114.94490623 val_loss 206933.12500000\n",
      "epoch 3275 train_loss 10978114.94480545 val_loss 206933.12500000\n",
      "epoch 3276 train_loss 10978114.94471596 val_loss 206933.12500000\n",
      "epoch 3277 train_loss 10978114.94462868 val_loss 206933.12500000\n",
      "epoch 3278 train_loss 10978114.94452545 val_loss 206933.12500000\n",
      "epoch 3279 train_loss 10978114.94442512 val_loss 206933.12500000\n",
      "epoch 3280 train_loss 10978114.94434891 val_loss 206933.12500000\n",
      "epoch 3281 train_loss 10978114.94427361 val_loss 206933.12500000\n",
      "epoch 3282 train_loss 10978114.94417541 val_loss 206933.12500000\n",
      "epoch 3283 train_loss 10978114.94409592 val_loss 206933.12500000\n",
      "epoch 3284 train_loss 10978114.94401260 val_loss 206933.12500000\n",
      "epoch 3285 train_loss 10978114.94391281 val_loss 206933.12500000\n",
      "epoch 3286 train_loss 10978114.94381416 val_loss 206933.12500000\n",
      "epoch 3287 train_loss 10978114.94373711 val_loss 206933.12500000\n",
      "epoch 3288 train_loss 10978114.94363167 val_loss 206933.12500000\n",
      "epoch 3289 train_loss 10978114.94351684 val_loss 206933.12500000\n",
      "epoch 3290 train_loss 10978114.94343353 val_loss 206933.12500000\n",
      "epoch 3291 train_loss 10978114.94335640 val_loss 206933.12500000\n",
      "epoch 3292 train_loss 10978114.94327141 val_loss 206933.12500000\n",
      "epoch 3293 train_loss 10978114.94319527 val_loss 206933.12500000\n",
      "epoch 3294 train_loss 10978114.94311546 val_loss 206933.12500000\n",
      "epoch 3295 train_loss 10978114.94301827 val_loss 206933.12500000\n",
      "epoch 3296 train_loss 10978114.94292992 val_loss 206933.12500000\n",
      "epoch 3297 train_loss 10978114.94284859 val_loss 206933.12500000\n",
      "epoch 3298 train_loss 10978114.94274963 val_loss 206933.12500000\n",
      "epoch 3299 train_loss 10978114.94266541 val_loss 206933.12500000\n",
      "epoch 3300 train_loss 10978114.94258972 val_loss 206933.12500000\n",
      "epoch 3301 train_loss 10978114.94248863 val_loss 206933.12500000\n",
      "epoch 3302 train_loss 10978114.94240288 val_loss 206933.12500000\n",
      "epoch 3303 train_loss 10978114.94232498 val_loss 206933.12500000\n",
      "epoch 3304 train_loss 10978114.94226059 val_loss 206933.12500000\n",
      "epoch 3305 train_loss 10978114.94216537 val_loss 206933.12500000\n",
      "epoch 3306 train_loss 10978114.94207886 val_loss 206933.12500000\n",
      "epoch 3307 train_loss 10978114.94198616 val_loss 206933.12500000\n",
      "epoch 3308 train_loss 10978114.94189850 val_loss 206933.12500000\n",
      "epoch 3309 train_loss 10978114.94182167 val_loss 206933.12500000\n",
      "epoch 3310 train_loss 10978114.94174904 val_loss 206933.12500000\n",
      "epoch 3311 train_loss 10978114.94165489 val_loss 206933.12500000\n",
      "epoch 3312 train_loss 10978114.94155502 val_loss 206933.14843750\n",
      "epoch 3313 train_loss 10978114.94148025 val_loss 206933.14843750\n",
      "epoch 3314 train_loss 10978114.94141594 val_loss 206933.14843750\n",
      "epoch 3315 train_loss 10978114.94131561 val_loss 206933.14843750\n",
      "epoch 3316 train_loss 10978114.94123543 val_loss 206933.14843750\n",
      "epoch 3317 train_loss 10978114.94114601 val_loss 206933.14843750\n",
      "epoch 3318 train_loss 10978114.94104118 val_loss 206933.14843750\n",
      "epoch 3319 train_loss 10978114.94095581 val_loss 206933.14843750\n",
      "epoch 3320 train_loss 10978114.94087402 val_loss 206933.14843750\n",
      "epoch 3321 train_loss 10978114.94080147 val_loss 206933.14843750\n",
      "epoch 3322 train_loss 10978114.94068932 val_loss 206933.14843750\n",
      "epoch 3323 train_loss 10978114.94059578 val_loss 206933.14843750\n",
      "epoch 3324 train_loss 10978114.94051926 val_loss 206933.14843750\n",
      "epoch 3325 train_loss 10978114.94041519 val_loss 206933.14843750\n",
      "epoch 3326 train_loss 10978114.94031998 val_loss 206933.14843750\n",
      "epoch 3327 train_loss 10978114.94023537 val_loss 206933.14843750\n",
      "epoch 3328 train_loss 10978114.94014542 val_loss 206933.14843750\n",
      "epoch 3329 train_loss 10978114.94004402 val_loss 206933.14843750\n",
      "epoch 3330 train_loss 10978114.93995171 val_loss 206933.14843750\n",
      "epoch 3331 train_loss 10978114.93986908 val_loss 206933.14843750\n",
      "epoch 3332 train_loss 10978114.93977799 val_loss 206933.14843750\n",
      "epoch 3333 train_loss 10978114.93967758 val_loss 206933.14843750\n",
      "epoch 3334 train_loss 10978114.93959511 val_loss 206933.14843750\n",
      "epoch 3335 train_loss 10978114.93950752 val_loss 206933.14843750\n",
      "epoch 3336 train_loss 10978114.93943138 val_loss 206933.14843750\n",
      "epoch 3337 train_loss 10978114.93933930 val_loss 206933.14843750\n",
      "epoch 3338 train_loss 10978114.93925026 val_loss 206933.14843750\n",
      "epoch 3339 train_loss 10978114.93917778 val_loss 206933.14843750\n",
      "epoch 3340 train_loss 10978114.93907944 val_loss 206933.14843750\n",
      "epoch 3341 train_loss 10978114.93896789 val_loss 206933.14843750\n",
      "epoch 3342 train_loss 10978114.93887520 val_loss 206933.14843750\n",
      "epoch 3343 train_loss 10978114.93882988 val_loss 206933.14843750\n",
      "epoch 3344 train_loss 10978114.93875244 val_loss 206933.14843750\n",
      "epoch 3345 train_loss 10978114.93865898 val_loss 206933.14843750\n",
      "epoch 3346 train_loss 10978114.93858589 val_loss 206933.14843750\n",
      "epoch 3347 train_loss 10978114.93849052 val_loss 206933.14843750\n",
      "epoch 3348 train_loss 10978114.93842117 val_loss 206933.14843750\n",
      "epoch 3349 train_loss 10978114.93832329 val_loss 206933.14843750\n",
      "epoch 3350 train_loss 10978114.93821999 val_loss 206933.14843750\n",
      "epoch 3351 train_loss 10978114.93820458 val_loss 206933.14843750\n",
      "epoch 3352 train_loss 10978114.93810974 val_loss 206933.14843750\n",
      "epoch 3353 train_loss 10978114.93807312 val_loss 206933.14843750\n",
      "epoch 3354 train_loss 10978114.93797790 val_loss 206933.14843750\n",
      "epoch 3355 train_loss 10978114.93789337 val_loss 206933.14843750\n",
      "epoch 3356 train_loss 10978114.93779175 val_loss 206933.14843750\n",
      "epoch 3357 train_loss 10978114.93769768 val_loss 206933.14843750\n",
      "epoch 3358 train_loss 10978114.93761368 val_loss 206933.14843750\n",
      "epoch 3359 train_loss 10978114.93751221 val_loss 206933.14843750\n",
      "epoch 3360 train_loss 10978114.93743294 val_loss 206933.14843750\n",
      "epoch 3361 train_loss 10978114.93733109 val_loss 206933.14843750\n",
      "epoch 3362 train_loss 10978114.93725120 val_loss 206933.14843750\n",
      "epoch 3363 train_loss 10978114.93714722 val_loss 206933.14843750\n",
      "epoch 3364 train_loss 10978114.93705131 val_loss 206933.14843750\n",
      "epoch 3365 train_loss 10978114.93696114 val_loss 206933.14843750\n",
      "epoch 3366 train_loss 10978114.93685097 val_loss 206933.14843750\n",
      "epoch 3367 train_loss 10978114.93681465 val_loss 206933.14843750\n",
      "epoch 3368 train_loss 10978114.93671501 val_loss 206933.14843750\n",
      "epoch 3369 train_loss 10978114.93662231 val_loss 206933.14843750\n",
      "epoch 3370 train_loss 10978114.93656158 val_loss 206933.14843750\n",
      "epoch 3371 train_loss 10978114.93646301 val_loss 206933.14843750\n",
      "epoch 3372 train_loss 10978114.93642410 val_loss 206933.14843750\n",
      "epoch 3373 train_loss 10978114.93632645 val_loss 206933.14843750\n",
      "epoch 3374 train_loss 10978114.93622360 val_loss 206933.14843750\n",
      "epoch 3375 train_loss 10978114.93612495 val_loss 206933.14843750\n",
      "epoch 3376 train_loss 10978114.93608353 val_loss 206933.14843750\n",
      "epoch 3377 train_loss 10978114.93598602 val_loss 206933.14843750\n",
      "epoch 3378 train_loss 10978114.93590866 val_loss 206933.14843750\n",
      "epoch 3379 train_loss 10978114.93583397 val_loss 206933.14843750\n",
      "epoch 3380 train_loss 10978114.93575859 val_loss 206933.14843750\n",
      "epoch 3381 train_loss 10978114.93567024 val_loss 206933.14843750\n",
      "epoch 3382 train_loss 10978114.93557549 val_loss 206933.14843750\n",
      "epoch 3383 train_loss 10978114.93549675 val_loss 206933.14843750\n",
      "epoch 3384 train_loss 10978114.93540802 val_loss 206933.14843750\n",
      "epoch 3385 train_loss 10978114.93532013 val_loss 206933.14843750\n",
      "epoch 3386 train_loss 10978114.93524063 val_loss 206933.14843750\n",
      "epoch 3387 train_loss 10978114.93513657 val_loss 206933.14843750\n",
      "epoch 3388 train_loss 10978114.93503921 val_loss 206933.14843750\n",
      "epoch 3389 train_loss 10978114.93496246 val_loss 206933.14843750\n",
      "epoch 3390 train_loss 10978114.93484421 val_loss 206933.14843750\n",
      "epoch 3391 train_loss 10978114.93476112 val_loss 206933.14843750\n",
      "epoch 3392 train_loss 10978114.93467239 val_loss 206933.14843750\n",
      "epoch 3393 train_loss 10978114.93459358 val_loss 206933.14843750\n",
      "epoch 3394 train_loss 10978114.93448936 val_loss 206933.14843750\n",
      "epoch 3395 train_loss 10978114.93441315 val_loss 206933.14843750\n",
      "epoch 3396 train_loss 10978114.93432121 val_loss 206933.14843750\n",
      "epoch 3397 train_loss 10978114.93422233 val_loss 206933.14843750\n",
      "epoch 3398 train_loss 10978114.93416931 val_loss 206933.14843750\n",
      "epoch 3399 train_loss 10978114.93408943 val_loss 206933.14843750\n",
      "epoch 3400 train_loss 10978114.93401566 val_loss 206933.14843750\n",
      "epoch 3401 train_loss 10978114.93388832 val_loss 206933.14843750\n",
      "epoch 3402 train_loss 10978114.93380524 val_loss 206933.14843750\n",
      "epoch 3403 train_loss 10978114.93372086 val_loss 206933.14843750\n",
      "epoch 3404 train_loss 10978114.93361359 val_loss 206933.14843750\n",
      "epoch 3405 train_loss 10978114.93352333 val_loss 206933.14843750\n",
      "epoch 3406 train_loss 10978114.93347290 val_loss 206933.14843750\n",
      "epoch 3407 train_loss 10978114.93340172 val_loss 206933.14843750\n",
      "epoch 3408 train_loss 10978114.93330200 val_loss 206933.14843750\n",
      "epoch 3409 train_loss 10978114.93322685 val_loss 206933.14843750\n",
      "epoch 3410 train_loss 10978114.93315186 val_loss 206933.14843750\n",
      "epoch 3411 train_loss 10978114.93308037 val_loss 206933.14843750\n",
      "epoch 3412 train_loss 10978114.93298057 val_loss 206933.14843750\n",
      "epoch 3413 train_loss 10978114.93288429 val_loss 206933.14843750\n",
      "epoch 3414 train_loss 10978114.93282432 val_loss 206933.14843750\n",
      "epoch 3415 train_loss 10978114.93271462 val_loss 206933.14843750\n",
      "epoch 3416 train_loss 10978114.93262291 val_loss 206933.14843750\n",
      "epoch 3417 train_loss 10978114.93257126 val_loss 206933.14843750\n",
      "epoch 3418 train_loss 10978114.93247414 val_loss 206933.14843750\n",
      "epoch 3419 train_loss 10978114.93237923 val_loss 206933.14843750\n",
      "epoch 3420 train_loss 10978114.93229027 val_loss 206933.14843750\n",
      "epoch 3421 train_loss 10978114.93222824 val_loss 206933.14843750\n",
      "epoch 3422 train_loss 10978114.93214531 val_loss 206933.14843750\n",
      "epoch 3423 train_loss 10978114.93205696 val_loss 206933.14843750\n",
      "epoch 3424 train_loss 10978114.93196014 val_loss 206933.14843750\n",
      "epoch 3425 train_loss 10978114.93187752 val_loss 206933.14843750\n",
      "epoch 3426 train_loss 10978114.93176865 val_loss 206933.14843750\n",
      "epoch 3427 train_loss 10978114.93172073 val_loss 206933.14843750\n",
      "epoch 3428 train_loss 10978114.93163498 val_loss 206933.14843750\n",
      "epoch 3429 train_loss 10978114.93153976 val_loss 206933.14843750\n",
      "epoch 3430 train_loss 10978114.93142387 val_loss 206933.14843750\n",
      "epoch 3431 train_loss 10978114.93133591 val_loss 206933.14843750\n",
      "epoch 3432 train_loss 10978114.93124969 val_loss 206933.14843750\n",
      "epoch 3433 train_loss 10978114.93114952 val_loss 206933.14843750\n",
      "epoch 3434 train_loss 10978114.93106209 val_loss 206933.14843750\n",
      "epoch 3435 train_loss 10978114.93098801 val_loss 206933.14843750\n",
      "epoch 3436 train_loss 10978114.93087814 val_loss 206933.14843750\n",
      "epoch 3437 train_loss 10978114.93080650 val_loss 206933.14843750\n",
      "epoch 3438 train_loss 10978114.93071068 val_loss 206933.14843750\n",
      "epoch 3439 train_loss 10978114.93061905 val_loss 206933.14843750\n",
      "epoch 3440 train_loss 10978114.93053429 val_loss 206933.14843750\n",
      "epoch 3441 train_loss 10978114.93045136 val_loss 206933.14843750\n",
      "epoch 3442 train_loss 10978114.93035500 val_loss 206933.14843750\n",
      "epoch 3443 train_loss 10978114.93027107 val_loss 206933.14843750\n",
      "epoch 3444 train_loss 10978114.93016006 val_loss 206933.14843750\n",
      "epoch 3445 train_loss 10978114.93009697 val_loss 206933.14843750\n",
      "epoch 3446 train_loss 10978114.93000458 val_loss 206933.14843750\n",
      "epoch 3447 train_loss 10978114.92991615 val_loss 206933.14843750\n",
      "epoch 3448 train_loss 10978114.92982956 val_loss 206933.14843750\n",
      "epoch 3449 train_loss 10978114.92975639 val_loss 206933.14843750\n",
      "epoch 3450 train_loss 10978114.92968033 val_loss 206933.14843750\n",
      "epoch 3451 train_loss 10978114.92957848 val_loss 206933.14843750\n",
      "epoch 3452 train_loss 10978114.92948944 val_loss 206933.14843750\n",
      "epoch 3453 train_loss 10978114.92939705 val_loss 206933.14843750\n",
      "epoch 3454 train_loss 10978114.92929787 val_loss 206933.14843750\n",
      "epoch 3455 train_loss 10978114.92920372 val_loss 206933.14843750\n",
      "epoch 3456 train_loss 10978114.92911430 val_loss 206933.14843750\n",
      "epoch 3457 train_loss 10978114.92903229 val_loss 206933.14843750\n",
      "epoch 3458 train_loss 10978114.92893868 val_loss 206933.14843750\n",
      "epoch 3459 train_loss 10978114.92884514 val_loss 206933.14843750\n",
      "epoch 3460 train_loss 10978114.92877449 val_loss 206933.14843750\n",
      "epoch 3461 train_loss 10978114.92868019 val_loss 206933.14843750\n",
      "epoch 3462 train_loss 10978114.92860374 val_loss 206933.14843750\n",
      "epoch 3463 train_loss 10978114.92850807 val_loss 206933.14843750\n",
      "epoch 3464 train_loss 10978114.92842560 val_loss 206933.14843750\n",
      "epoch 3465 train_loss 10978114.92833633 val_loss 206933.14843750\n",
      "epoch 3466 train_loss 10978114.92822784 val_loss 206933.14843750\n",
      "epoch 3467 train_loss 10978114.92822014 val_loss 206933.14843750\n",
      "epoch 3468 train_loss 10978114.92815330 val_loss 206933.14843750\n",
      "epoch 3469 train_loss 10978114.92806610 val_loss 206933.14843750\n",
      "epoch 3470 train_loss 10978114.92799522 val_loss 206933.14843750\n",
      "epoch 3471 train_loss 10978114.92791023 val_loss 206933.14843750\n",
      "epoch 3472 train_loss 10978114.92781639 val_loss 206933.14843750\n",
      "epoch 3473 train_loss 10978114.92772133 val_loss 206933.14843750\n",
      "epoch 3474 train_loss 10978114.92763145 val_loss 206933.14843750\n",
      "epoch 3475 train_loss 10978114.92754585 val_loss 206933.14843750\n",
      "epoch 3476 train_loss 10978114.92744011 val_loss 206933.14843750\n",
      "epoch 3477 train_loss 10978114.92736603 val_loss 206933.14843750\n",
      "epoch 3478 train_loss 10978114.92726547 val_loss 206933.14843750\n",
      "epoch 3479 train_loss 10978114.92717316 val_loss 206933.14843750\n",
      "epoch 3480 train_loss 10978114.92707253 val_loss 206933.14843750\n",
      "epoch 3481 train_loss 10978114.92699547 val_loss 206933.14843750\n",
      "epoch 3482 train_loss 10978114.92693214 val_loss 206933.14843750\n",
      "epoch 3483 train_loss 10978114.92685349 val_loss 206933.14843750\n",
      "epoch 3484 train_loss 10978114.92675919 val_loss 206933.14843750\n",
      "epoch 3485 train_loss 10978114.92665169 val_loss 206933.14843750\n",
      "epoch 3486 train_loss 10978114.92657669 val_loss 206933.14843750\n",
      "epoch 3487 train_loss 10978114.92647408 val_loss 206933.14843750\n",
      "epoch 3488 train_loss 10978114.92638466 val_loss 206933.14843750\n",
      "epoch 3489 train_loss 10978114.92629387 val_loss 206933.14843750\n",
      "epoch 3490 train_loss 10978114.92617828 val_loss 206933.14843750\n",
      "epoch 3491 train_loss 10978114.92608551 val_loss 206933.14843750\n",
      "epoch 3492 train_loss 10978114.92600304 val_loss 206933.14843750\n",
      "epoch 3493 train_loss 10978114.92594841 val_loss 206933.14843750\n",
      "epoch 3494 train_loss 10978114.92585297 val_loss 206933.14843750\n",
      "epoch 3495 train_loss 10978114.92574303 val_loss 206933.14843750\n",
      "epoch 3496 train_loss 10978114.92568207 val_loss 206933.14843750\n",
      "epoch 3497 train_loss 10978114.92558800 val_loss 206933.14843750\n",
      "epoch 3498 train_loss 10978114.92547875 val_loss 206933.14843750\n",
      "epoch 3499 train_loss 10978114.92540184 val_loss 206933.14843750\n",
      "epoch 3500 train_loss 10978114.92530449 val_loss 206933.14843750\n",
      "epoch 3501 train_loss 10978114.92522057 val_loss 206933.14843750\n",
      "epoch 3502 train_loss 10978114.92512764 val_loss 206933.14843750\n",
      "epoch 3503 train_loss 10978114.92503090 val_loss 206933.14843750\n",
      "epoch 3504 train_loss 10978114.92495209 val_loss 206933.14843750\n",
      "epoch 3505 train_loss 10978114.92486206 val_loss 206933.14843750\n",
      "epoch 3506 train_loss 10978114.92477264 val_loss 206933.14843750\n",
      "epoch 3507 train_loss 10978114.92468720 val_loss 206933.14843750\n",
      "epoch 3508 train_loss 10978114.92458359 val_loss 206933.14843750\n",
      "epoch 3509 train_loss 10978114.92450935 val_loss 206933.14843750\n",
      "epoch 3510 train_loss 10978114.92441261 val_loss 206933.14843750\n",
      "epoch 3511 train_loss 10978114.92431900 val_loss 206933.14843750\n",
      "epoch 3512 train_loss 10978114.92425728 val_loss 206933.14843750\n",
      "epoch 3513 train_loss 10978114.92416237 val_loss 206933.14843750\n",
      "epoch 3514 train_loss 10978114.92408211 val_loss 206933.14843750\n",
      "epoch 3515 train_loss 10978114.92399742 val_loss 206933.14843750\n",
      "epoch 3516 train_loss 10978114.92389458 val_loss 206933.14843750\n",
      "epoch 3517 train_loss 10978114.92378708 val_loss 206933.14843750\n",
      "epoch 3518 train_loss 10978114.92369690 val_loss 206933.14843750\n",
      "epoch 3519 train_loss 10978114.92361557 val_loss 206933.14843750\n",
      "epoch 3520 train_loss 10978114.92351707 val_loss 206933.14843750\n",
      "epoch 3521 train_loss 10978114.92344864 val_loss 206933.14843750\n",
      "epoch 3522 train_loss 10978114.92335327 val_loss 206933.14843750\n",
      "epoch 3523 train_loss 10978114.92324493 val_loss 206933.14843750\n",
      "epoch 3524 train_loss 10978114.92316628 val_loss 206933.14843750\n",
      "epoch 3525 train_loss 10978114.92305977 val_loss 206933.14843750\n",
      "epoch 3526 train_loss 10978114.92297020 val_loss 206933.14843750\n",
      "epoch 3527 train_loss 10978114.92287827 val_loss 206933.14843750\n",
      "epoch 3528 train_loss 10978114.92286644 val_loss 206933.14843750\n",
      "epoch 3529 train_loss 10978114.92278908 val_loss 206933.14843750\n",
      "epoch 3530 train_loss 10978114.92270836 val_loss 206933.14843750\n",
      "epoch 3531 train_loss 10978114.92260429 val_loss 206933.14843750\n",
      "epoch 3532 train_loss 10978114.92251427 val_loss 206933.14843750\n",
      "epoch 3533 train_loss 10978114.92243263 val_loss 206933.14843750\n",
      "epoch 3534 train_loss 10978114.92234398 val_loss 206933.14843750\n",
      "epoch 3535 train_loss 10978114.92226921 val_loss 206933.14843750\n",
      "epoch 3536 train_loss 10978114.92216675 val_loss 206933.14843750\n",
      "epoch 3537 train_loss 10978114.92207550 val_loss 206933.14843750\n",
      "epoch 3538 train_loss 10978114.92197777 val_loss 206933.14843750\n",
      "epoch 3539 train_loss 10978114.92188026 val_loss 206933.14843750\n",
      "epoch 3540 train_loss 10978114.92178757 val_loss 206933.14843750\n",
      "epoch 3541 train_loss 10978114.92168686 val_loss 206933.14843750\n",
      "epoch 3542 train_loss 10978114.92164391 val_loss 206933.14843750\n",
      "epoch 3543 train_loss 10978114.92155739 val_loss 206933.14843750\n",
      "epoch 3544 train_loss 10978114.92147041 val_loss 206933.14843750\n",
      "epoch 3545 train_loss 10978114.92140030 val_loss 206933.14843750\n",
      "epoch 3546 train_loss 10978114.92131424 val_loss 206933.14843750\n",
      "epoch 3547 train_loss 10978114.92122215 val_loss 206933.14843750\n",
      "epoch 3548 train_loss 10978114.92112991 val_loss 206933.14843750\n",
      "epoch 3549 train_loss 10978114.92102257 val_loss 206933.14843750\n",
      "epoch 3550 train_loss 10978114.92094048 val_loss 206933.14843750\n",
      "epoch 3551 train_loss 10978114.92089294 val_loss 206933.14843750\n",
      "epoch 3552 train_loss 10978114.92081925 val_loss 206933.14843750\n",
      "epoch 3553 train_loss 10978114.92070595 val_loss 206933.14843750\n",
      "epoch 3554 train_loss 10978114.92062630 val_loss 206933.14843750\n",
      "epoch 3555 train_loss 10978114.92055038 val_loss 206933.14843750\n",
      "epoch 3556 train_loss 10978114.92043419 val_loss 206933.14843750\n",
      "epoch 3557 train_loss 10978114.92036324 val_loss 206933.14843750\n",
      "epoch 3558 train_loss 10978114.92026253 val_loss 206933.14843750\n",
      "epoch 3559 train_loss 10978114.92076904 val_loss 206933.14843750\n",
      "epoch 3560 train_loss 10978114.92070915 val_loss 206933.14843750\n",
      "epoch 3561 train_loss 10978114.92063660 val_loss 206933.14843750\n",
      "epoch 3562 train_loss 10978114.92052109 val_loss 206933.14843750\n",
      "epoch 3563 train_loss 10978114.92043282 val_loss 206933.14843750\n",
      "epoch 3564 train_loss 10978114.92033928 val_loss 206933.14843750\n",
      "epoch 3565 train_loss 10978114.92025963 val_loss 206933.14843750\n",
      "epoch 3566 train_loss 10978114.92016968 val_loss 206933.14843750\n",
      "epoch 3567 train_loss 10978114.92009659 val_loss 206933.14843750\n",
      "epoch 3568 train_loss 10978114.92001762 val_loss 206933.14843750\n",
      "epoch 3569 train_loss 10978114.92001587 val_loss 206933.14843750\n",
      "epoch 3570 train_loss 10978114.91990433 val_loss 206933.14843750\n",
      "epoch 3571 train_loss 10978114.91980682 val_loss 206933.14843750\n",
      "epoch 3572 train_loss 10978114.91970421 val_loss 206933.14843750\n",
      "epoch 3573 train_loss 10978114.91961334 val_loss 206933.14843750\n",
      "epoch 3574 train_loss 10978114.91950798 val_loss 206933.14843750\n",
      "epoch 3575 train_loss 10978114.91945236 val_loss 206933.14843750\n",
      "epoch 3576 train_loss 10978114.91935310 val_loss 206933.14843750\n",
      "epoch 3577 train_loss 10978114.91927185 val_loss 206933.14843750\n",
      "epoch 3578 train_loss 10978114.91918709 val_loss 206933.14843750\n",
      "epoch 3579 train_loss 10978114.91909843 val_loss 206933.14843750\n",
      "epoch 3580 train_loss 10978114.91902634 val_loss 206933.14843750\n",
      "epoch 3581 train_loss 10978114.91892288 val_loss 206933.14843750\n",
      "epoch 3582 train_loss 10978114.91891945 val_loss 206933.14843750\n",
      "epoch 3583 train_loss 10978114.91883598 val_loss 206933.14843750\n",
      "epoch 3584 train_loss 10978114.91875595 val_loss 206933.14843750\n",
      "epoch 3585 train_loss 10978114.91867027 val_loss 206933.14843750\n",
      "epoch 3586 train_loss 10978114.91857063 val_loss 206933.14843750\n",
      "epoch 3587 train_loss 10978114.91847099 val_loss 206933.14843750\n",
      "epoch 3588 train_loss 10978114.91842857 val_loss 206933.14843750\n",
      "epoch 3589 train_loss 10978114.91834572 val_loss 206933.14843750\n",
      "epoch 3590 train_loss 10978114.91827431 val_loss 206933.14843750\n",
      "epoch 3591 train_loss 10978114.91819115 val_loss 206933.14843750\n",
      "epoch 3592 train_loss 10978114.91809448 val_loss 206933.14843750\n",
      "epoch 3593 train_loss 10978114.91799011 val_loss 206933.14843750\n",
      "epoch 3594 train_loss 10978114.91790810 val_loss 206933.14843750\n",
      "epoch 3595 train_loss 10978114.91782669 val_loss 206933.14843750\n",
      "epoch 3596 train_loss 10978114.91771149 val_loss 206933.14843750\n",
      "epoch 3597 train_loss 10978114.91763451 val_loss 206933.14843750\n",
      "epoch 3598 train_loss 10978114.91752701 val_loss 206933.14843750\n",
      "epoch 3599 train_loss 10978114.91742065 val_loss 206933.14843750\n",
      "epoch 3600 train_loss 10978114.91733139 val_loss 206933.14843750\n",
      "epoch 3601 train_loss 10978114.91724388 val_loss 206933.14843750\n",
      "epoch 3602 train_loss 10978114.91717407 val_loss 206933.14843750\n",
      "epoch 3603 train_loss 10978114.91707916 val_loss 206933.14843750\n",
      "epoch 3604 train_loss 10978114.91699089 val_loss 206933.14843750\n",
      "epoch 3605 train_loss 10978114.91692429 val_loss 206933.14843750\n",
      "epoch 3606 train_loss 10978114.91682739 val_loss 206933.14843750\n",
      "epoch 3607 train_loss 10978114.91673202 val_loss 206933.14843750\n",
      "epoch 3608 train_loss 10978114.91664436 val_loss 206933.14843750\n",
      "epoch 3609 train_loss 10978114.91659714 val_loss 206933.14843750\n",
      "epoch 3610 train_loss 10978114.91656349 val_loss 206933.14843750\n",
      "epoch 3611 train_loss 10978114.91646034 val_loss 206933.14843750\n",
      "epoch 3612 train_loss 10978114.91637169 val_loss 206933.14843750\n",
      "epoch 3613 train_loss 10978114.91627075 val_loss 206933.14843750\n",
      "epoch 3614 train_loss 10978114.91620842 val_loss 206933.14843750\n",
      "epoch 3615 train_loss 10978114.91611145 val_loss 206933.14843750\n",
      "epoch 3616 train_loss 10978114.91602524 val_loss 206933.14843750\n",
      "epoch 3617 train_loss 10978114.91598274 val_loss 206933.14843750\n",
      "epoch 3618 train_loss 10978114.91588661 val_loss 206933.14843750\n",
      "epoch 3619 train_loss 10978114.91580292 val_loss 206933.14843750\n",
      "epoch 3620 train_loss 10978114.91569542 val_loss 206933.14843750\n",
      "epoch 3621 train_loss 10978114.91559959 val_loss 206933.14843750\n",
      "epoch 3622 train_loss 10978114.91553558 val_loss 206933.14843750\n",
      "epoch 3623 train_loss 10978114.91550530 val_loss 206933.14843750\n",
      "epoch 3624 train_loss 10978114.91538712 val_loss 206933.14843750\n",
      "epoch 3625 train_loss 10978114.91530067 val_loss 206933.14843750\n",
      "epoch 3626 train_loss 10978114.91521919 val_loss 206933.14843750\n",
      "epoch 3627 train_loss 10978114.91512802 val_loss 206933.14843750\n",
      "epoch 3628 train_loss 10978114.91504692 val_loss 206933.14843750\n",
      "epoch 3629 train_loss 10978114.91494293 val_loss 206933.14843750\n",
      "epoch 3630 train_loss 10978114.91485023 val_loss 206933.14843750\n",
      "epoch 3631 train_loss 10978114.91476624 val_loss 206933.14843750\n",
      "epoch 3632 train_loss 10978114.91464859 val_loss 206933.14843750\n",
      "epoch 3633 train_loss 10978114.91465569 val_loss 206933.14843750\n",
      "epoch 3634 train_loss 10978114.91456367 val_loss 206933.14843750\n",
      "epoch 3635 train_loss 10978114.91445694 val_loss 206933.14843750\n",
      "epoch 3636 train_loss 10978114.91439293 val_loss 206933.14843750\n",
      "epoch 3637 train_loss 10978114.91429710 val_loss 206933.14843750\n",
      "epoch 3638 train_loss 10978114.91420769 val_loss 206933.14843750\n",
      "epoch 3639 train_loss 10978114.91412888 val_loss 206933.14843750\n",
      "epoch 3640 train_loss 10978114.91401695 val_loss 206933.14843750\n",
      "epoch 3641 train_loss 10978114.91395668 val_loss 206933.14843750\n",
      "epoch 3642 train_loss 10978114.91384804 val_loss 206933.14843750\n",
      "epoch 3643 train_loss 10978114.91377098 val_loss 206933.14843750\n",
      "epoch 3644 train_loss 10978114.91367790 val_loss 206933.14843750\n",
      "epoch 3645 train_loss 10978114.91360634 val_loss 206933.14843750\n",
      "epoch 3646 train_loss 10978114.91351204 val_loss 206933.14843750\n",
      "epoch 3647 train_loss 10978114.91341736 val_loss 206933.14843750\n",
      "epoch 3648 train_loss 10978114.91331123 val_loss 206933.14843750\n",
      "epoch 3649 train_loss 10978114.91322212 val_loss 206933.14843750\n",
      "epoch 3650 train_loss 10978114.91315178 val_loss 206933.14843750\n",
      "epoch 3651 train_loss 10978114.91304085 val_loss 206933.14843750\n",
      "epoch 3652 train_loss 10978114.91299026 val_loss 206933.14843750\n",
      "epoch 3653 train_loss 10978114.91289536 val_loss 206933.14843750\n",
      "epoch 3654 train_loss 10978114.91278503 val_loss 206933.14843750\n",
      "epoch 3655 train_loss 10978114.91270767 val_loss 206933.14843750\n",
      "epoch 3656 train_loss 10978114.91261406 val_loss 206933.14843750\n",
      "epoch 3657 train_loss 10978114.91251267 val_loss 206933.14843750\n",
      "epoch 3658 train_loss 10978114.91242699 val_loss 206933.14843750\n",
      "epoch 3659 train_loss 10978114.91234619 val_loss 206933.14843750\n",
      "epoch 3660 train_loss 10978114.91225929 val_loss 206933.14843750\n",
      "epoch 3661 train_loss 10978114.91216705 val_loss 206933.14843750\n",
      "epoch 3662 train_loss 10978114.91206230 val_loss 206933.14843750\n",
      "epoch 3663 train_loss 10978114.91198006 val_loss 206933.14843750\n",
      "epoch 3664 train_loss 10978114.91189125 val_loss 206933.14843750\n",
      "epoch 3665 train_loss 10978114.91181564 val_loss 206933.14843750\n",
      "epoch 3666 train_loss 10978114.91174248 val_loss 206933.14843750\n",
      "epoch 3667 train_loss 10978114.91166229 val_loss 206933.14843750\n",
      "epoch 3668 train_loss 10978114.91155014 val_loss 206933.14843750\n",
      "epoch 3669 train_loss 10978114.91147926 val_loss 206933.14843750\n",
      "epoch 3670 train_loss 10978114.91139023 val_loss 206933.14843750\n",
      "epoch 3671 train_loss 10978114.91130089 val_loss 206933.14843750\n",
      "epoch 3672 train_loss 10978114.91121460 val_loss 206933.14843750\n",
      "epoch 3673 train_loss 10978114.91111549 val_loss 206933.14843750\n",
      "epoch 3674 train_loss 10978114.91103851 val_loss 206933.14843750\n",
      "epoch 3675 train_loss 10978114.91092880 val_loss 206933.14843750\n",
      "epoch 3676 train_loss 10978114.91083511 val_loss 206933.14843750\n",
      "epoch 3677 train_loss 10978114.91076073 val_loss 206933.14843750\n",
      "epoch 3678 train_loss 10978114.91066841 val_loss 206933.14843750\n",
      "epoch 3679 train_loss 10978114.91056717 val_loss 206933.14843750\n",
      "epoch 3680 train_loss 10978114.91047379 val_loss 206933.14843750\n",
      "epoch 3681 train_loss 10978114.91040443 val_loss 206933.14843750\n",
      "epoch 3682 train_loss 10978114.91031853 val_loss 206933.14843750\n",
      "epoch 3683 train_loss 10978114.91023499 val_loss 206933.14843750\n",
      "epoch 3684 train_loss 10978114.91017685 val_loss 206933.14843750\n",
      "epoch 3685 train_loss 10978114.91007416 val_loss 206933.14843750\n",
      "epoch 3686 train_loss 10978114.91002212 val_loss 206933.14843750\n",
      "epoch 3687 train_loss 10978114.90992775 val_loss 206933.14843750\n",
      "epoch 3688 train_loss 10978114.90983887 val_loss 206933.14843750\n",
      "epoch 3689 train_loss 10978114.90973610 val_loss 206933.14843750\n",
      "epoch 3690 train_loss 10978114.90965118 val_loss 206933.14843750\n",
      "epoch 3691 train_loss 10978114.90956024 val_loss 206933.14843750\n",
      "epoch 3692 train_loss 10978114.90948555 val_loss 206933.14843750\n",
      "epoch 3693 train_loss 10978114.90952156 val_loss 206933.14843750\n",
      "epoch 3694 train_loss 10978114.90947556 val_loss 206933.14843750\n",
      "epoch 3695 train_loss 10978114.90939179 val_loss 206933.14843750\n",
      "epoch 3696 train_loss 10978114.90932991 val_loss 206933.14843750\n",
      "epoch 3697 train_loss 10978114.90923912 val_loss 206933.14843750\n",
      "epoch 3698 train_loss 10978114.90915642 val_loss 206933.14843750\n",
      "epoch 3699 train_loss 10978114.90905128 val_loss 206933.14843750\n",
      "epoch 3700 train_loss 10978114.90896996 val_loss 206933.14843750\n",
      "epoch 3701 train_loss 10978114.90890930 val_loss 206933.14843750\n",
      "epoch 3702 train_loss 10978114.90882881 val_loss 206933.14843750\n",
      "epoch 3703 train_loss 10978114.90872459 val_loss 206933.14843750\n",
      "epoch 3704 train_loss 10978114.90862953 val_loss 206933.14843750\n",
      "epoch 3705 train_loss 10978114.90853905 val_loss 206933.14843750\n",
      "epoch 3706 train_loss 10978114.90845665 val_loss 206933.14843750\n",
      "epoch 3707 train_loss 10978114.90834618 val_loss 206933.14843750\n",
      "epoch 3708 train_loss 10978114.90826073 val_loss 206933.14843750\n",
      "epoch 3709 train_loss 10978114.90817078 val_loss 206933.14843750\n",
      "epoch 3710 train_loss 10978114.90807899 val_loss 206933.14843750\n",
      "epoch 3711 train_loss 10978114.90797997 val_loss 206933.14843750\n",
      "epoch 3712 train_loss 10978114.90789108 val_loss 206933.14843750\n",
      "epoch 3713 train_loss 10978114.90779617 val_loss 206933.14843750\n",
      "epoch 3714 train_loss 10978114.90774666 val_loss 206933.14843750\n",
      "epoch 3715 train_loss 10978114.90763725 val_loss 206933.14843750\n",
      "epoch 3716 train_loss 10978114.90755325 val_loss 206933.14843750\n",
      "epoch 3717 train_loss 10978114.90747543 val_loss 206933.14843750\n",
      "epoch 3718 train_loss 10978114.90736382 val_loss 206933.14843750\n",
      "epoch 3719 train_loss 10978114.90727806 val_loss 206933.14843750\n",
      "epoch 3720 train_loss 10978114.90718567 val_loss 206933.14843750\n",
      "epoch 3721 train_loss 10978114.90710403 val_loss 206933.14843750\n",
      "epoch 3722 train_loss 10978114.90700928 val_loss 206933.14843750\n",
      "epoch 3723 train_loss 10978114.90692680 val_loss 206933.14843750\n",
      "epoch 3724 train_loss 10978114.90682770 val_loss 206933.14843750\n",
      "epoch 3725 train_loss 10978114.90673645 val_loss 206933.14843750\n",
      "epoch 3726 train_loss 10978114.90665810 val_loss 206933.14843750\n",
      "epoch 3727 train_loss 10978114.90655922 val_loss 206933.14843750\n",
      "epoch 3728 train_loss 10978114.90647911 val_loss 206933.14843750\n",
      "epoch 3729 train_loss 10978114.90636749 val_loss 206933.14843750\n",
      "epoch 3730 train_loss 10978114.90627586 val_loss 206933.14843750\n",
      "epoch 3731 train_loss 10978114.90618912 val_loss 206933.14843750\n",
      "epoch 3732 train_loss 10978114.90609154 val_loss 206933.14843750\n",
      "epoch 3733 train_loss 10978114.90604019 val_loss 206933.14843750\n",
      "epoch 3734 train_loss 10978114.90595131 val_loss 206933.14843750\n",
      "epoch 3735 train_loss 10978114.90584747 val_loss 206933.14843750\n",
      "epoch 3736 train_loss 10978114.90575386 val_loss 206933.14843750\n",
      "epoch 3737 train_loss 10978114.90570366 val_loss 206933.14843750\n",
      "epoch 3738 train_loss 10978114.90559082 val_loss 206933.14843750\n",
      "epoch 3739 train_loss 10978114.90551949 val_loss 206933.14843750\n",
      "epoch 3740 train_loss 10978114.90542541 val_loss 206933.14843750\n",
      "epoch 3741 train_loss 10978114.90533295 val_loss 206933.14843750\n",
      "epoch 3742 train_loss 10978114.90524803 val_loss 206933.14843750\n",
      "epoch 3743 train_loss 10978114.90514061 val_loss 206933.14843750\n",
      "epoch 3744 train_loss 10978114.90504364 val_loss 206933.14843750\n",
      "epoch 3745 train_loss 10978114.90496323 val_loss 206933.14843750\n",
      "epoch 3746 train_loss 10978114.90490814 val_loss 206933.14843750\n",
      "epoch 3747 train_loss 10978114.90485359 val_loss 206933.14843750\n",
      "epoch 3748 train_loss 10978114.90475716 val_loss 206933.14843750\n",
      "epoch 3749 train_loss 10978114.90468262 val_loss 206933.14843750\n",
      "epoch 3750 train_loss 10978114.90459404 val_loss 206933.14843750\n",
      "epoch 3751 train_loss 10978114.90450577 val_loss 206933.14843750\n",
      "epoch 3752 train_loss 10978114.90441010 val_loss 206933.14843750\n",
      "epoch 3753 train_loss 10978114.90434082 val_loss 206933.14843750\n",
      "epoch 3754 train_loss 10978114.90425331 val_loss 206933.14843750\n",
      "epoch 3755 train_loss 10978114.90414391 val_loss 206933.14843750\n",
      "epoch 3756 train_loss 10978114.90406677 val_loss 206933.14843750\n",
      "epoch 3757 train_loss 10978114.90395752 val_loss 206933.14843750\n",
      "epoch 3758 train_loss 10978114.90385902 val_loss 206933.14843750\n",
      "epoch 3759 train_loss 10978114.90377556 val_loss 206933.14843750\n",
      "epoch 3760 train_loss 10978114.90368401 val_loss 206933.14843750\n",
      "epoch 3761 train_loss 10978114.90360336 val_loss 206933.14843750\n",
      "epoch 3762 train_loss 10978114.90349022 val_loss 206933.14843750\n",
      "epoch 3763 train_loss 10978114.90346611 val_loss 206933.14843750\n",
      "epoch 3764 train_loss 10978114.90345642 val_loss 206933.14843750\n",
      "epoch 3765 train_loss 10978114.90335709 val_loss 206933.14843750\n",
      "epoch 3766 train_loss 10978114.90324593 val_loss 206933.14843750\n",
      "epoch 3767 train_loss 10978114.90318840 val_loss 206933.14843750\n",
      "epoch 3768 train_loss 10978114.90308006 val_loss 206933.14843750\n",
      "epoch 3769 train_loss 10978114.90298668 val_loss 206933.14843750\n",
      "epoch 3770 train_loss 10978114.90291435 val_loss 206933.14843750\n",
      "epoch 3771 train_loss 10978114.90281105 val_loss 206933.14843750\n",
      "epoch 3772 train_loss 10978114.90270508 val_loss 206933.14843750\n",
      "epoch 3773 train_loss 10978114.90261070 val_loss 206933.14843750\n",
      "epoch 3774 train_loss 10978114.90253815 val_loss 206933.14843750\n",
      "epoch 3775 train_loss 10978114.90245255 val_loss 206933.14843750\n",
      "epoch 3776 train_loss 10978114.90240395 val_loss 206933.14843750\n",
      "epoch 3777 train_loss 10978114.90237419 val_loss 206933.14843750\n",
      "epoch 3778 train_loss 10978114.90226425 val_loss 206933.14843750\n",
      "epoch 3779 train_loss 10978114.90217148 val_loss 206933.14843750\n",
      "epoch 3780 train_loss 10978114.90209724 val_loss 206933.14843750\n",
      "epoch 3781 train_loss 10978114.90202072 val_loss 206933.14843750\n",
      "epoch 3782 train_loss 10978114.90194672 val_loss 206933.14843750\n",
      "epoch 3783 train_loss 10978114.90184082 val_loss 206933.14843750\n",
      "epoch 3784 train_loss 10978114.90174934 val_loss 206933.14843750\n",
      "epoch 3785 train_loss 10978114.90164909 val_loss 206933.14843750\n",
      "epoch 3786 train_loss 10978114.90156372 val_loss 206933.14843750\n",
      "epoch 3787 train_loss 10978114.90149025 val_loss 206933.14843750\n",
      "epoch 3788 train_loss 10978114.90139801 val_loss 206933.14843750\n",
      "epoch 3789 train_loss 10978114.90133377 val_loss 206933.14843750\n",
      "epoch 3790 train_loss 10978114.90121269 val_loss 206933.14843750\n",
      "epoch 3791 train_loss 10978114.90112747 val_loss 206933.14843750\n",
      "epoch 3792 train_loss 10978114.90102470 val_loss 206933.14843750\n",
      "epoch 3793 train_loss 10978114.90098381 val_loss 206933.14843750\n",
      "epoch 3794 train_loss 10978114.90086327 val_loss 206933.14843750\n",
      "epoch 3795 train_loss 10978114.90079246 val_loss 206933.14843750\n",
      "epoch 3796 train_loss 10978114.90070068 val_loss 206933.14843750\n",
      "epoch 3797 train_loss 10978114.90060806 val_loss 206933.14843750\n",
      "epoch 3798 train_loss 10978114.90053932 val_loss 206933.14843750\n",
      "epoch 3799 train_loss 10978114.90043892 val_loss 206933.14843750\n",
      "epoch 3800 train_loss 10978114.90034714 val_loss 206933.14843750\n",
      "epoch 3801 train_loss 10978114.90025436 val_loss 206933.14843750\n",
      "epoch 3802 train_loss 10978114.90015510 val_loss 206933.14843750\n",
      "epoch 3803 train_loss 10978114.90007050 val_loss 206933.14843750\n",
      "epoch 3804 train_loss 10978114.89997650 val_loss 206933.14843750\n",
      "epoch 3805 train_loss 10978114.89989433 val_loss 206933.14843750\n",
      "epoch 3806 train_loss 10978114.89979942 val_loss 206933.14843750\n",
      "epoch 3807 train_loss 10978114.89971794 val_loss 206933.14843750\n",
      "epoch 3808 train_loss 10978114.89965439 val_loss 206933.14843750\n",
      "epoch 3809 train_loss 10978114.89955795 val_loss 206933.14843750\n",
      "epoch 3810 train_loss 10978114.89948067 val_loss 206933.14843750\n",
      "epoch 3811 train_loss 10978114.89937332 val_loss 206933.14843750\n",
      "epoch 3812 train_loss 10978114.89927673 val_loss 206933.14843750\n",
      "epoch 3813 train_loss 10978114.89922111 val_loss 206933.14843750\n",
      "epoch 3814 train_loss 10978114.89912209 val_loss 206933.14843750\n",
      "epoch 3815 train_loss 10978114.89904671 val_loss 206933.14843750\n",
      "epoch 3816 train_loss 10978114.89895691 val_loss 206933.14843750\n",
      "epoch 3817 train_loss 10978114.89886261 val_loss 206933.14843750\n",
      "epoch 3818 train_loss 10978114.89876160 val_loss 206933.14843750\n",
      "epoch 3819 train_loss 10978114.89865990 val_loss 206933.14843750\n",
      "epoch 3820 train_loss 10978114.89857369 val_loss 206933.14843750\n",
      "epoch 3821 train_loss 10978114.89848946 val_loss 206933.14843750\n",
      "epoch 3822 train_loss 10978114.89839508 val_loss 206933.14843750\n",
      "epoch 3823 train_loss 10978114.89830933 val_loss 206933.14843750\n",
      "epoch 3824 train_loss 10978114.89823753 val_loss 206933.14843750\n",
      "epoch 3825 train_loss 10978114.89814796 val_loss 206933.14843750\n",
      "epoch 3826 train_loss 10978114.89804420 val_loss 206933.14843750\n",
      "epoch 3827 train_loss 10978114.89798325 val_loss 206933.14843750\n",
      "epoch 3828 train_loss 10978114.89790947 val_loss 206933.14843750\n",
      "epoch 3829 train_loss 10978114.89780922 val_loss 206933.14843750\n",
      "epoch 3830 train_loss 10978114.89770660 val_loss 206933.14843750\n",
      "epoch 3831 train_loss 10978114.89764198 val_loss 206933.14843750\n",
      "epoch 3832 train_loss 10978114.89755821 val_loss 206933.14843750\n",
      "epoch 3833 train_loss 10978114.89745407 val_loss 206933.14843750\n",
      "epoch 3834 train_loss 10978114.89735741 val_loss 206933.14843750\n",
      "epoch 3835 train_loss 10978114.89726448 val_loss 206933.14843750\n",
      "epoch 3836 train_loss 10978114.89717308 val_loss 206933.14843750\n",
      "epoch 3837 train_loss 10978114.89709732 val_loss 206933.14843750\n",
      "epoch 3838 train_loss 10978114.89699608 val_loss 206933.14843750\n",
      "epoch 3839 train_loss 10978114.89691231 val_loss 206933.14843750\n",
      "epoch 3840 train_loss 10978114.89682228 val_loss 206933.14843750\n",
      "epoch 3841 train_loss 10978114.89672653 val_loss 206933.14843750\n",
      "epoch 3842 train_loss 10978114.89663277 val_loss 206933.14843750\n",
      "epoch 3843 train_loss 10978114.89654457 val_loss 206933.14843750\n",
      "epoch 3844 train_loss 10978114.89643783 val_loss 206933.14843750\n",
      "epoch 3845 train_loss 10978114.89634872 val_loss 206933.14843750\n",
      "epoch 3846 train_loss 10978114.89627846 val_loss 206933.14843750\n",
      "epoch 3847 train_loss 10978114.89618065 val_loss 206933.14843750\n",
      "epoch 3848 train_loss 10978114.89607498 val_loss 206933.14843750\n",
      "epoch 3849 train_loss 10978114.89601379 val_loss 206933.14843750\n",
      "epoch 3850 train_loss 10978114.89599190 val_loss 206933.14843750\n",
      "epoch 3851 train_loss 10978114.89588867 val_loss 206933.14843750\n",
      "epoch 3852 train_loss 10978114.89578308 val_loss 206933.14843750\n",
      "epoch 3853 train_loss 10978114.89570847 val_loss 206933.14843750\n",
      "epoch 3854 train_loss 10978114.89561600 val_loss 206933.14843750\n",
      "epoch 3855 train_loss 10978114.89554611 val_loss 206933.14843750\n",
      "epoch 3856 train_loss 10978114.89546539 val_loss 206933.14843750\n",
      "epoch 3857 train_loss 10978114.89538208 val_loss 206933.14843750\n",
      "epoch 3858 train_loss 10978114.89530090 val_loss 206933.14843750\n",
      "epoch 3859 train_loss 10978114.89521683 val_loss 206933.14843750\n",
      "epoch 3860 train_loss 10978114.89512733 val_loss 206933.14843750\n",
      "epoch 3861 train_loss 10978114.89503838 val_loss 206933.14843750\n",
      "epoch 3862 train_loss 10978114.89496010 val_loss 206933.14843750\n",
      "epoch 3863 train_loss 10978114.89501648 val_loss 206933.14843750\n",
      "epoch 3864 train_loss 10978114.89493248 val_loss 206933.14843750\n",
      "epoch 3865 train_loss 10978114.89484253 val_loss 206933.14843750\n",
      "epoch 3866 train_loss 10978114.89472885 val_loss 206933.14843750\n",
      "epoch 3867 train_loss 10978114.89464050 val_loss 206933.14843750\n",
      "epoch 3868 train_loss 10978114.89456032 val_loss 206933.14843750\n",
      "epoch 3869 train_loss 10978114.89445976 val_loss 206933.14843750\n",
      "epoch 3870 train_loss 10978114.89436325 val_loss 206933.14843750\n",
      "epoch 3871 train_loss 10978114.89426720 val_loss 206933.14843750\n",
      "epoch 3872 train_loss 10978114.89418663 val_loss 206933.14843750\n",
      "epoch 3873 train_loss 10978114.89413452 val_loss 206933.14843750\n",
      "epoch 3874 train_loss 10978114.89403534 val_loss 206933.14843750\n",
      "epoch 3875 train_loss 10978114.89397720 val_loss 206933.14843750\n",
      "epoch 3876 train_loss 10978114.89392166 val_loss 206933.14843750\n",
      "epoch 3877 train_loss 10978114.89386200 val_loss 206933.14843750\n",
      "epoch 3878 train_loss 10978114.89377388 val_loss 206933.14843750\n",
      "epoch 3879 train_loss 10978114.89366814 val_loss 206933.14843750\n",
      "epoch 3880 train_loss 10978114.89358116 val_loss 206933.14843750\n",
      "epoch 3881 train_loss 10978114.89352791 val_loss 206933.14843750\n",
      "epoch 3882 train_loss 10978114.89343941 val_loss 206933.14843750\n",
      "epoch 3883 train_loss 10978114.89334099 val_loss 206933.14843750\n",
      "epoch 3884 train_loss 10978114.89326569 val_loss 206933.14843750\n",
      "epoch 3885 train_loss 10978114.89320557 val_loss 206933.14843750\n",
      "epoch 3886 train_loss 10978114.89311577 val_loss 206933.14843750\n",
      "epoch 3887 train_loss 10978114.89304649 val_loss 206933.14843750\n",
      "epoch 3888 train_loss 10978114.89294250 val_loss 206933.14843750\n",
      "epoch 3889 train_loss 10978114.89284424 val_loss 206933.14843750\n",
      "epoch 3890 train_loss 10978114.89274605 val_loss 206933.14843750\n",
      "epoch 3891 train_loss 10978114.89264450 val_loss 206933.14843750\n",
      "epoch 3892 train_loss 10978114.89255325 val_loss 206933.14843750\n",
      "epoch 3893 train_loss 10978114.89248558 val_loss 206933.14843750\n",
      "epoch 3894 train_loss 10978114.89239395 val_loss 206933.14843750\n",
      "epoch 3895 train_loss 10978114.89230408 val_loss 206933.14843750\n",
      "epoch 3896 train_loss 10978114.89221390 val_loss 206933.14843750\n",
      "epoch 3897 train_loss 10978114.89212753 val_loss 206933.14843750\n",
      "epoch 3898 train_loss 10978114.89203835 val_loss 206933.14843750\n",
      "epoch 3899 train_loss 10978114.89194473 val_loss 206933.14843750\n",
      "epoch 3900 train_loss 10978114.89184761 val_loss 206933.14843750\n",
      "epoch 3901 train_loss 10978114.89176674 val_loss 206933.14843750\n",
      "epoch 3902 train_loss 10978114.89165459 val_loss 206933.14843750\n",
      "epoch 3903 train_loss 10978114.89156990 val_loss 206933.14843750\n",
      "epoch 3904 train_loss 10978114.89148521 val_loss 206933.14843750\n",
      "epoch 3905 train_loss 10978114.89138794 val_loss 206933.14843750\n",
      "epoch 3906 train_loss 10978114.89128586 val_loss 206933.14843750\n",
      "epoch 3907 train_loss 10978114.89121483 val_loss 206933.14843750\n",
      "epoch 3908 train_loss 10978114.89111824 val_loss 206933.14843750\n",
      "epoch 3909 train_loss 10978114.89105797 val_loss 206933.14843750\n",
      "epoch 3910 train_loss 10978114.89097099 val_loss 206933.14843750\n",
      "epoch 3911 train_loss 10978114.89090042 val_loss 206933.14843750\n",
      "epoch 3912 train_loss 10978114.89080559 val_loss 206933.14843750\n",
      "epoch 3913 train_loss 10978114.89070152 val_loss 206933.14843750\n",
      "epoch 3914 train_loss 10978114.89061302 val_loss 206933.14843750\n",
      "epoch 3915 train_loss 10978114.89051521 val_loss 206933.14843750\n",
      "epoch 3916 train_loss 10978114.89043541 val_loss 206933.14843750\n",
      "epoch 3917 train_loss 10978114.89031982 val_loss 206933.14843750\n",
      "epoch 3918 train_loss 10978114.89025177 val_loss 206933.14843750\n",
      "epoch 3919 train_loss 10978114.89018295 val_loss 206933.14843750\n",
      "epoch 3920 train_loss 10978114.89009041 val_loss 206933.16406250\n",
      "epoch 3921 train_loss 10978114.88999542 val_loss 206933.16406250\n",
      "epoch 3922 train_loss 10978114.88992599 val_loss 206933.16406250\n",
      "epoch 3923 train_loss 10978114.88984673 val_loss 206933.16406250\n",
      "epoch 3924 train_loss 10978114.88975449 val_loss 206933.16406250\n",
      "epoch 3925 train_loss 10978114.88965477 val_loss 206933.16406250\n",
      "epoch 3926 train_loss 10978114.88955750 val_loss 206933.16406250\n",
      "epoch 3927 train_loss 10978114.88945274 val_loss 206933.16406250\n",
      "epoch 3928 train_loss 10978114.88936798 val_loss 206933.16406250\n",
      "epoch 3929 train_loss 10978114.88927658 val_loss 206933.16406250\n",
      "epoch 3930 train_loss 10978114.88918297 val_loss 206933.16406250\n",
      "epoch 3931 train_loss 10978114.88910126 val_loss 206933.16406250\n",
      "epoch 3932 train_loss 10978114.88900810 val_loss 206933.16406250\n",
      "epoch 3933 train_loss 10978114.88892097 val_loss 206933.16406250\n",
      "epoch 3934 train_loss 10978114.88882896 val_loss 206933.16406250\n",
      "epoch 3935 train_loss 10978114.88873367 val_loss 206933.16406250\n",
      "epoch 3936 train_loss 10978114.88865311 val_loss 206933.16406250\n",
      "epoch 3937 train_loss 10978114.88855652 val_loss 206933.16406250\n",
      "epoch 3938 train_loss 10978114.88846519 val_loss 206933.16406250\n",
      "epoch 3939 train_loss 10978114.88836700 val_loss 206933.16406250\n",
      "epoch 3940 train_loss 10978114.88828171 val_loss 206933.16406250\n",
      "epoch 3941 train_loss 10978114.88819542 val_loss 206933.16406250\n",
      "epoch 3942 train_loss 10978114.88810547 val_loss 206933.16406250\n",
      "epoch 3943 train_loss 10978114.88800461 val_loss 206933.16406250\n",
      "epoch 3944 train_loss 10978114.88791901 val_loss 206933.16406250\n",
      "epoch 3945 train_loss 10978114.88787201 val_loss 206933.16406250\n",
      "epoch 3946 train_loss 10978114.88779739 val_loss 206933.16406250\n",
      "epoch 3947 train_loss 10978114.88771011 val_loss 206933.16406250\n",
      "epoch 3948 train_loss 10978114.88762070 val_loss 206933.16406250\n",
      "epoch 3949 train_loss 10978114.88754829 val_loss 206933.16406250\n",
      "epoch 3950 train_loss 10978114.88747345 val_loss 206933.16406250\n",
      "epoch 3951 train_loss 10978114.88736931 val_loss 206933.16406250\n",
      "epoch 3952 train_loss 10978114.88727997 val_loss 206933.16406250\n",
      "epoch 3953 train_loss 10978114.88717735 val_loss 206933.16406250\n",
      "epoch 3954 train_loss 10978114.88708694 val_loss 206933.16406250\n",
      "epoch 3955 train_loss 10978114.88700844 val_loss 206933.16406250\n",
      "epoch 3956 train_loss 10978114.88691536 val_loss 206933.16406250\n",
      "epoch 3957 train_loss 10978114.88683128 val_loss 206933.16406250\n",
      "epoch 3958 train_loss 10978114.88672653 val_loss 206933.16406250\n",
      "epoch 3959 train_loss 10978114.88664528 val_loss 206933.16406250\n",
      "epoch 3960 train_loss 10978114.88655952 val_loss 206933.16406250\n",
      "epoch 3961 train_loss 10978114.88647697 val_loss 206933.16406250\n",
      "epoch 3962 train_loss 10978114.88637985 val_loss 206933.16406250\n",
      "epoch 3963 train_loss 10978114.88628349 val_loss 206933.16406250\n",
      "epoch 3964 train_loss 10978114.88619118 val_loss 206933.16406250\n",
      "epoch 3965 train_loss 10978114.88611923 val_loss 206933.16406250\n",
      "epoch 3966 train_loss 10978114.88603203 val_loss 206933.16406250\n",
      "epoch 3967 train_loss 10978114.88592918 val_loss 206933.16406250\n",
      "epoch 3968 train_loss 10978114.88585358 val_loss 206933.16406250\n",
      "epoch 3969 train_loss 10978114.88579101 val_loss 206933.16406250\n",
      "epoch 3970 train_loss 10978114.88569817 val_loss 206933.16406250\n",
      "epoch 3971 train_loss 10978114.88561058 val_loss 206933.16406250\n",
      "epoch 3972 train_loss 10978114.88552178 val_loss 206933.16406250\n",
      "epoch 3973 train_loss 10978114.88547836 val_loss 206933.16406250\n",
      "epoch 3974 train_loss 10978114.88536522 val_loss 206933.16406250\n",
      "epoch 3975 train_loss 10978114.88528541 val_loss 206933.16406250\n",
      "epoch 3976 train_loss 10978114.88519020 val_loss 206933.16406250\n",
      "epoch 3977 train_loss 10978114.88510567 val_loss 206933.16406250\n",
      "epoch 3978 train_loss 10978114.88501152 val_loss 206933.16406250\n",
      "epoch 3979 train_loss 10978114.88490204 val_loss 206933.16406250\n",
      "epoch 3980 train_loss 10978114.88483955 val_loss 206933.16406250\n",
      "epoch 3981 train_loss 10978114.88472755 val_loss 206933.16406250\n",
      "epoch 3982 train_loss 10978114.88463234 val_loss 206933.16406250\n",
      "epoch 3983 train_loss 10978114.88455643 val_loss 206933.16406250\n",
      "epoch 3984 train_loss 10978114.88448563 val_loss 206933.16406250\n",
      "epoch 3985 train_loss 10978114.88437599 val_loss 206933.16406250\n",
      "epoch 3986 train_loss 10978114.88430435 val_loss 206933.17968750\n",
      "epoch 3987 train_loss 10978114.88423515 val_loss 206933.17968750\n",
      "epoch 3988 train_loss 10978114.88413475 val_loss 206933.17968750\n",
      "epoch 3989 train_loss 10978114.88406776 val_loss 206933.17968750\n",
      "epoch 3990 train_loss 10978114.88397011 val_loss 206933.17968750\n",
      "epoch 3991 train_loss 10978114.88386932 val_loss 206933.17968750\n",
      "epoch 3992 train_loss 10978114.88376289 val_loss 206933.17968750\n",
      "epoch 3993 train_loss 10978114.88369194 val_loss 206933.17968750\n",
      "epoch 3994 train_loss 10978114.88358490 val_loss 206933.17968750\n",
      "epoch 3995 train_loss 10978114.88354057 val_loss 206933.17968750\n",
      "epoch 3996 train_loss 10978114.88344688 val_loss 206933.17968750\n",
      "epoch 3997 train_loss 10978114.88335846 val_loss 206933.17968750\n",
      "epoch 3998 train_loss 10978114.88330261 val_loss 206933.17968750\n",
      "epoch 3999 train_loss 10978114.88328346 val_loss 206933.17968750\n",
      "epoch 4000 train_loss 10978114.88316597 val_loss 206933.17968750\n",
      "epoch 4001 train_loss 10978114.88309402 val_loss 206933.17968750\n",
      "epoch 4002 train_loss 10978114.88300827 val_loss 206933.17968750\n",
      "epoch 4003 train_loss 10978114.88290535 val_loss 206933.17968750\n",
      "epoch 4004 train_loss 10978114.88281769 val_loss 206933.17968750\n",
      "epoch 4005 train_loss 10978114.88271759 val_loss 206933.17968750\n",
      "epoch 4006 train_loss 10978114.88262840 val_loss 206933.17968750\n",
      "epoch 4007 train_loss 10978114.88254898 val_loss 206933.17968750\n",
      "epoch 4008 train_loss 10978114.88228966 val_loss 206933.17968750\n",
      "epoch 4009 train_loss 10978114.88220078 val_loss 206933.17968750\n",
      "epoch 4010 train_loss 10978114.88210983 val_loss 206933.17968750\n",
      "epoch 4011 train_loss 10978114.88202156 val_loss 206933.17968750\n",
      "epoch 4012 train_loss 10978114.88192429 val_loss 206933.17968750\n",
      "epoch 4013 train_loss 10978114.88184235 val_loss 206933.17968750\n",
      "epoch 4014 train_loss 10978114.88178924 val_loss 206933.17968750\n",
      "epoch 4015 train_loss 10978114.88169044 val_loss 206933.17968750\n",
      "epoch 4016 train_loss 10978114.88161636 val_loss 206933.17968750\n",
      "epoch 4017 train_loss 10978114.88151894 val_loss 206933.17968750\n",
      "epoch 4018 train_loss 10978114.88151855 val_loss 206933.17968750\n",
      "epoch 4019 train_loss 10978114.88142479 val_loss 206933.17968750\n",
      "epoch 4020 train_loss 10978114.88134903 val_loss 206933.17968750\n",
      "epoch 4021 train_loss 10978114.88123406 val_loss 206933.17968750\n",
      "epoch 4022 train_loss 10978114.88115021 val_loss 206933.17968750\n",
      "epoch 4023 train_loss 10978114.88108192 val_loss 206933.17968750\n",
      "epoch 4024 train_loss 10978114.88097916 val_loss 206933.17968750\n",
      "epoch 4025 train_loss 10978114.88088432 val_loss 206933.17968750\n",
      "epoch 4026 train_loss 10978114.88079422 val_loss 206933.17968750\n",
      "epoch 4027 train_loss 10978114.88070839 val_loss 206933.17968750\n",
      "epoch 4028 train_loss 10978114.88060806 val_loss 206933.17968750\n",
      "epoch 4029 train_loss 10978114.88053185 val_loss 206933.17968750\n",
      "epoch 4030 train_loss 10978114.88044891 val_loss 206933.17968750\n",
      "epoch 4031 train_loss 10978114.88035248 val_loss 206933.17968750\n",
      "epoch 4032 train_loss 10978114.88026711 val_loss 206933.17968750\n",
      "epoch 4033 train_loss 10978114.88015114 val_loss 206933.17968750\n",
      "epoch 4034 train_loss 10978114.88008606 val_loss 206933.17968750\n",
      "epoch 4035 train_loss 10978114.87999413 val_loss 206933.17968750\n",
      "epoch 4036 train_loss 10978114.87989883 val_loss 206933.17968750\n",
      "epoch 4037 train_loss 10978114.87981567 val_loss 206933.17968750\n",
      "epoch 4038 train_loss 10978114.87973625 val_loss 206933.17968750\n",
      "epoch 4039 train_loss 10978114.87962952 val_loss 206933.17968750\n",
      "epoch 4040 train_loss 10978114.87953964 val_loss 206933.17968750\n",
      "epoch 4041 train_loss 10978114.87944695 val_loss 206933.17968750\n",
      "epoch 4042 train_loss 10978114.87937729 val_loss 206933.17968750\n",
      "epoch 4043 train_loss 10978114.87927925 val_loss 206933.17968750\n",
      "epoch 4044 train_loss 10978114.87918877 val_loss 206933.17968750\n",
      "epoch 4045 train_loss 10978114.87913681 val_loss 206933.17968750\n",
      "epoch 4046 train_loss 10978114.87903313 val_loss 206933.17968750\n",
      "epoch 4047 train_loss 10978114.87893929 val_loss 206933.17968750\n",
      "epoch 4048 train_loss 10978114.87886024 val_loss 206933.17968750\n",
      "epoch 4049 train_loss 10978114.87878380 val_loss 206933.17968750\n",
      "epoch 4050 train_loss 10978114.87867706 val_loss 206933.17968750\n",
      "epoch 4051 train_loss 10978114.87861061 val_loss 206933.17968750\n",
      "epoch 4052 train_loss 10978114.87854012 val_loss 206933.17968750\n",
      "epoch 4053 train_loss 10978114.87843582 val_loss 206933.17968750\n",
      "epoch 4054 train_loss 10978114.87836189 val_loss 206933.17968750\n",
      "epoch 4055 train_loss 10978114.87826691 val_loss 206933.17968750\n",
      "epoch 4056 train_loss 10978114.87819443 val_loss 206933.17968750\n",
      "epoch 4057 train_loss 10978114.87808212 val_loss 206933.17968750\n",
      "epoch 4058 train_loss 10978114.87798470 val_loss 206933.17968750\n",
      "epoch 4059 train_loss 10978114.87789322 val_loss 206933.17968750\n",
      "epoch 4060 train_loss 10978114.87782089 val_loss 206933.17968750\n",
      "epoch 4061 train_loss 10978114.87771179 val_loss 206933.17968750\n",
      "epoch 4062 train_loss 10978114.87763237 val_loss 206933.17968750\n",
      "epoch 4063 train_loss 10978114.87752228 val_loss 206933.17968750\n",
      "epoch 4064 train_loss 10978114.87742882 val_loss 206933.17968750\n",
      "epoch 4065 train_loss 10978114.87736603 val_loss 206933.17968750\n",
      "epoch 4066 train_loss 10978114.87728127 val_loss 206933.17968750\n",
      "epoch 4067 train_loss 10978114.87720840 val_loss 206933.17968750\n",
      "epoch 4068 train_loss 10978114.87712189 val_loss 206933.17968750\n",
      "epoch 4069 train_loss 10978114.87703590 val_loss 206933.17968750\n",
      "epoch 4070 train_loss 10978114.87694542 val_loss 206933.17968750\n",
      "epoch 4071 train_loss 10978114.87683403 val_loss 206933.17968750\n",
      "epoch 4072 train_loss 10978114.87676582 val_loss 206933.17968750\n",
      "epoch 4073 train_loss 10978114.87668373 val_loss 206933.17968750\n",
      "epoch 4074 train_loss 10978114.87658668 val_loss 206933.17968750\n",
      "epoch 4075 train_loss 10978114.87652817 val_loss 206933.17968750\n",
      "epoch 4076 train_loss 10978114.87642685 val_loss 206933.17968750\n",
      "epoch 4077 train_loss 10978114.87636200 val_loss 206933.17968750\n",
      "epoch 4078 train_loss 10978114.87628929 val_loss 206933.17968750\n",
      "epoch 4079 train_loss 10978114.87618118 val_loss 206933.17968750\n",
      "epoch 4080 train_loss 10978114.87609337 val_loss 206933.17968750\n",
      "epoch 4081 train_loss 10978114.87600578 val_loss 206933.17968750\n",
      "epoch 4082 train_loss 10978114.87591476 val_loss 206933.17968750\n",
      "epoch 4083 train_loss 10978114.87581299 val_loss 206933.17968750\n",
      "epoch 4084 train_loss 10978114.87573585 val_loss 206933.17968750\n",
      "epoch 4085 train_loss 10978114.87572304 val_loss 206933.17968750\n",
      "epoch 4086 train_loss 10978114.87562401 val_loss 206933.17968750\n",
      "epoch 4087 train_loss 10978114.87553429 val_loss 206933.17968750\n",
      "epoch 4088 train_loss 10978114.87544281 val_loss 206933.17968750\n",
      "epoch 4089 train_loss 10978114.87535912 val_loss 206933.17968750\n",
      "epoch 4090 train_loss 10978114.87525574 val_loss 206933.17968750\n",
      "epoch 4091 train_loss 10978114.87518661 val_loss 206933.17968750\n",
      "epoch 4092 train_loss 10978114.87509529 val_loss 206933.17968750\n",
      "epoch 4093 train_loss 10978114.87503304 val_loss 206933.17968750\n",
      "epoch 4094 train_loss 10978114.87494125 val_loss 206933.17968750\n",
      "epoch 4095 train_loss 10978114.87486534 val_loss 206933.17968750\n",
      "epoch 4096 train_loss 10978114.87491005 val_loss 206933.17968750\n",
      "epoch 4097 train_loss 10978114.87481766 val_loss 206933.17968750\n",
      "epoch 4098 train_loss 10978114.87473755 val_loss 206933.17968750\n",
      "epoch 4099 train_loss 10978114.87462051 val_loss 206933.17968750\n",
      "epoch 4100 train_loss 10978114.87452087 val_loss 206933.17968750\n",
      "epoch 4101 train_loss 10978114.87445015 val_loss 206933.17968750\n",
      "epoch 4102 train_loss 10978114.87434814 val_loss 206933.17968750\n",
      "epoch 4103 train_loss 10978114.87427803 val_loss 206933.17968750\n",
      "epoch 4104 train_loss 10978114.87417191 val_loss 206933.17968750\n",
      "epoch 4105 train_loss 10978114.87407692 val_loss 206933.17968750\n",
      "epoch 4106 train_loss 10978114.87401848 val_loss 206933.17968750\n",
      "epoch 4107 train_loss 10978114.87392357 val_loss 206933.17968750\n",
      "epoch 4108 train_loss 10978114.87387108 val_loss 206933.17968750\n",
      "epoch 4109 train_loss 10978114.87379913 val_loss 206933.17968750\n",
      "epoch 4110 train_loss 10978114.87370399 val_loss 206933.17968750\n",
      "epoch 4111 train_loss 10978114.87362724 val_loss 206933.17968750\n",
      "epoch 4112 train_loss 10978114.87357437 val_loss 206933.17968750\n",
      "epoch 4113 train_loss 10978114.87348694 val_loss 206933.17968750\n",
      "epoch 4114 train_loss 10978114.87341194 val_loss 206933.17968750\n",
      "epoch 4115 train_loss 10978114.87332863 val_loss 206933.17968750\n",
      "epoch 4116 train_loss 10978114.87322006 val_loss 206933.17968750\n",
      "epoch 4117 train_loss 10978114.87313355 val_loss 206933.17968750\n",
      "epoch 4118 train_loss 10978114.87302757 val_loss 206933.17968750\n",
      "epoch 4119 train_loss 10978114.87293251 val_loss 206933.17968750\n",
      "epoch 4120 train_loss 10978114.87285233 val_loss 206933.17968750\n",
      "epoch 4121 train_loss 10978114.87276565 val_loss 206933.17968750\n",
      "epoch 4122 train_loss 10978114.87266724 val_loss 206933.17968750\n",
      "epoch 4123 train_loss 10978114.87255653 val_loss 206933.17968750\n",
      "epoch 4124 train_loss 10978114.87248947 val_loss 206933.17968750\n",
      "epoch 4125 train_loss 10978114.87246330 val_loss 206933.17968750\n",
      "epoch 4126 train_loss 10978114.87235191 val_loss 206933.17968750\n",
      "epoch 4127 train_loss 10978114.87226623 val_loss 206933.17968750\n",
      "epoch 4128 train_loss 10978114.87218262 val_loss 206933.17968750\n",
      "epoch 4129 train_loss 10978114.87207222 val_loss 206933.17968750\n",
      "epoch 4130 train_loss 10978114.87198479 val_loss 206933.17968750\n",
      "epoch 4131 train_loss 10978114.87190857 val_loss 206933.17968750\n",
      "epoch 4132 train_loss 10978114.87182152 val_loss 206933.17968750\n",
      "epoch 4133 train_loss 10978114.87171471 val_loss 206933.17968750\n",
      "epoch 4134 train_loss 10978114.87164070 val_loss 206933.17968750\n",
      "epoch 4135 train_loss 10978114.87153747 val_loss 206933.17968750\n",
      "epoch 4136 train_loss 10978114.87149559 val_loss 206933.17968750\n",
      "epoch 4137 train_loss 10978114.87140343 val_loss 206933.17968750\n",
      "epoch 4138 train_loss 10978114.87136276 val_loss 206933.17968750\n",
      "epoch 4139 train_loss 10978114.87128296 val_loss 206933.17968750\n",
      "epoch 4140 train_loss 10978114.87118858 val_loss 206933.17968750\n",
      "epoch 4141 train_loss 10978114.87107124 val_loss 206933.17968750\n",
      "epoch 4142 train_loss 10978114.87097969 val_loss 206933.17968750\n",
      "epoch 4143 train_loss 10978114.87090256 val_loss 206933.17968750\n",
      "epoch 4144 train_loss 10978114.87088150 val_loss 206933.17968750\n",
      "epoch 4145 train_loss 10978114.87078949 val_loss 206933.17968750\n",
      "epoch 4146 train_loss 10978114.87070633 val_loss 206933.17968750\n",
      "epoch 4147 train_loss 10978114.87061058 val_loss 206933.17968750\n",
      "epoch 4148 train_loss 10978114.87052116 val_loss 206933.17968750\n",
      "epoch 4149 train_loss 10978114.87043076 val_loss 206933.17968750\n",
      "epoch 4150 train_loss 10978114.87033714 val_loss 206933.17968750\n",
      "epoch 4151 train_loss 10978114.87031120 val_loss 206933.17968750\n",
      "epoch 4152 train_loss 10978114.87022972 val_loss 206933.17968750\n",
      "epoch 4153 train_loss 10978114.87014603 val_loss 206933.17968750\n",
      "epoch 4154 train_loss 10978114.87004898 val_loss 206933.17968750\n",
      "epoch 4155 train_loss 10978114.86995064 val_loss 206933.17968750\n",
      "epoch 4156 train_loss 10978114.86987183 val_loss 206933.17968750\n",
      "epoch 4157 train_loss 10978114.86977371 val_loss 206933.17968750\n",
      "epoch 4158 train_loss 10978114.86968407 val_loss 206933.17968750\n",
      "epoch 4159 train_loss 10978114.86960930 val_loss 206933.17968750\n",
      "epoch 4160 train_loss 10978114.86952606 val_loss 206933.17968750\n",
      "epoch 4161 train_loss 10978114.86941803 val_loss 206933.17968750\n",
      "epoch 4162 train_loss 10978114.86932625 val_loss 206933.17968750\n",
      "epoch 4163 train_loss 10978114.86921578 val_loss 206933.17968750\n",
      "epoch 4164 train_loss 10978114.86912323 val_loss 206933.17968750\n",
      "epoch 4165 train_loss 10978114.86902061 val_loss 206933.17968750\n",
      "epoch 4166 train_loss 10978114.86892952 val_loss 206933.17968750\n",
      "epoch 4167 train_loss 10978114.86884338 val_loss 206933.17968750\n",
      "epoch 4168 train_loss 10978114.86876984 val_loss 206933.17968750\n",
      "epoch 4169 train_loss 10978114.86866081 val_loss 206933.17968750\n",
      "epoch 4170 train_loss 10978114.86858498 val_loss 206933.17968750\n",
      "epoch 4171 train_loss 10978114.86853241 val_loss 206933.17968750\n",
      "epoch 4172 train_loss 10978114.86845993 val_loss 206933.17968750\n",
      "epoch 4173 train_loss 10978114.86838097 val_loss 206933.17968750\n",
      "epoch 4174 train_loss 10978114.86829521 val_loss 206933.17968750\n",
      "epoch 4175 train_loss 10978114.86821434 val_loss 206933.17968750\n",
      "epoch 4176 train_loss 10978114.86815292 val_loss 206933.17968750\n",
      "epoch 4177 train_loss 10978114.86805740 val_loss 206933.17968750\n",
      "epoch 4178 train_loss 10978114.86796654 val_loss 206933.17968750\n",
      "epoch 4179 train_loss 10978114.86786598 val_loss 206933.17968750\n",
      "epoch 4180 train_loss 10978114.86777100 val_loss 206933.17968750\n",
      "epoch 4181 train_loss 10978114.86769936 val_loss 206933.17968750\n",
      "epoch 4182 train_loss 10978114.86762878 val_loss 206933.17968750\n",
      "epoch 4183 train_loss 10978114.86751678 val_loss 206933.17968750\n",
      "epoch 4184 train_loss 10978114.86741264 val_loss 206933.17968750\n",
      "epoch 4185 train_loss 10978114.86734055 val_loss 206933.17968750\n",
      "epoch 4186 train_loss 10978114.86722885 val_loss 206933.17968750\n",
      "epoch 4187 train_loss 10978114.86713768 val_loss 206933.17968750\n",
      "epoch 4188 train_loss 10978114.86704773 val_loss 206933.17968750\n",
      "epoch 4189 train_loss 10978114.86695892 val_loss 206933.17968750\n",
      "epoch 4190 train_loss 10978114.86686539 val_loss 206933.17968750\n",
      "epoch 4191 train_loss 10978114.86677711 val_loss 206933.17968750\n",
      "epoch 4192 train_loss 10978114.86667793 val_loss 206933.17968750\n",
      "epoch 4193 train_loss 10978114.86660622 val_loss 206933.17968750\n",
      "epoch 4194 train_loss 10978114.86651466 val_loss 206933.17968750\n",
      "epoch 4195 train_loss 10978114.86641792 val_loss 206933.17968750\n",
      "epoch 4196 train_loss 10978114.86632828 val_loss 206933.17968750\n",
      "epoch 4197 train_loss 10978114.86621536 val_loss 206933.17968750\n",
      "epoch 4198 train_loss 10978114.86614639 val_loss 206933.17968750\n",
      "epoch 4199 train_loss 10978114.86606461 val_loss 206933.17968750\n",
      "epoch 4200 train_loss 10978114.86598862 val_loss 206933.17968750\n",
      "epoch 4201 train_loss 10978114.86587295 val_loss 206933.17968750\n",
      "epoch 4202 train_loss 10978114.86579216 val_loss 206933.17968750\n",
      "epoch 4203 train_loss 10978114.86570221 val_loss 206933.17968750\n",
      "epoch 4204 train_loss 10978114.86561157 val_loss 206933.17968750\n",
      "epoch 4205 train_loss 10978114.86549622 val_loss 206933.17968750\n",
      "epoch 4206 train_loss 10978114.86546310 val_loss 206933.17968750\n",
      "epoch 4207 train_loss 10978114.86539101 val_loss 206933.17968750\n",
      "epoch 4208 train_loss 10978114.86527115 val_loss 206933.17968750\n",
      "epoch 4209 train_loss 10978114.86518349 val_loss 206933.17968750\n",
      "epoch 4210 train_loss 10978114.86509468 val_loss 206933.17968750\n",
      "epoch 4211 train_loss 10978114.86500725 val_loss 206933.17968750\n",
      "epoch 4212 train_loss 10978114.86490082 val_loss 206933.17968750\n",
      "epoch 4213 train_loss 10978114.86481987 val_loss 206933.17968750\n",
      "epoch 4214 train_loss 10978114.86472130 val_loss 206933.17968750\n",
      "epoch 4215 train_loss 10978114.86463097 val_loss 206933.17968750\n",
      "epoch 4216 train_loss 10978114.86456169 val_loss 206933.17968750\n",
      "epoch 4217 train_loss 10978114.86446861 val_loss 206933.17968750\n",
      "epoch 4218 train_loss 10978114.86437676 val_loss 206933.17968750\n",
      "epoch 4219 train_loss 10978114.86427254 val_loss 206933.17968750\n",
      "epoch 4220 train_loss 10978114.86418091 val_loss 206933.17968750\n",
      "epoch 4221 train_loss 10978114.86414055 val_loss 206933.17968750\n",
      "epoch 4222 train_loss 10978114.86409683 val_loss 206933.17968750\n",
      "epoch 4223 train_loss 10978114.86397736 val_loss 206933.17968750\n",
      "epoch 4224 train_loss 10978114.86389999 val_loss 206933.17968750\n",
      "epoch 4225 train_loss 10978114.86380440 val_loss 206933.17968750\n",
      "epoch 4226 train_loss 10978114.86372490 val_loss 206933.17968750\n",
      "epoch 4227 train_loss 10978114.86361908 val_loss 206933.17968750\n",
      "epoch 4228 train_loss 10978114.86356468 val_loss 206933.17968750\n",
      "epoch 4229 train_loss 10978114.86346619 val_loss 206933.17968750\n",
      "epoch 4230 train_loss 10978114.86369141 val_loss 206933.17968750\n",
      "epoch 4231 train_loss 10978114.86358994 val_loss 206933.17968750\n",
      "epoch 4232 train_loss 10978114.86349770 val_loss 206933.17968750\n",
      "epoch 4233 train_loss 10978114.86342941 val_loss 206933.17968750\n",
      "epoch 4234 train_loss 10978114.86333923 val_loss 206933.17968750\n",
      "epoch 4235 train_loss 10978114.86324387 val_loss 206933.17968750\n",
      "epoch 4236 train_loss 10978114.86313622 val_loss 206933.17968750\n",
      "epoch 4237 train_loss 10978114.86304268 val_loss 206933.17968750\n",
      "epoch 4238 train_loss 10978114.86294983 val_loss 206933.17968750\n",
      "epoch 4239 train_loss 10978114.86289642 val_loss 206933.17968750\n",
      "epoch 4240 train_loss 10978114.86279732 val_loss 206933.17968750\n",
      "epoch 4241 train_loss 10978114.86272430 val_loss 206933.17968750\n",
      "epoch 4242 train_loss 10978114.86264114 val_loss 206933.17968750\n",
      "epoch 4243 train_loss 10978114.86255188 val_loss 206933.17968750\n",
      "epoch 4244 train_loss 10978114.86244560 val_loss 206933.17968750\n",
      "epoch 4245 train_loss 10978114.86238083 val_loss 206933.17968750\n",
      "epoch 4246 train_loss 10978114.86231575 val_loss 206933.17968750\n",
      "epoch 4247 train_loss 10978114.86220367 val_loss 206933.17968750\n",
      "epoch 4248 train_loss 10978114.86210335 val_loss 206933.17968750\n",
      "epoch 4249 train_loss 10978114.86200378 val_loss 206933.17968750\n",
      "epoch 4250 train_loss 10978114.86192100 val_loss 206933.17968750\n",
      "epoch 4251 train_loss 10978114.86183762 val_loss 206933.17968750\n",
      "epoch 4252 train_loss 10978114.86173935 val_loss 206933.17968750\n",
      "epoch 4253 train_loss 10978114.86165543 val_loss 206933.17968750\n",
      "epoch 4254 train_loss 10978114.86157814 val_loss 206933.17968750\n",
      "epoch 4255 train_loss 10978114.86147865 val_loss 206933.17968750\n",
      "epoch 4256 train_loss 10978114.86139725 val_loss 206933.17968750\n",
      "epoch 4257 train_loss 10978114.86131660 val_loss 206933.17968750\n",
      "epoch 4258 train_loss 10978114.86122826 val_loss 206933.17968750\n",
      "epoch 4259 train_loss 10978114.86110832 val_loss 206933.17968750\n",
      "epoch 4260 train_loss 10978114.86104538 val_loss 206933.17968750\n",
      "epoch 4261 train_loss 10978114.86095566 val_loss 206933.17968750\n",
      "epoch 4262 train_loss 10978114.86084557 val_loss 206933.17968750\n",
      "epoch 4263 train_loss 10978114.86075638 val_loss 206933.17968750\n",
      "epoch 4264 train_loss 10978114.86066299 val_loss 206933.17968750\n",
      "epoch 4265 train_loss 10978114.86073731 val_loss 206933.17968750\n",
      "epoch 4266 train_loss 10978114.86067444 val_loss 206933.17968750\n",
      "epoch 4267 train_loss 10978114.86059441 val_loss 206933.17968750\n",
      "epoch 4268 train_loss 10978114.86052612 val_loss 206933.17968750\n",
      "epoch 4269 train_loss 10978114.86043716 val_loss 206933.17968750\n",
      "epoch 4270 train_loss 10978114.86033554 val_loss 206933.17968750\n",
      "epoch 4271 train_loss 10978114.86024139 val_loss 206933.17968750\n",
      "epoch 4272 train_loss 10978114.86015236 val_loss 206933.17968750\n",
      "epoch 4273 train_loss 10978114.86004250 val_loss 206933.17968750\n",
      "epoch 4274 train_loss 10978114.85997528 val_loss 206933.17968750\n",
      "epoch 4275 train_loss 10978114.85989616 val_loss 206933.17968750\n",
      "epoch 4276 train_loss 10978114.85980362 val_loss 206933.17968750\n",
      "epoch 4277 train_loss 10978114.85972694 val_loss 206933.17968750\n",
      "epoch 4278 train_loss 10978114.85961502 val_loss 206933.17968750\n",
      "epoch 4279 train_loss 10978114.85954025 val_loss 206933.17968750\n",
      "epoch 4280 train_loss 10978114.85946983 val_loss 206933.17968750\n",
      "epoch 4281 train_loss 10978114.85937889 val_loss 206933.17968750\n",
      "epoch 4282 train_loss 10978114.85929153 val_loss 206933.17968750\n",
      "epoch 4283 train_loss 10978114.85919167 val_loss 206933.17968750\n",
      "epoch 4284 train_loss 10978114.85909935 val_loss 206933.17968750\n",
      "epoch 4285 train_loss 10978114.85899819 val_loss 206933.17968750\n",
      "epoch 4286 train_loss 10978114.85891769 val_loss 206933.17968750\n",
      "epoch 4287 train_loss 10978114.85883049 val_loss 206933.17968750\n",
      "epoch 4288 train_loss 10978114.85873299 val_loss 206933.17968750\n",
      "epoch 4289 train_loss 10978114.85865059 val_loss 206933.17968750\n",
      "epoch 4290 train_loss 10978114.85854965 val_loss 206933.17968750\n",
      "epoch 4291 train_loss 10978114.85851219 val_loss 206933.17968750\n",
      "epoch 4292 train_loss 10978114.85841530 val_loss 206933.17968750\n",
      "epoch 4293 train_loss 10978114.85831421 val_loss 206933.17968750\n",
      "epoch 4294 train_loss 10978114.85828590 val_loss 206933.17968750\n",
      "epoch 4295 train_loss 10978114.85818901 val_loss 206933.17968750\n",
      "epoch 4296 train_loss 10978114.85809647 val_loss 206933.17968750\n",
      "epoch 4297 train_loss 10978114.85801537 val_loss 206933.17968750\n",
      "epoch 4298 train_loss 10978114.85792191 val_loss 206933.17968750\n",
      "epoch 4299 train_loss 10978114.85784004 val_loss 206933.17968750\n",
      "epoch 4300 train_loss 10978114.85775101 val_loss 206933.17968750\n",
      "epoch 4301 train_loss 10978114.85765167 val_loss 206933.17968750\n",
      "epoch 4302 train_loss 10978114.85756020 val_loss 206933.17968750\n",
      "epoch 4303 train_loss 10978114.85746147 val_loss 206933.17968750\n",
      "epoch 4304 train_loss 10978114.85737915 val_loss 206933.17968750\n",
      "epoch 4305 train_loss 10978114.85734138 val_loss 206933.17968750\n",
      "epoch 4306 train_loss 10978114.85729210 val_loss 206933.17968750\n",
      "epoch 4307 train_loss 10978114.85723358 val_loss 206933.17968750\n",
      "epoch 4308 train_loss 10978114.85715240 val_loss 206933.17968750\n",
      "epoch 4309 train_loss 10978114.85713936 val_loss 206933.17968750\n",
      "epoch 4310 train_loss 10978114.85707054 val_loss 206933.17968750\n",
      "epoch 4311 train_loss 10978114.85697548 val_loss 206933.17968750\n",
      "epoch 4312 train_loss 10978114.85688248 val_loss 206933.17968750\n",
      "epoch 4313 train_loss 10978114.85678940 val_loss 206933.17968750\n",
      "epoch 4314 train_loss 10978114.85669228 val_loss 206933.17968750\n",
      "epoch 4315 train_loss 10978114.85660599 val_loss 206933.17968750\n",
      "epoch 4316 train_loss 10978114.85649582 val_loss 206933.17968750\n",
      "epoch 4317 train_loss 10978114.85641350 val_loss 206933.17968750\n",
      "epoch 4318 train_loss 10978114.85635414 val_loss 206933.17968750\n",
      "epoch 4319 train_loss 10978114.85626221 val_loss 206933.17968750\n",
      "epoch 4320 train_loss 10978114.85618584 val_loss 206933.17968750\n",
      "epoch 4321 train_loss 10978114.85615967 val_loss 206933.17968750\n",
      "epoch 4322 train_loss 10978114.85606689 val_loss 206933.17968750\n",
      "epoch 4323 train_loss 10978114.85597549 val_loss 206933.17968750\n",
      "epoch 4324 train_loss 10978114.85587639 val_loss 206933.17968750\n",
      "epoch 4325 train_loss 10978114.85578964 val_loss 206933.17968750\n",
      "epoch 4326 train_loss 10978114.85569260 val_loss 206933.17968750\n",
      "epoch 4327 train_loss 10978114.85559914 val_loss 206933.17968750\n",
      "epoch 4328 train_loss 10978114.85550743 val_loss 206933.17968750\n",
      "epoch 4329 train_loss 10978114.85540314 val_loss 206933.17968750\n",
      "epoch 4330 train_loss 10978114.85534409 val_loss 206933.17968750\n",
      "epoch 4331 train_loss 10978114.85523644 val_loss 206933.17968750\n",
      "epoch 4332 train_loss 10978114.85513954 val_loss 206933.17968750\n",
      "epoch 4333 train_loss 10978114.85505341 val_loss 206933.17968750\n",
      "epoch 4334 train_loss 10978114.85495613 val_loss 206933.17968750\n",
      "epoch 4335 train_loss 10978114.85486694 val_loss 206933.17968750\n",
      "epoch 4336 train_loss 10978114.85477615 val_loss 206933.17968750\n",
      "epoch 4337 train_loss 10978114.85470184 val_loss 206933.17968750\n",
      "epoch 4338 train_loss 10978114.85459251 val_loss 206933.17968750\n",
      "epoch 4339 train_loss 10978114.85452225 val_loss 206933.17968750\n",
      "epoch 4340 train_loss 10978114.85442802 val_loss 206933.17968750\n",
      "epoch 4341 train_loss 10978114.85433510 val_loss 206933.17968750\n",
      "epoch 4342 train_loss 10978114.85425377 val_loss 206933.17968750\n",
      "epoch 4343 train_loss 10978114.85416031 val_loss 206933.17968750\n",
      "epoch 4344 train_loss 10978114.85406326 val_loss 206933.17968750\n",
      "epoch 4345 train_loss 10978114.85397926 val_loss 206933.17968750\n",
      "epoch 4346 train_loss 10978114.85391647 val_loss 206933.17968750\n",
      "epoch 4347 train_loss 10978114.85390030 val_loss 206933.17968750\n",
      "epoch 4348 train_loss 10978114.85381020 val_loss 206933.17968750\n",
      "epoch 4349 train_loss 10978114.85371864 val_loss 206933.17968750\n",
      "epoch 4350 train_loss 10978114.85360962 val_loss 206933.17968750\n",
      "epoch 4351 train_loss 10978114.85352287 val_loss 206933.17968750\n",
      "epoch 4352 train_loss 10978114.85343491 val_loss 206933.17968750\n",
      "epoch 4353 train_loss 10978114.85335442 val_loss 206933.17968750\n",
      "epoch 4354 train_loss 10978114.85326088 val_loss 206933.17968750\n",
      "epoch 4355 train_loss 10978114.85319138 val_loss 206933.17968750\n",
      "epoch 4356 train_loss 10978114.85309906 val_loss 206933.17968750\n",
      "epoch 4357 train_loss 10978114.85300682 val_loss 206933.17968750\n",
      "epoch 4358 train_loss 10978114.85292412 val_loss 206933.17968750\n",
      "epoch 4359 train_loss 10978114.85284515 val_loss 206933.17968750\n",
      "epoch 4360 train_loss 10978114.85274498 val_loss 206933.17968750\n",
      "epoch 4361 train_loss 10978114.85265358 val_loss 206933.17968750\n",
      "epoch 4362 train_loss 10978114.85257034 val_loss 206933.17968750\n",
      "epoch 4363 train_loss 10978114.85246643 val_loss 206933.17968750\n",
      "epoch 4364 train_loss 10978114.85236717 val_loss 206933.17968750\n",
      "epoch 4365 train_loss 10978114.85227493 val_loss 206933.17968750\n",
      "epoch 4366 train_loss 10978114.85219025 val_loss 206933.17968750\n",
      "epoch 4367 train_loss 10978114.85207870 val_loss 206933.17968750\n",
      "epoch 4368 train_loss 10978114.85200691 val_loss 206933.17968750\n",
      "epoch 4369 train_loss 10978114.85192154 val_loss 206933.17968750\n",
      "epoch 4370 train_loss 10978114.85182419 val_loss 206933.17968750\n",
      "epoch 4371 train_loss 10978114.85173523 val_loss 206933.17968750\n",
      "epoch 4372 train_loss 10978114.85166679 val_loss 206933.17968750\n",
      "epoch 4373 train_loss 10978114.85159584 val_loss 206933.17968750\n",
      "epoch 4374 train_loss 10978114.85148720 val_loss 206933.17968750\n",
      "epoch 4375 train_loss 10978114.85141541 val_loss 206933.17968750\n",
      "epoch 4376 train_loss 10978114.85131744 val_loss 206933.17968750\n",
      "epoch 4377 train_loss 10978114.85121719 val_loss 206933.17968750\n",
      "epoch 4378 train_loss 10978114.85111732 val_loss 206933.17968750\n",
      "epoch 4379 train_loss 10978114.85105865 val_loss 206933.17968750\n",
      "epoch 4380 train_loss 10978114.85098679 val_loss 206933.17968750\n",
      "epoch 4381 train_loss 10978114.85088959 val_loss 206933.17968750\n",
      "epoch 4382 train_loss 10978114.85079781 val_loss 206933.17968750\n",
      "epoch 4383 train_loss 10978114.85071716 val_loss 206933.17968750\n",
      "epoch 4384 train_loss 10978114.85063065 val_loss 206933.17968750\n",
      "epoch 4385 train_loss 10978114.85052132 val_loss 206933.17968750\n",
      "epoch 4386 train_loss 10978114.85044121 val_loss 206933.17968750\n",
      "epoch 4387 train_loss 10978114.85031937 val_loss 206933.17968750\n",
      "epoch 4388 train_loss 10978114.85024063 val_loss 206933.17968750\n",
      "epoch 4389 train_loss 10978114.85017509 val_loss 206933.17968750\n",
      "epoch 4390 train_loss 10978114.85011330 val_loss 206933.17968750\n",
      "epoch 4391 train_loss 10978114.85002220 val_loss 206933.17968750\n",
      "epoch 4392 train_loss 10978114.84992302 val_loss 206933.17968750\n",
      "epoch 4393 train_loss 10978114.84983414 val_loss 206933.17968750\n",
      "epoch 4394 train_loss 10978114.84976341 val_loss 206933.17968750\n",
      "epoch 4395 train_loss 10978114.84967117 val_loss 206933.17968750\n",
      "epoch 4396 train_loss 10978114.84957832 val_loss 206933.17968750\n",
      "epoch 4397 train_loss 10978114.84950417 val_loss 206933.17968750\n",
      "epoch 4398 train_loss 10978114.84941223 val_loss 206933.17968750\n",
      "epoch 4399 train_loss 10978114.84929550 val_loss 206933.17968750\n",
      "epoch 4400 train_loss 10978114.84924622 val_loss 206933.17968750\n",
      "epoch 4401 train_loss 10978114.84916740 val_loss 206933.17968750\n",
      "epoch 4402 train_loss 10978114.84907158 val_loss 206933.17968750\n",
      "epoch 4403 train_loss 10978114.84897560 val_loss 206933.17968750\n",
      "epoch 4404 train_loss 10978114.84888451 val_loss 206933.17968750\n",
      "epoch 4405 train_loss 10978114.84880898 val_loss 206933.17968750\n",
      "epoch 4406 train_loss 10978114.84871704 val_loss 206933.17968750\n",
      "epoch 4407 train_loss 10978114.84862060 val_loss 206933.17968750\n",
      "epoch 4408 train_loss 10978114.84855247 val_loss 206933.17968750\n",
      "epoch 4409 train_loss 10978114.84845947 val_loss 206933.17968750\n",
      "epoch 4410 train_loss 10978114.84835289 val_loss 206933.17968750\n",
      "epoch 4411 train_loss 10978114.84826233 val_loss 206933.17968750\n",
      "epoch 4412 train_loss 10978114.84819862 val_loss 206933.17968750\n",
      "epoch 4413 train_loss 10978114.84809486 val_loss 206933.17968750\n",
      "epoch 4414 train_loss 10978114.84799355 val_loss 206933.17968750\n",
      "epoch 4415 train_loss 10978114.84791763 val_loss 206933.18750000\n",
      "epoch 4416 train_loss 10978114.84783676 val_loss 206933.18750000\n",
      "epoch 4417 train_loss 10978114.84773926 val_loss 206933.18750000\n",
      "epoch 4418 train_loss 10978114.84765579 val_loss 206933.18750000\n",
      "epoch 4419 train_loss 10978114.84758003 val_loss 206933.18750000\n",
      "epoch 4420 train_loss 10978114.84749085 val_loss 206933.18750000\n",
      "epoch 4421 train_loss 10978114.84744949 val_loss 206933.18750000\n",
      "epoch 4422 train_loss 10978114.84736908 val_loss 206933.18750000\n",
      "epoch 4423 train_loss 10978114.84728210 val_loss 206933.18750000\n",
      "epoch 4424 train_loss 10978114.84725212 val_loss 206933.18750000\n",
      "epoch 4425 train_loss 10978114.84716057 val_loss 206933.18750000\n",
      "epoch 4426 train_loss 10978114.84707710 val_loss 206933.18750000\n",
      "epoch 4427 train_loss 10978114.84697868 val_loss 206933.18750000\n",
      "epoch 4428 train_loss 10978114.84688713 val_loss 206933.18750000\n",
      "epoch 4429 train_loss 10978114.84680603 val_loss 206933.18750000\n",
      "epoch 4430 train_loss 10978114.84671974 val_loss 206933.18750000\n",
      "epoch 4431 train_loss 10978114.84663124 val_loss 206933.18750000\n",
      "epoch 4432 train_loss 10978114.84654549 val_loss 206933.18750000\n",
      "epoch 4433 train_loss 10978114.84643219 val_loss 206933.18750000\n",
      "epoch 4434 train_loss 10978114.84635498 val_loss 206933.18750000\n",
      "epoch 4435 train_loss 10978114.84624596 val_loss 206933.18750000\n",
      "epoch 4436 train_loss 10978114.84618439 val_loss 206933.18750000\n",
      "epoch 4437 train_loss 10978114.84608986 val_loss 206933.18750000\n",
      "epoch 4438 train_loss 10978114.84601524 val_loss 206933.18750000\n",
      "epoch 4439 train_loss 10978114.84591545 val_loss 206933.18750000\n",
      "epoch 4440 train_loss 10978114.84582443 val_loss 206933.18750000\n",
      "epoch 4441 train_loss 10978114.84572914 val_loss 206933.18750000\n",
      "epoch 4442 train_loss 10978114.84563179 val_loss 206933.18750000\n",
      "epoch 4443 train_loss 10978114.84554756 val_loss 206933.18750000\n",
      "epoch 4444 train_loss 10978114.84545723 val_loss 206933.18750000\n",
      "epoch 4445 train_loss 10978114.84539513 val_loss 206933.18750000\n",
      "epoch 4446 train_loss 10978114.84527718 val_loss 206933.18750000\n",
      "epoch 4447 train_loss 10978114.84525116 val_loss 206933.18750000\n",
      "epoch 4448 train_loss 10978114.84514679 val_loss 206933.18750000\n",
      "epoch 4449 train_loss 10978114.84506867 val_loss 206933.18750000\n",
      "epoch 4450 train_loss 10978114.84496361 val_loss 206933.18750000\n",
      "epoch 4451 train_loss 10978114.84487640 val_loss 206933.18750000\n",
      "epoch 4452 train_loss 10978114.84477837 val_loss 206933.18750000\n",
      "epoch 4453 train_loss 10978114.84468308 val_loss 206933.18750000\n",
      "epoch 4454 train_loss 10978114.84460190 val_loss 206933.18750000\n",
      "epoch 4455 train_loss 10978114.84450500 val_loss 206933.18750000\n",
      "epoch 4456 train_loss 10978114.84440163 val_loss 206933.18750000\n",
      "epoch 4457 train_loss 10978114.84431473 val_loss 206933.18750000\n",
      "epoch 4458 train_loss 10978114.84425835 val_loss 206933.18750000\n",
      "epoch 4459 train_loss 10978114.84419853 val_loss 206933.18750000\n",
      "epoch 4460 train_loss 10978114.84408684 val_loss 206933.18750000\n",
      "epoch 4461 train_loss 10978114.84402191 val_loss 206933.18750000\n",
      "epoch 4462 train_loss 10978114.84394577 val_loss 206933.18750000\n",
      "epoch 4463 train_loss 10978114.84386162 val_loss 206933.18750000\n",
      "epoch 4464 train_loss 10978114.84375786 val_loss 206933.18750000\n",
      "epoch 4465 train_loss 10978114.84367035 val_loss 206933.18750000\n",
      "epoch 4466 train_loss 10978114.84357926 val_loss 206933.18750000\n",
      "epoch 4467 train_loss 10978114.84348335 val_loss 206933.18750000\n",
      "epoch 4468 train_loss 10978114.84340691 val_loss 206933.18750000\n",
      "epoch 4469 train_loss 10978114.84330872 val_loss 206933.18750000\n",
      "epoch 4470 train_loss 10978114.84321030 val_loss 206933.18750000\n",
      "epoch 4471 train_loss 10978114.84311150 val_loss 206933.18750000\n",
      "epoch 4472 train_loss 10978114.84303299 val_loss 206933.18750000\n",
      "epoch 4473 train_loss 10978114.84293076 val_loss 206933.18750000\n",
      "epoch 4474 train_loss 10978114.84286789 val_loss 206933.18750000\n",
      "epoch 4475 train_loss 10978114.84275566 val_loss 206933.18750000\n",
      "epoch 4476 train_loss 10978114.84267067 val_loss 206933.18750000\n",
      "epoch 4477 train_loss 10978114.84257721 val_loss 206933.18750000\n",
      "epoch 4478 train_loss 10978114.84247353 val_loss 206933.18750000\n",
      "epoch 4479 train_loss 10978114.84241096 val_loss 206933.18750000\n",
      "epoch 4480 train_loss 10978114.84231392 val_loss 206933.18750000\n",
      "epoch 4481 train_loss 10978114.84223984 val_loss 206933.18750000\n",
      "epoch 4482 train_loss 10978114.84215050 val_loss 206933.18750000\n",
      "epoch 4483 train_loss 10978114.84204926 val_loss 206933.18750000\n",
      "epoch 4484 train_loss 10978114.84195374 val_loss 206933.18750000\n",
      "epoch 4485 train_loss 10978114.84185753 val_loss 206933.18750000\n",
      "epoch 4486 train_loss 10978114.84176788 val_loss 206933.18750000\n",
      "epoch 4487 train_loss 10978114.84170525 val_loss 206933.18750000\n",
      "epoch 4488 train_loss 10978114.84164497 val_loss 206933.18750000\n",
      "epoch 4489 train_loss 10978114.84154610 val_loss 206933.18750000\n",
      "epoch 4490 train_loss 10978114.84149162 val_loss 206933.18750000\n",
      "epoch 4491 train_loss 10978114.84140724 val_loss 206933.18750000\n",
      "epoch 4492 train_loss 10978114.84134110 val_loss 206933.18750000\n",
      "epoch 4493 train_loss 10978114.84123161 val_loss 206933.18750000\n",
      "epoch 4494 train_loss 10978114.84113983 val_loss 206933.18750000\n",
      "epoch 4495 train_loss 10978114.84105659 val_loss 206933.18750000\n",
      "epoch 4496 train_loss 10978114.84095261 val_loss 206933.18750000\n",
      "epoch 4497 train_loss 10978114.84086205 val_loss 206933.18750000\n",
      "epoch 4498 train_loss 10978114.84076729 val_loss 206933.18750000\n",
      "epoch 4499 train_loss 10978114.84066864 val_loss 206933.18750000\n",
      "epoch 4500 train_loss 10978114.84057007 val_loss 206933.18750000\n",
      "epoch 4501 train_loss 10978114.84048714 val_loss 206933.18750000\n",
      "epoch 4502 train_loss 10978114.84042961 val_loss 206933.18750000\n",
      "epoch 4503 train_loss 10978114.84043083 val_loss 206933.18750000\n",
      "epoch 4504 train_loss 10978114.84033005 val_loss 206933.18750000\n",
      "epoch 4505 train_loss 10978114.84023674 val_loss 206933.18750000\n",
      "epoch 4506 train_loss 10978114.84016228 val_loss 206933.18750000\n",
      "epoch 4507 train_loss 10978114.84006409 val_loss 206933.18750000\n",
      "epoch 4508 train_loss 10978114.83998543 val_loss 206933.18750000\n",
      "epoch 4509 train_loss 10978114.83993477 val_loss 206933.18750000\n",
      "epoch 4510 train_loss 10978114.83984146 val_loss 206933.18750000\n",
      "epoch 4511 train_loss 10978114.83965012 val_loss 206933.18750000\n",
      "epoch 4512 train_loss 10978114.83966087 val_loss 206933.18750000\n",
      "epoch 4513 train_loss 10978114.83947487 val_loss 206933.18750000\n",
      "epoch 4514 train_loss 10978114.83937309 val_loss 206933.18750000\n",
      "epoch 4515 train_loss 10978114.83928245 val_loss 206933.18750000\n",
      "epoch 4516 train_loss 10978114.83920441 val_loss 206933.18750000\n",
      "epoch 4517 train_loss 10978114.83918655 val_loss 206933.18750000\n",
      "epoch 4518 train_loss 10978114.83908005 val_loss 206933.18750000\n",
      "epoch 4519 train_loss 10978114.83898811 val_loss 206933.18750000\n",
      "epoch 4520 train_loss 10978114.83891411 val_loss 206933.18750000\n",
      "epoch 4521 train_loss 10978114.83881752 val_loss 206933.18750000\n",
      "epoch 4522 train_loss 10978114.83872177 val_loss 206933.18750000\n",
      "epoch 4523 train_loss 10978114.83861992 val_loss 206933.18750000\n",
      "epoch 4524 train_loss 10978114.83853211 val_loss 206933.18750000\n",
      "epoch 4525 train_loss 10978114.83844231 val_loss 206933.18750000\n",
      "epoch 4526 train_loss 10978114.83833542 val_loss 206933.18750000\n",
      "epoch 4527 train_loss 10978114.83828819 val_loss 206933.18750000\n",
      "epoch 4528 train_loss 10978114.83818298 val_loss 206933.18750000\n",
      "epoch 4529 train_loss 10978114.83808563 val_loss 206933.18750000\n",
      "epoch 4530 train_loss 10978114.83801651 val_loss 206933.18750000\n",
      "epoch 4531 train_loss 10978114.83790886 val_loss 206933.18750000\n",
      "epoch 4532 train_loss 10978114.83786964 val_loss 206933.18750000\n",
      "epoch 4533 train_loss 10978114.83778580 val_loss 206933.18750000\n",
      "epoch 4534 train_loss 10978114.83769325 val_loss 206933.18750000\n",
      "epoch 4535 train_loss 10978114.83760475 val_loss 206933.18750000\n",
      "epoch 4536 train_loss 10978114.83750137 val_loss 206933.18750000\n",
      "epoch 4537 train_loss 10978114.83749619 val_loss 206933.18750000\n",
      "epoch 4538 train_loss 10978114.83740974 val_loss 206933.18750000\n",
      "epoch 4539 train_loss 10978114.83731667 val_loss 206933.18750000\n",
      "epoch 4540 train_loss 10978114.83722351 val_loss 206933.18750000\n",
      "epoch 4541 train_loss 10978114.83713699 val_loss 206933.18750000\n",
      "epoch 4542 train_loss 10978114.83705475 val_loss 206933.18750000\n",
      "epoch 4543 train_loss 10978114.83695732 val_loss 206933.18750000\n",
      "epoch 4544 train_loss 10978114.83687233 val_loss 206933.18750000\n",
      "epoch 4545 train_loss 10978114.83677521 val_loss 206933.18750000\n",
      "epoch 4546 train_loss 10978114.83667549 val_loss 206933.18750000\n",
      "epoch 4547 train_loss 10978114.83658310 val_loss 206933.18750000\n",
      "epoch 4548 train_loss 10978114.83648514 val_loss 206933.18750000\n",
      "epoch 4549 train_loss 10978114.83649666 val_loss 206933.18750000\n",
      "epoch 4550 train_loss 10978114.83638969 val_loss 206933.18750000\n",
      "epoch 4551 train_loss 10978114.83627731 val_loss 206933.18750000\n",
      "epoch 4552 train_loss 10978114.83620010 val_loss 206933.18750000\n",
      "epoch 4553 train_loss 10978114.83610359 val_loss 206933.18750000\n",
      "epoch 4554 train_loss 10978114.83600761 val_loss 206933.18750000\n",
      "epoch 4555 train_loss 10978114.83593330 val_loss 206933.18750000\n",
      "epoch 4556 train_loss 10978114.83584030 val_loss 206933.18750000\n",
      "epoch 4557 train_loss 10978114.83575050 val_loss 206933.18750000\n",
      "epoch 4558 train_loss 10978114.83565971 val_loss 206933.18750000\n",
      "epoch 4559 train_loss 10978114.83556191 val_loss 206933.18750000\n",
      "epoch 4560 train_loss 10978114.83545448 val_loss 206933.18750000\n",
      "epoch 4561 train_loss 10978114.83540512 val_loss 206933.18750000\n",
      "epoch 4562 train_loss 10978114.83531776 val_loss 206933.18750000\n",
      "epoch 4563 train_loss 10978114.83528824 val_loss 206933.18750000\n",
      "epoch 4564 train_loss 10978114.83519112 val_loss 206933.18750000\n",
      "epoch 4565 train_loss 10978114.83510460 val_loss 206933.18750000\n",
      "epoch 4566 train_loss 10978114.83503754 val_loss 206933.18750000\n",
      "epoch 4567 train_loss 10978114.83496429 val_loss 206933.18750000\n",
      "epoch 4568 train_loss 10978114.83488403 val_loss 206933.18750000\n",
      "epoch 4569 train_loss 10978114.83480247 val_loss 206933.18750000\n",
      "epoch 4570 train_loss 10978114.83469818 val_loss 206933.18750000\n",
      "epoch 4571 train_loss 10978114.83459808 val_loss 206933.18750000\n",
      "epoch 4572 train_loss 10978114.83453171 val_loss 206933.18750000\n",
      "epoch 4573 train_loss 10978114.83442909 val_loss 206933.18750000\n",
      "epoch 4574 train_loss 10978114.83433777 val_loss 206933.18750000\n",
      "epoch 4575 train_loss 10978114.83425133 val_loss 206933.18750000\n",
      "epoch 4576 train_loss 10978114.83415016 val_loss 206933.18750000\n",
      "epoch 4577 train_loss 10978114.83406746 val_loss 206933.18750000\n",
      "epoch 4578 train_loss 10978114.83395897 val_loss 206933.18750000\n",
      "epoch 4579 train_loss 10978114.83386032 val_loss 206933.18750000\n",
      "epoch 4580 train_loss 10978114.83380379 val_loss 206933.18750000\n",
      "epoch 4581 train_loss 10978114.83372467 val_loss 206933.18750000\n",
      "epoch 4582 train_loss 10978114.83363388 val_loss 206933.18750000\n",
      "epoch 4583 train_loss 10978114.83351982 val_loss 206933.18750000\n",
      "epoch 4584 train_loss 10978114.83343994 val_loss 206933.18750000\n",
      "epoch 4585 train_loss 10978114.83335434 val_loss 206933.18750000\n",
      "epoch 4586 train_loss 10978114.83325684 val_loss 206933.18750000\n",
      "epoch 4587 train_loss 10978114.83316933 val_loss 206933.18750000\n",
      "epoch 4588 train_loss 10978114.83305992 val_loss 206933.18750000\n",
      "epoch 4589 train_loss 10978114.83296265 val_loss 206933.18750000\n",
      "epoch 4590 train_loss 10978114.83287758 val_loss 206933.18750000\n",
      "epoch 4591 train_loss 10978114.83277855 val_loss 206933.18750000\n",
      "epoch 4592 train_loss 10978114.83268333 val_loss 206933.18750000\n",
      "epoch 4593 train_loss 10978114.83259506 val_loss 206933.18750000\n",
      "epoch 4594 train_loss 10978114.83252724 val_loss 206933.18750000\n",
      "epoch 4595 train_loss 10978114.83243790 val_loss 206933.18750000\n",
      "epoch 4596 train_loss 10978114.83237190 val_loss 206933.18750000\n",
      "epoch 4597 train_loss 10978114.83227089 val_loss 206933.18750000\n",
      "epoch 4598 train_loss 10978114.83218651 val_loss 206933.18750000\n",
      "epoch 4599 train_loss 10978114.83210045 val_loss 206933.18750000\n",
      "epoch 4600 train_loss 10978114.83205193 val_loss 206933.18750000\n",
      "epoch 4601 train_loss 10978114.83195595 val_loss 206933.18750000\n",
      "epoch 4602 train_loss 10978114.83186607 val_loss 206933.18750000\n",
      "epoch 4603 train_loss 10978114.83179344 val_loss 206933.18750000\n",
      "epoch 4604 train_loss 10978114.83171059 val_loss 206933.18750000\n",
      "epoch 4605 train_loss 10978114.83160339 val_loss 206933.18750000\n",
      "epoch 4606 train_loss 10978114.83151207 val_loss 206933.18750000\n",
      "epoch 4607 train_loss 10978114.83150413 val_loss 206933.18750000\n",
      "epoch 4608 train_loss 10978114.83140221 val_loss 206933.18750000\n",
      "epoch 4609 train_loss 10978114.83132927 val_loss 206933.18750000\n",
      "epoch 4610 train_loss 10978114.83124062 val_loss 206933.18750000\n",
      "epoch 4611 train_loss 10978114.83120254 val_loss 206933.18750000\n",
      "epoch 4612 train_loss 10978114.83108139 val_loss 206933.18750000\n",
      "epoch 4613 train_loss 10978114.83098167 val_loss 206933.18750000\n",
      "epoch 4614 train_loss 10978114.83090538 val_loss 206933.18750000\n",
      "epoch 4615 train_loss 10978114.83081108 val_loss 206933.18750000\n",
      "epoch 4616 train_loss 10978114.83073189 val_loss 206933.18750000\n",
      "epoch 4617 train_loss 10978114.83062340 val_loss 206933.18750000\n",
      "epoch 4618 train_loss 10978114.83053604 val_loss 206933.18750000\n",
      "epoch 4619 train_loss 10978114.83043732 val_loss 206933.18750000\n",
      "epoch 4620 train_loss 10978114.83036003 val_loss 206933.18750000\n",
      "epoch 4621 train_loss 10978114.83028839 val_loss 206933.18750000\n",
      "epoch 4622 train_loss 10978114.83019020 val_loss 206933.18750000\n",
      "epoch 4623 train_loss 10978114.83009460 val_loss 206933.18750000\n",
      "epoch 4624 train_loss 10978114.83000031 val_loss 206933.18750000\n",
      "epoch 4625 train_loss 10978114.82992119 val_loss 206933.18750000\n",
      "epoch 4626 train_loss 10978114.82982849 val_loss 206933.18750000\n",
      "epoch 4627 train_loss 10978114.82974731 val_loss 206933.18750000\n",
      "epoch 4628 train_loss 10978114.82964989 val_loss 206933.18750000\n",
      "epoch 4629 train_loss 10978114.82956780 val_loss 206933.18750000\n",
      "epoch 4630 train_loss 10978114.82946121 val_loss 206933.18750000\n",
      "epoch 4631 train_loss 10978114.82938019 val_loss 206933.18750000\n",
      "epoch 4632 train_loss 10978114.82930458 val_loss 206933.18750000\n",
      "epoch 4633 train_loss 10978114.82922523 val_loss 206933.18750000\n",
      "epoch 4634 train_loss 10978114.82911499 val_loss 206933.18750000\n",
      "epoch 4635 train_loss 10978114.82902412 val_loss 206933.18750000\n",
      "epoch 4636 train_loss 10978114.82894478 val_loss 206933.18750000\n",
      "epoch 4637 train_loss 10978114.82882805 val_loss 206933.18750000\n",
      "epoch 4638 train_loss 10978114.82874527 val_loss 206933.18750000\n",
      "epoch 4639 train_loss 10978114.82867638 val_loss 206933.18750000\n",
      "epoch 4640 train_loss 10978114.82857964 val_loss 206933.18750000\n",
      "epoch 4641 train_loss 10978114.82849136 val_loss 206933.18750000\n",
      "epoch 4642 train_loss 10978114.82840538 val_loss 206933.18750000\n",
      "epoch 4643 train_loss 10978114.82831497 val_loss 206933.18750000\n",
      "epoch 4644 train_loss 10978114.82820457 val_loss 206933.18750000\n",
      "epoch 4645 train_loss 10978114.82812500 val_loss 206933.18750000\n",
      "epoch 4646 train_loss 10978114.82807503 val_loss 206933.18750000\n",
      "epoch 4647 train_loss 10978114.82801002 val_loss 206933.18750000\n",
      "epoch 4648 train_loss 10978114.82792702 val_loss 206933.18750000\n",
      "epoch 4649 train_loss 10978114.82781006 val_loss 206933.18750000\n",
      "epoch 4650 train_loss 10978114.82775917 val_loss 206933.18750000\n",
      "epoch 4651 train_loss 10978114.82766884 val_loss 206933.18750000\n",
      "epoch 4652 train_loss 10978114.82758026 val_loss 206933.18750000\n",
      "epoch 4653 train_loss 10978114.82750320 val_loss 206933.18750000\n",
      "epoch 4654 train_loss 10978114.82739387 val_loss 206933.18750000\n",
      "epoch 4655 train_loss 10978114.82729637 val_loss 206933.18750000\n",
      "epoch 4656 train_loss 10978114.82720123 val_loss 206933.18750000\n",
      "epoch 4657 train_loss 10978114.82710098 val_loss 206933.18750000\n",
      "epoch 4658 train_loss 10978114.82702446 val_loss 206933.18750000\n",
      "epoch 4659 train_loss 10978114.82695183 val_loss 206933.18750000\n",
      "epoch 4660 train_loss 10978114.82687096 val_loss 206933.18750000\n",
      "epoch 4661 train_loss 10978114.82679230 val_loss 206933.18750000\n",
      "epoch 4662 train_loss 10978114.82668076 val_loss 206933.18750000\n",
      "epoch 4663 train_loss 10978114.82660271 val_loss 206933.18750000\n",
      "epoch 4664 train_loss 10978114.82652847 val_loss 206933.18750000\n",
      "epoch 4665 train_loss 10978114.82643448 val_loss 206933.18750000\n",
      "epoch 4666 train_loss 10978114.82638466 val_loss 206933.18750000\n",
      "epoch 4667 train_loss 10978114.82628418 val_loss 206933.18750000\n",
      "epoch 4668 train_loss 10978114.82619644 val_loss 206933.18750000\n",
      "epoch 4669 train_loss 10978114.82608726 val_loss 206933.18750000\n",
      "epoch 4670 train_loss 10978114.82601852 val_loss 206933.18750000\n",
      "epoch 4671 train_loss 10978114.82590332 val_loss 206933.18750000\n",
      "epoch 4672 train_loss 10978114.82582039 val_loss 206933.18750000\n",
      "epoch 4673 train_loss 10978114.82573288 val_loss 206933.18750000\n",
      "epoch 4674 train_loss 10978114.82563713 val_loss 206933.18750000\n",
      "epoch 4675 train_loss 10978114.82554748 val_loss 206933.18750000\n",
      "epoch 4676 train_loss 10978114.82547005 val_loss 206933.18750000\n",
      "epoch 4677 train_loss 10978114.82536324 val_loss 206933.18750000\n",
      "epoch 4678 train_loss 10978114.82526993 val_loss 206933.18750000\n",
      "epoch 4679 train_loss 10978114.82518303 val_loss 206933.18750000\n",
      "epoch 4680 train_loss 10978114.82508949 val_loss 206933.18750000\n",
      "epoch 4681 train_loss 10978114.82500160 val_loss 206933.18750000\n",
      "epoch 4682 train_loss 10978114.82489464 val_loss 206933.18750000\n",
      "epoch 4683 train_loss 10978114.82482742 val_loss 206933.18750000\n",
      "epoch 4684 train_loss 10978114.82474419 val_loss 206933.18750000\n",
      "epoch 4685 train_loss 10978114.82464729 val_loss 206933.18750000\n",
      "epoch 4686 train_loss 10978114.82456329 val_loss 206933.18750000\n",
      "epoch 4687 train_loss 10978114.82445007 val_loss 206933.18750000\n",
      "epoch 4688 train_loss 10978114.82445946 val_loss 206933.18750000\n",
      "epoch 4689 train_loss 10978114.82436371 val_loss 206933.18750000\n",
      "epoch 4690 train_loss 10978114.82426987 val_loss 206933.18750000\n",
      "epoch 4691 train_loss 10978114.82417686 val_loss 206933.18750000\n",
      "epoch 4692 train_loss 10978114.82407585 val_loss 206933.18750000\n",
      "epoch 4693 train_loss 10978114.82397804 val_loss 206933.18750000\n",
      "epoch 4694 train_loss 10978114.82388863 val_loss 206933.18750000\n",
      "epoch 4695 train_loss 10978114.82379204 val_loss 206933.18750000\n",
      "epoch 4696 train_loss 10978114.82369232 val_loss 206933.18750000\n",
      "epoch 4697 train_loss 10978114.82360107 val_loss 206933.18750000\n",
      "epoch 4698 train_loss 10978114.82353287 val_loss 206933.18750000\n",
      "epoch 4699 train_loss 10978114.82345024 val_loss 206933.18750000\n",
      "epoch 4700 train_loss 10978114.82336098 val_loss 206933.18750000\n",
      "epoch 4701 train_loss 10978114.82328384 val_loss 206933.18750000\n",
      "epoch 4702 train_loss 10978114.82317345 val_loss 206933.18750000\n",
      "epoch 4703 train_loss 10978114.82315056 val_loss 206933.18750000\n",
      "epoch 4704 train_loss 10978114.82304512 val_loss 206933.18750000\n",
      "epoch 4705 train_loss 10978114.82297157 val_loss 206933.18750000\n",
      "epoch 4706 train_loss 10978114.82290092 val_loss 206933.18750000\n",
      "epoch 4707 train_loss 10978114.82280037 val_loss 206933.18750000\n",
      "epoch 4708 train_loss 10978114.82270111 val_loss 206933.18750000\n",
      "epoch 4709 train_loss 10978114.82259476 val_loss 206933.18750000\n",
      "epoch 4710 train_loss 10978114.82255371 val_loss 206933.18750000\n",
      "epoch 4711 train_loss 10978114.82245041 val_loss 206933.18750000\n",
      "epoch 4712 train_loss 10978114.82242325 val_loss 206933.18750000\n",
      "epoch 4713 train_loss 10978114.82232529 val_loss 206933.18750000\n",
      "epoch 4714 train_loss 10978114.82223289 val_loss 206933.18750000\n",
      "epoch 4715 train_loss 10978114.82215759 val_loss 206933.18750000\n",
      "epoch 4716 train_loss 10978114.82203697 val_loss 206933.18750000\n",
      "epoch 4717 train_loss 10978114.82194717 val_loss 206933.18750000\n",
      "epoch 4718 train_loss 10978114.82186111 val_loss 206933.18750000\n",
      "epoch 4719 train_loss 10978114.82175446 val_loss 206933.18750000\n",
      "epoch 4720 train_loss 10978114.82166504 val_loss 206933.18750000\n",
      "epoch 4721 train_loss 10978114.82156685 val_loss 206933.18750000\n",
      "epoch 4722 train_loss 10978114.82149239 val_loss 206933.18750000\n",
      "epoch 4723 train_loss 10978114.82140137 val_loss 206933.18750000\n",
      "epoch 4724 train_loss 10978114.82131676 val_loss 206933.18750000\n",
      "epoch 4725 train_loss 10978114.82122505 val_loss 206933.18750000\n",
      "epoch 4726 train_loss 10978114.82113266 val_loss 206933.18750000\n",
      "epoch 4727 train_loss 10978114.82103287 val_loss 206933.18750000\n",
      "epoch 4728 train_loss 10978114.82095634 val_loss 206933.18750000\n",
      "epoch 4729 train_loss 10978114.82085999 val_loss 206933.18750000\n",
      "epoch 4730 train_loss 10978114.82076653 val_loss 206933.18750000\n",
      "epoch 4731 train_loss 10978114.82065140 val_loss 206933.18750000\n",
      "epoch 4732 train_loss 10978114.82057777 val_loss 206933.18750000\n",
      "epoch 4733 train_loss 10978114.82048759 val_loss 206933.18750000\n",
      "epoch 4734 train_loss 10978114.82038948 val_loss 206933.18750000\n",
      "epoch 4735 train_loss 10978114.82029465 val_loss 206933.18750000\n",
      "epoch 4736 train_loss 10978114.82022148 val_loss 206933.18750000\n",
      "epoch 4737 train_loss 10978114.82020538 val_loss 206933.18750000\n",
      "epoch 4738 train_loss 10978114.82010818 val_loss 206933.18750000\n",
      "epoch 4739 train_loss 10978114.82002777 val_loss 206933.18750000\n",
      "epoch 4740 train_loss 10978114.81993813 val_loss 206933.18750000\n",
      "epoch 4741 train_loss 10978114.81982452 val_loss 206933.18750000\n",
      "epoch 4742 train_loss 10978114.81973053 val_loss 206933.18750000\n",
      "epoch 4743 train_loss 10978114.81964722 val_loss 206933.18750000\n",
      "epoch 4744 train_loss 10978114.81954216 val_loss 206933.18750000\n",
      "epoch 4745 train_loss 10978114.81947197 val_loss 206933.18750000\n",
      "epoch 4746 train_loss 10978114.81939537 val_loss 206933.18750000\n",
      "epoch 4747 train_loss 10978114.81930382 val_loss 206933.18750000\n",
      "epoch 4748 train_loss 10978114.81924217 val_loss 206933.18750000\n",
      "epoch 4749 train_loss 10978114.81915283 val_loss 206933.18750000\n",
      "epoch 4750 train_loss 10978114.81906937 val_loss 206933.18750000\n",
      "epoch 4751 train_loss 10978114.81898575 val_loss 206933.18750000\n",
      "epoch 4752 train_loss 10978114.81887833 val_loss 206933.18750000\n",
      "epoch 4753 train_loss 10978114.81878197 val_loss 206933.18750000\n",
      "epoch 4754 train_loss 10978114.81870087 val_loss 206933.18750000\n",
      "epoch 4755 train_loss 10978114.81861504 val_loss 206933.18750000\n",
      "epoch 4756 train_loss 10978114.81855507 val_loss 206933.18750000\n",
      "epoch 4757 train_loss 10978114.81846382 val_loss 206933.18750000\n",
      "epoch 4758 train_loss 10978114.81838936 val_loss 206933.18750000\n",
      "epoch 4759 train_loss 10978114.81828461 val_loss 206933.18750000\n",
      "epoch 4760 train_loss 10978114.81822136 val_loss 206933.18750000\n",
      "epoch 4761 train_loss 10978114.81811920 val_loss 206933.18750000\n",
      "epoch 4762 train_loss 10978114.81804672 val_loss 206933.18750000\n",
      "epoch 4763 train_loss 10978114.81793045 val_loss 206933.18750000\n",
      "epoch 4764 train_loss 10978114.81788399 val_loss 206933.18750000\n",
      "epoch 4765 train_loss 10978114.81779709 val_loss 206933.18750000\n",
      "epoch 4766 train_loss 10978114.81771271 val_loss 206933.18750000\n",
      "epoch 4767 train_loss 10978114.81762474 val_loss 206933.18750000\n",
      "epoch 4768 train_loss 10978114.81760101 val_loss 206933.18750000\n",
      "epoch 4769 train_loss 10978114.81750565 val_loss 206933.18750000\n",
      "epoch 4770 train_loss 10978114.81744751 val_loss 206933.18750000\n",
      "epoch 4771 train_loss 10978114.81735786 val_loss 206933.18750000\n",
      "epoch 4772 train_loss 10978114.81725677 val_loss 206933.18750000\n",
      "epoch 4773 train_loss 10978114.81717987 val_loss 206933.18750000\n",
      "epoch 4774 train_loss 10978114.81709511 val_loss 206933.18750000\n",
      "epoch 4775 train_loss 10978114.81701439 val_loss 206933.18750000\n",
      "epoch 4776 train_loss 10978114.81691124 val_loss 206933.18750000\n",
      "epoch 4777 train_loss 10978114.81681671 val_loss 206933.18750000\n",
      "epoch 4778 train_loss 10978114.81673431 val_loss 206933.18750000\n",
      "epoch 4779 train_loss 10978114.81666550 val_loss 206933.18750000\n",
      "epoch 4780 train_loss 10978114.81657120 val_loss 206933.18750000\n",
      "epoch 4781 train_loss 10978114.81648048 val_loss 206933.18750000\n",
      "epoch 4782 train_loss 10978114.81641624 val_loss 206933.18750000\n",
      "epoch 4783 train_loss 10978114.81631149 val_loss 206933.18750000\n",
      "epoch 4784 train_loss 10978114.81623047 val_loss 206933.18750000\n",
      "epoch 4785 train_loss 10978114.81614777 val_loss 206933.18750000\n",
      "epoch 4786 train_loss 10978114.81605087 val_loss 206933.18750000\n",
      "epoch 4787 train_loss 10978114.81596313 val_loss 206933.18750000\n",
      "epoch 4788 train_loss 10978114.81585548 val_loss 206933.18750000\n",
      "epoch 4789 train_loss 10978114.81575371 val_loss 206933.18750000\n",
      "epoch 4790 train_loss 10978114.81568336 val_loss 206933.18750000\n",
      "epoch 4791 train_loss 10978114.81560577 val_loss 206933.18750000\n",
      "epoch 4792 train_loss 10978114.81552017 val_loss 206933.18750000\n",
      "epoch 4793 train_loss 10978114.81540390 val_loss 206933.18750000\n",
      "epoch 4794 train_loss 10978114.81533943 val_loss 206933.18750000\n",
      "epoch 4795 train_loss 10978114.81523849 val_loss 206933.18750000\n",
      "epoch 4796 train_loss 10978114.81515251 val_loss 206933.18750000\n",
      "epoch 4797 train_loss 10978114.81504738 val_loss 206933.18750000\n",
      "epoch 4798 train_loss 10978114.81496757 val_loss 206933.18750000\n",
      "epoch 4799 train_loss 10978114.81495186 val_loss 206933.18750000\n",
      "epoch 4800 train_loss 10978114.81485024 val_loss 206933.18750000\n",
      "epoch 4801 train_loss 10978114.81476265 val_loss 206933.18750000\n",
      "epoch 4802 train_loss 10978114.81467072 val_loss 206933.18750000\n",
      "epoch 4803 train_loss 10978114.81456963 val_loss 206933.18750000\n",
      "epoch 4804 train_loss 10978114.81448097 val_loss 206933.18750000\n",
      "epoch 4805 train_loss 10978114.81438614 val_loss 206933.18750000\n",
      "epoch 4806 train_loss 10978114.81427445 val_loss 206933.18750000\n",
      "epoch 4807 train_loss 10978114.81418793 val_loss 206933.18750000\n",
      "epoch 4808 train_loss 10978114.81412102 val_loss 206933.18750000\n",
      "epoch 4809 train_loss 10978114.81403633 val_loss 206933.18750000\n",
      "epoch 4810 train_loss 10978114.81393967 val_loss 206933.18750000\n",
      "epoch 4811 train_loss 10978114.81385254 val_loss 206933.18750000\n",
      "epoch 4812 train_loss 10978114.81376839 val_loss 206933.18750000\n",
      "epoch 4813 train_loss 10978114.81368134 val_loss 206933.18750000\n",
      "epoch 4814 train_loss 10978114.81358849 val_loss 206933.18750000\n",
      "epoch 4815 train_loss 10978114.81349457 val_loss 206933.18750000\n",
      "epoch 4816 train_loss 10978114.81341103 val_loss 206933.18750000\n",
      "epoch 4817 train_loss 10978114.81329262 val_loss 206933.18750000\n",
      "epoch 4818 train_loss 10978114.81320091 val_loss 206933.18750000\n",
      "epoch 4819 train_loss 10978114.81312790 val_loss 206933.18750000\n",
      "epoch 4820 train_loss 10978114.81303398 val_loss 206933.18750000\n",
      "epoch 4821 train_loss 10978114.81294052 val_loss 206933.18750000\n",
      "epoch 4822 train_loss 10978114.81287888 val_loss 206933.18750000\n",
      "epoch 4823 train_loss 10978114.81281944 val_loss 206933.18750000\n",
      "epoch 4824 train_loss 10978114.81270256 val_loss 206933.18750000\n",
      "epoch 4825 train_loss 10978114.81262932 val_loss 206933.18750000\n",
      "epoch 4826 train_loss 10978114.81254883 val_loss 206933.18750000\n",
      "epoch 4827 train_loss 10978114.81246315 val_loss 206933.18750000\n",
      "epoch 4828 train_loss 10978114.81236671 val_loss 206933.18750000\n",
      "epoch 4829 train_loss 10978114.81229759 val_loss 206933.18750000\n",
      "epoch 4830 train_loss 10978114.81220543 val_loss 206933.18750000\n",
      "epoch 4831 train_loss 10978114.81214142 val_loss 206933.18750000\n",
      "epoch 4832 train_loss 10978114.81203667 val_loss 206933.18750000\n",
      "epoch 4833 train_loss 10978114.81194717 val_loss 206933.18750000\n",
      "epoch 4834 train_loss 10978114.81185951 val_loss 206933.18750000\n",
      "epoch 4835 train_loss 10978114.81175331 val_loss 206933.18750000\n",
      "epoch 4836 train_loss 10978114.81167076 val_loss 206933.18750000\n",
      "epoch 4837 train_loss 10978114.81157967 val_loss 206933.18750000\n",
      "epoch 4838 train_loss 10978114.81149864 val_loss 206933.18750000\n",
      "epoch 4839 train_loss 10978114.81140648 val_loss 206933.18750000\n",
      "epoch 4840 train_loss 10978114.81130234 val_loss 206933.18750000\n",
      "epoch 4841 train_loss 10978114.81122574 val_loss 206933.18750000\n",
      "epoch 4842 train_loss 10978114.81111778 val_loss 206933.18750000\n",
      "epoch 4843 train_loss 10978114.81103020 val_loss 206933.18750000\n",
      "epoch 4844 train_loss 10978114.81094353 val_loss 206933.18750000\n",
      "epoch 4845 train_loss 10978114.81087677 val_loss 206933.18750000\n",
      "epoch 4846 train_loss 10978114.81077553 val_loss 206933.18750000\n",
      "epoch 4847 train_loss 10978114.81068176 val_loss 206933.18750000\n",
      "epoch 4848 train_loss 10978114.81059257 val_loss 206933.18750000\n",
      "epoch 4849 train_loss 10978114.81049911 val_loss 206933.18750000\n",
      "epoch 4850 train_loss 10978114.81042290 val_loss 206933.18750000\n",
      "epoch 4851 train_loss 10978114.81033844 val_loss 206933.18750000\n",
      "epoch 4852 train_loss 10978114.81027878 val_loss 206933.18750000\n",
      "epoch 4853 train_loss 10978114.81017113 val_loss 206933.18750000\n",
      "epoch 4854 train_loss 10978114.81009636 val_loss 206933.18750000\n",
      "epoch 4855 train_loss 10978114.81000320 val_loss 206933.18750000\n",
      "epoch 4856 train_loss 10978114.80991165 val_loss 206933.18750000\n",
      "epoch 4857 train_loss 10978114.80981041 val_loss 206933.18750000\n",
      "epoch 4858 train_loss 10978114.80973450 val_loss 206933.18750000\n",
      "epoch 4859 train_loss 10978114.80962860 val_loss 206933.18750000\n",
      "epoch 4860 train_loss 10978114.80953140 val_loss 206933.18750000\n",
      "epoch 4861 train_loss 10978114.80944954 val_loss 206933.18750000\n",
      "epoch 4862 train_loss 10978114.80935615 val_loss 206933.18750000\n",
      "epoch 4863 train_loss 10978114.80926392 val_loss 206933.18750000\n",
      "epoch 4864 train_loss 10978114.80915985 val_loss 206933.18750000\n",
      "epoch 4865 train_loss 10978114.80906509 val_loss 206933.18750000\n",
      "epoch 4866 train_loss 10978114.80896454 val_loss 206933.18750000\n",
      "epoch 4867 train_loss 10978114.80887428 val_loss 206933.18750000\n",
      "epoch 4868 train_loss 10978114.80879234 val_loss 206933.18750000\n",
      "epoch 4869 train_loss 10978114.80870430 val_loss 206933.18750000\n",
      "epoch 4870 train_loss 10978114.80863518 val_loss 206933.18750000\n",
      "epoch 4871 train_loss 10978114.80855042 val_loss 206933.18750000\n",
      "epoch 4872 train_loss 10978114.80844612 val_loss 206933.18750000\n",
      "epoch 4873 train_loss 10978114.80837646 val_loss 206933.18750000\n",
      "epoch 4874 train_loss 10978114.80829552 val_loss 206933.18750000\n",
      "epoch 4875 train_loss 10978114.80818161 val_loss 206933.18750000\n",
      "epoch 4876 train_loss 10978114.80810181 val_loss 206933.18750000\n",
      "epoch 4877 train_loss 10978114.80802002 val_loss 206933.18750000\n",
      "epoch 4878 train_loss 10978114.80790680 val_loss 206933.18750000\n",
      "epoch 4879 train_loss 10978114.80785110 val_loss 206933.18750000\n",
      "epoch 4880 train_loss 10978114.80776573 val_loss 206933.18750000\n",
      "epoch 4881 train_loss 10978114.80768082 val_loss 206933.18750000\n",
      "epoch 4882 train_loss 10978114.80757927 val_loss 206933.18750000\n",
      "epoch 4883 train_loss 10978114.80748383 val_loss 206933.18750000\n",
      "epoch 4884 train_loss 10978114.80740402 val_loss 206933.18750000\n",
      "epoch 4885 train_loss 10978114.80733589 val_loss 206933.18750000\n",
      "epoch 4886 train_loss 10978114.80725052 val_loss 206933.18750000\n",
      "epoch 4887 train_loss 10978114.80716751 val_loss 206933.18750000\n",
      "epoch 4888 train_loss 10978114.80709725 val_loss 206933.18750000\n",
      "epoch 4889 train_loss 10978114.80700287 val_loss 206933.18750000\n",
      "epoch 4890 train_loss 10978114.80691238 val_loss 206933.18750000\n",
      "epoch 4891 train_loss 10978114.80682770 val_loss 206933.18750000\n",
      "epoch 4892 train_loss 10978114.80672569 val_loss 206933.18750000\n",
      "epoch 4893 train_loss 10978114.80664093 val_loss 206933.18750000\n",
      "epoch 4894 train_loss 10978114.80655670 val_loss 206933.18750000\n",
      "epoch 4895 train_loss 10978114.80646278 val_loss 206933.18750000\n",
      "epoch 4896 train_loss 10978114.80635750 val_loss 206933.18750000\n",
      "epoch 4897 train_loss 10978114.80628082 val_loss 206933.18750000\n",
      "epoch 4898 train_loss 10978114.80620056 val_loss 206933.18750000\n",
      "epoch 4899 train_loss 10978114.80612106 val_loss 206933.18750000\n",
      "epoch 4900 train_loss 10978114.80601479 val_loss 206933.18750000\n",
      "epoch 4901 train_loss 10978114.80591553 val_loss 206933.18750000\n",
      "epoch 4902 train_loss 10978114.80582878 val_loss 206933.18750000\n",
      "epoch 4903 train_loss 10978114.80575691 val_loss 206933.18750000\n",
      "epoch 4904 train_loss 10978114.80568603 val_loss 206933.18750000\n",
      "epoch 4905 train_loss 10978114.80557938 val_loss 206933.18750000\n",
      "epoch 4906 train_loss 10978114.80549889 val_loss 206933.18750000\n",
      "epoch 4907 train_loss 10978114.80540527 val_loss 206933.18750000\n",
      "epoch 4908 train_loss 10978114.80532852 val_loss 206933.18750000\n",
      "epoch 4909 train_loss 10978114.80523941 val_loss 206933.18750000\n",
      "epoch 4910 train_loss 10978114.80514870 val_loss 206933.18750000\n",
      "epoch 4911 train_loss 10978114.80505997 val_loss 206933.18750000\n",
      "epoch 4912 train_loss 10978114.80497559 val_loss 206933.18750000\n",
      "epoch 4913 train_loss 10978114.80488571 val_loss 206933.18750000\n",
      "epoch 4914 train_loss 10978114.80477653 val_loss 206933.18750000\n",
      "epoch 4915 train_loss 10978114.80468330 val_loss 206933.18750000\n",
      "epoch 4916 train_loss 10978114.80460945 val_loss 206933.18750000\n",
      "epoch 4917 train_loss 10978114.80450264 val_loss 206933.18750000\n",
      "epoch 4918 train_loss 10978114.80446053 val_loss 206933.18750000\n",
      "epoch 4919 train_loss 10978114.80435463 val_loss 206933.18750000\n",
      "epoch 4920 train_loss 10978114.80427658 val_loss 206933.18750000\n",
      "epoch 4921 train_loss 10978114.80419533 val_loss 206933.18750000\n",
      "epoch 4922 train_loss 10978114.80410522 val_loss 206933.18750000\n",
      "epoch 4923 train_loss 10978114.80401329 val_loss 206933.18750000\n",
      "epoch 4924 train_loss 10978114.80391007 val_loss 206933.18750000\n",
      "epoch 4925 train_loss 10978114.80381844 val_loss 206933.18750000\n",
      "epoch 4926 train_loss 10978114.80371284 val_loss 206933.18750000\n",
      "epoch 4927 train_loss 10978114.80362206 val_loss 206933.18750000\n",
      "epoch 4928 train_loss 10978114.80353928 val_loss 206933.18750000\n",
      "epoch 4929 train_loss 10978114.80342300 val_loss 206933.18750000\n",
      "epoch 4930 train_loss 10978114.80333069 val_loss 206933.18750000\n",
      "epoch 4931 train_loss 10978114.80325386 val_loss 206933.18750000\n",
      "epoch 4932 train_loss 10978114.80319977 val_loss 206933.18750000\n",
      "epoch 4933 train_loss 10978114.80311882 val_loss 206933.18750000\n",
      "epoch 4934 train_loss 10978114.80303940 val_loss 206933.18750000\n",
      "epoch 4935 train_loss 10978114.80296432 val_loss 206933.18750000\n",
      "epoch 4936 train_loss 10978114.80302849 val_loss 206933.18750000\n",
      "epoch 4937 train_loss 10978114.80294525 val_loss 206933.18750000\n",
      "epoch 4938 train_loss 10978114.80284164 val_loss 206933.18750000\n",
      "epoch 4939 train_loss 10978114.80280846 val_loss 206933.18750000\n",
      "epoch 4940 train_loss 10978114.80271286 val_loss 206933.18750000\n",
      "epoch 4941 train_loss 10978114.80260506 val_loss 206933.18750000\n",
      "epoch 4942 train_loss 10978114.80254341 val_loss 206933.18750000\n",
      "epoch 4943 train_loss 10978114.80244240 val_loss 206933.18750000\n",
      "epoch 4944 train_loss 10978114.80238602 val_loss 206933.18750000\n",
      "epoch 4945 train_loss 10978114.80231300 val_loss 206933.18750000\n",
      "epoch 4946 train_loss 10978114.80226715 val_loss 206933.18750000\n",
      "epoch 4947 train_loss 10978114.80217522 val_loss 206933.18750000\n",
      "epoch 4948 train_loss 10978114.80208252 val_loss 206933.18750000\n",
      "epoch 4949 train_loss 10978114.80199188 val_loss 206933.18750000\n",
      "epoch 4950 train_loss 10978114.80191170 val_loss 206933.18750000\n",
      "epoch 4951 train_loss 10978114.80179535 val_loss 206933.18750000\n",
      "epoch 4952 train_loss 10978114.80171699 val_loss 206933.18750000\n",
      "epoch 4953 train_loss 10978114.80161262 val_loss 206933.18750000\n",
      "epoch 4954 train_loss 10978114.80151634 val_loss 206933.18750000\n",
      "epoch 4955 train_loss 10978114.80141274 val_loss 206933.18750000\n",
      "epoch 4956 train_loss 10978114.80133751 val_loss 206933.18750000\n",
      "epoch 4957 train_loss 10978114.80124123 val_loss 206933.18750000\n",
      "epoch 4958 train_loss 10978114.80115417 val_loss 206933.18750000\n",
      "epoch 4959 train_loss 10978114.80106178 val_loss 206933.18750000\n",
      "epoch 4960 train_loss 10978114.80098366 val_loss 206933.18750000\n",
      "epoch 4961 train_loss 10978114.80087768 val_loss 206933.18750000\n",
      "epoch 4962 train_loss 10978114.80080093 val_loss 206933.18750000\n",
      "epoch 4963 train_loss 10978114.80070732 val_loss 206933.18750000\n",
      "epoch 4964 train_loss 10978114.80060944 val_loss 206933.18750000\n",
      "epoch 4965 train_loss 10978114.80051002 val_loss 206933.18750000\n",
      "epoch 4966 train_loss 10978114.80042358 val_loss 206933.18750000\n",
      "epoch 4967 train_loss 10978114.80034592 val_loss 206933.18750000\n",
      "epoch 4968 train_loss 10978114.80024437 val_loss 206933.18750000\n",
      "epoch 4969 train_loss 10978114.80014664 val_loss 206933.18750000\n",
      "epoch 4970 train_loss 10978114.80005882 val_loss 206933.18750000\n",
      "epoch 4971 train_loss 10978114.79998512 val_loss 206933.18750000\n",
      "epoch 4972 train_loss 10978114.79991364 val_loss 206933.18750000\n",
      "epoch 4973 train_loss 10978114.79985207 val_loss 206933.18750000\n",
      "epoch 4974 train_loss 10978114.79979065 val_loss 206933.18750000\n",
      "epoch 4975 train_loss 10978114.79972878 val_loss 206933.18750000\n",
      "epoch 4976 train_loss 10978114.79961830 val_loss 206933.18750000\n",
      "epoch 4977 train_loss 10978114.79951614 val_loss 206933.18750000\n",
      "epoch 4978 train_loss 10978114.79944946 val_loss 206933.18750000\n",
      "epoch 4979 train_loss 10978114.79935661 val_loss 206933.18750000\n",
      "epoch 4980 train_loss 10978114.79926125 val_loss 206933.18750000\n",
      "epoch 4981 train_loss 10978114.79915718 val_loss 206933.18750000\n",
      "epoch 4982 train_loss 10978114.79908882 val_loss 206933.18750000\n",
      "epoch 4983 train_loss 10978114.79900330 val_loss 206933.18750000\n",
      "epoch 4984 train_loss 10978114.79891464 val_loss 206933.18750000\n",
      "epoch 4985 train_loss 10978114.79884262 val_loss 206933.18750000\n",
      "epoch 4986 train_loss 10978114.79872139 val_loss 206933.18750000\n",
      "epoch 4987 train_loss 10978114.79865875 val_loss 206933.18750000\n",
      "epoch 4988 train_loss 10978114.79857452 val_loss 206933.18750000\n",
      "epoch 4989 train_loss 10978114.79846802 val_loss 206933.18750000\n",
      "epoch 4990 train_loss 10978114.79837250 val_loss 206933.18750000\n",
      "epoch 4991 train_loss 10978114.79827980 val_loss 206933.18750000\n",
      "epoch 4992 train_loss 10978114.79818878 val_loss 206933.18750000\n",
      "epoch 4993 train_loss 10978114.79809914 val_loss 206933.18750000\n",
      "epoch 4994 train_loss 10978114.79799583 val_loss 206933.18750000\n",
      "epoch 4995 train_loss 10978114.79789360 val_loss 206933.18750000\n",
      "epoch 4996 train_loss 10978114.79782989 val_loss 206933.18750000\n",
      "epoch 4997 train_loss 10978114.79777290 val_loss 206933.18750000\n",
      "epoch 4998 train_loss 10978114.79768242 val_loss 206933.18750000\n",
      "epoch 4999 train_loss 10978114.79759857 val_loss 206933.18750000\n",
      "epoch 5000 train_loss 10978114.79750023 val_loss 206933.18750000\n",
      "epoch 5001 train_loss 10978114.79740418 val_loss 206933.18750000\n",
      "epoch 5002 train_loss 10978114.79732819 val_loss 206933.18750000\n",
      "epoch 5003 train_loss 10978114.79723839 val_loss 206933.18750000\n",
      "epoch 5004 train_loss 10978114.79714600 val_loss 206933.18750000\n",
      "epoch 5005 train_loss 10978114.79702125 val_loss 206933.18750000\n",
      "epoch 5006 train_loss 10978114.79695259 val_loss 206933.18750000\n",
      "epoch 5007 train_loss 10978114.79686401 val_loss 206933.18750000\n",
      "epoch 5008 train_loss 10978114.79676605 val_loss 206933.18750000\n",
      "epoch 5009 train_loss 10978114.79670395 val_loss 206933.18750000\n",
      "epoch 5010 train_loss 10978114.79660027 val_loss 206933.18750000\n",
      "epoch 5011 train_loss 10978114.79652443 val_loss 206933.18750000\n",
      "epoch 5012 train_loss 10978114.79644035 val_loss 206933.18750000\n",
      "epoch 5013 train_loss 10978114.79638031 val_loss 206933.18750000\n",
      "epoch 5014 train_loss 10978114.79629005 val_loss 206933.18750000\n",
      "epoch 5015 train_loss 10978114.79622375 val_loss 206933.18750000\n",
      "epoch 5016 train_loss 10978114.79611275 val_loss 206933.18750000\n",
      "epoch 5017 train_loss 10978114.79603317 val_loss 206933.18750000\n",
      "epoch 5018 train_loss 10978114.79595314 val_loss 206933.18750000\n",
      "epoch 5019 train_loss 10978114.79583305 val_loss 206933.18750000\n",
      "epoch 5020 train_loss 10978114.79579193 val_loss 206933.18750000\n",
      "epoch 5021 train_loss 10978114.79570007 val_loss 206933.18750000\n",
      "epoch 5022 train_loss 10978114.79557754 val_loss 206933.18750000\n",
      "epoch 5023 train_loss 10978114.79550583 val_loss 206933.18750000\n",
      "epoch 5024 train_loss 10978114.79548447 val_loss 206933.18750000\n",
      "epoch 5025 train_loss 10978114.79540718 val_loss 206933.18750000\n",
      "epoch 5026 train_loss 10978114.79531029 val_loss 206933.18750000\n",
      "epoch 5027 train_loss 10978114.79521332 val_loss 206933.18750000\n",
      "epoch 5028 train_loss 10978114.79513168 val_loss 206933.18750000\n",
      "epoch 5029 train_loss 10978114.79508423 val_loss 206933.18750000\n",
      "epoch 5030 train_loss 10978114.79499420 val_loss 206933.18750000\n",
      "epoch 5031 train_loss 10978114.79491493 val_loss 206933.18750000\n",
      "epoch 5032 train_loss 10978114.79482727 val_loss 206933.18750000\n",
      "epoch 5033 train_loss 10978114.79476471 val_loss 206933.18750000\n",
      "epoch 5034 train_loss 10978114.79467514 val_loss 206933.18750000\n",
      "epoch 5035 train_loss 10978114.79457146 val_loss 206933.18750000\n",
      "epoch 5036 train_loss 10978114.79450295 val_loss 206933.18750000\n",
      "epoch 5037 train_loss 10978114.79441887 val_loss 206933.18750000\n",
      "epoch 5038 train_loss 10978114.79431831 val_loss 206933.18750000\n",
      "epoch 5039 train_loss 10978114.79423675 val_loss 206933.18750000\n",
      "epoch 5040 train_loss 10978114.79411468 val_loss 206933.18750000\n",
      "epoch 5041 train_loss 10978114.79402168 val_loss 206933.18750000\n",
      "epoch 5042 train_loss 10978114.79385811 val_loss 206933.18750000\n",
      "epoch 5043 train_loss 10978114.79377632 val_loss 206933.18750000\n",
      "epoch 5044 train_loss 10978114.79368126 val_loss 206933.18750000\n",
      "epoch 5045 train_loss 10978114.79359131 val_loss 206933.18750000\n",
      "epoch 5046 train_loss 10978114.79350708 val_loss 206933.18750000\n",
      "epoch 5047 train_loss 10978114.79341240 val_loss 206933.18750000\n",
      "epoch 5048 train_loss 10978114.79333702 val_loss 206933.18750000\n",
      "epoch 5049 train_loss 10978114.79325729 val_loss 206933.18750000\n",
      "epoch 5050 train_loss 10978114.79318436 val_loss 206933.18750000\n",
      "epoch 5051 train_loss 10978114.79306175 val_loss 206933.18750000\n",
      "epoch 5052 train_loss 10978114.79304947 val_loss 206933.18750000\n",
      "epoch 5053 train_loss 10978114.79295364 val_loss 206933.18750000\n",
      "epoch 5054 train_loss 10978114.79286766 val_loss 206933.18750000\n",
      "epoch 5055 train_loss 10978114.79279701 val_loss 206933.18750000\n",
      "epoch 5056 train_loss 10978114.79270958 val_loss 206933.18750000\n",
      "epoch 5057 train_loss 10978114.79262260 val_loss 206933.18750000\n",
      "epoch 5058 train_loss 10978114.79253449 val_loss 206933.18750000\n",
      "epoch 5059 train_loss 10978114.79243248 val_loss 206933.18750000\n",
      "epoch 5060 train_loss 10978114.79236168 val_loss 206933.18750000\n",
      "epoch 5061 train_loss 10978114.79226608 val_loss 206933.18750000\n",
      "epoch 5062 train_loss 10978114.79215584 val_loss 206933.18750000\n",
      "epoch 5063 train_loss 10978114.79207390 val_loss 206933.18750000\n",
      "epoch 5064 train_loss 10978114.79197388 val_loss 206933.18750000\n",
      "epoch 5065 train_loss 10978114.79190529 val_loss 206933.18750000\n",
      "epoch 5066 train_loss 10978114.79182709 val_loss 206933.18750000\n",
      "epoch 5067 train_loss 10978114.79173378 val_loss 206933.18750000\n",
      "epoch 5068 train_loss 10978114.79163445 val_loss 206933.18750000\n",
      "epoch 5069 train_loss 10978114.79158043 val_loss 206933.18750000\n",
      "epoch 5070 train_loss 10978114.79145660 val_loss 206933.18750000\n",
      "epoch 5071 train_loss 10978114.79136192 val_loss 206933.18750000\n",
      "epoch 5072 train_loss 10978114.79128494 val_loss 206933.18750000\n",
      "epoch 5073 train_loss 10978114.79118477 val_loss 206933.18750000\n",
      "epoch 5074 train_loss 10978114.79110008 val_loss 206933.18750000\n",
      "epoch 5075 train_loss 10978114.79100952 val_loss 206933.18750000\n",
      "epoch 5076 train_loss 10978114.79090538 val_loss 206933.18750000\n",
      "epoch 5077 train_loss 10978114.79081642 val_loss 206933.18750000\n",
      "epoch 5078 train_loss 10978114.79073265 val_loss 206933.18750000\n",
      "epoch 5079 train_loss 10978114.79062737 val_loss 206933.18750000\n",
      "epoch 5080 train_loss 10978114.79056992 val_loss 206933.18750000\n",
      "epoch 5081 train_loss 10978114.79048164 val_loss 206933.18750000\n",
      "epoch 5082 train_loss 10978114.79039154 val_loss 206933.18750000\n",
      "epoch 5083 train_loss 10978114.79030289 val_loss 206933.18750000\n",
      "epoch 5084 train_loss 10978114.79020500 val_loss 206933.18750000\n",
      "epoch 5085 train_loss 10978114.79010773 val_loss 206933.18750000\n",
      "epoch 5086 train_loss 10978114.79001724 val_loss 206933.18750000\n",
      "epoch 5087 train_loss 10978114.78989517 val_loss 206933.18750000\n",
      "epoch 5088 train_loss 10978114.78980919 val_loss 206933.18750000\n",
      "epoch 5089 train_loss 10978114.78976677 val_loss 206933.18750000\n",
      "epoch 5090 train_loss 10978114.78966805 val_loss 206933.18750000\n",
      "epoch 5091 train_loss 10978114.78955864 val_loss 206933.18750000\n",
      "epoch 5092 train_loss 10978114.78947807 val_loss 206933.18750000\n",
      "epoch 5093 train_loss 10978114.78939674 val_loss 206933.18750000\n",
      "epoch 5094 train_loss 10978114.78929436 val_loss 206933.18750000\n",
      "epoch 5095 train_loss 10978114.78919876 val_loss 206933.18750000\n",
      "epoch 5096 train_loss 10978114.78914421 val_loss 206933.18750000\n",
      "epoch 5097 train_loss 10978114.78905533 val_loss 206933.18750000\n",
      "epoch 5098 train_loss 10978114.78894974 val_loss 206933.18750000\n",
      "epoch 5099 train_loss 10978114.78887306 val_loss 206933.18750000\n",
      "epoch 5100 train_loss 10978114.78877709 val_loss 206933.18750000\n",
      "epoch 5101 train_loss 10978114.78866554 val_loss 206933.18750000\n",
      "epoch 5102 train_loss 10978114.78858299 val_loss 206933.18750000\n",
      "epoch 5103 train_loss 10978114.78849625 val_loss 206933.18750000\n",
      "epoch 5104 train_loss 10978114.78840630 val_loss 206933.18750000\n",
      "epoch 5105 train_loss 10978114.78828194 val_loss 206933.18750000\n",
      "epoch 5106 train_loss 10978114.78821335 val_loss 206933.18750000\n",
      "epoch 5107 train_loss 10978114.78811569 val_loss 206933.18750000\n",
      "epoch 5108 train_loss 10978114.78803612 val_loss 206933.18750000\n",
      "epoch 5109 train_loss 10978114.78795341 val_loss 206933.18750000\n",
      "epoch 5110 train_loss 10978114.78786026 val_loss 206933.18750000\n",
      "epoch 5111 train_loss 10978114.78776588 val_loss 206933.18750000\n",
      "epoch 5112 train_loss 10978114.78770912 val_loss 206933.18750000\n",
      "epoch 5113 train_loss 10978114.78764389 val_loss 206933.18750000\n",
      "epoch 5114 train_loss 10978114.78754807 val_loss 206933.18750000\n",
      "epoch 5115 train_loss 10978114.78747078 val_loss 206933.18750000\n",
      "epoch 5116 train_loss 10978114.78736565 val_loss 206933.18750000\n",
      "epoch 5117 train_loss 10978114.78728798 val_loss 206933.18750000\n",
      "epoch 5118 train_loss 10978114.78719696 val_loss 206933.18750000\n",
      "epoch 5119 train_loss 10978114.78711472 val_loss 206933.18750000\n",
      "epoch 5120 train_loss 10978114.78703316 val_loss 206933.18750000\n",
      "epoch 5121 train_loss 10978114.78698730 val_loss 206933.18750000\n",
      "epoch 5122 train_loss 10978114.78692238 val_loss 206933.18750000\n",
      "epoch 5123 train_loss 10978114.78684662 val_loss 206933.18750000\n",
      "epoch 5124 train_loss 10978114.78672775 val_loss 206933.18750000\n",
      "epoch 5125 train_loss 10978114.78663071 val_loss 206933.18750000\n",
      "epoch 5126 train_loss 10978114.78658226 val_loss 206933.18750000\n",
      "epoch 5127 train_loss 10978114.78648140 val_loss 206933.18750000\n",
      "epoch 5128 train_loss 10978114.78638809 val_loss 206933.18750000\n",
      "epoch 5129 train_loss 10978114.78629196 val_loss 206933.18750000\n",
      "epoch 5130 train_loss 10978114.78620720 val_loss 206933.18750000\n",
      "epoch 5131 train_loss 10978114.78609924 val_loss 206933.18750000\n",
      "epoch 5132 train_loss 10978114.78603706 val_loss 206933.18750000\n",
      "epoch 5133 train_loss 10978114.78591568 val_loss 206933.18750000\n",
      "epoch 5134 train_loss 10978114.78584511 val_loss 206933.18750000\n",
      "epoch 5135 train_loss 10978114.78576004 val_loss 206933.18750000\n",
      "epoch 5136 train_loss 10978114.78567833 val_loss 206933.18750000\n",
      "epoch 5137 train_loss 10978114.78558968 val_loss 206933.18750000\n",
      "epoch 5138 train_loss 10978114.78548683 val_loss 206933.18750000\n",
      "epoch 5139 train_loss 10978114.78539734 val_loss 206933.18750000\n",
      "epoch 5140 train_loss 10978114.78531113 val_loss 206933.18750000\n",
      "epoch 5141 train_loss 10978114.78519875 val_loss 206933.18750000\n",
      "epoch 5142 train_loss 10978114.78511589 val_loss 206933.18750000\n",
      "epoch 5143 train_loss 10978114.78507194 val_loss 206933.18750000\n",
      "epoch 5144 train_loss 10978114.78497238 val_loss 206933.18750000\n",
      "epoch 5145 train_loss 10978114.78486710 val_loss 206933.18750000\n",
      "epoch 5146 train_loss 10978114.78480865 val_loss 206933.18750000\n",
      "epoch 5147 train_loss 10978114.78470879 val_loss 206933.18750000\n",
      "epoch 5148 train_loss 10978114.78461777 val_loss 206933.18750000\n",
      "epoch 5149 train_loss 10978114.78450813 val_loss 206933.18750000\n",
      "epoch 5150 train_loss 10978114.78441978 val_loss 206933.18750000\n",
      "epoch 5151 train_loss 10978114.78433662 val_loss 206933.18750000\n",
      "epoch 5152 train_loss 10978114.78421997 val_loss 206933.18750000\n",
      "epoch 5153 train_loss 10978114.78414703 val_loss 206933.18750000\n",
      "epoch 5154 train_loss 10978114.78408028 val_loss 206933.18750000\n",
      "epoch 5155 train_loss 10978114.78398643 val_loss 206933.18750000\n",
      "epoch 5156 train_loss 10978114.78390312 val_loss 206933.18750000\n",
      "epoch 5157 train_loss 10978114.78381607 val_loss 206933.18750000\n",
      "epoch 5158 train_loss 10978114.78371941 val_loss 206933.18750000\n",
      "epoch 5159 train_loss 10978114.78362053 val_loss 206933.18750000\n",
      "epoch 5160 train_loss 10978114.78354263 val_loss 206933.18750000\n",
      "epoch 5161 train_loss 10978114.78345680 val_loss 206933.18750000\n",
      "epoch 5162 train_loss 10978114.78335319 val_loss 206933.18750000\n",
      "epoch 5163 train_loss 10978114.78326523 val_loss 206933.18750000\n",
      "epoch 5164 train_loss 10978114.78317596 val_loss 206933.18750000\n",
      "epoch 5165 train_loss 10978114.78311882 val_loss 206933.18750000\n",
      "epoch 5166 train_loss 10978114.78302025 val_loss 206933.18750000\n",
      "epoch 5167 train_loss 10978114.78293640 val_loss 206933.18750000\n",
      "epoch 5168 train_loss 10978114.78287949 val_loss 206933.18750000\n",
      "epoch 5169 train_loss 10978114.78279594 val_loss 206933.18750000\n",
      "epoch 5170 train_loss 10978114.78277924 val_loss 206933.18750000\n",
      "epoch 5171 train_loss 10978114.78269600 val_loss 206933.18750000\n",
      "epoch 5172 train_loss 10978114.78260200 val_loss 206933.18750000\n",
      "epoch 5173 train_loss 10978114.78251594 val_loss 206933.18750000\n",
      "epoch 5174 train_loss 10978114.78244034 val_loss 206933.18750000\n",
      "epoch 5175 train_loss 10978114.78233643 val_loss 206933.20312500\n",
      "epoch 5176 train_loss 10978114.78225265 val_loss 206933.20312500\n",
      "epoch 5177 train_loss 10978114.78214561 val_loss 206933.20312500\n",
      "epoch 5178 train_loss 10978114.78204605 val_loss 206933.20312500\n",
      "epoch 5179 train_loss 10978114.78196564 val_loss 206933.20312500\n",
      "epoch 5180 train_loss 10978114.78187347 val_loss 206933.20312500\n",
      "epoch 5181 train_loss 10978114.78176613 val_loss 206933.20312500\n",
      "epoch 5182 train_loss 10978114.78169022 val_loss 206933.20312500\n",
      "epoch 5183 train_loss 10978114.78161041 val_loss 206933.20312500\n",
      "epoch 5184 train_loss 10978114.78150673 val_loss 206933.20312500\n",
      "epoch 5185 train_loss 10978114.78141609 val_loss 206933.20312500\n",
      "epoch 5186 train_loss 10978114.78135422 val_loss 206933.20312500\n",
      "epoch 5187 train_loss 10978114.78140160 val_loss 206933.20312500\n",
      "epoch 5188 train_loss 10978114.78130875 val_loss 206933.20312500\n",
      "epoch 5189 train_loss 10978114.78121315 val_loss 206933.20312500\n",
      "epoch 5190 train_loss 10978114.78110764 val_loss 206933.20312500\n",
      "epoch 5191 train_loss 10978114.78102486 val_loss 206933.20312500\n",
      "epoch 5192 train_loss 10978114.78102676 val_loss 206933.20312500\n",
      "epoch 5193 train_loss 10978114.78092712 val_loss 206933.20312500\n",
      "epoch 5194 train_loss 10978114.78083664 val_loss 206933.20312500\n",
      "epoch 5195 train_loss 10978114.78074127 val_loss 206933.20312500\n",
      "epoch 5196 train_loss 10978114.78066429 val_loss 206933.20312500\n",
      "epoch 5197 train_loss 10978114.78056869 val_loss 206933.20312500\n",
      "epoch 5198 train_loss 10978114.78048218 val_loss 206933.20312500\n",
      "epoch 5199 train_loss 10978114.78039146 val_loss 206933.20312500\n",
      "epoch 5200 train_loss 10978114.78027802 val_loss 206933.20312500\n",
      "epoch 5201 train_loss 10978114.78021118 val_loss 206933.20312500\n",
      "epoch 5202 train_loss 10978114.78012802 val_loss 206933.20312500\n",
      "epoch 5203 train_loss 10978114.78002678 val_loss 206933.20312500\n",
      "epoch 5204 train_loss 10978114.77995117 val_loss 206933.20312500\n",
      "epoch 5205 train_loss 10978114.77989647 val_loss 206933.20312500\n",
      "epoch 5206 train_loss 10978114.77980164 val_loss 206933.20312500\n",
      "epoch 5207 train_loss 10978114.77972496 val_loss 206933.20312500\n",
      "epoch 5208 train_loss 10978114.77964645 val_loss 206933.20312500\n",
      "epoch 5209 train_loss 10978114.77954002 val_loss 206933.20312500\n",
      "epoch 5210 train_loss 10978114.77943520 val_loss 206933.20312500\n",
      "epoch 5211 train_loss 10978114.77934548 val_loss 206933.20312500\n",
      "epoch 5212 train_loss 10978114.77926941 val_loss 206933.20312500\n",
      "epoch 5213 train_loss 10978114.77917526 val_loss 206933.18750000\n",
      "epoch 5214 train_loss 10978114.77907127 val_loss 206933.18750000\n",
      "epoch 5215 train_loss 10978114.77897156 val_loss 206933.18750000\n",
      "epoch 5216 train_loss 10978114.77890373 val_loss 206933.18750000\n",
      "epoch 5217 train_loss 10978114.77880066 val_loss 206933.18750000\n",
      "epoch 5218 train_loss 10978114.77871086 val_loss 206933.18750000\n",
      "epoch 5219 train_loss 10978114.77861771 val_loss 206933.18750000\n",
      "epoch 5220 train_loss 10978114.77851875 val_loss 206933.18750000\n",
      "epoch 5221 train_loss 10978114.77847878 val_loss 206933.18750000\n",
      "epoch 5222 train_loss 10978114.77839928 val_loss 206933.18750000\n",
      "epoch 5223 train_loss 10978114.77829994 val_loss 206933.18750000\n",
      "epoch 5224 train_loss 10978114.77821449 val_loss 206933.18750000\n",
      "epoch 5225 train_loss 10978114.77812264 val_loss 206933.18750000\n",
      "epoch 5226 train_loss 10978114.77803627 val_loss 206933.18750000\n",
      "epoch 5227 train_loss 10978114.77797981 val_loss 206933.18750000\n",
      "epoch 5228 train_loss 10978114.77787643 val_loss 206933.18750000\n",
      "epoch 5229 train_loss 10978114.77779343 val_loss 206933.18750000\n",
      "epoch 5230 train_loss 10978114.77772697 val_loss 206933.18750000\n",
      "epoch 5231 train_loss 10978114.77761353 val_loss 206933.18750000\n",
      "epoch 5232 train_loss 10978114.77752914 val_loss 206933.18750000\n",
      "epoch 5233 train_loss 10978114.77747208 val_loss 206933.18750000\n",
      "epoch 5234 train_loss 10978114.77738579 val_loss 206933.18750000\n",
      "epoch 5235 train_loss 10978114.77732193 val_loss 206933.18750000\n",
      "epoch 5236 train_loss 10978114.77724022 val_loss 206933.18750000\n",
      "epoch 5237 train_loss 10978114.77714638 val_loss 206933.18750000\n",
      "epoch 5238 train_loss 10978114.77705956 val_loss 206933.18750000\n",
      "epoch 5239 train_loss 10978114.77697296 val_loss 206933.18750000\n",
      "epoch 5240 train_loss 10978114.77688057 val_loss 206933.18750000\n",
      "epoch 5241 train_loss 10978114.77679375 val_loss 206933.20312500\n",
      "epoch 5242 train_loss 10978114.77677284 val_loss 206933.20312500\n",
      "epoch 5243 train_loss 10978114.77667816 val_loss 206933.20312500\n",
      "epoch 5244 train_loss 10978114.77658684 val_loss 206933.20312500\n",
      "epoch 5245 train_loss 10978114.77649742 val_loss 206933.20312500\n",
      "epoch 5246 train_loss 10978114.77639587 val_loss 206933.20312500\n",
      "epoch 5247 train_loss 10978114.77629326 val_loss 206933.20312500\n",
      "epoch 5248 train_loss 10978114.77620598 val_loss 206933.20312500\n",
      "epoch 5249 train_loss 10978114.77611359 val_loss 206933.20312500\n",
      "epoch 5250 train_loss 10978114.77602570 val_loss 206933.20312500\n",
      "epoch 5251 train_loss 10978114.77598022 val_loss 206933.20312500\n",
      "epoch 5252 train_loss 10978114.77589157 val_loss 206933.20312500\n",
      "epoch 5253 train_loss 10978114.77579155 val_loss 206933.20312500\n",
      "epoch 5254 train_loss 10978114.77571854 val_loss 206933.20312500\n",
      "epoch 5255 train_loss 10978114.77566109 val_loss 206933.20312500\n",
      "epoch 5256 train_loss 10978114.77554497 val_loss 206933.20312500\n",
      "epoch 5257 train_loss 10978114.77543083 val_loss 206933.20312500\n",
      "epoch 5258 train_loss 10978114.77534225 val_loss 206933.20312500\n",
      "epoch 5259 train_loss 10978114.77526283 val_loss 206933.20312500\n",
      "epoch 5260 train_loss 10978114.77515442 val_loss 206933.20312500\n",
      "epoch 5261 train_loss 10978114.77506645 val_loss 206933.20312500\n",
      "epoch 5262 train_loss 10978114.77498291 val_loss 206933.20312500\n",
      "epoch 5263 train_loss 10978114.77488747 val_loss 206933.20312500\n",
      "epoch 5264 train_loss 10978114.77480080 val_loss 206933.20312500\n",
      "epoch 5265 train_loss 10978114.77473328 val_loss 206933.20312500\n",
      "epoch 5266 train_loss 10978114.77462524 val_loss 206933.20312500\n",
      "epoch 5267 train_loss 10978114.77456375 val_loss 206933.20312500\n",
      "epoch 5268 train_loss 10978114.77445518 val_loss 206933.20312500\n",
      "epoch 5269 train_loss 10978114.77436920 val_loss 206933.20312500\n",
      "epoch 5270 train_loss 10978114.77427147 val_loss 206933.20312500\n",
      "epoch 5271 train_loss 10978114.77415802 val_loss 206933.20312500\n",
      "epoch 5272 train_loss 10978114.77407440 val_loss 206933.20312500\n",
      "epoch 5273 train_loss 10978114.77400391 val_loss 206933.20312500\n",
      "epoch 5274 train_loss 10978114.77392197 val_loss 206933.20312500\n",
      "epoch 5275 train_loss 10978114.77383858 val_loss 206933.20312500\n",
      "epoch 5276 train_loss 10978114.77373611 val_loss 206933.20312500\n",
      "epoch 5277 train_loss 10978114.77366455 val_loss 206933.20312500\n",
      "epoch 5278 train_loss 10978114.77354820 val_loss 206933.20312500\n",
      "epoch 5279 train_loss 10978114.77346901 val_loss 206933.20312500\n",
      "epoch 5280 train_loss 10978114.77338249 val_loss 206933.20312500\n",
      "epoch 5281 train_loss 10978114.77329712 val_loss 206933.20312500\n",
      "epoch 5282 train_loss 10978114.77317467 val_loss 206933.20312500\n",
      "epoch 5283 train_loss 10978114.77310905 val_loss 206933.20312500\n",
      "epoch 5284 train_loss 10978114.77300102 val_loss 206933.20312500\n",
      "epoch 5285 train_loss 10978114.77289825 val_loss 206933.20312500\n",
      "epoch 5286 train_loss 10978114.77281685 val_loss 206933.20312500\n",
      "epoch 5287 train_loss 10978114.77273003 val_loss 206933.20312500\n",
      "epoch 5288 train_loss 10978114.77265587 val_loss 206933.20312500\n",
      "epoch 5289 train_loss 10978114.77255600 val_loss 206933.20312500\n",
      "epoch 5290 train_loss 10978114.77246605 val_loss 206933.20312500\n",
      "epoch 5291 train_loss 10978114.77237915 val_loss 206933.20312500\n",
      "epoch 5292 train_loss 10978114.77229462 val_loss 206933.20312500\n",
      "epoch 5293 train_loss 10978114.77222488 val_loss 206933.20312500\n",
      "epoch 5294 train_loss 10978114.77213768 val_loss 206933.20312500\n",
      "epoch 5295 train_loss 10978114.77204819 val_loss 206933.20312500\n",
      "epoch 5296 train_loss 10978114.77193352 val_loss 206933.20312500\n",
      "epoch 5297 train_loss 10978114.77184494 val_loss 206933.20312500\n",
      "epoch 5298 train_loss 10978114.77174767 val_loss 206933.20312500\n",
      "epoch 5299 train_loss 10978114.77166840 val_loss 206933.20312500\n",
      "epoch 5300 train_loss 10978114.77164566 val_loss 206933.20312500\n",
      "epoch 5301 train_loss 10978114.77154793 val_loss 206933.20312500\n",
      "epoch 5302 train_loss 10978114.77146339 val_loss 206933.20312500\n",
      "epoch 5303 train_loss 10978114.77136444 val_loss 206933.20312500\n",
      "epoch 5304 train_loss 10978114.77126984 val_loss 206933.20312500\n",
      "epoch 5305 train_loss 10978114.77117699 val_loss 206933.20312500\n",
      "epoch 5306 train_loss 10978114.77110329 val_loss 206933.20312500\n",
      "epoch 5307 train_loss 10978114.77100601 val_loss 206933.20312500\n",
      "epoch 5308 train_loss 10978114.77092514 val_loss 206933.20312500\n",
      "epoch 5309 train_loss 10978114.77085167 val_loss 206933.20312500\n",
      "epoch 5310 train_loss 10978114.77076004 val_loss 206933.20312500\n",
      "epoch 5311 train_loss 10978114.77066650 val_loss 206933.20312500\n",
      "epoch 5312 train_loss 10978114.77087593 val_loss 206933.20312500\n",
      "epoch 5313 train_loss 10978114.77080826 val_loss 206933.20312500\n",
      "epoch 5314 train_loss 10978114.77070313 val_loss 206933.20312500\n",
      "epoch 5315 train_loss 10978114.77061050 val_loss 206933.20312500\n",
      "epoch 5316 train_loss 10978114.77054588 val_loss 206933.20312500\n",
      "epoch 5317 train_loss 10978114.77045013 val_loss 206933.20312500\n",
      "epoch 5318 train_loss 10978114.77035637 val_loss 206933.20312500\n",
      "epoch 5319 train_loss 10978114.77028114 val_loss 206933.20312500\n",
      "epoch 5320 train_loss 10978114.77018822 val_loss 206933.20312500\n",
      "epoch 5321 train_loss 10978114.77008942 val_loss 206933.20312500\n",
      "epoch 5322 train_loss 10978114.77002457 val_loss 206933.20312500\n",
      "epoch 5323 train_loss 10978114.76992249 val_loss 206933.20312500\n",
      "epoch 5324 train_loss 10978114.76986030 val_loss 206933.20312500\n",
      "epoch 5325 train_loss 10978114.76977013 val_loss 206933.20312500\n",
      "epoch 5326 train_loss 10978114.76974724 val_loss 206933.20312500\n",
      "epoch 5327 train_loss 10978114.76965317 val_loss 206933.20312500\n",
      "epoch 5328 train_loss 10978114.76953316 val_loss 206933.20312500\n",
      "epoch 5329 train_loss 10978114.76943451 val_loss 206933.20312500\n",
      "epoch 5330 train_loss 10978114.76935623 val_loss 206933.20312500\n",
      "epoch 5331 train_loss 10978114.76926636 val_loss 206933.20312500\n",
      "epoch 5332 train_loss 10978114.76918983 val_loss 206933.20312500\n",
      "epoch 5333 train_loss 10978114.76911621 val_loss 206933.20312500\n",
      "epoch 5334 train_loss 10978114.76904228 val_loss 206933.20312500\n",
      "epoch 5335 train_loss 10978114.76894249 val_loss 206933.20312500\n",
      "epoch 5336 train_loss 10978114.76886291 val_loss 206933.20312500\n",
      "epoch 5337 train_loss 10978114.76875969 val_loss 206933.20312500\n",
      "epoch 5338 train_loss 10978114.76867310 val_loss 206933.20312500\n",
      "epoch 5339 train_loss 10978114.76857857 val_loss 206933.20312500\n",
      "epoch 5340 train_loss 10978114.76848167 val_loss 206933.20312500\n",
      "epoch 5341 train_loss 10978114.76840668 val_loss 206933.20312500\n",
      "epoch 5342 train_loss 10978114.76831398 val_loss 206933.21875000\n",
      "epoch 5343 train_loss 10978114.76826447 val_loss 206933.21875000\n",
      "epoch 5344 train_loss 10978114.76817146 val_loss 206933.21875000\n",
      "epoch 5345 train_loss 10978114.76808792 val_loss 206933.21875000\n",
      "epoch 5346 train_loss 10978114.76797798 val_loss 206933.21875000\n",
      "epoch 5347 train_loss 10978114.76788796 val_loss 206933.21875000\n",
      "epoch 5348 train_loss 10978114.76780640 val_loss 206933.21875000\n",
      "epoch 5349 train_loss 10978114.76772606 val_loss 206933.21875000\n",
      "epoch 5350 train_loss 10978114.76760696 val_loss 206933.21875000\n",
      "epoch 5351 train_loss 10978114.76752358 val_loss 206933.21875000\n",
      "epoch 5352 train_loss 10978114.76744690 val_loss 206933.21875000\n",
      "epoch 5353 train_loss 10978114.76736130 val_loss 206933.21875000\n",
      "epoch 5354 train_loss 10978114.76726906 val_loss 206933.21875000\n",
      "epoch 5355 train_loss 10978114.76717812 val_loss 206933.21875000\n",
      "epoch 5356 train_loss 10978114.76707603 val_loss 206933.21875000\n",
      "epoch 5357 train_loss 10978114.76700195 val_loss 206933.21875000\n",
      "epoch 5358 train_loss 10978114.76696945 val_loss 206933.21875000\n",
      "epoch 5359 train_loss 10978114.76687820 val_loss 206933.21875000\n",
      "epoch 5360 train_loss 10978114.76678436 val_loss 206933.21875000\n",
      "epoch 5361 train_loss 10978114.76669724 val_loss 206933.21875000\n",
      "epoch 5362 train_loss 10978114.76662079 val_loss 206933.21875000\n",
      "epoch 5363 train_loss 10978114.76651733 val_loss 206933.21875000\n",
      "epoch 5364 train_loss 10978114.76642632 val_loss 206933.21875000\n",
      "epoch 5365 train_loss 10978114.76633400 val_loss 206933.21875000\n",
      "epoch 5366 train_loss 10978114.76623253 val_loss 206933.21875000\n",
      "epoch 5367 train_loss 10978114.76615883 val_loss 206933.21875000\n",
      "epoch 5368 train_loss 10978114.76605362 val_loss 206933.21875000\n",
      "epoch 5369 train_loss 10978114.76597046 val_loss 206933.21875000\n",
      "epoch 5370 train_loss 10978114.76587944 val_loss 206933.21875000\n",
      "epoch 5371 train_loss 10978114.76580589 val_loss 206933.21875000\n",
      "epoch 5372 train_loss 10978114.76569664 val_loss 206933.21875000\n",
      "epoch 5373 train_loss 10978114.76561890 val_loss 206933.21875000\n",
      "epoch 5374 train_loss 10978114.76551331 val_loss 206933.21875000\n",
      "epoch 5375 train_loss 10978114.76541412 val_loss 206933.21875000\n",
      "epoch 5376 train_loss 10978114.76537826 val_loss 206933.21875000\n",
      "epoch 5377 train_loss 10978114.76527504 val_loss 206933.21875000\n",
      "epoch 5378 train_loss 10978114.76518776 val_loss 206933.21875000\n",
      "epoch 5379 train_loss 10978114.76510033 val_loss 206933.21875000\n",
      "epoch 5380 train_loss 10978114.76501106 val_loss 206933.21875000\n",
      "epoch 5381 train_loss 10978114.76492058 val_loss 206933.21875000\n",
      "epoch 5382 train_loss 10978114.76480621 val_loss 206933.21875000\n",
      "epoch 5383 train_loss 10978114.76473183 val_loss 206933.21875000\n",
      "epoch 5384 train_loss 10978114.76465500 val_loss 206933.21875000\n",
      "epoch 5385 train_loss 10978114.76455116 val_loss 206933.21875000\n",
      "epoch 5386 train_loss 10978114.76447937 val_loss 206933.21875000\n",
      "epoch 5387 train_loss 10978114.76439087 val_loss 206933.21875000\n",
      "epoch 5388 train_loss 10978114.76431870 val_loss 206933.21875000\n",
      "epoch 5389 train_loss 10978114.76425537 val_loss 206933.21875000\n",
      "epoch 5390 train_loss 10978114.76415390 val_loss 206933.21875000\n",
      "epoch 5391 train_loss 10978114.76405334 val_loss 206933.21875000\n",
      "epoch 5392 train_loss 10978114.76396896 val_loss 206933.21875000\n",
      "epoch 5393 train_loss 10978114.76386093 val_loss 206933.21875000\n",
      "epoch 5394 train_loss 10978114.76378838 val_loss 206933.21875000\n",
      "epoch 5395 train_loss 10978114.76369515 val_loss 206933.21875000\n",
      "epoch 5396 train_loss 10978114.76362274 val_loss 206933.21875000\n",
      "epoch 5397 train_loss 10978114.76350861 val_loss 206933.21875000\n",
      "epoch 5398 train_loss 10978114.76343353 val_loss 206933.21875000\n",
      "epoch 5399 train_loss 10978114.76332710 val_loss 206933.21875000\n",
      "epoch 5400 train_loss 10978114.76322693 val_loss 206933.21875000\n",
      "epoch 5401 train_loss 10978114.76316078 val_loss 206933.21875000\n",
      "epoch 5402 train_loss 10978114.76306297 val_loss 206933.21875000\n",
      "epoch 5403 train_loss 10978114.76298294 val_loss 206933.21875000\n",
      "epoch 5404 train_loss 10978114.76287208 val_loss 206933.21875000\n",
      "epoch 5405 train_loss 10978114.76278351 val_loss 206933.21875000\n",
      "epoch 5406 train_loss 10978114.76270760 val_loss 206933.21875000\n",
      "epoch 5407 train_loss 10978114.76261574 val_loss 206933.21875000\n",
      "epoch 5408 train_loss 10978114.76251061 val_loss 206933.21875000\n",
      "epoch 5409 train_loss 10978114.76241737 val_loss 206933.21875000\n",
      "epoch 5410 train_loss 10978114.76232941 val_loss 206933.21875000\n",
      "epoch 5411 train_loss 10978114.76225632 val_loss 206933.21875000\n",
      "epoch 5412 train_loss 10978114.76216125 val_loss 206933.21875000\n",
      "epoch 5413 train_loss 10978114.76207085 val_loss 206933.21875000\n",
      "epoch 5414 train_loss 10978114.76199158 val_loss 206933.21875000\n",
      "epoch 5415 train_loss 10978114.76189613 val_loss 206933.21875000\n",
      "epoch 5416 train_loss 10978114.76179550 val_loss 206933.21875000\n",
      "epoch 5417 train_loss 10978114.76171692 val_loss 206933.21875000\n",
      "epoch 5418 train_loss 10978114.76158936 val_loss 206933.21875000\n",
      "epoch 5419 train_loss 10978114.76157654 val_loss 206933.21875000\n",
      "epoch 5420 train_loss 10978114.76149033 val_loss 206933.21875000\n",
      "epoch 5421 train_loss 10978114.76140518 val_loss 206933.21875000\n",
      "epoch 5422 train_loss 10978114.76133385 val_loss 206933.21875000\n",
      "epoch 5423 train_loss 10978114.76125595 val_loss 206933.21875000\n",
      "epoch 5424 train_loss 10978114.76117439 val_loss 206933.21875000\n",
      "epoch 5425 train_loss 10978114.76108910 val_loss 206933.21875000\n",
      "epoch 5426 train_loss 10978114.76099403 val_loss 206933.21875000\n",
      "epoch 5427 train_loss 10978114.76091820 val_loss 206933.21875000\n",
      "epoch 5428 train_loss 10978114.76080978 val_loss 206933.21875000\n",
      "epoch 5429 train_loss 10978114.76072594 val_loss 206933.21875000\n",
      "epoch 5430 train_loss 10978114.76062233 val_loss 206933.21875000\n",
      "epoch 5431 train_loss 10978114.76056717 val_loss 206933.21875000\n",
      "epoch 5432 train_loss 10978114.76048798 val_loss 206933.21875000\n",
      "epoch 5433 train_loss 10978114.76038483 val_loss 206933.21875000\n",
      "epoch 5434 train_loss 10978114.76028984 val_loss 206933.21875000\n",
      "epoch 5435 train_loss 10978114.76021408 val_loss 206933.21875000\n",
      "epoch 5436 train_loss 10978114.76011078 val_loss 206933.21875000\n",
      "epoch 5437 train_loss 10978114.76002731 val_loss 206933.21875000\n",
      "epoch 5438 train_loss 10978114.75997192 val_loss 206933.21875000\n",
      "epoch 5439 train_loss 10978114.75991348 val_loss 206933.21875000\n",
      "epoch 5440 train_loss 10978114.75981903 val_loss 206933.21875000\n",
      "epoch 5441 train_loss 10978114.75972191 val_loss 206933.21875000\n",
      "epoch 5442 train_loss 10978114.75963005 val_loss 206933.21875000\n",
      "epoch 5443 train_loss 10978114.75953339 val_loss 206933.21875000\n",
      "epoch 5444 train_loss 10978114.75943611 val_loss 206933.21875000\n",
      "epoch 5445 train_loss 10978114.75935387 val_loss 206933.21875000\n",
      "epoch 5446 train_loss 10978114.75927818 val_loss 206933.21875000\n",
      "epoch 5447 train_loss 10978114.75915665 val_loss 206933.21875000\n",
      "epoch 5448 train_loss 10978114.75907448 val_loss 206933.21875000\n",
      "epoch 5449 train_loss 10978114.75899109 val_loss 206933.21875000\n",
      "epoch 5450 train_loss 10978114.75889122 val_loss 206933.21875000\n",
      "epoch 5451 train_loss 10978114.75879906 val_loss 206933.21875000\n",
      "epoch 5452 train_loss 10978114.75871956 val_loss 206933.21875000\n",
      "epoch 5453 train_loss 10978114.75866829 val_loss 206933.21875000\n",
      "epoch 5454 train_loss 10978114.75857368 val_loss 206933.21875000\n",
      "epoch 5455 train_loss 10978114.75854477 val_loss 206933.21875000\n",
      "epoch 5456 train_loss 10978114.75844292 val_loss 206933.21875000\n",
      "epoch 5457 train_loss 10978114.75838356 val_loss 206933.21875000\n",
      "epoch 5458 train_loss 10978114.75828575 val_loss 206933.21875000\n",
      "epoch 5459 train_loss 10978114.75817696 val_loss 206933.21875000\n",
      "epoch 5460 train_loss 10978114.75810326 val_loss 206933.21875000\n",
      "epoch 5461 train_loss 10978114.75800468 val_loss 206933.21875000\n",
      "epoch 5462 train_loss 10978114.75791039 val_loss 206933.21875000\n",
      "epoch 5463 train_loss 10978114.75783882 val_loss 206933.21875000\n",
      "epoch 5464 train_loss 10978114.75776291 val_loss 206933.21875000\n",
      "epoch 5465 train_loss 10978114.75767281 val_loss 206933.21875000\n",
      "epoch 5466 train_loss 10978114.75761246 val_loss 206933.21875000\n",
      "epoch 5467 train_loss 10978114.75759048 val_loss 206933.21875000\n",
      "epoch 5468 train_loss 10978114.75752113 val_loss 206933.21875000\n",
      "epoch 5469 train_loss 10978114.75740837 val_loss 206933.21875000\n",
      "epoch 5470 train_loss 10978114.75730240 val_loss 206933.21875000\n",
      "epoch 5471 train_loss 10978114.75720825 val_loss 206933.21875000\n",
      "epoch 5472 train_loss 10978114.75712860 val_loss 206933.21875000\n",
      "epoch 5473 train_loss 10978114.75704155 val_loss 206933.21875000\n",
      "epoch 5474 train_loss 10978114.75696182 val_loss 206933.21875000\n",
      "epoch 5475 train_loss 10978114.75686935 val_loss 206933.21875000\n",
      "epoch 5476 train_loss 10978114.75675026 val_loss 206933.21875000\n",
      "epoch 5477 train_loss 10978114.75667198 val_loss 206933.21875000\n",
      "epoch 5478 train_loss 10978114.75659668 val_loss 206933.21875000\n",
      "epoch 5479 train_loss 10978114.75649673 val_loss 206933.21875000\n",
      "epoch 5480 train_loss 10978114.75639519 val_loss 206933.21875000\n",
      "epoch 5481 train_loss 10978114.75631653 val_loss 206933.21875000\n",
      "epoch 5482 train_loss 10978114.75625519 val_loss 206933.21875000\n",
      "epoch 5483 train_loss 10978114.75615212 val_loss 206933.21875000\n",
      "epoch 5484 train_loss 10978114.75606041 val_loss 206933.21875000\n",
      "epoch 5485 train_loss 10978114.75598755 val_loss 206933.21875000\n",
      "epoch 5486 train_loss 10978114.75589035 val_loss 206933.21875000\n",
      "epoch 5487 train_loss 10978114.75578834 val_loss 206933.21875000\n",
      "epoch 5488 train_loss 10978114.75572441 val_loss 206933.21875000\n",
      "epoch 5489 train_loss 10978114.75567513 val_loss 206933.21875000\n",
      "epoch 5490 train_loss 10978114.75556717 val_loss 206933.21875000\n",
      "epoch 5491 train_loss 10978114.75550346 val_loss 206933.21875000\n",
      "epoch 5492 train_loss 10978114.75540451 val_loss 206933.21875000\n",
      "epoch 5493 train_loss 10978114.75531319 val_loss 206933.21875000\n",
      "epoch 5494 train_loss 10978114.75522492 val_loss 206933.21875000\n",
      "epoch 5495 train_loss 10978114.75513939 val_loss 206933.21875000\n",
      "epoch 5496 train_loss 10978114.75504707 val_loss 206933.21875000\n",
      "epoch 5497 train_loss 10978114.75496071 val_loss 206933.21875000\n",
      "epoch 5498 train_loss 10978114.75485016 val_loss 206933.21875000\n",
      "epoch 5499 train_loss 10978114.75478508 val_loss 206933.21875000\n",
      "epoch 5500 train_loss 10978114.75469238 val_loss 206933.21875000\n",
      "epoch 5501 train_loss 10978114.75460182 val_loss 206933.21875000\n",
      "epoch 5502 train_loss 10978114.75454117 val_loss 206933.21875000\n",
      "epoch 5503 train_loss 10978114.75444199 val_loss 206933.21875000\n",
      "epoch 5504 train_loss 10978114.75435188 val_loss 206933.21875000\n",
      "epoch 5505 train_loss 10978114.75427154 val_loss 206933.21875000\n",
      "epoch 5506 train_loss 10978114.75418083 val_loss 206933.21875000\n",
      "epoch 5507 train_loss 10978114.75409645 val_loss 206933.21875000\n",
      "epoch 5508 train_loss 10978114.75399933 val_loss 206933.21875000\n",
      "epoch 5509 train_loss 10978114.75390816 val_loss 206933.21875000\n",
      "epoch 5510 train_loss 10978114.75382851 val_loss 206933.21875000\n",
      "epoch 5511 train_loss 10978114.75374924 val_loss 206933.21875000\n",
      "epoch 5512 train_loss 10978114.75364349 val_loss 206933.21875000\n",
      "epoch 5513 train_loss 10978114.75355362 val_loss 206933.21875000\n",
      "epoch 5514 train_loss 10978114.75348328 val_loss 206933.21875000\n",
      "epoch 5515 train_loss 10978114.75338440 val_loss 206933.21875000\n",
      "epoch 5516 train_loss 10978114.75329155 val_loss 206933.21875000\n",
      "epoch 5517 train_loss 10978114.75320656 val_loss 206933.21875000\n",
      "epoch 5518 train_loss 10978114.75310356 val_loss 206933.21875000\n",
      "epoch 5519 train_loss 10978114.75300415 val_loss 206933.21875000\n",
      "epoch 5520 train_loss 10978114.75290894 val_loss 206933.21875000\n",
      "epoch 5521 train_loss 10978114.75282104 val_loss 206933.21875000\n",
      "epoch 5522 train_loss 10978114.75272392 val_loss 206933.21875000\n",
      "epoch 5523 train_loss 10978114.75262711 val_loss 206933.21875000\n",
      "epoch 5524 train_loss 10978114.75255234 val_loss 206933.21875000\n",
      "epoch 5525 train_loss 10978114.75246086 val_loss 206933.21875000\n",
      "epoch 5526 train_loss 10978114.75234550 val_loss 206933.21875000\n",
      "epoch 5527 train_loss 10978114.75225891 val_loss 206933.21875000\n",
      "epoch 5528 train_loss 10978114.75217667 val_loss 206933.21875000\n",
      "epoch 5529 train_loss 10978114.75208839 val_loss 206933.21875000\n",
      "epoch 5530 train_loss 10978114.75200363 val_loss 206933.21875000\n",
      "epoch 5531 train_loss 10978114.75191818 val_loss 206933.21875000\n",
      "epoch 5532 train_loss 10978114.75185371 val_loss 206933.21875000\n",
      "epoch 5533 train_loss 10978114.75176720 val_loss 206933.21875000\n",
      "epoch 5534 train_loss 10978114.75168808 val_loss 206933.21875000\n",
      "epoch 5535 train_loss 10978114.75158989 val_loss 206933.21875000\n",
      "epoch 5536 train_loss 10978114.75150825 val_loss 206933.21875000\n",
      "epoch 5537 train_loss 10978114.75139809 val_loss 206933.21875000\n",
      "epoch 5538 train_loss 10978114.75131432 val_loss 206933.21875000\n",
      "epoch 5539 train_loss 10978114.75121033 val_loss 206933.21875000\n",
      "epoch 5540 train_loss 10978114.75113647 val_loss 206933.21875000\n",
      "epoch 5541 train_loss 10978114.75108055 val_loss 206933.21875000\n",
      "epoch 5542 train_loss 10978114.75100395 val_loss 206933.21875000\n",
      "epoch 5543 train_loss 10978114.75092300 val_loss 206933.21875000\n",
      "epoch 5544 train_loss 10978114.75086083 val_loss 206933.21875000\n",
      "epoch 5545 train_loss 10978114.75076714 val_loss 206933.21875000\n",
      "epoch 5546 train_loss 10978114.75066704 val_loss 206933.21875000\n",
      "epoch 5547 train_loss 10978114.75057388 val_loss 206933.21875000\n",
      "epoch 5548 train_loss 10978114.75047714 val_loss 206933.21875000\n",
      "epoch 5549 train_loss 10978114.75042534 val_loss 206933.21875000\n",
      "epoch 5550 train_loss 10978114.75033554 val_loss 206933.21875000\n",
      "epoch 5551 train_loss 10978114.75026024 val_loss 206933.21875000\n",
      "epoch 5552 train_loss 10978114.75014496 val_loss 206933.21875000\n",
      "epoch 5553 train_loss 10978114.75005180 val_loss 206933.21875000\n",
      "epoch 5554 train_loss 10978114.74996643 val_loss 206933.21875000\n",
      "epoch 5555 train_loss 10978114.74984726 val_loss 206933.21875000\n",
      "epoch 5556 train_loss 10978114.74980514 val_loss 206933.21875000\n",
      "epoch 5557 train_loss 10978114.74970787 val_loss 206933.21875000\n",
      "epoch 5558 train_loss 10978114.74963104 val_loss 206933.21875000\n",
      "epoch 5559 train_loss 10978114.74952438 val_loss 206933.21875000\n",
      "epoch 5560 train_loss 10978114.74943245 val_loss 206933.21875000\n",
      "epoch 5561 train_loss 10978114.74935417 val_loss 206933.21875000\n",
      "epoch 5562 train_loss 10978114.74926895 val_loss 206933.21875000\n",
      "epoch 5563 train_loss 10978114.74917938 val_loss 206933.21875000\n",
      "epoch 5564 train_loss 10978114.74908363 val_loss 206933.21875000\n",
      "epoch 5565 train_loss 10978114.74898621 val_loss 206933.21875000\n",
      "epoch 5566 train_loss 10978114.74887833 val_loss 206933.21875000\n",
      "epoch 5567 train_loss 10978114.74878388 val_loss 206933.21875000\n",
      "epoch 5568 train_loss 10978114.74870056 val_loss 206933.21875000\n",
      "epoch 5569 train_loss 10978114.74862427 val_loss 206933.21875000\n",
      "epoch 5570 train_loss 10978114.74851646 val_loss 206933.21875000\n",
      "epoch 5571 train_loss 10978114.74842010 val_loss 206933.21875000\n",
      "epoch 5572 train_loss 10978114.74832176 val_loss 206933.21875000\n",
      "epoch 5573 train_loss 10978114.74822838 val_loss 206933.21875000\n",
      "epoch 5574 train_loss 10978114.74817444 val_loss 206933.21875000\n",
      "epoch 5575 train_loss 10978114.74807678 val_loss 206933.21875000\n",
      "epoch 5576 train_loss 10978114.74798988 val_loss 206933.21875000\n",
      "epoch 5577 train_loss 10978114.74789505 val_loss 206933.21875000\n",
      "epoch 5578 train_loss 10978114.74779205 val_loss 206933.21875000\n",
      "epoch 5579 train_loss 10978114.74770325 val_loss 206933.21875000\n",
      "epoch 5580 train_loss 10978114.74758842 val_loss 206933.21875000\n",
      "epoch 5581 train_loss 10978114.74750572 val_loss 206933.21875000\n",
      "epoch 5582 train_loss 10978114.74746429 val_loss 206933.21875000\n",
      "epoch 5583 train_loss 10978114.74737656 val_loss 206933.21875000\n",
      "epoch 5584 train_loss 10978114.74727058 val_loss 206933.21875000\n",
      "epoch 5585 train_loss 10978114.74718002 val_loss 206933.21875000\n",
      "epoch 5586 train_loss 10978114.74709007 val_loss 206933.21875000\n",
      "epoch 5587 train_loss 10978114.74700386 val_loss 206933.21875000\n",
      "epoch 5588 train_loss 10978114.74692497 val_loss 206933.21875000\n",
      "epoch 5589 train_loss 10978114.74684937 val_loss 206933.21875000\n",
      "epoch 5590 train_loss 10978114.74674698 val_loss 206933.21875000\n",
      "epoch 5591 train_loss 10978114.74666634 val_loss 206933.21875000\n",
      "epoch 5592 train_loss 10978114.74657593 val_loss 206933.21875000\n",
      "epoch 5593 train_loss 10978114.74650726 val_loss 206933.21875000\n",
      "epoch 5594 train_loss 10978114.74640190 val_loss 206933.21875000\n",
      "epoch 5595 train_loss 10978114.74630722 val_loss 206933.21875000\n",
      "epoch 5596 train_loss 10978114.74625824 val_loss 206933.21875000\n",
      "epoch 5597 train_loss 10978114.74617394 val_loss 206933.21875000\n",
      "epoch 5598 train_loss 10978114.74608109 val_loss 206933.21875000\n",
      "epoch 5599 train_loss 10978114.74597145 val_loss 206933.21875000\n",
      "epoch 5600 train_loss 10978114.74594727 val_loss 206933.21875000\n",
      "epoch 5601 train_loss 10978114.74587356 val_loss 206933.21875000\n",
      "epoch 5602 train_loss 10978114.74579201 val_loss 206933.21875000\n",
      "epoch 5603 train_loss 10978114.74569214 val_loss 206933.21875000\n",
      "epoch 5604 train_loss 10978114.74568008 val_loss 206933.21875000\n",
      "epoch 5605 train_loss 10978114.74558601 val_loss 206933.21875000\n",
      "epoch 5606 train_loss 10978114.74548111 val_loss 206933.21875000\n",
      "epoch 5607 train_loss 10978114.74538994 val_loss 206933.21875000\n",
      "epoch 5608 train_loss 10978114.74529266 val_loss 206933.21875000\n",
      "epoch 5609 train_loss 10978114.74519203 val_loss 206933.21875000\n",
      "epoch 5610 train_loss 10978114.74512642 val_loss 206933.21875000\n",
      "epoch 5611 train_loss 10978114.74503456 val_loss 206933.21875000\n",
      "epoch 5612 train_loss 10978114.74494820 val_loss 206933.21875000\n",
      "epoch 5613 train_loss 10978114.74485970 val_loss 206933.21875000\n",
      "epoch 5614 train_loss 10978114.74474625 val_loss 206933.21875000\n",
      "epoch 5615 train_loss 10978114.74466873 val_loss 206933.21875000\n",
      "epoch 5616 train_loss 10978114.74457787 val_loss 206933.21875000\n",
      "epoch 5617 train_loss 10978114.74449318 val_loss 206933.21875000\n",
      "epoch 5618 train_loss 10978114.74439812 val_loss 206933.21875000\n",
      "epoch 5619 train_loss 10978114.74430679 val_loss 206933.21875000\n",
      "epoch 5620 train_loss 10978114.74419861 val_loss 206933.21875000\n",
      "epoch 5621 train_loss 10978114.74411026 val_loss 206933.21875000\n",
      "epoch 5622 train_loss 10978114.74403191 val_loss 206933.21875000\n",
      "epoch 5623 train_loss 10978114.74393837 val_loss 206933.21875000\n",
      "epoch 5624 train_loss 10978114.74383629 val_loss 206933.21875000\n",
      "epoch 5625 train_loss 10978114.74376328 val_loss 206933.21875000\n",
      "epoch 5626 train_loss 10978114.74369179 val_loss 206933.21875000\n",
      "epoch 5627 train_loss 10978114.74326309 val_loss 206933.21875000\n",
      "epoch 5628 train_loss 10978114.74319817 val_loss 206933.21875000\n",
      "epoch 5629 train_loss 10978114.74312294 val_loss 206933.21875000\n",
      "epoch 5630 train_loss 10978114.74303215 val_loss 206933.21875000\n",
      "epoch 5631 train_loss 10978114.74293503 val_loss 206933.21875000\n",
      "epoch 5632 train_loss 10978114.74283897 val_loss 206933.21875000\n",
      "epoch 5633 train_loss 10978114.74274956 val_loss 206933.21875000\n",
      "epoch 5634 train_loss 10978114.74264977 val_loss 206933.21875000\n",
      "epoch 5635 train_loss 10978114.74256561 val_loss 206933.21875000\n",
      "epoch 5636 train_loss 10978114.74247711 val_loss 206933.21875000\n",
      "epoch 5637 train_loss 10978114.74238930 val_loss 206933.21875000\n",
      "epoch 5638 train_loss 10978114.74229004 val_loss 206933.21875000\n",
      "epoch 5639 train_loss 10978114.74218781 val_loss 206933.21875000\n",
      "epoch 5640 train_loss 10978114.74211609 val_loss 206933.21875000\n",
      "epoch 5641 train_loss 10978114.74202316 val_loss 206933.21875000\n",
      "epoch 5642 train_loss 10978114.74192978 val_loss 206933.21875000\n",
      "epoch 5643 train_loss 10978114.74182884 val_loss 206933.21875000\n",
      "epoch 5644 train_loss 10978114.74174843 val_loss 206933.21875000\n",
      "epoch 5645 train_loss 10978114.74168198 val_loss 206933.21875000\n",
      "epoch 5646 train_loss 10978114.74159126 val_loss 206933.21875000\n",
      "epoch 5647 train_loss 10978114.74149673 val_loss 206933.21875000\n",
      "epoch 5648 train_loss 10978114.74140022 val_loss 206933.21875000\n",
      "epoch 5649 train_loss 10978114.74132011 val_loss 206933.21875000\n",
      "epoch 5650 train_loss 10978114.74120216 val_loss 206933.21875000\n",
      "epoch 5651 train_loss 10978114.74112030 val_loss 206933.21875000\n",
      "epoch 5652 train_loss 10978114.74102280 val_loss 206933.21875000\n",
      "epoch 5653 train_loss 10978114.74093742 val_loss 206933.21875000\n",
      "epoch 5654 train_loss 10978114.74084724 val_loss 206933.21875000\n",
      "epoch 5655 train_loss 10978114.74077423 val_loss 206933.21875000\n",
      "epoch 5656 train_loss 10978114.74071022 val_loss 206933.21875000\n",
      "epoch 5657 train_loss 10978114.74062668 val_loss 206933.21875000\n",
      "epoch 5658 train_loss 10978114.74053413 val_loss 206933.21875000\n",
      "epoch 5659 train_loss 10978114.74044129 val_loss 206933.21875000\n",
      "epoch 5660 train_loss 10978114.74037346 val_loss 206933.21875000\n",
      "epoch 5661 train_loss 10978114.74028656 val_loss 206933.21875000\n",
      "epoch 5662 train_loss 10978114.74022324 val_loss 206933.21875000\n",
      "epoch 5663 train_loss 10978114.74013001 val_loss 206933.21875000\n",
      "epoch 5664 train_loss 10978114.74003273 val_loss 206933.21875000\n",
      "epoch 5665 train_loss 10978114.73994949 val_loss 206933.21875000\n",
      "epoch 5666 train_loss 10978114.73985130 val_loss 206933.21875000\n",
      "epoch 5667 train_loss 10978114.73974350 val_loss 206933.21875000\n",
      "epoch 5668 train_loss 10978114.73965759 val_loss 206933.21875000\n",
      "epoch 5669 train_loss 10978114.73956291 val_loss 206933.21875000\n",
      "epoch 5670 train_loss 10978114.73965332 val_loss 206933.21875000\n",
      "epoch 5671 train_loss 10978114.73955208 val_loss 206933.21875000\n",
      "epoch 5672 train_loss 10978114.73945183 val_loss 206933.21875000\n",
      "epoch 5673 train_loss 10978114.73937508 val_loss 206933.21875000\n",
      "epoch 5674 train_loss 10978114.73927994 val_loss 206933.21875000\n",
      "epoch 5675 train_loss 10978114.73920677 val_loss 206933.21875000\n",
      "epoch 5676 train_loss 10978114.73912270 val_loss 206933.21875000\n",
      "epoch 5677 train_loss 10978114.73903961 val_loss 206933.21875000\n",
      "epoch 5678 train_loss 10978114.73892639 val_loss 206933.21875000\n",
      "epoch 5679 train_loss 10978114.73884888 val_loss 206933.21875000\n",
      "epoch 5680 train_loss 10978114.73879341 val_loss 206933.21875000\n",
      "epoch 5681 train_loss 10978114.73868164 val_loss 206933.21875000\n",
      "epoch 5682 train_loss 10978114.73860176 val_loss 206933.21875000\n",
      "epoch 5683 train_loss 10978114.73851570 val_loss 206933.21875000\n",
      "epoch 5684 train_loss 10978114.73842194 val_loss 206933.21875000\n",
      "epoch 5685 train_loss 10978114.73833618 val_loss 206933.21875000\n",
      "epoch 5686 train_loss 10978114.73824524 val_loss 206933.21875000\n",
      "epoch 5687 train_loss 10978114.73816315 val_loss 206933.21875000\n",
      "epoch 5688 train_loss 10978114.73805328 val_loss 206933.21875000\n",
      "epoch 5689 train_loss 10978114.73797035 val_loss 206933.21875000\n",
      "epoch 5690 train_loss 10978114.73787018 val_loss 206933.21875000\n",
      "epoch 5691 train_loss 10978114.73781174 val_loss 206933.21875000\n",
      "epoch 5692 train_loss 10978114.73771591 val_loss 206933.21875000\n",
      "epoch 5693 train_loss 10978114.73760841 val_loss 206933.21875000\n",
      "epoch 5694 train_loss 10978114.73752708 val_loss 206933.21875000\n",
      "epoch 5695 train_loss 10978114.73747109 val_loss 206933.21875000\n",
      "epoch 5696 train_loss 10978114.73736084 val_loss 206933.21875000\n",
      "epoch 5697 train_loss 10978114.73727051 val_loss 206933.21875000\n",
      "epoch 5698 train_loss 10978114.73717728 val_loss 206933.21875000\n",
      "epoch 5699 train_loss 10978114.73710159 val_loss 206933.21875000\n",
      "epoch 5700 train_loss 10978114.73700645 val_loss 206933.21875000\n",
      "epoch 5701 train_loss 10978114.73692451 val_loss 206933.21875000\n",
      "epoch 5702 train_loss 10978114.73682426 val_loss 206933.21875000\n",
      "epoch 5703 train_loss 10978114.73673660 val_loss 206933.21875000\n",
      "epoch 5704 train_loss 10978114.73667564 val_loss 206933.21875000\n",
      "epoch 5705 train_loss 10978114.73657013 val_loss 206933.21875000\n",
      "epoch 5706 train_loss 10978114.73646355 val_loss 206933.21875000\n",
      "epoch 5707 train_loss 10978114.73642899 val_loss 206933.21875000\n",
      "epoch 5708 train_loss 10978114.73632942 val_loss 206933.21875000\n",
      "epoch 5709 train_loss 10978114.73623573 val_loss 206933.21875000\n",
      "epoch 5710 train_loss 10978114.73614166 val_loss 206933.21875000\n",
      "epoch 5711 train_loss 10978114.73606049 val_loss 206933.21875000\n",
      "epoch 5712 train_loss 10978114.73596642 val_loss 206933.21875000\n",
      "epoch 5713 train_loss 10978114.73587853 val_loss 206933.21875000\n",
      "epoch 5714 train_loss 10978114.73577469 val_loss 206933.21875000\n",
      "epoch 5715 train_loss 10978114.73569405 val_loss 206933.21875000\n",
      "epoch 5716 train_loss 10978114.73560783 val_loss 206933.21875000\n",
      "epoch 5717 train_loss 10978114.73550224 val_loss 206933.21875000\n",
      "epoch 5718 train_loss 10978114.73539970 val_loss 206933.21875000\n",
      "epoch 5719 train_loss 10978114.73535255 val_loss 206933.21875000\n",
      "epoch 5720 train_loss 10978114.73525795 val_loss 206933.21875000\n",
      "epoch 5721 train_loss 10978114.73515297 val_loss 206933.21875000\n",
      "epoch 5722 train_loss 10978114.73505524 val_loss 206933.21875000\n",
      "epoch 5723 train_loss 10978114.73496742 val_loss 206933.21875000\n",
      "epoch 5724 train_loss 10978114.73485458 val_loss 206933.21875000\n",
      "epoch 5725 train_loss 10978114.73480064 val_loss 206933.21875000\n",
      "epoch 5726 train_loss 10978114.73468781 val_loss 206933.21875000\n",
      "epoch 5727 train_loss 10978114.73460831 val_loss 206933.21875000\n",
      "epoch 5728 train_loss 10978114.73451141 val_loss 206933.21875000\n",
      "epoch 5729 train_loss 10978114.73441818 val_loss 206933.21875000\n",
      "epoch 5730 train_loss 10978114.73432594 val_loss 206933.21875000\n",
      "epoch 5731 train_loss 10978114.73422035 val_loss 206933.21875000\n",
      "epoch 5732 train_loss 10978114.73421242 val_loss 206933.21875000\n",
      "epoch 5733 train_loss 10978114.73412674 val_loss 206933.21875000\n",
      "epoch 5734 train_loss 10978114.73403526 val_loss 206933.21875000\n",
      "epoch 5735 train_loss 10978114.73393791 val_loss 206933.21875000\n",
      "epoch 5736 train_loss 10978114.73390221 val_loss 206933.21875000\n",
      "epoch 5737 train_loss 10978114.73381500 val_loss 206933.21875000\n",
      "epoch 5738 train_loss 10978114.73376900 val_loss 206933.21875000\n",
      "epoch 5739 train_loss 10978114.73363960 val_loss 206933.21875000\n",
      "epoch 5740 train_loss 10978114.73356102 val_loss 206933.21875000\n",
      "epoch 5741 train_loss 10978114.73345688 val_loss 206933.21875000\n",
      "epoch 5742 train_loss 10978114.73336739 val_loss 206933.21875000\n",
      "epoch 5743 train_loss 10978114.73328712 val_loss 206933.21875000\n",
      "epoch 5744 train_loss 10978114.73320076 val_loss 206933.21875000\n",
      "epoch 5745 train_loss 10978114.73311974 val_loss 206933.21875000\n",
      "epoch 5746 train_loss 10978114.73304710 val_loss 206933.21875000\n",
      "epoch 5747 train_loss 10978114.73295799 val_loss 206933.21875000\n",
      "epoch 5748 train_loss 10978114.73285622 val_loss 206933.21875000\n",
      "epoch 5749 train_loss 10978114.73275833 val_loss 206933.21875000\n",
      "epoch 5750 train_loss 10978114.73266045 val_loss 206933.21875000\n",
      "epoch 5751 train_loss 10978114.73257019 val_loss 206933.21875000\n",
      "epoch 5752 train_loss 10978114.73248627 val_loss 206933.21875000\n",
      "epoch 5753 train_loss 10978114.73238670 val_loss 206933.21875000\n",
      "epoch 5754 train_loss 10978114.73229408 val_loss 206933.21875000\n",
      "epoch 5755 train_loss 10978114.73221069 val_loss 206933.21875000\n",
      "epoch 5756 train_loss 10978114.73212265 val_loss 206933.21875000\n",
      "epoch 5757 train_loss 10978114.73201958 val_loss 206933.21875000\n",
      "epoch 5758 train_loss 10978114.73194206 val_loss 206933.21875000\n",
      "epoch 5759 train_loss 10978114.73185898 val_loss 206933.21875000\n",
      "epoch 5760 train_loss 10978114.73173538 val_loss 206933.21875000\n",
      "epoch 5761 train_loss 10978114.73167412 val_loss 206933.21875000\n",
      "epoch 5762 train_loss 10978114.73162773 val_loss 206933.21875000\n",
      "epoch 5763 train_loss 10978114.73154228 val_loss 206933.21875000\n",
      "epoch 5764 train_loss 10978114.73144684 val_loss 206933.21875000\n",
      "epoch 5765 train_loss 10978114.73135658 val_loss 206933.21875000\n",
      "epoch 5766 train_loss 10978114.73127159 val_loss 206933.21875000\n",
      "epoch 5767 train_loss 10978114.73117279 val_loss 206933.21875000\n",
      "epoch 5768 train_loss 10978114.73107575 val_loss 206933.21875000\n",
      "epoch 5769 train_loss 10978114.73099495 val_loss 206933.21875000\n",
      "epoch 5770 train_loss 10978114.73090973 val_loss 206933.21875000\n",
      "epoch 5771 train_loss 10978114.73081337 val_loss 206933.21875000\n",
      "epoch 5772 train_loss 10978114.73072395 val_loss 206933.21875000\n",
      "epoch 5773 train_loss 10978114.73064339 val_loss 206933.21875000\n",
      "epoch 5774 train_loss 10978114.73053436 val_loss 206933.21875000\n",
      "epoch 5775 train_loss 10978114.73042412 val_loss 206933.21875000\n",
      "epoch 5776 train_loss 10978114.73033409 val_loss 206933.21875000\n",
      "epoch 5777 train_loss 10978114.73025589 val_loss 206933.21875000\n",
      "epoch 5778 train_loss 10978114.73016052 val_loss 206933.21875000\n",
      "epoch 5779 train_loss 10978114.73007492 val_loss 206933.21875000\n",
      "epoch 5780 train_loss 10978114.72998161 val_loss 206933.21875000\n",
      "epoch 5781 train_loss 10978114.72990158 val_loss 206933.21875000\n",
      "epoch 5782 train_loss 10978114.72977898 val_loss 206933.21875000\n",
      "epoch 5783 train_loss 10978114.72974113 val_loss 206933.21875000\n",
      "epoch 5784 train_loss 10978114.72965752 val_loss 206933.21875000\n",
      "epoch 5785 train_loss 10978114.72955116 val_loss 206933.21875000\n",
      "epoch 5786 train_loss 10978114.72948952 val_loss 206933.21875000\n",
      "epoch 5787 train_loss 10978114.72941841 val_loss 206933.21875000\n",
      "epoch 5788 train_loss 10978114.72932076 val_loss 206933.21875000\n",
      "epoch 5789 train_loss 10978114.72921722 val_loss 206933.21875000\n",
      "epoch 5790 train_loss 10978114.72911896 val_loss 206933.21875000\n",
      "epoch 5791 train_loss 10978114.72904671 val_loss 206933.21875000\n",
      "epoch 5792 train_loss 10978114.72893120 val_loss 206933.21875000\n",
      "epoch 5793 train_loss 10978114.72881874 val_loss 206933.21875000\n",
      "epoch 5794 train_loss 10978114.72875115 val_loss 206933.21875000\n",
      "epoch 5795 train_loss 10978114.72867867 val_loss 206933.21875000\n",
      "epoch 5796 train_loss 10978114.72857910 val_loss 206933.21875000\n",
      "epoch 5797 train_loss 10978114.72848206 val_loss 206933.21875000\n",
      "epoch 5798 train_loss 10978114.72839897 val_loss 206933.21875000\n",
      "epoch 5799 train_loss 10978114.72831825 val_loss 206933.21875000\n",
      "epoch 5800 train_loss 10978114.72822235 val_loss 206933.21875000\n",
      "epoch 5801 train_loss 10978114.72811928 val_loss 206933.21875000\n",
      "epoch 5802 train_loss 10978114.72810860 val_loss 206933.21875000\n",
      "epoch 5803 train_loss 10978114.72801628 val_loss 206933.21875000\n",
      "epoch 5804 train_loss 10978114.72792809 val_loss 206933.21875000\n",
      "epoch 5805 train_loss 10978114.72783440 val_loss 206933.21875000\n",
      "epoch 5806 train_loss 10978114.72775124 val_loss 206933.21875000\n",
      "epoch 5807 train_loss 10978114.72762665 val_loss 206933.21875000\n",
      "epoch 5808 train_loss 10978114.72754402 val_loss 206933.21875000\n",
      "epoch 5809 train_loss 10978114.72746811 val_loss 206933.21875000\n",
      "epoch 5810 train_loss 10978114.72740219 val_loss 206933.21875000\n",
      "epoch 5811 train_loss 10978114.72732529 val_loss 206933.21875000\n",
      "epoch 5812 train_loss 10978114.72725014 val_loss 206933.21875000\n",
      "epoch 5813 train_loss 10978114.72713501 val_loss 206933.21875000\n",
      "epoch 5814 train_loss 10978114.72705223 val_loss 206933.21875000\n",
      "epoch 5815 train_loss 10978114.72694984 val_loss 206933.21875000\n",
      "epoch 5816 train_loss 10978114.72688164 val_loss 206933.21875000\n",
      "epoch 5817 train_loss 10978114.72681587 val_loss 206933.21875000\n",
      "epoch 5818 train_loss 10978114.72674828 val_loss 206933.21875000\n",
      "epoch 5819 train_loss 10978114.72664169 val_loss 206933.21875000\n",
      "epoch 5820 train_loss 10978114.72655640 val_loss 206933.21875000\n",
      "epoch 5821 train_loss 10978114.72645424 val_loss 206933.21875000\n",
      "epoch 5822 train_loss 10978114.72637817 val_loss 206933.21875000\n",
      "epoch 5823 train_loss 10978114.72629654 val_loss 206933.21875000\n",
      "epoch 5824 train_loss 10978114.72620918 val_loss 206933.21875000\n",
      "epoch 5825 train_loss 10978114.72609528 val_loss 206933.21875000\n",
      "epoch 5826 train_loss 10978114.72601860 val_loss 206933.21875000\n",
      "epoch 5827 train_loss 10978114.72592255 val_loss 206933.21875000\n",
      "epoch 5828 train_loss 10978114.72582169 val_loss 206933.21875000\n",
      "epoch 5829 train_loss 10978114.72572838 val_loss 206933.21875000\n",
      "epoch 5830 train_loss 10978114.72564133 val_loss 206933.21875000\n",
      "epoch 5831 train_loss 10978114.72555199 val_loss 206933.21875000\n",
      "epoch 5832 train_loss 10978114.72545441 val_loss 206933.21875000\n",
      "epoch 5833 train_loss 10978114.72536331 val_loss 206933.21875000\n",
      "epoch 5834 train_loss 10978114.72527458 val_loss 206933.21875000\n",
      "epoch 5835 train_loss 10978114.72518219 val_loss 206933.21875000\n",
      "epoch 5836 train_loss 10978114.72509659 val_loss 206933.21875000\n",
      "epoch 5837 train_loss 10978114.72501556 val_loss 206933.21875000\n",
      "epoch 5838 train_loss 10978114.72490829 val_loss 206933.21875000\n",
      "epoch 5839 train_loss 10978114.72479996 val_loss 206933.21875000\n",
      "epoch 5840 train_loss 10978114.72470970 val_loss 206933.21875000\n",
      "epoch 5841 train_loss 10978114.72461220 val_loss 206933.21875000\n",
      "epoch 5842 train_loss 10978114.72452736 val_loss 206933.21875000\n",
      "epoch 5843 train_loss 10978114.72443474 val_loss 206933.21875000\n",
      "epoch 5844 train_loss 10978114.72435730 val_loss 206933.21875000\n",
      "epoch 5845 train_loss 10978114.72428383 val_loss 206933.21875000\n",
      "epoch 5846 train_loss 10978114.72424690 val_loss 206933.21875000\n",
      "epoch 5847 train_loss 10978114.72417755 val_loss 206933.21875000\n",
      "epoch 5848 train_loss 10978114.72410110 val_loss 206933.21875000\n",
      "epoch 5849 train_loss 10978114.72400436 val_loss 206933.21875000\n",
      "epoch 5850 train_loss 10978114.72390472 val_loss 206933.21875000\n",
      "epoch 5851 train_loss 10978114.72383041 val_loss 206933.21875000\n",
      "epoch 5852 train_loss 10978114.72372856 val_loss 206933.21875000\n",
      "epoch 5853 train_loss 10978114.72364967 val_loss 206933.21875000\n",
      "epoch 5854 train_loss 10978114.72355217 val_loss 206933.21875000\n",
      "epoch 5855 train_loss 10978114.72346039 val_loss 206933.21875000\n",
      "epoch 5856 train_loss 10978114.72337196 val_loss 206933.21875000\n",
      "epoch 5857 train_loss 10978114.72329285 val_loss 206933.21875000\n",
      "epoch 5858 train_loss 10978114.72318832 val_loss 206933.21875000\n",
      "epoch 5859 train_loss 10978114.72310692 val_loss 206933.21875000\n",
      "epoch 5860 train_loss 10978114.72301262 val_loss 206933.21875000\n",
      "epoch 5861 train_loss 10978114.72293838 val_loss 206933.21875000\n",
      "epoch 5862 train_loss 10978114.72284294 val_loss 206933.21875000\n",
      "epoch 5863 train_loss 10978114.72277412 val_loss 206933.21875000\n",
      "epoch 5864 train_loss 10978114.72266251 val_loss 206933.21875000\n",
      "epoch 5865 train_loss 10978114.72261276 val_loss 206933.21875000\n",
      "epoch 5866 train_loss 10978114.72251206 val_loss 206933.21875000\n",
      "epoch 5867 train_loss 10978114.72245018 val_loss 206933.21875000\n",
      "epoch 5868 train_loss 10978114.72233101 val_loss 206933.22656250\n",
      "epoch 5869 train_loss 10978114.72231667 val_loss 206933.22656250\n",
      "epoch 5870 train_loss 10978114.72222343 val_loss 206933.22656250\n",
      "epoch 5871 train_loss 10978114.72214302 val_loss 206933.22656250\n",
      "epoch 5872 train_loss 10978114.72204575 val_loss 206933.22656250\n",
      "epoch 5873 train_loss 10978114.72194336 val_loss 206933.22656250\n",
      "epoch 5874 train_loss 10978114.72188255 val_loss 206933.22656250\n",
      "epoch 5875 train_loss 10978114.72178810 val_loss 206933.22656250\n",
      "epoch 5876 train_loss 10978114.72169914 val_loss 206933.22656250\n",
      "epoch 5877 train_loss 10978114.72161560 val_loss 206933.22656250\n",
      "epoch 5878 train_loss 10978114.72152573 val_loss 206933.22656250\n",
      "epoch 5879 train_loss 10978114.72142448 val_loss 206933.22656250\n",
      "epoch 5880 train_loss 10978114.72133347 val_loss 206933.22656250\n",
      "epoch 5881 train_loss 10978114.72126473 val_loss 206933.22656250\n",
      "epoch 5882 train_loss 10978114.72120857 val_loss 206933.22656250\n",
      "epoch 5883 train_loss 10978114.72110550 val_loss 206933.22656250\n",
      "epoch 5884 train_loss 10978114.72104385 val_loss 206933.22656250\n",
      "epoch 5885 train_loss 10978114.72097382 val_loss 206933.24218750\n",
      "epoch 5886 train_loss 10978114.72086311 val_loss 206933.24218750\n",
      "epoch 5887 train_loss 10978114.72077934 val_loss 206933.24218750\n",
      "epoch 5888 train_loss 10978114.72067055 val_loss 206933.24218750\n",
      "epoch 5889 train_loss 10978114.72060944 val_loss 206933.24218750\n",
      "epoch 5890 train_loss 10978114.72054069 val_loss 206933.24218750\n",
      "epoch 5891 train_loss 10978114.72048462 val_loss 206933.24218750\n",
      "epoch 5892 train_loss 10978114.72038086 val_loss 206933.24218750\n",
      "epoch 5893 train_loss 10978114.72034729 val_loss 206933.24218750\n",
      "epoch 5894 train_loss 10978114.72029183 val_loss 206933.24218750\n",
      "epoch 5895 train_loss 10978114.72017761 val_loss 206933.24218750\n",
      "epoch 5896 train_loss 10978114.72007713 val_loss 206933.24218750\n",
      "epoch 5897 train_loss 10978114.71998650 val_loss 206933.24218750\n",
      "epoch 5898 train_loss 10978114.71990471 val_loss 206933.24218750\n",
      "epoch 5899 train_loss 10978114.71981590 val_loss 206933.24218750\n",
      "epoch 5900 train_loss 10978114.71970871 val_loss 206933.24218750\n",
      "epoch 5901 train_loss 10978114.71961479 val_loss 206933.24218750\n",
      "epoch 5902 train_loss 10978114.71954208 val_loss 206933.24218750\n",
      "epoch 5903 train_loss 10978114.71945396 val_loss 206933.24218750\n",
      "epoch 5904 train_loss 10978114.71935120 val_loss 206933.24218750\n",
      "epoch 5905 train_loss 10978114.71925606 val_loss 206933.24218750\n",
      "epoch 5906 train_loss 10978114.71917236 val_loss 206933.24218750\n",
      "epoch 5907 train_loss 10978114.71908699 val_loss 206933.24218750\n",
      "epoch 5908 train_loss 10978114.71900879 val_loss 206933.24218750\n",
      "epoch 5909 train_loss 10978114.71892670 val_loss 206933.24218750\n",
      "epoch 5910 train_loss 10978114.71882957 val_loss 206933.24218750\n",
      "epoch 5911 train_loss 10978114.71872376 val_loss 206933.24218750\n",
      "epoch 5912 train_loss 10978114.71863770 val_loss 206933.24218750\n",
      "epoch 5913 train_loss 10978114.71854622 val_loss 206933.24218750\n",
      "epoch 5914 train_loss 10978114.71843841 val_loss 206933.24218750\n",
      "epoch 5915 train_loss 10978114.71835457 val_loss 206933.24218750\n",
      "epoch 5916 train_loss 10978114.71823952 val_loss 206933.24218750\n",
      "epoch 5917 train_loss 10978114.71819054 val_loss 206933.24218750\n",
      "epoch 5918 train_loss 10978114.71809151 val_loss 206933.24218750\n",
      "epoch 5919 train_loss 10978114.71800797 val_loss 206933.24218750\n",
      "epoch 5920 train_loss 10978114.71792397 val_loss 206933.24218750\n",
      "epoch 5921 train_loss 10978114.71783775 val_loss 206933.24218750\n",
      "epoch 5922 train_loss 10978114.71773666 val_loss 206933.24218750\n",
      "epoch 5923 train_loss 10978114.71765953 val_loss 206933.24218750\n",
      "epoch 5924 train_loss 10978114.71757858 val_loss 206933.24218750\n",
      "epoch 5925 train_loss 10978114.71747025 val_loss 206933.24218750\n",
      "epoch 5926 train_loss 10978114.71738945 val_loss 206933.24218750\n",
      "epoch 5927 train_loss 10978114.71728638 val_loss 206933.24218750\n",
      "epoch 5928 train_loss 10978114.71722237 val_loss 206933.24218750\n",
      "epoch 5929 train_loss 10978114.71712692 val_loss 206933.24218750\n",
      "epoch 5930 train_loss 10978114.71701477 val_loss 206933.24218750\n",
      "epoch 5931 train_loss 10978114.71694626 val_loss 206933.24218750\n",
      "epoch 5932 train_loss 10978114.71685524 val_loss 206933.24218750\n",
      "epoch 5933 train_loss 10978114.71677826 val_loss 206933.24218750\n",
      "epoch 5934 train_loss 10978114.71668717 val_loss 206933.24218750\n",
      "epoch 5935 train_loss 10978114.71660500 val_loss 206933.24218750\n",
      "epoch 5936 train_loss 10978114.71647476 val_loss 206933.24218750\n",
      "epoch 5937 train_loss 10978114.71639366 val_loss 206933.24218750\n",
      "epoch 5938 train_loss 10978114.71632889 val_loss 206933.24218750\n",
      "epoch 5939 train_loss 10978114.71622475 val_loss 206933.24218750\n",
      "epoch 5940 train_loss 10978114.71622040 val_loss 206933.24218750\n",
      "epoch 5941 train_loss 10978114.71614540 val_loss 206933.24218750\n",
      "epoch 5942 train_loss 10978114.71604919 val_loss 206933.24218750\n",
      "epoch 5943 train_loss 10978114.71594566 val_loss 206933.24218750\n",
      "epoch 5944 train_loss 10978114.71584892 val_loss 206933.24218750\n",
      "epoch 5945 train_loss 10978114.71577934 val_loss 206933.24218750\n",
      "epoch 5946 train_loss 10978114.71568413 val_loss 206933.24218750\n",
      "epoch 5947 train_loss 10978114.71558678 val_loss 206933.24218750\n",
      "epoch 5948 train_loss 10978114.71558228 val_loss 206933.24218750\n",
      "epoch 5949 train_loss 10978114.71547722 val_loss 206933.24218750\n",
      "epoch 5950 train_loss 10978114.71538033 val_loss 206933.24218750\n",
      "epoch 5951 train_loss 10978114.71528656 val_loss 206933.24218750\n",
      "epoch 5952 train_loss 10978114.71519981 val_loss 206933.24218750\n",
      "epoch 5953 train_loss 10978114.71511528 val_loss 206933.24218750\n",
      "epoch 5954 train_loss 10978114.71501610 val_loss 206933.24218750\n",
      "epoch 5955 train_loss 10978114.71491905 val_loss 206933.24218750\n",
      "epoch 5956 train_loss 10978114.71483604 val_loss 206933.24218750\n",
      "epoch 5957 train_loss 10978114.71474388 val_loss 206933.24218750\n",
      "epoch 5958 train_loss 10978114.71465172 val_loss 206933.24218750\n",
      "epoch 5959 train_loss 10978114.71457192 val_loss 206933.24218750\n",
      "epoch 5960 train_loss 10978114.71448212 val_loss 206933.24218750\n",
      "epoch 5961 train_loss 10978114.71436935 val_loss 206933.24218750\n",
      "epoch 5962 train_loss 10978114.71430016 val_loss 206933.24218750\n",
      "epoch 5963 train_loss 10978114.71421852 val_loss 206933.24218750\n",
      "epoch 5964 train_loss 10978114.71412010 val_loss 206933.24218750\n",
      "epoch 5965 train_loss 10978114.71408714 val_loss 206933.24218750\n",
      "epoch 5966 train_loss 10978114.71400162 val_loss 206933.24218750\n",
      "epoch 5967 train_loss 10978114.71390717 val_loss 206933.24218750\n",
      "epoch 5968 train_loss 10978114.71380287 val_loss 206933.24218750\n",
      "epoch 5969 train_loss 10978114.71372459 val_loss 206933.24218750\n",
      "epoch 5970 train_loss 10978114.71366623 val_loss 206933.24218750\n",
      "epoch 5971 train_loss 10978114.71358170 val_loss 206933.24218750\n",
      "epoch 5972 train_loss 10978114.71348068 val_loss 206933.24218750\n",
      "epoch 5973 train_loss 10978114.71337868 val_loss 206933.24218750\n",
      "epoch 5974 train_loss 10978114.71331879 val_loss 206933.24218750\n",
      "epoch 5975 train_loss 10978114.71329186 val_loss 206933.24218750\n",
      "epoch 5976 train_loss 10978114.71321205 val_loss 206933.24218750\n",
      "epoch 5977 train_loss 10978114.71311119 val_loss 206933.24218750\n",
      "epoch 5978 train_loss 10978114.71301094 val_loss 206933.24218750\n",
      "epoch 5979 train_loss 10978114.71293594 val_loss 206933.24218750\n",
      "epoch 5980 train_loss 10978114.71283989 val_loss 206933.24218750\n",
      "epoch 5981 train_loss 10978114.71273888 val_loss 206933.24218750\n",
      "epoch 5982 train_loss 10978114.71264359 val_loss 206933.24218750\n",
      "epoch 5983 train_loss 10978114.71253830 val_loss 206933.24218750\n",
      "epoch 5984 train_loss 10978114.71247765 val_loss 206933.24218750\n",
      "epoch 5985 train_loss 10978114.71239143 val_loss 206933.24218750\n",
      "epoch 5986 train_loss 10978114.71230034 val_loss 206933.24218750\n",
      "epoch 5987 train_loss 10978114.71225037 val_loss 206933.24218750\n",
      "epoch 5988 train_loss 10978114.71215446 val_loss 206933.24218750\n",
      "epoch 5989 train_loss 10978114.71207077 val_loss 206933.24218750\n",
      "epoch 5990 train_loss 10978114.71198982 val_loss 206933.24218750\n",
      "epoch 5991 train_loss 10978114.71190582 val_loss 206933.24218750\n",
      "epoch 5992 train_loss 10978114.71180702 val_loss 206933.24218750\n",
      "epoch 5993 train_loss 10978114.71170807 val_loss 206933.24218750\n",
      "epoch 5994 train_loss 10978114.71160950 val_loss 206933.24218750\n",
      "epoch 5995 train_loss 10978114.71153252 val_loss 206933.24218750\n",
      "epoch 5996 train_loss 10978114.71143326 val_loss 206933.24218750\n",
      "epoch 5997 train_loss 10978114.71135170 val_loss 206933.24218750\n",
      "epoch 5998 train_loss 10978114.71125900 val_loss 206933.24218750\n",
      "epoch 5999 train_loss 10978114.71118530 val_loss 206933.24218750\n",
      "epoch 6000 train_loss 10978114.71109520 val_loss 206933.24218750\n",
      "epoch 6001 train_loss 10978114.71099495 val_loss 206933.24218750\n",
      "epoch 6002 train_loss 10978114.71091629 val_loss 206933.24218750\n",
      "epoch 6003 train_loss 10978114.71084373 val_loss 206933.24218750\n",
      "epoch 6004 train_loss 10978114.71073845 val_loss 206933.24218750\n",
      "epoch 6005 train_loss 10978114.71064346 val_loss 206933.24218750\n",
      "epoch 6006 train_loss 10978114.71054977 val_loss 206933.24218750\n",
      "epoch 6007 train_loss 10978114.71046349 val_loss 206933.24218750\n",
      "epoch 6008 train_loss 10978114.71035469 val_loss 206933.24218750\n",
      "epoch 6009 train_loss 10978114.71027527 val_loss 206933.24218750\n",
      "epoch 6010 train_loss 10978114.71018997 val_loss 206933.24218750\n",
      "epoch 6011 train_loss 10978114.71009773 val_loss 206933.24218750\n",
      "epoch 6012 train_loss 10978114.71000160 val_loss 206933.24218750\n",
      "epoch 6013 train_loss 10978114.70991966 val_loss 206933.24218750\n",
      "epoch 6014 train_loss 10978114.70981293 val_loss 206933.24218750\n",
      "epoch 6015 train_loss 10978114.70976959 val_loss 206933.24218750\n",
      "epoch 6016 train_loss 10978114.70965935 val_loss 206933.24218750\n",
      "epoch 6017 train_loss 10978114.70958145 val_loss 206933.24218750\n",
      "epoch 6018 train_loss 10978114.70949776 val_loss 206933.24218750\n",
      "epoch 6019 train_loss 10978114.70938385 val_loss 206933.24218750\n",
      "epoch 6020 train_loss 10978114.70932182 val_loss 206933.24218750\n",
      "epoch 6021 train_loss 10978114.70922524 val_loss 206933.24218750\n",
      "epoch 6022 train_loss 10978114.70912041 val_loss 206933.24218750\n",
      "epoch 6023 train_loss 10978114.70904251 val_loss 206933.24218750\n",
      "epoch 6024 train_loss 10978114.70895515 val_loss 206933.24218750\n",
      "epoch 6025 train_loss 10978114.70885254 val_loss 206933.24218750\n",
      "epoch 6026 train_loss 10978114.70876808 val_loss 206933.24218750\n",
      "epoch 6027 train_loss 10978114.70870293 val_loss 206933.24218750\n",
      "epoch 6028 train_loss 10978114.70861427 val_loss 206933.24218750\n",
      "epoch 6029 train_loss 10978114.70848679 val_loss 206933.24218750\n",
      "epoch 6030 train_loss 10978114.70839958 val_loss 206933.24218750\n",
      "epoch 6031 train_loss 10978114.70831932 val_loss 206933.24218750\n",
      "epoch 6032 train_loss 10978114.70827057 val_loss 206933.24218750\n",
      "epoch 6033 train_loss 10978114.70819702 val_loss 206933.24218750\n",
      "epoch 6034 train_loss 10978114.70808220 val_loss 206933.24218750\n",
      "epoch 6035 train_loss 10978114.70800667 val_loss 206933.24218750\n",
      "epoch 6036 train_loss 10978114.70792221 val_loss 206933.24218750\n",
      "epoch 6037 train_loss 10978114.70782684 val_loss 206933.24218750\n",
      "epoch 6038 train_loss 10978114.70772865 val_loss 206933.24218750\n",
      "epoch 6039 train_loss 10978114.70766075 val_loss 206933.24218750\n",
      "epoch 6040 train_loss 10978114.70753052 val_loss 206933.24218750\n",
      "epoch 6041 train_loss 10978114.70737282 val_loss 206933.24218750\n",
      "epoch 6042 train_loss 10978114.70728142 val_loss 206933.24218750\n",
      "epoch 6043 train_loss 10978114.70718536 val_loss 206933.24218750\n",
      "epoch 6044 train_loss 10978114.70711540 val_loss 206933.24218750\n",
      "epoch 6045 train_loss 10978114.70703453 val_loss 206933.24218750\n",
      "epoch 6046 train_loss 10978114.70693977 val_loss 206933.24218750\n",
      "epoch 6047 train_loss 10978114.70683830 val_loss 206933.24218750\n",
      "epoch 6048 train_loss 10978114.70675293 val_loss 206933.24218750\n",
      "epoch 6049 train_loss 10978114.70665047 val_loss 206933.24218750\n",
      "epoch 6050 train_loss 10978114.70655846 val_loss 206933.24218750\n",
      "epoch 6051 train_loss 10978114.70649963 val_loss 206933.24218750\n",
      "epoch 6052 train_loss 10978114.70641159 val_loss 206933.24218750\n",
      "epoch 6053 train_loss 10978114.70631294 val_loss 206933.24218750\n",
      "epoch 6054 train_loss 10978114.70621864 val_loss 206933.24218750\n",
      "epoch 6055 train_loss 10978114.70613800 val_loss 206933.24218750\n",
      "epoch 6056 train_loss 10978114.70603958 val_loss 206933.24218750\n",
      "epoch 6057 train_loss 10978114.70596504 val_loss 206933.24218750\n",
      "epoch 6058 train_loss 10978114.70585243 val_loss 206933.24218750\n",
      "epoch 6059 train_loss 10978114.70575882 val_loss 206933.24218750\n",
      "epoch 6060 train_loss 10978114.70574020 val_loss 206933.24218750\n",
      "epoch 6061 train_loss 10978114.70566917 val_loss 206933.24218750\n",
      "epoch 6062 train_loss 10978114.70553650 val_loss 206933.24218750\n",
      "epoch 6063 train_loss 10978114.70545425 val_loss 206933.24218750\n",
      "epoch 6064 train_loss 10978114.70537437 val_loss 206933.24218750\n",
      "epoch 6065 train_loss 10978114.70526566 val_loss 206933.24218750\n",
      "epoch 6066 train_loss 10978114.70519234 val_loss 206933.24218750\n",
      "epoch 6067 train_loss 10978114.70509849 val_loss 206933.24218750\n",
      "epoch 6068 train_loss 10978114.70509453 val_loss 206933.24218750\n",
      "epoch 6069 train_loss 10978114.70499809 val_loss 206933.24218750\n",
      "epoch 6070 train_loss 10978114.70493744 val_loss 206933.24218750\n",
      "epoch 6071 train_loss 10978114.70483078 val_loss 206933.24218750\n",
      "epoch 6072 train_loss 10978114.70473625 val_loss 206933.24218750\n",
      "epoch 6073 train_loss 10978114.70464211 val_loss 206933.24218750\n",
      "epoch 6074 train_loss 10978114.70455238 val_loss 206933.24218750\n",
      "epoch 6075 train_loss 10978114.70445610 val_loss 206933.24218750\n",
      "epoch 6076 train_loss 10978114.70439919 val_loss 206933.24218750\n",
      "epoch 6077 train_loss 10978114.70430992 val_loss 206933.24218750\n",
      "epoch 6078 train_loss 10978114.70422241 val_loss 206933.24218750\n",
      "epoch 6079 train_loss 10978114.70413048 val_loss 206933.24218750\n",
      "epoch 6080 train_loss 10978114.70402771 val_loss 206933.24218750\n",
      "epoch 6081 train_loss 10978114.70397308 val_loss 206933.24218750\n",
      "epoch 6082 train_loss 10978114.70386063 val_loss 206933.24218750\n",
      "epoch 6083 train_loss 10978114.70376259 val_loss 206933.24218750\n",
      "epoch 6084 train_loss 10978114.70368591 val_loss 206933.24218750\n",
      "epoch 6085 train_loss 10978114.70359222 val_loss 206933.24218750\n",
      "epoch 6086 train_loss 10978114.70349190 val_loss 206933.24218750\n",
      "epoch 6087 train_loss 10978114.70344894 val_loss 206933.24218750\n",
      "epoch 6088 train_loss 10978114.70337914 val_loss 206933.24218750\n",
      "epoch 6089 train_loss 10978114.70328606 val_loss 206933.24218750\n",
      "epoch 6090 train_loss 10978114.70317482 val_loss 206933.24218750\n",
      "epoch 6091 train_loss 10978114.70309700 val_loss 206933.24218750\n",
      "epoch 6092 train_loss 10978114.70307861 val_loss 206933.24218750\n",
      "epoch 6093 train_loss 10978114.70298721 val_loss 206933.24218750\n",
      "epoch 6094 train_loss 10978114.70291176 val_loss 206933.24218750\n",
      "epoch 6095 train_loss 10978114.70283234 val_loss 206933.24218750\n",
      "epoch 6096 train_loss 10978114.70277313 val_loss 206933.24218750\n",
      "epoch 6097 train_loss 10978114.70267487 val_loss 206933.24218750\n",
      "epoch 6098 train_loss 10978114.70257622 val_loss 206933.24218750\n",
      "epoch 6099 train_loss 10978114.70248161 val_loss 206933.24218750\n",
      "epoch 6100 train_loss 10978114.70237854 val_loss 206933.24218750\n",
      "epoch 6101 train_loss 10978114.70229294 val_loss 206933.24218750\n",
      "epoch 6102 train_loss 10978114.70220627 val_loss 206933.24218750\n",
      "epoch 6103 train_loss 10978114.70212929 val_loss 206933.24218750\n",
      "epoch 6104 train_loss 10978114.70202393 val_loss 206933.24218750\n",
      "epoch 6105 train_loss 10978114.70193695 val_loss 206933.24218750\n",
      "epoch 6106 train_loss 10978114.70182747 val_loss 206933.24218750\n",
      "epoch 6107 train_loss 10978114.70172905 val_loss 206933.24218750\n",
      "epoch 6108 train_loss 10978114.70164307 val_loss 206933.24218750\n",
      "epoch 6109 train_loss 10978114.70161018 val_loss 206933.24218750\n",
      "epoch 6110 train_loss 10978114.70153343 val_loss 206933.24218750\n",
      "epoch 6111 train_loss 10978114.70143036 val_loss 206933.24218750\n",
      "epoch 6112 train_loss 10978114.70132134 val_loss 206933.24218750\n",
      "epoch 6113 train_loss 10978114.70123619 val_loss 206933.24218750\n",
      "epoch 6114 train_loss 10978114.70114052 val_loss 206933.24218750\n",
      "epoch 6115 train_loss 10978114.70104492 val_loss 206933.24218750\n",
      "epoch 6116 train_loss 10978114.70098770 val_loss 206933.24218750\n",
      "epoch 6117 train_loss 10978114.70092400 val_loss 206933.24218750\n",
      "epoch 6118 train_loss 10978114.70086021 val_loss 206933.24218750\n",
      "epoch 6119 train_loss 10978114.70074745 val_loss 206933.24218750\n",
      "epoch 6120 train_loss 10978114.70065537 val_loss 206933.24218750\n",
      "epoch 6121 train_loss 10978114.70058823 val_loss 206933.24218750\n",
      "epoch 6122 train_loss 10978114.70053581 val_loss 206933.24218750\n",
      "epoch 6123 train_loss 10978114.70045624 val_loss 206933.24218750\n",
      "epoch 6124 train_loss 10978114.70035019 val_loss 206933.24218750\n",
      "epoch 6125 train_loss 10978114.70032074 val_loss 206933.24218750\n",
      "epoch 6126 train_loss 10978114.70020988 val_loss 206933.24218750\n",
      "epoch 6127 train_loss 10978114.70011818 val_loss 206933.24218750\n",
      "epoch 6128 train_loss 10978114.70003944 val_loss 206933.24218750\n",
      "epoch 6129 train_loss 10978114.69995415 val_loss 206933.24218750\n",
      "epoch 6130 train_loss 10978114.69984818 val_loss 206933.24218750\n",
      "epoch 6131 train_loss 10978114.69978348 val_loss 206933.24218750\n",
      "epoch 6132 train_loss 10978114.69967834 val_loss 206933.24218750\n",
      "epoch 6133 train_loss 10978114.69958382 val_loss 206933.24218750\n",
      "epoch 6134 train_loss 10978114.69948830 val_loss 206933.24218750\n",
      "epoch 6135 train_loss 10978114.69937592 val_loss 206933.24218750\n",
      "epoch 6136 train_loss 10978114.69930183 val_loss 206933.24218750\n",
      "epoch 6137 train_loss 10978114.69919998 val_loss 206933.24218750\n",
      "epoch 6138 train_loss 10978114.69911041 val_loss 206933.24218750\n",
      "epoch 6139 train_loss 10978114.69901306 val_loss 206933.24218750\n",
      "epoch 6140 train_loss 10978114.69893280 val_loss 206933.24218750\n",
      "epoch 6141 train_loss 10978114.69884094 val_loss 206933.24218750\n",
      "epoch 6142 train_loss 10978114.69873619 val_loss 206933.24218750\n",
      "epoch 6143 train_loss 10978114.69865952 val_loss 206933.24218750\n",
      "epoch 6144 train_loss 10978114.69856255 val_loss 206933.24218750\n",
      "epoch 6145 train_loss 10978114.69857162 val_loss 206933.24218750\n",
      "epoch 6146 train_loss 10978114.69847336 val_loss 206933.24218750\n",
      "epoch 6147 train_loss 10978114.69834839 val_loss 206933.24218750\n",
      "epoch 6148 train_loss 10978114.69826714 val_loss 206933.24218750\n",
      "epoch 6149 train_loss 10978114.69817772 val_loss 206933.24218750\n",
      "epoch 6150 train_loss 10978114.69809586 val_loss 206933.24218750\n",
      "epoch 6151 train_loss 10978114.69799454 val_loss 206933.24218750\n",
      "epoch 6152 train_loss 10978114.69789131 val_loss 206933.24218750\n",
      "epoch 6153 train_loss 10978114.69783890 val_loss 206933.24218750\n",
      "epoch 6154 train_loss 10978114.69776779 val_loss 206933.24218750\n",
      "epoch 6155 train_loss 10978114.69768791 val_loss 206933.24218750\n",
      "epoch 6156 train_loss 10978114.69759377 val_loss 206933.24218750\n",
      "epoch 6157 train_loss 10978114.69750511 val_loss 206933.24218750\n",
      "epoch 6158 train_loss 10978114.69740395 val_loss 206933.24218750\n",
      "epoch 6159 train_loss 10978114.69732017 val_loss 206933.24218750\n",
      "epoch 6160 train_loss 10978114.69731071 val_loss 206933.24218750\n",
      "epoch 6161 train_loss 10978114.69723343 val_loss 206933.24218750\n",
      "epoch 6162 train_loss 10978114.69713783 val_loss 206933.24218750\n",
      "epoch 6163 train_loss 10978114.69704292 val_loss 206933.24218750\n",
      "epoch 6164 train_loss 10978114.69695801 val_loss 206933.24218750\n",
      "epoch 6165 train_loss 10978114.69685226 val_loss 206933.24218750\n",
      "epoch 6166 train_loss 10978114.69676285 val_loss 206933.24218750\n",
      "epoch 6167 train_loss 10978114.69667259 val_loss 206933.24218750\n",
      "epoch 6168 train_loss 10978114.69659309 val_loss 206933.24218750\n",
      "epoch 6169 train_loss 10978114.69648384 val_loss 206933.24218750\n",
      "epoch 6170 train_loss 10978114.69640099 val_loss 206933.24218750\n",
      "epoch 6171 train_loss 10978114.69630569 val_loss 206933.24218750\n",
      "epoch 6172 train_loss 10978114.69621361 val_loss 206933.24218750\n",
      "epoch 6173 train_loss 10978114.69613709 val_loss 206933.24218750\n",
      "epoch 6174 train_loss 10978114.69603981 val_loss 206933.24218750\n",
      "epoch 6175 train_loss 10978114.69594170 val_loss 206933.24218750\n",
      "epoch 6176 train_loss 10978114.69584633 val_loss 206933.24218750\n",
      "epoch 6177 train_loss 10978114.69573990 val_loss 206933.24218750\n",
      "epoch 6178 train_loss 10978114.69566139 val_loss 206933.24218750\n",
      "epoch 6179 train_loss 10978114.69557167 val_loss 206933.24218750\n",
      "epoch 6180 train_loss 10978114.69547989 val_loss 206933.24218750\n",
      "epoch 6181 train_loss 10978114.69538834 val_loss 206933.24218750\n",
      "epoch 6182 train_loss 10978114.69530083 val_loss 206933.24218750\n",
      "epoch 6183 train_loss 10978114.69519852 val_loss 206933.24218750\n",
      "epoch 6184 train_loss 10978114.69510200 val_loss 206933.24218750\n",
      "epoch 6185 train_loss 10978114.69501198 val_loss 206933.24218750\n",
      "epoch 6186 train_loss 10978114.69490334 val_loss 206933.24218750\n",
      "epoch 6187 train_loss 10978114.69483940 val_loss 206933.24218750\n",
      "epoch 6188 train_loss 10978114.69476517 val_loss 206933.24218750\n",
      "epoch 6189 train_loss 10978114.69467209 val_loss 206933.24218750\n",
      "epoch 6190 train_loss 10978114.69461494 val_loss 206933.24218750\n",
      "epoch 6191 train_loss 10978114.69453354 val_loss 206933.24218750\n",
      "epoch 6192 train_loss 10978114.69442879 val_loss 206933.24218750\n",
      "epoch 6193 train_loss 10978114.69435066 val_loss 206933.24218750\n",
      "epoch 6194 train_loss 10978114.69427818 val_loss 206933.24218750\n",
      "epoch 6195 train_loss 10978114.69417244 val_loss 206933.24218750\n",
      "epoch 6196 train_loss 10978114.69408791 val_loss 206933.24218750\n",
      "epoch 6197 train_loss 10978114.69397102 val_loss 206933.24218750\n",
      "epoch 6198 train_loss 10978114.69388481 val_loss 206933.24218750\n",
      "epoch 6199 train_loss 10978114.69377899 val_loss 206933.24218750\n",
      "epoch 6200 train_loss 10978114.69374420 val_loss 206933.24218750\n",
      "epoch 6201 train_loss 10978114.69364891 val_loss 206933.24218750\n",
      "epoch 6202 train_loss 10978114.69359070 val_loss 206933.24218750\n",
      "epoch 6203 train_loss 10978114.69349716 val_loss 206933.24218750\n",
      "epoch 6204 train_loss 10978114.69342323 val_loss 206933.24218750\n",
      "epoch 6205 train_loss 10978114.69333557 val_loss 206933.24218750\n",
      "epoch 6206 train_loss 10978114.69325470 val_loss 206933.24218750\n",
      "epoch 6207 train_loss 10978114.69316681 val_loss 206933.24218750\n",
      "epoch 6208 train_loss 10978114.69306419 val_loss 206933.24218750\n",
      "epoch 6209 train_loss 10978114.69300118 val_loss 206933.24218750\n",
      "epoch 6210 train_loss 10978114.69290482 val_loss 206933.24218750\n",
      "epoch 6211 train_loss 10978114.69284103 val_loss 206933.24218750\n",
      "epoch 6212 train_loss 10978114.69274834 val_loss 206933.24218750\n",
      "epoch 6213 train_loss 10978114.69264793 val_loss 206933.24218750\n",
      "epoch 6214 train_loss 10978114.69254379 val_loss 206933.24218750\n",
      "epoch 6215 train_loss 10978114.69244331 val_loss 206933.24218750\n",
      "epoch 6216 train_loss 10978114.69235611 val_loss 206933.24218750\n",
      "epoch 6217 train_loss 10978114.69227478 val_loss 206933.24218750\n",
      "epoch 6218 train_loss 10978114.69218330 val_loss 206933.24218750\n",
      "epoch 6219 train_loss 10978114.69208511 val_loss 206933.24218750\n",
      "epoch 6220 train_loss 10978114.69201111 val_loss 206933.24218750\n",
      "epoch 6221 train_loss 10978114.69192520 val_loss 206933.24218750\n",
      "epoch 6222 train_loss 10978114.69184105 val_loss 206933.24218750\n",
      "epoch 6223 train_loss 10978114.69173012 val_loss 206933.24218750\n",
      "epoch 6224 train_loss 10978114.69164520 val_loss 206933.24218750\n",
      "epoch 6225 train_loss 10978114.69154503 val_loss 206933.24218750\n",
      "epoch 6226 train_loss 10978114.69148666 val_loss 206933.24218750\n",
      "epoch 6227 train_loss 10978114.69142342 val_loss 206933.24218750\n",
      "epoch 6228 train_loss 10978114.69130982 val_loss 206933.24218750\n",
      "epoch 6229 train_loss 10978114.69123901 val_loss 206933.24218750\n",
      "epoch 6230 train_loss 10978114.69111969 val_loss 206933.24218750\n",
      "epoch 6231 train_loss 10978114.69106979 val_loss 206933.24218750\n",
      "epoch 6232 train_loss 10978114.69099098 val_loss 206933.24218750\n",
      "epoch 6233 train_loss 10978114.69088554 val_loss 206933.24218750\n",
      "epoch 6234 train_loss 10978114.69079758 val_loss 206933.24218750\n",
      "epoch 6235 train_loss 10978114.69070953 val_loss 206933.24218750\n",
      "epoch 6236 train_loss 10978114.69062141 val_loss 206933.24218750\n",
      "epoch 6237 train_loss 10978114.69055176 val_loss 206933.24218750\n",
      "epoch 6238 train_loss 10978114.69043495 val_loss 206933.24218750\n",
      "epoch 6239 train_loss 10978114.69037018 val_loss 206933.24218750\n",
      "epoch 6240 train_loss 10978114.69026382 val_loss 206933.24218750\n",
      "epoch 6241 train_loss 10978114.69017494 val_loss 206933.24218750\n",
      "epoch 6242 train_loss 10978114.69008141 val_loss 206933.24218750\n",
      "epoch 6243 train_loss 10978114.68999481 val_loss 206933.24218750\n",
      "epoch 6244 train_loss 10978114.68988823 val_loss 206933.24218750\n",
      "epoch 6245 train_loss 10978114.68982338 val_loss 206933.24218750\n",
      "epoch 6246 train_loss 10978114.68972076 val_loss 206933.24218750\n",
      "epoch 6247 train_loss 10978114.68962440 val_loss 206933.24218750\n",
      "epoch 6248 train_loss 10978114.68953346 val_loss 206933.24218750\n",
      "epoch 6249 train_loss 10978114.68948021 val_loss 206933.24218750\n",
      "epoch 6250 train_loss 10978114.68938706 val_loss 206933.24218750\n",
      "epoch 6251 train_loss 10978114.68927795 val_loss 206933.24218750\n",
      "epoch 6252 train_loss 10978114.68919846 val_loss 206933.24218750\n",
      "epoch 6253 train_loss 10978114.68909523 val_loss 206933.24218750\n",
      "epoch 6254 train_loss 10978114.68901306 val_loss 206933.24218750\n",
      "epoch 6255 train_loss 10978114.68887497 val_loss 206933.24218750\n",
      "epoch 6256 train_loss 10978114.68879890 val_loss 206933.24218750\n",
      "epoch 6257 train_loss 10978114.68871727 val_loss 206933.24218750\n",
      "epoch 6258 train_loss 10978114.68861466 val_loss 206933.24218750\n",
      "epoch 6259 train_loss 10978114.68854355 val_loss 206933.24218750\n",
      "epoch 6260 train_loss 10978114.68845360 val_loss 206933.24218750\n",
      "epoch 6261 train_loss 10978114.68835388 val_loss 206933.24218750\n",
      "epoch 6262 train_loss 10978114.68826828 val_loss 206933.24218750\n",
      "epoch 6263 train_loss 10978114.68817711 val_loss 206933.24218750\n",
      "epoch 6264 train_loss 10978114.68808632 val_loss 206933.24218750\n",
      "epoch 6265 train_loss 10978114.68799744 val_loss 206933.24218750\n",
      "epoch 6266 train_loss 10978114.68789268 val_loss 206933.24218750\n",
      "epoch 6267 train_loss 10978114.68780579 val_loss 206933.24218750\n",
      "epoch 6268 train_loss 10978114.68773666 val_loss 206933.24218750\n",
      "epoch 6269 train_loss 10978114.68769577 val_loss 206933.24218750\n",
      "epoch 6270 train_loss 10978114.68760872 val_loss 206933.24218750\n",
      "epoch 6271 train_loss 10978114.68752708 val_loss 206933.24218750\n",
      "epoch 6272 train_loss 10978114.68743378 val_loss 206933.24218750\n",
      "epoch 6273 train_loss 10978114.68734093 val_loss 206933.24218750\n",
      "epoch 6274 train_loss 10978114.68723938 val_loss 206933.24218750\n",
      "epoch 6275 train_loss 10978114.68714302 val_loss 206933.24218750\n",
      "epoch 6276 train_loss 10978114.68704887 val_loss 206933.24218750\n",
      "epoch 6277 train_loss 10978114.68696205 val_loss 206933.24218750\n",
      "epoch 6278 train_loss 10978114.68687332 val_loss 206933.24218750\n",
      "epoch 6279 train_loss 10978114.68678307 val_loss 206933.24218750\n",
      "epoch 6280 train_loss 10978114.68669998 val_loss 206933.24218750\n",
      "epoch 6281 train_loss 10978114.68663917 val_loss 206933.24218750\n",
      "epoch 6282 train_loss 10978114.68657570 val_loss 206933.24218750\n",
      "epoch 6283 train_loss 10978114.68645965 val_loss 206933.24218750\n",
      "epoch 6284 train_loss 10978114.68639030 val_loss 206933.24218750\n",
      "epoch 6285 train_loss 10978114.68629143 val_loss 206933.24218750\n",
      "epoch 6286 train_loss 10978114.68620308 val_loss 206933.24218750\n",
      "epoch 6287 train_loss 10978114.68610916 val_loss 206933.24218750\n",
      "epoch 6288 train_loss 10978114.68601326 val_loss 206933.24218750\n",
      "epoch 6289 train_loss 10978114.68599808 val_loss 206933.24218750\n",
      "epoch 6290 train_loss 10978114.68591019 val_loss 206933.24218750\n",
      "epoch 6291 train_loss 10978114.68581825 val_loss 206933.24218750\n",
      "epoch 6292 train_loss 10978114.68571083 val_loss 206933.24218750\n",
      "epoch 6293 train_loss 10978114.68561760 val_loss 206933.24218750\n",
      "epoch 6294 train_loss 10978114.68552116 val_loss 206933.24218750\n",
      "epoch 6295 train_loss 10978114.68546539 val_loss 206933.24218750\n",
      "epoch 6296 train_loss 10978114.68539314 val_loss 206933.24218750\n",
      "epoch 6297 train_loss 10978114.68527290 val_loss 206933.24218750\n",
      "epoch 6298 train_loss 10978114.68521866 val_loss 206933.24218750\n",
      "epoch 6299 train_loss 10978114.68513061 val_loss 206933.24218750\n",
      "epoch 6300 train_loss 10978114.68504082 val_loss 206933.24218750\n",
      "epoch 6301 train_loss 10978114.68495033 val_loss 206933.24218750\n",
      "epoch 6302 train_loss 10978114.68490707 val_loss 206933.24218750\n",
      "epoch 6303 train_loss 10978114.68482330 val_loss 206933.24218750\n",
      "epoch 6304 train_loss 10978114.68478004 val_loss 206933.24218750\n",
      "epoch 6305 train_loss 10978114.68465446 val_loss 206933.24218750\n",
      "epoch 6306 train_loss 10978114.68458679 val_loss 206933.24218750\n",
      "epoch 6307 train_loss 10978114.68450279 val_loss 206933.24218750\n",
      "epoch 6308 train_loss 10978114.68440193 val_loss 206933.24218750\n",
      "epoch 6309 train_loss 10978114.68431061 val_loss 206933.24218750\n",
      "epoch 6310 train_loss 10978114.68422081 val_loss 206933.24218750\n",
      "epoch 6311 train_loss 10978114.68413056 val_loss 206933.24218750\n",
      "epoch 6312 train_loss 10978114.68407158 val_loss 206933.24218750\n",
      "epoch 6313 train_loss 10978114.68398285 val_loss 206933.24218750\n",
      "epoch 6314 train_loss 10978114.68387955 val_loss 206933.24218750\n",
      "epoch 6315 train_loss 10978114.68378136 val_loss 206933.24218750\n",
      "epoch 6316 train_loss 10978114.68369865 val_loss 206933.24218750\n",
      "epoch 6317 train_loss 10978114.68361649 val_loss 206933.24218750\n",
      "epoch 6318 train_loss 10978114.68352211 val_loss 206933.24218750\n",
      "epoch 6319 train_loss 10978114.68342262 val_loss 206933.24218750\n",
      "epoch 6320 train_loss 10978114.68333901 val_loss 206933.24218750\n",
      "epoch 6321 train_loss 10978114.68324143 val_loss 206933.24218750\n",
      "epoch 6322 train_loss 10978114.68316017 val_loss 206933.24218750\n",
      "epoch 6323 train_loss 10978114.68306389 val_loss 206933.24218750\n",
      "epoch 6324 train_loss 10978114.68298172 val_loss 206933.24218750\n",
      "epoch 6325 train_loss 10978114.68288315 val_loss 206933.24218750\n",
      "epoch 6326 train_loss 10978114.68280937 val_loss 206933.24218750\n",
      "epoch 6327 train_loss 10978114.68271225 val_loss 206933.24218750\n",
      "epoch 6328 train_loss 10978114.68262779 val_loss 206933.24218750\n",
      "epoch 6329 train_loss 10978114.68254646 val_loss 206933.24218750\n",
      "epoch 6330 train_loss 10978114.68243202 val_loss 206933.24218750\n",
      "epoch 6331 train_loss 10978114.68235168 val_loss 206933.24218750\n",
      "epoch 6332 train_loss 10978114.68225708 val_loss 206933.24218750\n",
      "epoch 6333 train_loss 10978114.68215027 val_loss 206933.24218750\n",
      "epoch 6334 train_loss 10978114.68205055 val_loss 206933.24218750\n",
      "epoch 6335 train_loss 10978114.68196365 val_loss 206933.24218750\n",
      "epoch 6336 train_loss 10978114.68188530 val_loss 206933.24218750\n",
      "epoch 6337 train_loss 10978114.68181107 val_loss 206933.24218750\n",
      "epoch 6338 train_loss 10978114.68171539 val_loss 206933.24218750\n",
      "epoch 6339 train_loss 10978114.68166023 val_loss 206933.24218750\n",
      "epoch 6340 train_loss 10978114.68156662 val_loss 206933.24218750\n",
      "epoch 6341 train_loss 10978114.68145989 val_loss 206933.24218750\n",
      "epoch 6342 train_loss 10978114.68137802 val_loss 206933.24218750\n",
      "epoch 6343 train_loss 10978114.68132011 val_loss 206933.24218750\n",
      "epoch 6344 train_loss 10978114.68120903 val_loss 206933.24218750\n",
      "epoch 6345 train_loss 10978114.68111343 val_loss 206933.24218750\n",
      "epoch 6346 train_loss 10978114.68102966 val_loss 206933.24218750\n",
      "epoch 6347 train_loss 10978114.68097160 val_loss 206933.24218750\n",
      "epoch 6348 train_loss 10978114.68091087 val_loss 206933.24218750\n",
      "epoch 6349 train_loss 10978114.68080017 val_loss 206933.24218750\n",
      "epoch 6350 train_loss 10978114.68072441 val_loss 206933.24218750\n",
      "epoch 6351 train_loss 10978114.68063065 val_loss 206933.24218750\n",
      "epoch 6352 train_loss 10978114.68051010 val_loss 206933.24218750\n",
      "epoch 6353 train_loss 10978114.68042526 val_loss 206933.24218750\n",
      "epoch 6354 train_loss 10978114.68032875 val_loss 206933.24218750\n",
      "epoch 6355 train_loss 10978114.68023705 val_loss 206933.24218750\n",
      "epoch 6356 train_loss 10978114.68014297 val_loss 206933.24218750\n",
      "epoch 6357 train_loss 10978114.68007149 val_loss 206933.24218750\n",
      "epoch 6358 train_loss 10978114.67996460 val_loss 206933.24218750\n",
      "epoch 6359 train_loss 10978114.67987450 val_loss 206933.24218750\n",
      "epoch 6360 train_loss 10978114.67978951 val_loss 206933.24218750\n",
      "epoch 6361 train_loss 10978114.67970993 val_loss 206933.24218750\n",
      "epoch 6362 train_loss 10978114.67959007 val_loss 206933.24218750\n",
      "epoch 6363 train_loss 10978114.67951393 val_loss 206933.24218750\n",
      "epoch 6364 train_loss 10978114.67944428 val_loss 206933.24218750\n",
      "epoch 6365 train_loss 10978114.67935547 val_loss 206933.24218750\n",
      "epoch 6366 train_loss 10978114.67926002 val_loss 206933.24218750\n",
      "epoch 6367 train_loss 10978114.67915321 val_loss 206933.24218750\n",
      "epoch 6368 train_loss 10978114.67908554 val_loss 206933.24218750\n",
      "epoch 6369 train_loss 10978114.67897514 val_loss 206933.24218750\n",
      "epoch 6370 train_loss 10978114.67888756 val_loss 206933.24218750\n",
      "epoch 6371 train_loss 10978114.67878319 val_loss 206933.24218750\n",
      "epoch 6372 train_loss 10978114.67866859 val_loss 206933.24218750\n",
      "epoch 6373 train_loss 10978114.67859901 val_loss 206933.24218750\n",
      "epoch 6374 train_loss 10978114.67852547 val_loss 206933.24218750\n",
      "epoch 6375 train_loss 10978114.67843491 val_loss 206933.24218750\n",
      "epoch 6376 train_loss 10978114.67832932 val_loss 206933.24218750\n",
      "epoch 6377 train_loss 10978114.67822746 val_loss 206933.24218750\n",
      "epoch 6378 train_loss 10978114.67814995 val_loss 206933.24218750\n",
      "epoch 6379 train_loss 10978114.67803062 val_loss 206933.24218750\n",
      "epoch 6380 train_loss 10978114.67793694 val_loss 206933.24218750\n",
      "epoch 6381 train_loss 10978114.67787018 val_loss 206933.24218750\n",
      "epoch 6382 train_loss 10978114.67783005 val_loss 206933.24218750\n",
      "epoch 6383 train_loss 10978114.67773850 val_loss 206933.24218750\n",
      "epoch 6384 train_loss 10978114.67765373 val_loss 206933.24218750\n",
      "epoch 6385 train_loss 10978114.67756172 val_loss 206933.24218750\n",
      "epoch 6386 train_loss 10978114.67748444 val_loss 206933.24218750\n",
      "epoch 6387 train_loss 10978114.67738617 val_loss 206933.24218750\n",
      "epoch 6388 train_loss 10978114.67729179 val_loss 206933.24218750\n",
      "epoch 6389 train_loss 10978114.67719658 val_loss 206933.24218750\n",
      "epoch 6390 train_loss 10978114.67709465 val_loss 206933.24218750\n",
      "epoch 6391 train_loss 10978114.67699265 val_loss 206933.24218750\n",
      "epoch 6392 train_loss 10978114.67692223 val_loss 206933.24218750\n",
      "epoch 6393 train_loss 10978114.67683228 val_loss 206933.24218750\n",
      "epoch 6394 train_loss 10978114.67672974 val_loss 206933.24218750\n",
      "epoch 6395 train_loss 10978114.67664444 val_loss 206933.24218750\n",
      "epoch 6396 train_loss 10978114.67654961 val_loss 206933.24218750\n",
      "epoch 6397 train_loss 10978114.67644516 val_loss 206933.24218750\n",
      "epoch 6398 train_loss 10978114.67637222 val_loss 206933.24218750\n",
      "epoch 6399 train_loss 10978114.67631660 val_loss 206933.24218750\n",
      "epoch 6400 train_loss 10978114.67622086 val_loss 206933.24218750\n",
      "epoch 6401 train_loss 10978114.67612419 val_loss 206933.24218750\n",
      "epoch 6402 train_loss 10978114.67601753 val_loss 206933.24218750\n",
      "epoch 6403 train_loss 10978114.67593842 val_loss 206933.24218750\n",
      "epoch 6404 train_loss 10978114.67584572 val_loss 206933.24218750\n",
      "epoch 6405 train_loss 10978114.67577278 val_loss 206933.24218750\n",
      "epoch 6406 train_loss 10978114.67572434 val_loss 206933.24218750\n",
      "epoch 6407 train_loss 10978114.67564247 val_loss 206933.24218750\n",
      "epoch 6408 train_loss 10978114.67553947 val_loss 206933.24218750\n",
      "epoch 6409 train_loss 10978114.67545113 val_loss 206933.24218750\n",
      "epoch 6410 train_loss 10978114.67537544 val_loss 206933.24218750\n",
      "epoch 6411 train_loss 10978114.67530678 val_loss 206933.24218750\n",
      "epoch 6412 train_loss 10978114.67522560 val_loss 206933.24218750\n",
      "epoch 6413 train_loss 10978114.67514298 val_loss 206933.24218750\n",
      "epoch 6414 train_loss 10978114.67504662 val_loss 206933.24218750\n",
      "epoch 6415 train_loss 10978114.67494835 val_loss 206933.24218750\n",
      "epoch 6416 train_loss 10978114.67485397 val_loss 206933.24218750\n",
      "epoch 6417 train_loss 10978114.67476540 val_loss 206933.24218750\n",
      "epoch 6418 train_loss 10978114.67466118 val_loss 206933.24218750\n",
      "epoch 6419 train_loss 10978114.67454353 val_loss 206933.24218750\n",
      "epoch 6420 train_loss 10978114.67446945 val_loss 206933.24218750\n",
      "epoch 6421 train_loss 10978114.67438728 val_loss 206933.24218750\n",
      "epoch 6422 train_loss 10978114.67428665 val_loss 206933.24218750\n",
      "epoch 6423 train_loss 10978114.67419640 val_loss 206933.24218750\n",
      "epoch 6424 train_loss 10978114.67410049 val_loss 206933.24218750\n",
      "epoch 6425 train_loss 10978114.67401779 val_loss 206933.24218750\n",
      "epoch 6426 train_loss 10978114.67391991 val_loss 206933.24218750\n",
      "epoch 6427 train_loss 10978114.67382370 val_loss 206933.24218750\n",
      "epoch 6428 train_loss 10978114.67372665 val_loss 206933.24218750\n",
      "epoch 6429 train_loss 10978114.67367668 val_loss 206933.24218750\n",
      "epoch 6430 train_loss 10978114.67357628 val_loss 206933.24218750\n",
      "epoch 6431 train_loss 10978114.67347656 val_loss 206933.24218750\n",
      "epoch 6432 train_loss 10978114.67337097 val_loss 206933.24218750\n",
      "epoch 6433 train_loss 10978114.67327995 val_loss 206933.24218750\n",
      "epoch 6434 train_loss 10978114.67320328 val_loss 206933.24218750\n",
      "epoch 6435 train_loss 10978114.67313080 val_loss 206933.24218750\n",
      "epoch 6436 train_loss 10978114.67304085 val_loss 206933.24218750\n",
      "epoch 6437 train_loss 10978114.67292671 val_loss 206933.24218750\n",
      "epoch 6438 train_loss 10978114.67284042 val_loss 206933.24218750\n",
      "epoch 6439 train_loss 10978114.67274902 val_loss 206933.24218750\n",
      "epoch 6440 train_loss 10978114.67265541 val_loss 206933.24218750\n",
      "epoch 6441 train_loss 10978114.67255157 val_loss 206933.24218750\n",
      "epoch 6442 train_loss 10978114.67245430 val_loss 206933.24218750\n",
      "epoch 6443 train_loss 10978114.67237549 val_loss 206933.24218750\n",
      "epoch 6444 train_loss 10978114.67227242 val_loss 206933.24218750\n",
      "epoch 6445 train_loss 10978114.67218941 val_loss 206933.24218750\n",
      "epoch 6446 train_loss 10978114.67215782 val_loss 206933.24218750\n",
      "epoch 6447 train_loss 10978114.67208305 val_loss 206933.24218750\n",
      "epoch 6448 train_loss 10978114.67199173 val_loss 206933.24218750\n",
      "epoch 6449 train_loss 10978114.67189995 val_loss 206933.24218750\n",
      "epoch 6450 train_loss 10978114.67180130 val_loss 206933.24218750\n",
      "epoch 6451 train_loss 10978114.67169975 val_loss 206933.24218750\n",
      "epoch 6452 train_loss 10978114.67165016 val_loss 206933.24218750\n",
      "epoch 6453 train_loss 10978114.67155846 val_loss 206933.24218750\n",
      "epoch 6454 train_loss 10978114.67147537 val_loss 206933.24218750\n",
      "epoch 6455 train_loss 10978114.67139183 val_loss 206933.24218750\n",
      "epoch 6456 train_loss 10978114.67128593 val_loss 206933.24218750\n",
      "epoch 6457 train_loss 10978114.67120270 val_loss 206933.24218750\n",
      "epoch 6458 train_loss 10978114.67110252 val_loss 206933.24218750\n",
      "epoch 6459 train_loss 10978114.67103455 val_loss 206933.24218750\n",
      "epoch 6460 train_loss 10978114.67094818 val_loss 206933.24218750\n",
      "epoch 6461 train_loss 10978114.67089203 val_loss 206933.24218750\n",
      "epoch 6462 train_loss 10978114.67078087 val_loss 206933.24218750\n",
      "epoch 6463 train_loss 10978114.67068924 val_loss 206933.24218750\n",
      "epoch 6464 train_loss 10978114.67061127 val_loss 206933.24218750\n",
      "epoch 6465 train_loss 10978114.67050659 val_loss 206933.24218750\n",
      "epoch 6466 train_loss 10978114.67044411 val_loss 206933.24218750\n",
      "epoch 6467 train_loss 10978114.67035126 val_loss 206933.24218750\n",
      "epoch 6468 train_loss 10978114.67026566 val_loss 206933.24218750\n",
      "epoch 6469 train_loss 10978114.67021256 val_loss 206933.24218750\n",
      "epoch 6470 train_loss 10978114.67011910 val_loss 206933.24218750\n",
      "epoch 6471 train_loss 10978114.67005386 val_loss 206933.24218750\n",
      "epoch 6472 train_loss 10978114.66994392 val_loss 206933.24218750\n",
      "epoch 6473 train_loss 10978114.66987061 val_loss 206933.24218750\n",
      "epoch 6474 train_loss 10978114.67008652 val_loss 206933.24218750\n",
      "epoch 6475 train_loss 10978114.66998932 val_loss 206933.24218750\n",
      "epoch 6476 train_loss 10978114.66989967 val_loss 206933.24218750\n",
      "epoch 6477 train_loss 10978114.66981285 val_loss 206933.24218750\n",
      "epoch 6478 train_loss 10978114.66971474 val_loss 206933.24218750\n",
      "epoch 6479 train_loss 10978114.66963059 val_loss 206933.24218750\n",
      "epoch 6480 train_loss 10978114.66954597 val_loss 206933.24218750\n",
      "epoch 6481 train_loss 10978114.66945648 val_loss 206933.24218750\n",
      "epoch 6482 train_loss 10978114.66937126 val_loss 206933.24218750\n",
      "epoch 6483 train_loss 10978114.66925644 val_loss 206933.24218750\n",
      "epoch 6484 train_loss 10978114.66918129 val_loss 206933.24218750\n",
      "epoch 6485 train_loss 10978114.66909470 val_loss 206933.24218750\n",
      "epoch 6486 train_loss 10978114.66899498 val_loss 206933.24218750\n",
      "epoch 6487 train_loss 10978114.66889519 val_loss 206933.24218750\n",
      "epoch 6488 train_loss 10978114.66886284 val_loss 206933.24218750\n",
      "epoch 6489 train_loss 10978114.66877907 val_loss 206933.24218750\n",
      "epoch 6490 train_loss 10978114.66866882 val_loss 206933.24218750\n",
      "epoch 6491 train_loss 10978114.66857284 val_loss 206933.24218750\n",
      "epoch 6492 train_loss 10978114.66846916 val_loss 206933.24218750\n",
      "epoch 6493 train_loss 10978114.66839745 val_loss 206933.24218750\n",
      "epoch 6494 train_loss 10978114.66831291 val_loss 206933.24218750\n",
      "epoch 6495 train_loss 10978114.66821625 val_loss 206933.24218750\n",
      "epoch 6496 train_loss 10978114.66817238 val_loss 206933.24218750\n",
      "epoch 6497 train_loss 10978114.66808182 val_loss 206933.24218750\n",
      "epoch 6498 train_loss 10978114.66798813 val_loss 206933.24218750\n",
      "epoch 6499 train_loss 10978114.66789421 val_loss 206933.24218750\n",
      "epoch 6500 train_loss 10978114.66782005 val_loss 206933.24218750\n",
      "epoch 6501 train_loss 10978114.66771858 val_loss 206933.24218750\n",
      "epoch 6502 train_loss 10978114.66762649 val_loss 206933.24218750\n",
      "epoch 6503 train_loss 10978114.66751381 val_loss 206933.24218750\n",
      "epoch 6504 train_loss 10978114.66742668 val_loss 206933.24218750\n",
      "epoch 6505 train_loss 10978114.66734726 val_loss 206933.24218750\n",
      "epoch 6506 train_loss 10978114.66726707 val_loss 206933.24218750\n",
      "epoch 6507 train_loss 10978114.66718658 val_loss 206933.24218750\n",
      "epoch 6508 train_loss 10978114.66707596 val_loss 206933.24218750\n",
      "epoch 6509 train_loss 10978114.66699524 val_loss 206933.24218750\n",
      "epoch 6510 train_loss 10978114.66689903 val_loss 206933.24218750\n",
      "epoch 6511 train_loss 10978114.66678780 val_loss 206933.24218750\n",
      "epoch 6512 train_loss 10978114.66672775 val_loss 206933.24218750\n",
      "epoch 6513 train_loss 10978114.66663887 val_loss 206933.24218750\n",
      "epoch 6514 train_loss 10978114.66655037 val_loss 206933.24218750\n",
      "epoch 6515 train_loss 10978114.66643990 val_loss 206933.24218750\n",
      "epoch 6516 train_loss 10978114.66635162 val_loss 206933.24218750\n",
      "epoch 6517 train_loss 10978114.66625290 val_loss 206933.24218750\n",
      "epoch 6518 train_loss 10978114.66617577 val_loss 206933.24218750\n",
      "epoch 6519 train_loss 10978114.66607017 val_loss 206933.24218750\n",
      "epoch 6520 train_loss 10978114.66598389 val_loss 206933.24218750\n",
      "epoch 6521 train_loss 10978114.66590309 val_loss 206933.24218750\n",
      "epoch 6522 train_loss 10978114.66581711 val_loss 206933.24218750\n",
      "epoch 6523 train_loss 10978114.66573822 val_loss 206933.24218750\n",
      "epoch 6524 train_loss 10978114.66565613 val_loss 206933.24218750\n",
      "epoch 6525 train_loss 10978114.66559952 val_loss 206933.24218750\n",
      "epoch 6526 train_loss 10978114.66550377 val_loss 206933.24218750\n",
      "epoch 6527 train_loss 10978114.66541473 val_loss 206933.24218750\n",
      "epoch 6528 train_loss 10978114.66535683 val_loss 206933.24218750\n",
      "epoch 6529 train_loss 10978114.66525536 val_loss 206933.24218750\n",
      "epoch 6530 train_loss 10978114.66516762 val_loss 206933.24218750\n",
      "epoch 6531 train_loss 10978114.66508003 val_loss 206933.24218750\n",
      "epoch 6532 train_loss 10978114.66499069 val_loss 206933.24218750\n",
      "epoch 6533 train_loss 10978114.66489250 val_loss 206933.24218750\n",
      "epoch 6534 train_loss 10978114.66479866 val_loss 206933.24218750\n",
      "epoch 6535 train_loss 10978114.66472153 val_loss 206933.24218750\n",
      "epoch 6536 train_loss 10978114.66464134 val_loss 206933.24218750\n",
      "epoch 6537 train_loss 10978114.66453300 val_loss 206933.24218750\n",
      "epoch 6538 train_loss 10978114.66444832 val_loss 206933.24218750\n",
      "epoch 6539 train_loss 10978114.66434929 val_loss 206933.24218750\n",
      "epoch 6540 train_loss 10978114.66426163 val_loss 206933.24218750\n",
      "epoch 6541 train_loss 10978114.66417183 val_loss 206933.24218750\n",
      "epoch 6542 train_loss 10978114.66407165 val_loss 206933.24218750\n",
      "epoch 6543 train_loss 10978114.66398270 val_loss 206933.24218750\n",
      "epoch 6544 train_loss 10978114.66388359 val_loss 206933.24218750\n",
      "epoch 6545 train_loss 10978114.66378319 val_loss 206933.24218750\n",
      "epoch 6546 train_loss 10978114.66371971 val_loss 206933.24218750\n",
      "epoch 6547 train_loss 10978114.66364403 val_loss 206933.24218750\n",
      "epoch 6548 train_loss 10978114.66353127 val_loss 206933.24218750\n",
      "epoch 6549 train_loss 10978114.66346893 val_loss 206933.24218750\n",
      "epoch 6550 train_loss 10978114.66337845 val_loss 206933.24218750\n",
      "epoch 6551 train_loss 10978114.66327934 val_loss 206933.24218750\n",
      "epoch 6552 train_loss 10978114.66318298 val_loss 206933.24218750\n",
      "epoch 6553 train_loss 10978114.66309311 val_loss 206933.24218750\n",
      "epoch 6554 train_loss 10978114.66298744 val_loss 206933.24218750\n",
      "epoch 6555 train_loss 10978114.66289619 val_loss 206933.24218750\n",
      "epoch 6556 train_loss 10978114.66280907 val_loss 206933.24218750\n",
      "epoch 6557 train_loss 10978114.66271332 val_loss 206933.24218750\n",
      "epoch 6558 train_loss 10978114.66260712 val_loss 206933.24218750\n",
      "epoch 6559 train_loss 10978114.66251289 val_loss 206933.24218750\n",
      "epoch 6560 train_loss 10978114.66242043 val_loss 206933.24218750\n",
      "epoch 6561 train_loss 10978114.66232407 val_loss 206933.24218750\n",
      "epoch 6562 train_loss 10978114.66225708 val_loss 206933.24218750\n",
      "epoch 6563 train_loss 10978114.66221413 val_loss 206933.24218750\n",
      "epoch 6564 train_loss 10978114.66213341 val_loss 206933.24218750\n",
      "epoch 6565 train_loss 10978114.66202347 val_loss 206933.24218750\n",
      "epoch 6566 train_loss 10978114.66193977 val_loss 206933.24218750\n",
      "epoch 6567 train_loss 10978114.66183250 val_loss 206933.24218750\n",
      "epoch 6568 train_loss 10978114.66174469 val_loss 206933.24218750\n",
      "epoch 6569 train_loss 10978114.66162971 val_loss 206933.24218750\n",
      "epoch 6570 train_loss 10978114.66155312 val_loss 206933.24218750\n",
      "epoch 6571 train_loss 10978114.66144615 val_loss 206933.24218750\n",
      "epoch 6572 train_loss 10978114.66135178 val_loss 206933.24218750\n",
      "epoch 6573 train_loss 10978114.66125984 val_loss 206933.24218750\n",
      "epoch 6574 train_loss 10978114.66117836 val_loss 206933.24218750\n",
      "epoch 6575 train_loss 10978114.66107933 val_loss 206933.24218750\n",
      "epoch 6576 train_loss 10978114.66098595 val_loss 206933.24218750\n",
      "epoch 6577 train_loss 10978114.66092896 val_loss 206933.24218750\n",
      "epoch 6578 train_loss 10978114.66085381 val_loss 206933.24218750\n",
      "epoch 6579 train_loss 10978114.66076431 val_loss 206933.24218750\n",
      "epoch 6580 train_loss 10978114.66067444 val_loss 206933.24218750\n",
      "epoch 6581 train_loss 10978114.66057136 val_loss 206933.24218750\n",
      "epoch 6582 train_loss 10978114.66047790 val_loss 206933.24218750\n",
      "epoch 6583 train_loss 10978114.66037796 val_loss 206933.24218750\n",
      "epoch 6584 train_loss 10978114.66027702 val_loss 206933.24218750\n",
      "epoch 6585 train_loss 10978114.66020218 val_loss 206933.24218750\n",
      "epoch 6586 train_loss 10978114.66015907 val_loss 206933.24218750\n",
      "epoch 6587 train_loss 10978114.66004562 val_loss 206933.24218750\n",
      "epoch 6588 train_loss 10978114.65996452 val_loss 206933.24218750\n",
      "epoch 6589 train_loss 10978114.65989036 val_loss 206933.24218750\n",
      "epoch 6590 train_loss 10978114.65978966 val_loss 206933.24218750\n",
      "epoch 6591 train_loss 10978114.65970512 val_loss 206933.24218750\n",
      "epoch 6592 train_loss 10978114.65961082 val_loss 206933.24218750\n",
      "epoch 6593 train_loss 10978114.65953552 val_loss 206933.24218750\n",
      "epoch 6594 train_loss 10978114.65942360 val_loss 206933.24218750\n",
      "epoch 6595 train_loss 10978114.65932915 val_loss 206933.24218750\n",
      "epoch 6596 train_loss 10978114.65923195 val_loss 206933.24218750\n",
      "epoch 6597 train_loss 10978114.65913620 val_loss 206933.24218750\n",
      "epoch 6598 train_loss 10978114.65907127 val_loss 206933.24218750\n",
      "epoch 6599 train_loss 10978114.65898598 val_loss 206933.24218750\n",
      "epoch 6600 train_loss 10978114.65889000 val_loss 206933.24218750\n",
      "epoch 6601 train_loss 10978114.65878311 val_loss 206933.24218750\n",
      "epoch 6602 train_loss 10978114.65870644 val_loss 206933.24218750\n",
      "epoch 6603 train_loss 10978114.65866173 val_loss 206933.24218750\n",
      "epoch 6604 train_loss 10978114.65855972 val_loss 206933.24218750\n",
      "epoch 6605 train_loss 10978114.65848160 val_loss 206933.24218750\n",
      "epoch 6606 train_loss 10978114.65840370 val_loss 206933.24218750\n",
      "epoch 6607 train_loss 10978114.65830795 val_loss 206933.24218750\n",
      "epoch 6608 train_loss 10978114.65820618 val_loss 206933.24218750\n",
      "epoch 6609 train_loss 10978114.65811325 val_loss 206933.24218750\n",
      "epoch 6610 train_loss 10978114.65801674 val_loss 206933.24218750\n",
      "epoch 6611 train_loss 10978114.65792732 val_loss 206933.24218750\n",
      "epoch 6612 train_loss 10978114.65784073 val_loss 206933.24218750\n",
      "epoch 6613 train_loss 10978114.65774918 val_loss 206933.24218750\n",
      "epoch 6614 train_loss 10978114.65765152 val_loss 206933.24218750\n",
      "epoch 6615 train_loss 10978114.65754356 val_loss 206933.24218750\n",
      "epoch 6616 train_loss 10978114.65745926 val_loss 206933.24218750\n",
      "epoch 6617 train_loss 10978114.65736076 val_loss 206933.24218750\n",
      "epoch 6618 train_loss 10978114.65726914 val_loss 206933.24218750\n",
      "epoch 6619 train_loss 10978114.65718445 val_loss 206933.24218750\n",
      "epoch 6620 train_loss 10978114.65710022 val_loss 206933.24218750\n",
      "epoch 6621 train_loss 10978114.65700371 val_loss 206933.24218750\n",
      "epoch 6622 train_loss 10978114.65691444 val_loss 206933.24218750\n",
      "epoch 6623 train_loss 10978114.65682846 val_loss 206933.24218750\n",
      "epoch 6624 train_loss 10978114.65682396 val_loss 206933.24218750\n",
      "epoch 6625 train_loss 10978114.65669716 val_loss 206933.24218750\n",
      "epoch 6626 train_loss 10978114.65660545 val_loss 206933.24218750\n",
      "epoch 6627 train_loss 10978114.65652741 val_loss 206933.24218750\n",
      "epoch 6628 train_loss 10978114.65644692 val_loss 206933.24218750\n",
      "epoch 6629 train_loss 10978114.65634865 val_loss 206933.24218750\n",
      "epoch 6630 train_loss 10978114.65629646 val_loss 206933.24218750\n",
      "epoch 6631 train_loss 10978114.65618446 val_loss 206933.24218750\n",
      "epoch 6632 train_loss 10978114.65611763 val_loss 206933.24218750\n",
      "epoch 6633 train_loss 10978114.65600006 val_loss 206933.24218750\n",
      "epoch 6634 train_loss 10978114.65592606 val_loss 206933.24218750\n",
      "epoch 6635 train_loss 10978114.65582550 val_loss 206933.24218750\n",
      "epoch 6636 train_loss 10978114.65572174 val_loss 206933.24218750\n",
      "epoch 6637 train_loss 10978114.65571282 val_loss 206933.24218750\n",
      "epoch 6638 train_loss 10978114.65563225 val_loss 206933.24218750\n",
      "epoch 6639 train_loss 10978114.65554756 val_loss 206933.24218750\n",
      "epoch 6640 train_loss 10978114.65545494 val_loss 206933.24218750\n",
      "epoch 6641 train_loss 10978114.65534508 val_loss 206933.24218750\n",
      "epoch 6642 train_loss 10978114.65526314 val_loss 206933.24218750\n",
      "epoch 6643 train_loss 10978114.65515541 val_loss 206933.24218750\n",
      "epoch 6644 train_loss 10978114.65505173 val_loss 206933.24218750\n",
      "epoch 6645 train_loss 10978114.65498734 val_loss 206933.24218750\n",
      "epoch 6646 train_loss 10978114.65488808 val_loss 206933.24218750\n",
      "epoch 6647 train_loss 10978114.65480720 val_loss 206933.24218750\n",
      "epoch 6648 train_loss 10978114.65470619 val_loss 206933.24218750\n",
      "epoch 6649 train_loss 10978114.65466568 val_loss 206933.24218750\n",
      "epoch 6650 train_loss 10978114.65455017 val_loss 206933.24218750\n",
      "epoch 6651 train_loss 10978114.65446983 val_loss 206933.24218750\n",
      "epoch 6652 train_loss 10978114.65438194 val_loss 206933.24218750\n",
      "epoch 6653 train_loss 10978114.65428909 val_loss 206933.24218750\n",
      "epoch 6654 train_loss 10978114.65417664 val_loss 206933.24218750\n",
      "epoch 6655 train_loss 10978114.65409004 val_loss 206933.24218750\n",
      "epoch 6656 train_loss 10978114.65399933 val_loss 206933.24218750\n",
      "epoch 6657 train_loss 10978114.65392311 val_loss 206933.24218750\n",
      "epoch 6658 train_loss 10978114.65381157 val_loss 206933.24218750\n",
      "epoch 6659 train_loss 10978114.65372604 val_loss 206933.24218750\n",
      "epoch 6660 train_loss 10978114.65373306 val_loss 206933.24218750\n",
      "epoch 6661 train_loss 10978114.65362709 val_loss 206933.24218750\n",
      "epoch 6662 train_loss 10978114.65355522 val_loss 206933.24218750\n",
      "epoch 6663 train_loss 10978114.65350693 val_loss 206933.24218750\n",
      "epoch 6664 train_loss 10978114.65341766 val_loss 206933.24218750\n",
      "epoch 6665 train_loss 10978114.65333671 val_loss 206933.24218750\n",
      "epoch 6666 train_loss 10978114.65322548 val_loss 206933.24218750\n",
      "epoch 6667 train_loss 10978114.65314362 val_loss 206933.24218750\n",
      "epoch 6668 train_loss 10978114.65303551 val_loss 206933.24218750\n",
      "epoch 6669 train_loss 10978114.65293854 val_loss 206933.24218750\n",
      "epoch 6670 train_loss 10978114.65285339 val_loss 206933.24218750\n",
      "epoch 6671 train_loss 10978114.65277969 val_loss 206933.24218750\n",
      "epoch 6672 train_loss 10978114.65268227 val_loss 206933.24218750\n",
      "epoch 6673 train_loss 10978114.65259064 val_loss 206933.24218750\n",
      "epoch 6674 train_loss 10978114.65250618 val_loss 206933.24218750\n",
      "epoch 6675 train_loss 10978114.65240005 val_loss 206933.24218750\n",
      "epoch 6676 train_loss 10978114.65230644 val_loss 206933.24218750\n",
      "epoch 6677 train_loss 10978114.65221916 val_loss 206933.24218750\n",
      "epoch 6678 train_loss 10978114.65212883 val_loss 206933.24218750\n",
      "epoch 6679 train_loss 10978114.65203316 val_loss 206933.24218750\n",
      "epoch 6680 train_loss 10978114.65192360 val_loss 206933.24218750\n",
      "epoch 6681 train_loss 10978114.65184418 val_loss 206933.24218750\n",
      "epoch 6682 train_loss 10978114.65174530 val_loss 206933.24218750\n",
      "epoch 6683 train_loss 10978114.65165955 val_loss 206933.24218750\n",
      "epoch 6684 train_loss 10978114.65157425 val_loss 206933.24218750\n",
      "epoch 6685 train_loss 10978114.65148064 val_loss 206933.24218750\n",
      "epoch 6686 train_loss 10978114.65142838 val_loss 206933.24218750\n",
      "epoch 6687 train_loss 10978114.65132477 val_loss 206933.24218750\n",
      "epoch 6688 train_loss 10978114.65124245 val_loss 206933.24218750\n",
      "epoch 6689 train_loss 10978114.65113449 val_loss 206933.24218750\n",
      "epoch 6690 train_loss 10978114.65103683 val_loss 206933.24218750\n",
      "epoch 6691 train_loss 10978114.65095886 val_loss 206933.24218750\n",
      "epoch 6692 train_loss 10978114.65086769 val_loss 206933.24218750\n",
      "epoch 6693 train_loss 10978114.65077271 val_loss 206933.24218750\n",
      "epoch 6694 train_loss 10978114.65066200 val_loss 206933.24218750\n",
      "epoch 6695 train_loss 10978114.65058350 val_loss 206933.24218750\n",
      "epoch 6696 train_loss 10978114.65052628 val_loss 206933.24218750\n",
      "epoch 6697 train_loss 10978114.65040665 val_loss 206933.24218750\n",
      "epoch 6698 train_loss 10978114.65031822 val_loss 206933.24218750\n",
      "epoch 6699 train_loss 10978114.65023850 val_loss 206933.24218750\n",
      "epoch 6700 train_loss 10978114.65013580 val_loss 206933.24218750\n",
      "epoch 6701 train_loss 10978114.65005486 val_loss 206933.24218750\n",
      "epoch 6702 train_loss 10978114.64995781 val_loss 206933.24218750\n",
      "epoch 6703 train_loss 10978114.64985535 val_loss 206933.24218750\n",
      "epoch 6704 train_loss 10978114.64977463 val_loss 206933.24218750\n",
      "epoch 6705 train_loss 10978114.64966919 val_loss 206933.24218750\n",
      "epoch 6706 train_loss 10978114.64956963 val_loss 206933.24218750\n",
      "epoch 6707 train_loss 10978114.64946724 val_loss 206933.24218750\n",
      "epoch 6708 train_loss 10978114.64946175 val_loss 206933.24218750\n",
      "epoch 6709 train_loss 10978114.64941254 val_loss 206933.24218750\n",
      "epoch 6710 train_loss 10978114.64938332 val_loss 206933.24218750\n",
      "epoch 6711 train_loss 10978114.64931175 val_loss 206933.24218750\n",
      "epoch 6712 train_loss 10978114.64921410 val_loss 206933.24218750\n",
      "epoch 6713 train_loss 10978114.64912575 val_loss 206933.24218750\n",
      "epoch 6714 train_loss 10978114.64902893 val_loss 206933.24218750\n",
      "epoch 6715 train_loss 10978114.64892151 val_loss 206933.24218750\n",
      "epoch 6716 train_loss 10978114.64883400 val_loss 206933.24218750\n",
      "epoch 6717 train_loss 10978114.64874306 val_loss 206933.24218750\n",
      "epoch 6718 train_loss 10978114.64864578 val_loss 206933.24218750\n",
      "epoch 6719 train_loss 10978114.64854302 val_loss 206933.24218750\n",
      "epoch 6720 train_loss 10978114.64845947 val_loss 206933.24218750\n",
      "epoch 6721 train_loss 10978114.64835030 val_loss 206933.24218750\n",
      "epoch 6722 train_loss 10978114.64827248 val_loss 206933.24218750\n",
      "epoch 6723 train_loss 10978114.64818245 val_loss 206933.24218750\n",
      "epoch 6724 train_loss 10978114.64809776 val_loss 206933.24218750\n",
      "epoch 6725 train_loss 10978114.64800423 val_loss 206933.24218750\n",
      "epoch 6726 train_loss 10978114.64789345 val_loss 206933.24218750\n",
      "epoch 6727 train_loss 10978114.64785728 val_loss 206933.24218750\n",
      "epoch 6728 train_loss 10978114.64777130 val_loss 206933.24218750\n",
      "epoch 6729 train_loss 10978114.64766762 val_loss 206933.24218750\n",
      "epoch 6730 train_loss 10978114.64761536 val_loss 206933.24218750\n",
      "epoch 6731 train_loss 10978114.64754967 val_loss 206933.24218750\n",
      "epoch 6732 train_loss 10978114.64743507 val_loss 206933.24218750\n",
      "epoch 6733 train_loss 10978114.64735733 val_loss 206933.24218750\n",
      "epoch 6734 train_loss 10978114.64726814 val_loss 206933.24218750\n",
      "epoch 6735 train_loss 10978114.64717285 val_loss 206933.24218750\n",
      "epoch 6736 train_loss 10978114.64709198 val_loss 206933.24218750\n",
      "epoch 6737 train_loss 10978114.64698349 val_loss 206933.24218750\n",
      "epoch 6738 train_loss 10978114.64692215 val_loss 206933.24218750\n",
      "epoch 6739 train_loss 10978114.64683434 val_loss 206933.24218750\n",
      "epoch 6740 train_loss 10978114.64674591 val_loss 206933.24218750\n",
      "epoch 6741 train_loss 10978114.64671997 val_loss 206933.24218750\n",
      "epoch 6742 train_loss 10978114.64663361 val_loss 206933.24218750\n",
      "epoch 6743 train_loss 10978114.64656540 val_loss 206933.24218750\n",
      "epoch 6744 train_loss 10978114.64645279 val_loss 206933.24218750\n",
      "epoch 6745 train_loss 10978114.64637291 val_loss 206933.24218750\n",
      "epoch 6746 train_loss 10978114.64630020 val_loss 206933.24218750\n",
      "epoch 6747 train_loss 10978114.64620247 val_loss 206933.24218750\n",
      "epoch 6748 train_loss 10978114.64611305 val_loss 206933.24218750\n",
      "epoch 6749 train_loss 10978114.64601829 val_loss 206933.24218750\n",
      "epoch 6750 train_loss 10978114.64595634 val_loss 206933.24218750\n",
      "epoch 6751 train_loss 10978114.64585884 val_loss 206933.24218750\n",
      "epoch 6752 train_loss 10978114.64576798 val_loss 206933.24218750\n",
      "epoch 6753 train_loss 10978114.64568077 val_loss 206933.24218750\n",
      "epoch 6754 train_loss 10978114.64559738 val_loss 206933.24218750\n",
      "epoch 6755 train_loss 10978114.64548515 val_loss 206933.24218750\n",
      "epoch 6756 train_loss 10978114.64540901 val_loss 206933.24218750\n",
      "epoch 6757 train_loss 10978114.64531532 val_loss 206933.24218750\n",
      "epoch 6758 train_loss 10978114.64520874 val_loss 206933.24218750\n",
      "epoch 6759 train_loss 10978114.64513718 val_loss 206933.24218750\n",
      "epoch 6760 train_loss 10978114.64504845 val_loss 206933.24218750\n",
      "epoch 6761 train_loss 10978114.64494133 val_loss 206933.24218750\n",
      "epoch 6762 train_loss 10978114.64484985 val_loss 206933.24218750\n",
      "epoch 6763 train_loss 10978114.64476341 val_loss 206933.24218750\n",
      "epoch 6764 train_loss 10978114.64469269 val_loss 206933.24218750\n",
      "epoch 6765 train_loss 10978114.64460930 val_loss 206933.24218750\n",
      "epoch 6766 train_loss 10978114.64453445 val_loss 206933.25781250\n",
      "epoch 6767 train_loss 10978114.64444428 val_loss 206933.25781250\n",
      "epoch 6768 train_loss 10978114.64434616 val_loss 206933.25781250\n",
      "epoch 6769 train_loss 10978114.64429718 val_loss 206933.25781250\n",
      "epoch 6770 train_loss 10978114.64418770 val_loss 206933.25781250\n",
      "epoch 6771 train_loss 10978114.64409866 val_loss 206933.25781250\n",
      "epoch 6772 train_loss 10978114.64400101 val_loss 206933.25781250\n",
      "epoch 6773 train_loss 10978114.64391190 val_loss 206933.25781250\n",
      "epoch 6774 train_loss 10978114.64381897 val_loss 206933.25781250\n",
      "epoch 6775 train_loss 10978114.64370644 val_loss 206933.25781250\n",
      "epoch 6776 train_loss 10978114.64365669 val_loss 206933.25781250\n",
      "epoch 6777 train_loss 10978114.64357391 val_loss 206933.25781250\n",
      "epoch 6778 train_loss 10978114.64346519 val_loss 206933.25781250\n",
      "epoch 6779 train_loss 10978114.64337852 val_loss 206933.25781250\n",
      "epoch 6780 train_loss 10978114.64328232 val_loss 206933.25781250\n",
      "epoch 6781 train_loss 10978114.64320450 val_loss 206933.25781250\n",
      "epoch 6782 train_loss 10978114.64310295 val_loss 206933.25781250\n",
      "epoch 6783 train_loss 10978114.64302017 val_loss 206933.25781250\n",
      "epoch 6784 train_loss 10978114.64291283 val_loss 206933.25781250\n",
      "epoch 6785 train_loss 10978114.64283402 val_loss 206933.25781250\n",
      "epoch 6786 train_loss 10978114.64279137 val_loss 206933.25781250\n",
      "epoch 6787 train_loss 10978114.64270752 val_loss 206933.25781250\n",
      "epoch 6788 train_loss 10978114.64261475 val_loss 206933.25781250\n",
      "epoch 6789 train_loss 10978114.64251656 val_loss 206933.25781250\n",
      "epoch 6790 train_loss 10978114.64244453 val_loss 206933.25781250\n",
      "epoch 6791 train_loss 10978114.64234512 val_loss 206933.25781250\n",
      "epoch 6792 train_loss 10978114.64229431 val_loss 206933.25781250\n",
      "epoch 6793 train_loss 10978114.64219109 val_loss 206933.25781250\n",
      "epoch 6794 train_loss 10978114.64210106 val_loss 206933.25781250\n",
      "epoch 6795 train_loss 10978114.64203201 val_loss 206933.25781250\n",
      "epoch 6796 train_loss 10978114.64190559 val_loss 206933.25781250\n",
      "epoch 6797 train_loss 10978114.64180717 val_loss 206933.25781250\n",
      "epoch 6798 train_loss 10978114.64172302 val_loss 206933.25781250\n",
      "epoch 6799 train_loss 10978114.64162537 val_loss 206933.25781250\n",
      "epoch 6800 train_loss 10978114.64154213 val_loss 206933.25781250\n",
      "epoch 6801 train_loss 10978114.64145828 val_loss 206933.25781250\n",
      "epoch 6802 train_loss 10978114.64137604 val_loss 206933.25781250\n",
      "epoch 6803 train_loss 10978114.64135338 val_loss 206933.25781250\n",
      "epoch 6804 train_loss 10978114.64127327 val_loss 206933.25781250\n",
      "epoch 6805 train_loss 10978114.64118210 val_loss 206933.25781250\n",
      "epoch 6806 train_loss 10978114.64109711 val_loss 206933.25781250\n",
      "epoch 6807 train_loss 10978114.64099258 val_loss 206933.25781250\n",
      "epoch 6808 train_loss 10978114.64091041 val_loss 206933.25781250\n",
      "epoch 6809 train_loss 10978114.64081062 val_loss 206933.25781250\n",
      "epoch 6810 train_loss 10978114.64070656 val_loss 206933.25781250\n",
      "epoch 6811 train_loss 10978114.64062416 val_loss 206933.25781250\n",
      "epoch 6812 train_loss 10978114.64054146 val_loss 206933.25781250\n",
      "epoch 6813 train_loss 10978114.64045387 val_loss 206933.25781250\n",
      "epoch 6814 train_loss 10978114.64034828 val_loss 206933.25781250\n",
      "epoch 6815 train_loss 10978114.64026070 val_loss 206933.25781250\n",
      "epoch 6816 train_loss 10978114.64016319 val_loss 206933.25781250\n",
      "epoch 6817 train_loss 10978114.64004684 val_loss 206933.25781250\n",
      "epoch 6818 train_loss 10978114.63997643 val_loss 206933.25781250\n",
      "epoch 6819 train_loss 10978114.63987404 val_loss 206933.25781250\n",
      "epoch 6820 train_loss 10978114.63983116 val_loss 206933.25781250\n",
      "epoch 6821 train_loss 10978114.63975220 val_loss 206933.25781250\n",
      "epoch 6822 train_loss 10978114.63968994 val_loss 206933.25781250\n",
      "epoch 6823 train_loss 10978114.63959915 val_loss 206933.25781250\n",
      "epoch 6824 train_loss 10978114.63951431 val_loss 206933.25781250\n",
      "epoch 6825 train_loss 10978114.63941132 val_loss 206933.25781250\n",
      "epoch 6826 train_loss 10978114.63933426 val_loss 206933.25781250\n",
      "epoch 6827 train_loss 10978114.63924004 val_loss 206933.25781250\n",
      "epoch 6828 train_loss 10978114.63914024 val_loss 206933.25781250\n",
      "epoch 6829 train_loss 10978114.63906914 val_loss 206933.25781250\n",
      "epoch 6830 train_loss 10978114.63897430 val_loss 206933.25781250\n",
      "epoch 6831 train_loss 10978114.63889145 val_loss 206933.25781250\n",
      "epoch 6832 train_loss 10978114.63878510 val_loss 206933.25781250\n",
      "epoch 6833 train_loss 10978114.63867447 val_loss 206933.25781250\n",
      "epoch 6834 train_loss 10978114.63858955 val_loss 206933.25781250\n",
      "epoch 6835 train_loss 10978114.63854896 val_loss 206933.25781250\n",
      "epoch 6836 train_loss 10978114.63846794 val_loss 206933.25781250\n",
      "epoch 6837 train_loss 10978114.63838913 val_loss 206933.25781250\n",
      "epoch 6838 train_loss 10978114.63830025 val_loss 206933.25781250\n",
      "epoch 6839 train_loss 10978114.63821068 val_loss 206933.25781250\n",
      "epoch 6840 train_loss 10978114.63810997 val_loss 206933.25781250\n",
      "epoch 6841 train_loss 10978114.63801842 val_loss 206933.25781250\n",
      "epoch 6842 train_loss 10978114.63792290 val_loss 206933.25781250\n",
      "epoch 6843 train_loss 10978114.63785050 val_loss 206933.25781250\n",
      "epoch 6844 train_loss 10978114.63773933 val_loss 206933.25781250\n",
      "epoch 6845 train_loss 10978114.63764206 val_loss 206933.25781250\n",
      "epoch 6846 train_loss 10978114.63754677 val_loss 206933.25781250\n",
      "epoch 6847 train_loss 10978114.63746384 val_loss 206933.25781250\n",
      "epoch 6848 train_loss 10978114.63736656 val_loss 206933.25781250\n",
      "epoch 6849 train_loss 10978114.63731766 val_loss 206933.25781250\n",
      "epoch 6850 train_loss 10978114.63721588 val_loss 206933.25781250\n",
      "epoch 6851 train_loss 10978114.63709396 val_loss 206933.25781250\n",
      "epoch 6852 train_loss 10978114.63703018 val_loss 206933.25781250\n",
      "epoch 6853 train_loss 10978114.63692024 val_loss 206933.25781250\n",
      "epoch 6854 train_loss 10978114.63683167 val_loss 206933.25781250\n",
      "epoch 6855 train_loss 10978114.63673927 val_loss 206933.25781250\n",
      "epoch 6856 train_loss 10978114.63665443 val_loss 206933.25781250\n",
      "epoch 6857 train_loss 10978114.63658035 val_loss 206933.25781250\n",
      "epoch 6858 train_loss 10978114.63649445 val_loss 206933.25781250\n",
      "epoch 6859 train_loss 10978114.63641716 val_loss 206933.25781250\n",
      "epoch 6860 train_loss 10978114.63631477 val_loss 206933.25781250\n",
      "epoch 6861 train_loss 10978114.63620720 val_loss 206933.25781250\n",
      "epoch 6862 train_loss 10978114.63613220 val_loss 206933.25781250\n",
      "epoch 6863 train_loss 10978114.63602928 val_loss 206933.25781250\n",
      "epoch 6864 train_loss 10978114.63593842 val_loss 206933.25781250\n",
      "epoch 6865 train_loss 10978114.63588371 val_loss 206933.25781250\n",
      "epoch 6866 train_loss 10978114.63577095 val_loss 206933.25781250\n",
      "epoch 6867 train_loss 10978114.63568337 val_loss 206933.25781250\n",
      "epoch 6868 train_loss 10978114.63560661 val_loss 206933.25781250\n",
      "epoch 6869 train_loss 10978114.63550865 val_loss 206933.25781250\n",
      "epoch 6870 train_loss 10978114.63544090 val_loss 206933.25781250\n",
      "epoch 6871 train_loss 10978114.63534523 val_loss 206933.25781250\n",
      "epoch 6872 train_loss 10978114.63527679 val_loss 206933.25781250\n",
      "epoch 6873 train_loss 10978114.63518677 val_loss 206933.25781250\n",
      "epoch 6874 train_loss 10978114.63509255 val_loss 206933.25781250\n",
      "epoch 6875 train_loss 10978114.63504028 val_loss 206933.25781250\n",
      "epoch 6876 train_loss 10978114.63494018 val_loss 206933.25781250\n",
      "epoch 6877 train_loss 10978114.63486519 val_loss 206933.25781250\n",
      "epoch 6878 train_loss 10978114.63475128 val_loss 206933.25781250\n",
      "epoch 6879 train_loss 10978114.63464981 val_loss 206933.25781250\n",
      "epoch 6880 train_loss 10978114.63456291 val_loss 206933.25781250\n",
      "epoch 6881 train_loss 10978114.63445030 val_loss 206933.25781250\n",
      "epoch 6882 train_loss 10978114.63436653 val_loss 206933.25781250\n",
      "epoch 6883 train_loss 10978114.63432976 val_loss 206933.25781250\n",
      "epoch 6884 train_loss 10978114.63424378 val_loss 206933.25781250\n",
      "epoch 6885 train_loss 10978114.63414574 val_loss 206933.25781250\n",
      "epoch 6886 train_loss 10978114.63405815 val_loss 206933.25781250\n",
      "epoch 6887 train_loss 10978114.63396782 val_loss 206933.25781250\n",
      "epoch 6888 train_loss 10978114.63389595 val_loss 206933.25781250\n",
      "epoch 6889 train_loss 10978114.63382973 val_loss 206933.25781250\n",
      "epoch 6890 train_loss 10978114.63372116 val_loss 206933.25781250\n",
      "epoch 6891 train_loss 10978114.63365097 val_loss 206933.25781250\n",
      "epoch 6892 train_loss 10978114.63355507 val_loss 206933.25781250\n",
      "epoch 6893 train_loss 10978114.63347351 val_loss 206933.25781250\n",
      "epoch 6894 train_loss 10978114.63337967 val_loss 206933.25781250\n",
      "epoch 6895 train_loss 10978114.63328590 val_loss 206933.25781250\n",
      "epoch 6896 train_loss 10978114.63322731 val_loss 206933.25781250\n",
      "epoch 6897 train_loss 10978114.63311462 val_loss 206933.25781250\n",
      "epoch 6898 train_loss 10978114.63303947 val_loss 206933.25781250\n",
      "epoch 6899 train_loss 10978114.63293800 val_loss 206933.25781250\n",
      "epoch 6900 train_loss 10978114.63284538 val_loss 206933.25781250\n",
      "epoch 6901 train_loss 10978114.63275772 val_loss 206933.25781250\n",
      "epoch 6902 train_loss 10978114.63266296 val_loss 206933.25781250\n",
      "epoch 6903 train_loss 10978114.63253578 val_loss 206933.25781250\n",
      "epoch 6904 train_loss 10978114.63254471 val_loss 206933.25781250\n",
      "epoch 6905 train_loss 10978114.63246338 val_loss 206933.25781250\n",
      "epoch 6906 train_loss 10978114.63236290 val_loss 206933.25781250\n",
      "epoch 6907 train_loss 10978114.63225288 val_loss 206933.25781250\n",
      "epoch 6908 train_loss 10978114.63216301 val_loss 206933.25781250\n",
      "epoch 6909 train_loss 10978114.63216568 val_loss 206933.25781250\n",
      "epoch 6910 train_loss 10978114.63206680 val_loss 206933.25781250\n",
      "epoch 6911 train_loss 10978114.63196388 val_loss 206933.25781250\n",
      "epoch 6912 train_loss 10978114.63189796 val_loss 206933.25781250\n",
      "epoch 6913 train_loss 10978114.63179802 val_loss 206933.25781250\n",
      "epoch 6914 train_loss 10978114.63171036 val_loss 206933.25781250\n",
      "epoch 6915 train_loss 10978114.63160927 val_loss 206933.25781250\n",
      "epoch 6916 train_loss 10978114.63152603 val_loss 206933.25781250\n",
      "epoch 6917 train_loss 10978114.63144112 val_loss 206933.25781250\n",
      "epoch 6918 train_loss 10978114.63133987 val_loss 206933.25781250\n",
      "epoch 6919 train_loss 10978114.63126770 val_loss 206933.25781250\n",
      "epoch 6920 train_loss 10978114.63121109 val_loss 206933.25781250\n",
      "epoch 6921 train_loss 10978114.63110313 val_loss 206933.25781250\n",
      "epoch 6922 train_loss 10978114.63100975 val_loss 206933.25781250\n",
      "epoch 6923 train_loss 10978114.63093353 val_loss 206933.25781250\n",
      "epoch 6924 train_loss 10978114.63080849 val_loss 206933.25781250\n",
      "epoch 6925 train_loss 10978114.63075493 val_loss 206933.25781250\n",
      "epoch 6926 train_loss 10978114.63065269 val_loss 206933.25781250\n",
      "epoch 6927 train_loss 10978114.63056313 val_loss 206933.25781250\n",
      "epoch 6928 train_loss 10978114.63044808 val_loss 206933.25781250\n",
      "epoch 6929 train_loss 10978114.63037422 val_loss 206933.25781250\n",
      "epoch 6930 train_loss 10978114.63029724 val_loss 206933.25781250\n",
      "epoch 6931 train_loss 10978114.63017944 val_loss 206933.25781250\n",
      "epoch 6932 train_loss 10978114.63009193 val_loss 206933.25781250\n",
      "epoch 6933 train_loss 10978114.62999336 val_loss 206933.25781250\n",
      "epoch 6934 train_loss 10978114.62991928 val_loss 206933.25781250\n",
      "epoch 6935 train_loss 10978114.62980667 val_loss 206933.25781250\n",
      "epoch 6936 train_loss 10978114.62971313 val_loss 206933.25781250\n",
      "epoch 6937 train_loss 10978114.62962852 val_loss 206933.25781250\n",
      "epoch 6938 train_loss 10978114.62955429 val_loss 206933.25781250\n",
      "epoch 6939 train_loss 10978114.62947472 val_loss 206933.25781250\n",
      "epoch 6940 train_loss 10978114.62936295 val_loss 206933.25781250\n",
      "epoch 6941 train_loss 10978114.62927002 val_loss 206933.25781250\n",
      "epoch 6942 train_loss 10978114.62917130 val_loss 206933.25781250\n",
      "epoch 6943 train_loss 10978114.62909363 val_loss 206933.25781250\n",
      "epoch 6944 train_loss 10978114.62900673 val_loss 206933.25781250\n",
      "epoch 6945 train_loss 10978114.62890938 val_loss 206933.25781250\n",
      "epoch 6946 train_loss 10978114.62881432 val_loss 206933.25781250\n",
      "epoch 6947 train_loss 10978114.62873497 val_loss 206933.25781250\n",
      "epoch 6948 train_loss 10978114.62867981 val_loss 206933.25781250\n",
      "epoch 6949 train_loss 10978114.62858658 val_loss 206933.25781250\n",
      "epoch 6950 train_loss 10978114.62849808 val_loss 206933.25781250\n",
      "epoch 6951 train_loss 10978114.62841431 val_loss 206933.25781250\n",
      "epoch 6952 train_loss 10978114.62833160 val_loss 206933.25781250\n",
      "epoch 6953 train_loss 10978114.62822960 val_loss 206933.25781250\n",
      "epoch 6954 train_loss 10978114.62814568 val_loss 206933.25781250\n",
      "epoch 6955 train_loss 10978114.62807488 val_loss 206933.25781250\n",
      "epoch 6956 train_loss 10978114.62798348 val_loss 206933.25781250\n",
      "epoch 6957 train_loss 10978114.62789154 val_loss 206933.25781250\n",
      "epoch 6958 train_loss 10978114.62779800 val_loss 206933.25781250\n",
      "epoch 6959 train_loss 10978114.62770836 val_loss 206933.25781250\n",
      "epoch 6960 train_loss 10978114.62760246 val_loss 206933.25781250\n",
      "epoch 6961 train_loss 10978114.62751343 val_loss 206933.25781250\n",
      "epoch 6962 train_loss 10978114.62744423 val_loss 206933.25781250\n",
      "epoch 6963 train_loss 10978114.62732346 val_loss 206933.25781250\n",
      "epoch 6964 train_loss 10978114.62723007 val_loss 206933.25781250\n",
      "epoch 6965 train_loss 10978114.62713379 val_loss 206933.25781250\n",
      "epoch 6966 train_loss 10978114.62704979 val_loss 206933.25781250\n",
      "epoch 6967 train_loss 10978114.62695335 val_loss 206933.25781250\n",
      "epoch 6968 train_loss 10978114.62689438 val_loss 206933.25781250\n",
      "epoch 6969 train_loss 10978114.62678505 val_loss 206933.25781250\n",
      "epoch 6970 train_loss 10978114.62671768 val_loss 206933.25781250\n",
      "epoch 6971 train_loss 10978114.62662178 val_loss 206933.25781250\n",
      "epoch 6972 train_loss 10978114.62652748 val_loss 206933.25781250\n",
      "epoch 6973 train_loss 10978114.62644119 val_loss 206933.25781250\n",
      "epoch 6974 train_loss 10978114.62634934 val_loss 206933.25781250\n",
      "epoch 6975 train_loss 10978114.62633079 val_loss 206933.25781250\n",
      "epoch 6976 train_loss 10978114.62626549 val_loss 206933.25781250\n",
      "epoch 6977 train_loss 10978114.62617485 val_loss 206933.25781250\n",
      "epoch 6978 train_loss 10978114.62606529 val_loss 206933.25781250\n",
      "epoch 6979 train_loss 10978114.62595543 val_loss 206933.25781250\n",
      "epoch 6980 train_loss 10978114.62586655 val_loss 206933.25781250\n",
      "epoch 6981 train_loss 10978114.62577827 val_loss 206933.25781250\n",
      "epoch 6982 train_loss 10978114.62570290 val_loss 206933.25781250\n",
      "epoch 6983 train_loss 10978114.62562904 val_loss 206933.25781250\n",
      "epoch 6984 train_loss 10978114.62553711 val_loss 206933.25781250\n",
      "epoch 6985 train_loss 10978114.62545128 val_loss 206933.25781250\n",
      "epoch 6986 train_loss 10978114.62535652 val_loss 206933.25781250\n",
      "epoch 6987 train_loss 10978114.62527794 val_loss 206933.25781250\n",
      "epoch 6988 train_loss 10978114.62516983 val_loss 206933.25781250\n",
      "epoch 6989 train_loss 10978114.62507881 val_loss 206933.25781250\n",
      "epoch 6990 train_loss 10978114.62498016 val_loss 206933.25781250\n",
      "epoch 6991 train_loss 10978114.62488686 val_loss 206933.25781250\n",
      "epoch 6992 train_loss 10978114.62479469 val_loss 206933.25781250\n",
      "epoch 6993 train_loss 10978114.62471497 val_loss 206933.25781250\n",
      "epoch 6994 train_loss 10978114.62465736 val_loss 206933.25781250\n",
      "epoch 6995 train_loss 10978114.62453789 val_loss 206933.25781250\n",
      "epoch 6996 train_loss 10978114.62444344 val_loss 206933.25781250\n",
      "epoch 6997 train_loss 10978114.62436501 val_loss 206933.25781250\n",
      "epoch 6998 train_loss 10978114.62426193 val_loss 206933.25781250\n",
      "epoch 6999 train_loss 10978114.62416863 val_loss 206933.25781250\n",
      "epoch 7000 train_loss 10978114.62408112 val_loss 206933.25781250\n",
      "epoch 7001 train_loss 10978114.62400093 val_loss 206933.25781250\n",
      "epoch 7002 train_loss 10978114.62393059 val_loss 206933.25781250\n",
      "epoch 7003 train_loss 10978114.62382645 val_loss 206933.25781250\n",
      "epoch 7004 train_loss 10978114.62373703 val_loss 206933.25781250\n",
      "epoch 7005 train_loss 10978114.62364639 val_loss 206933.25781250\n",
      "epoch 7006 train_loss 10978114.62353157 val_loss 206933.25781250\n",
      "epoch 7007 train_loss 10978114.62344955 val_loss 206933.25781250\n",
      "epoch 7008 train_loss 10978114.62335304 val_loss 206933.25781250\n",
      "epoch 7009 train_loss 10978114.62325935 val_loss 206933.25781250\n",
      "epoch 7010 train_loss 10978114.62320969 val_loss 206933.25781250\n",
      "epoch 7011 train_loss 10978114.62316299 val_loss 206933.25781250\n",
      "epoch 7012 train_loss 10978114.62307266 val_loss 206933.25781250\n",
      "epoch 7013 train_loss 10978114.62298210 val_loss 206933.25781250\n",
      "epoch 7014 train_loss 10978114.62289955 val_loss 206933.25781250\n",
      "epoch 7015 train_loss 10978114.62279793 val_loss 206933.25781250\n",
      "epoch 7016 train_loss 10978114.62269546 val_loss 206933.25781250\n",
      "epoch 7017 train_loss 10978114.62260353 val_loss 206933.25781250\n",
      "epoch 7018 train_loss 10978114.62252411 val_loss 206933.25781250\n",
      "epoch 7019 train_loss 10978114.62242744 val_loss 206933.25781250\n",
      "epoch 7020 train_loss 10978114.62233826 val_loss 206933.25781250\n",
      "epoch 7021 train_loss 10978114.62223572 val_loss 206933.25781250\n",
      "epoch 7022 train_loss 10978114.62216675 val_loss 206933.25781250\n",
      "epoch 7023 train_loss 10978114.62204247 val_loss 206933.25781250\n",
      "epoch 7024 train_loss 10978114.62196701 val_loss 206933.25781250\n",
      "epoch 7025 train_loss 10978114.62189468 val_loss 206933.25781250\n",
      "epoch 7026 train_loss 10978114.62179459 val_loss 206933.25781250\n",
      "epoch 7027 train_loss 10978114.62169716 val_loss 206933.25781250\n",
      "epoch 7028 train_loss 10978114.62161644 val_loss 206933.25781250\n",
      "epoch 7029 train_loss 10978114.62155098 val_loss 206933.25781250\n",
      "epoch 7030 train_loss 10978114.62146110 val_loss 206933.25781250\n",
      "epoch 7031 train_loss 10978114.62135155 val_loss 206933.25781250\n",
      "epoch 7032 train_loss 10978114.62126015 val_loss 206933.25781250\n",
      "epoch 7033 train_loss 10978114.62119118 val_loss 206933.25781250\n",
      "epoch 7034 train_loss 10978114.62110825 val_loss 206933.25781250\n",
      "epoch 7035 train_loss 10978114.62101189 val_loss 206933.25781250\n",
      "epoch 7036 train_loss 10978114.62091621 val_loss 206933.25781250\n",
      "epoch 7037 train_loss 10978114.62082169 val_loss 206933.25781250\n",
      "epoch 7038 train_loss 10978114.62073326 val_loss 206933.25781250\n",
      "epoch 7039 train_loss 10978114.62064537 val_loss 206933.25781250\n",
      "epoch 7040 train_loss 10978114.62054550 val_loss 206933.25781250\n",
      "epoch 7041 train_loss 10978114.62046310 val_loss 206933.25781250\n",
      "epoch 7042 train_loss 10978114.62042053 val_loss 206933.25781250\n",
      "epoch 7043 train_loss 10978114.62033379 val_loss 206933.25781250\n",
      "epoch 7044 train_loss 10978114.62023995 val_loss 206933.25781250\n",
      "epoch 7045 train_loss 10978114.62018578 val_loss 206933.25781250\n",
      "epoch 7046 train_loss 10978114.62009720 val_loss 206933.25781250\n",
      "epoch 7047 train_loss 10978114.62004890 val_loss 206933.25781250\n",
      "epoch 7048 train_loss 10978114.61996315 val_loss 206933.25781250\n",
      "epoch 7049 train_loss 10978114.61987457 val_loss 206933.25781250\n",
      "epoch 7050 train_loss 10978114.61980926 val_loss 206933.25781250\n",
      "epoch 7051 train_loss 10978114.61971428 val_loss 206933.25781250\n",
      "epoch 7052 train_loss 10978114.61961411 val_loss 206933.25781250\n",
      "epoch 7053 train_loss 10978114.61952103 val_loss 206933.25781250\n",
      "epoch 7054 train_loss 10978114.61945892 val_loss 206933.25781250\n",
      "epoch 7055 train_loss 10978114.61938217 val_loss 206933.25781250\n",
      "epoch 7056 train_loss 10978114.61927025 val_loss 206933.25781250\n",
      "epoch 7057 train_loss 10978114.61916992 val_loss 206933.25781250\n",
      "epoch 7058 train_loss 10978114.61909577 val_loss 206933.25781250\n",
      "epoch 7059 train_loss 10978114.61900665 val_loss 206933.25781250\n",
      "epoch 7060 train_loss 10978114.61891884 val_loss 206933.25781250\n",
      "epoch 7061 train_loss 10978114.61881966 val_loss 206933.25781250\n",
      "epoch 7062 train_loss 10978114.61874184 val_loss 206933.25781250\n",
      "epoch 7063 train_loss 10978114.61862190 val_loss 206933.25781250\n",
      "epoch 7064 train_loss 10978114.61853325 val_loss 206933.25781250\n",
      "epoch 7065 train_loss 10978114.61845032 val_loss 206933.25781250\n",
      "epoch 7066 train_loss 10978114.61835747 val_loss 206933.25781250\n",
      "epoch 7067 train_loss 10978114.61827225 val_loss 206933.25781250\n",
      "epoch 7068 train_loss 10978114.61817436 val_loss 206933.25781250\n",
      "epoch 7069 train_loss 10978114.61807900 val_loss 206933.25781250\n",
      "epoch 7070 train_loss 10978114.61798408 val_loss 206933.25781250\n",
      "epoch 7071 train_loss 10978114.61788277 val_loss 206933.25781250\n",
      "epoch 7072 train_loss 10978114.61779640 val_loss 206933.25781250\n",
      "epoch 7073 train_loss 10978114.61772446 val_loss 206933.25781250\n",
      "epoch 7074 train_loss 10978114.61762329 val_loss 206933.25781250\n",
      "epoch 7075 train_loss 10978114.61752312 val_loss 206933.25781250\n",
      "epoch 7076 train_loss 10978114.61743813 val_loss 206933.25781250\n",
      "epoch 7077 train_loss 10978114.61733215 val_loss 206933.25781250\n",
      "epoch 7078 train_loss 10978114.61723961 val_loss 206933.25781250\n",
      "epoch 7079 train_loss 10978114.61714493 val_loss 206933.25781250\n",
      "epoch 7080 train_loss 10978114.61705688 val_loss 206933.25781250\n",
      "epoch 7081 train_loss 10978114.61696373 val_loss 206933.25781250\n",
      "epoch 7082 train_loss 10978114.61687729 val_loss 206933.25781250\n",
      "epoch 7083 train_loss 10978114.61681236 val_loss 206933.25781250\n",
      "epoch 7084 train_loss 10978114.61672249 val_loss 206933.25781250\n",
      "epoch 7085 train_loss 10978114.61661041 val_loss 206933.25781250\n",
      "epoch 7086 train_loss 10978114.61652473 val_loss 206933.25781250\n",
      "epoch 7087 train_loss 10978114.61642906 val_loss 206933.25781250\n",
      "epoch 7088 train_loss 10978114.61633125 val_loss 206933.25781250\n",
      "epoch 7089 train_loss 10978114.61625206 val_loss 206933.25781250\n",
      "epoch 7090 train_loss 10978114.61618034 val_loss 206933.25781250\n",
      "epoch 7091 train_loss 10978114.61608193 val_loss 206933.25781250\n",
      "epoch 7092 train_loss 10978114.61598503 val_loss 206933.25781250\n",
      "epoch 7093 train_loss 10978114.61591934 val_loss 206933.25781250\n",
      "epoch 7094 train_loss 10978114.61582459 val_loss 206933.25781250\n",
      "epoch 7095 train_loss 10978114.61572212 val_loss 206933.25781250\n",
      "epoch 7096 train_loss 10978114.61565041 val_loss 206933.25781250\n",
      "epoch 7097 train_loss 10978114.61556625 val_loss 206933.25781250\n",
      "epoch 7098 train_loss 10978114.61547714 val_loss 206933.25781250\n",
      "epoch 7099 train_loss 10978114.61537285 val_loss 206933.25781250\n",
      "epoch 7100 train_loss 10978114.61532791 val_loss 206933.25781250\n",
      "epoch 7101 train_loss 10978114.61525734 val_loss 206933.25781250\n",
      "epoch 7102 train_loss 10978114.61514565 val_loss 206933.25781250\n",
      "epoch 7103 train_loss 10978114.61506180 val_loss 206933.25781250\n",
      "epoch 7104 train_loss 10978114.61497757 val_loss 206933.25781250\n",
      "epoch 7105 train_loss 10978114.61487640 val_loss 206933.25781250\n",
      "epoch 7106 train_loss 10978114.61477264 val_loss 206933.25781250\n",
      "epoch 7107 train_loss 10978114.61469467 val_loss 206933.25781250\n",
      "epoch 7108 train_loss 10978114.61461899 val_loss 206933.25781250\n",
      "epoch 7109 train_loss 10978114.61452194 val_loss 206933.25781250\n",
      "epoch 7110 train_loss 10978114.61444038 val_loss 206933.25781250\n",
      "epoch 7111 train_loss 10978114.61433723 val_loss 206933.25781250\n",
      "epoch 7112 train_loss 10978114.61424957 val_loss 206933.25781250\n",
      "epoch 7113 train_loss 10978114.61416473 val_loss 206933.25781250\n",
      "epoch 7114 train_loss 10978114.61407051 val_loss 206933.25781250\n",
      "epoch 7115 train_loss 10978114.61398079 val_loss 206933.25781250\n",
      "epoch 7116 train_loss 10978114.61389099 val_loss 206933.25781250\n",
      "epoch 7117 train_loss 10978114.61380097 val_loss 206933.25781250\n",
      "epoch 7118 train_loss 10978114.61370964 val_loss 206933.25781250\n",
      "epoch 7119 train_loss 10978114.61361755 val_loss 206933.25781250\n",
      "epoch 7120 train_loss 10978114.61351913 val_loss 206933.25781250\n",
      "epoch 7121 train_loss 10978114.61346024 val_loss 206933.25781250\n",
      "epoch 7122 train_loss 10978114.61338432 val_loss 206933.25781250\n",
      "epoch 7123 train_loss 10978114.61329399 val_loss 206933.25781250\n",
      "epoch 7124 train_loss 10978114.61319344 val_loss 206933.25781250\n",
      "epoch 7125 train_loss 10978114.61309456 val_loss 206933.25781250\n",
      "epoch 7126 train_loss 10978114.61301559 val_loss 206933.25781250\n",
      "epoch 7127 train_loss 10978114.61292770 val_loss 206933.25781250\n",
      "epoch 7128 train_loss 10978114.61280884 val_loss 206933.25781250\n",
      "epoch 7129 train_loss 10978114.61274750 val_loss 206933.25781250\n",
      "epoch 7130 train_loss 10978114.61266853 val_loss 206933.25781250\n",
      "epoch 7131 train_loss 10978114.61254341 val_loss 206933.25781250\n",
      "epoch 7132 train_loss 10978114.61246437 val_loss 206933.25781250\n",
      "epoch 7133 train_loss 10978114.61240997 val_loss 206933.25781250\n",
      "epoch 7134 train_loss 10978114.61228958 val_loss 206933.25781250\n",
      "epoch 7135 train_loss 10978114.61223167 val_loss 206933.25781250\n",
      "epoch 7136 train_loss 10978114.61212578 val_loss 206933.25781250\n",
      "epoch 7137 train_loss 10978114.61203659 val_loss 206933.25781250\n",
      "epoch 7138 train_loss 10978114.61194527 val_loss 206933.25781250\n",
      "epoch 7139 train_loss 10978114.61191574 val_loss 206933.25781250\n",
      "epoch 7140 train_loss 10978114.61181946 val_loss 206933.25781250\n",
      "epoch 7141 train_loss 10978114.61173492 val_loss 206933.25781250\n",
      "epoch 7142 train_loss 10978114.61164436 val_loss 206933.27343750\n",
      "epoch 7143 train_loss 10978114.61155510 val_loss 206933.27343750\n",
      "epoch 7144 train_loss 10978114.61145470 val_loss 206933.27343750\n",
      "epoch 7145 train_loss 10978114.61134354 val_loss 206933.27343750\n",
      "epoch 7146 train_loss 10978114.61124771 val_loss 206933.27343750\n",
      "epoch 7147 train_loss 10978114.61115974 val_loss 206933.27343750\n",
      "epoch 7148 train_loss 10978114.61112114 val_loss 206933.27343750\n",
      "epoch 7149 train_loss 10978114.61103790 val_loss 206933.27343750\n",
      "epoch 7150 train_loss 10978114.61095665 val_loss 206933.27343750\n",
      "epoch 7151 train_loss 10978114.61086906 val_loss 206933.27343750\n",
      "epoch 7152 train_loss 10978114.61076317 val_loss 206933.27343750\n",
      "epoch 7153 train_loss 10978114.61066071 val_loss 206933.27343750\n",
      "epoch 7154 train_loss 10978114.61056892 val_loss 206933.27343750\n",
      "epoch 7155 train_loss 10978114.61047676 val_loss 206933.27343750\n",
      "epoch 7156 train_loss 10978114.61037911 val_loss 206933.27343750\n",
      "epoch 7157 train_loss 10978114.61028763 val_loss 206933.27343750\n",
      "epoch 7158 train_loss 10978114.61019920 val_loss 206933.27343750\n",
      "epoch 7159 train_loss 10978114.61009880 val_loss 206933.27343750\n",
      "epoch 7160 train_loss 10978114.61001793 val_loss 206933.27343750\n",
      "epoch 7161 train_loss 10978114.60992516 val_loss 206933.27343750\n",
      "epoch 7162 train_loss 10978114.60983162 val_loss 206933.27343750\n",
      "epoch 7163 train_loss 10978114.60978676 val_loss 206933.27343750\n",
      "epoch 7164 train_loss 10978114.60968681 val_loss 206933.27343750\n",
      "epoch 7165 train_loss 10978114.60958275 val_loss 206933.27343750\n",
      "epoch 7166 train_loss 10978114.60951019 val_loss 206933.27343750\n",
      "epoch 7167 train_loss 10978114.60939133 val_loss 206933.27343750\n",
      "epoch 7168 train_loss 10978114.60931274 val_loss 206933.27343750\n",
      "epoch 7169 train_loss 10978114.60922646 val_loss 206933.27343750\n",
      "epoch 7170 train_loss 10978114.60912880 val_loss 206933.27343750\n",
      "epoch 7171 train_loss 10978114.60904152 val_loss 206933.27343750\n",
      "epoch 7172 train_loss 10978114.60895500 val_loss 206933.27343750\n",
      "epoch 7173 train_loss 10978114.60886024 val_loss 206933.27343750\n",
      "epoch 7174 train_loss 10978114.60876305 val_loss 206933.27343750\n",
      "epoch 7175 train_loss 10978114.60868950 val_loss 206933.27343750\n",
      "epoch 7176 train_loss 10978114.60862564 val_loss 206933.27343750\n",
      "epoch 7177 train_loss 10978114.60852028 val_loss 206933.27343750\n",
      "epoch 7178 train_loss 10978114.60844292 val_loss 206933.27343750\n",
      "epoch 7179 train_loss 10978114.60832954 val_loss 206933.27343750\n",
      "epoch 7180 train_loss 10978114.60826752 val_loss 206933.27343750\n",
      "epoch 7181 train_loss 10978114.60816597 val_loss 206933.27343750\n",
      "epoch 7182 train_loss 10978114.60806450 val_loss 206933.27343750\n",
      "epoch 7183 train_loss 10978114.60800102 val_loss 206933.27343750\n",
      "epoch 7184 train_loss 10978114.60789093 val_loss 206933.27343750\n",
      "epoch 7185 train_loss 10978114.60780327 val_loss 206933.27343750\n",
      "epoch 7186 train_loss 10978114.60770470 val_loss 206933.27343750\n",
      "epoch 7187 train_loss 10978114.60760139 val_loss 206933.27343750\n",
      "epoch 7188 train_loss 10978114.60752457 val_loss 206933.27343750\n",
      "epoch 7189 train_loss 10978114.60743790 val_loss 206933.27343750\n",
      "epoch 7190 train_loss 10978114.60734512 val_loss 206933.27343750\n",
      "epoch 7191 train_loss 10978114.60726273 val_loss 206933.27343750\n",
      "epoch 7192 train_loss 10978114.60718361 val_loss 206933.27343750\n",
      "epoch 7193 train_loss 10978114.60710052 val_loss 206933.27343750\n",
      "epoch 7194 train_loss 10978114.60700172 val_loss 206933.27343750\n",
      "epoch 7195 train_loss 10978114.60692055 val_loss 206933.27343750\n",
      "epoch 7196 train_loss 10978114.60684372 val_loss 206933.27343750\n",
      "epoch 7197 train_loss 10978114.60675514 val_loss 206933.27343750\n",
      "epoch 7198 train_loss 10978114.60667030 val_loss 206933.27343750\n",
      "epoch 7199 train_loss 10978114.60655777 val_loss 206933.27343750\n",
      "epoch 7200 train_loss 10978114.60651115 val_loss 206933.27343750\n",
      "epoch 7201 train_loss 10978114.60641106 val_loss 206933.27343750\n",
      "epoch 7202 train_loss 10978114.60632866 val_loss 206933.27343750\n",
      "epoch 7203 train_loss 10978114.60622757 val_loss 206933.27343750\n",
      "epoch 7204 train_loss 10978114.60615318 val_loss 206933.27343750\n",
      "epoch 7205 train_loss 10978114.60606705 val_loss 206933.27343750\n",
      "epoch 7206 train_loss 10978114.60599091 val_loss 206933.27343750\n",
      "epoch 7207 train_loss 10978114.60587723 val_loss 206933.27343750\n",
      "epoch 7208 train_loss 10978114.60578903 val_loss 206933.27343750\n",
      "epoch 7209 train_loss 10978114.60569298 val_loss 206933.27343750\n",
      "epoch 7210 train_loss 10978114.60556915 val_loss 206933.27343750\n",
      "epoch 7211 train_loss 10978114.60553909 val_loss 206933.27343750\n",
      "epoch 7212 train_loss 10978114.60548943 val_loss 206933.27343750\n",
      "epoch 7213 train_loss 10978114.60539917 val_loss 206933.27343750\n",
      "epoch 7214 train_loss 10978114.60532097 val_loss 206933.27343750\n",
      "epoch 7215 train_loss 10978114.60527809 val_loss 206933.27343750\n",
      "epoch 7216 train_loss 10978114.60518616 val_loss 206933.27343750\n",
      "epoch 7217 train_loss 10978114.60510056 val_loss 206933.27343750\n",
      "epoch 7218 train_loss 10978114.60500359 val_loss 206933.27343750\n",
      "epoch 7219 train_loss 10978114.60491257 val_loss 206933.27343750\n",
      "epoch 7220 train_loss 10978114.60481689 val_loss 206933.27343750\n",
      "epoch 7221 train_loss 10978114.60471413 val_loss 206933.27343750\n",
      "epoch 7222 train_loss 10978114.60464088 val_loss 206933.27343750\n",
      "epoch 7223 train_loss 10978114.60456459 val_loss 206933.27343750\n",
      "epoch 7224 train_loss 10978114.60446335 val_loss 206933.27343750\n",
      "epoch 7225 train_loss 10978114.60436874 val_loss 206933.27343750\n",
      "epoch 7226 train_loss 10978114.60429504 val_loss 206933.27343750\n",
      "epoch 7227 train_loss 10978114.60420181 val_loss 206933.27343750\n",
      "epoch 7228 train_loss 10978114.60410065 val_loss 206933.27343750\n",
      "epoch 7229 train_loss 10978114.60399689 val_loss 206933.27343750\n",
      "epoch 7230 train_loss 10978114.60392143 val_loss 206933.27343750\n",
      "epoch 7231 train_loss 10978114.60382553 val_loss 206933.27343750\n",
      "epoch 7232 train_loss 10978114.60373253 val_loss 206933.27343750\n",
      "epoch 7233 train_loss 10978114.60364479 val_loss 206933.29687500\n",
      "epoch 7234 train_loss 10978114.60356323 val_loss 206933.29687500\n",
      "epoch 7235 train_loss 10978114.60345261 val_loss 206933.29687500\n",
      "epoch 7236 train_loss 10978114.60336578 val_loss 206933.29687500\n",
      "epoch 7237 train_loss 10978114.60328224 val_loss 206933.29687500\n",
      "epoch 7238 train_loss 10978114.60318596 val_loss 206933.29687500\n",
      "epoch 7239 train_loss 10978114.60309166 val_loss 206933.29687500\n",
      "epoch 7240 train_loss 10978114.60299667 val_loss 206933.29687500\n",
      "epoch 7241 train_loss 10978114.60291718 val_loss 206933.29687500\n",
      "epoch 7242 train_loss 10978114.60281303 val_loss 206933.29687500\n",
      "epoch 7243 train_loss 10978114.60272461 val_loss 206933.29687500\n",
      "epoch 7244 train_loss 10978114.60262901 val_loss 206933.29687500\n",
      "epoch 7245 train_loss 10978114.60254288 val_loss 206933.29687500\n",
      "epoch 7246 train_loss 10978114.60245247 val_loss 206933.29687500\n",
      "epoch 7247 train_loss 10978114.60237022 val_loss 206933.29687500\n",
      "epoch 7248 train_loss 10978114.60228325 val_loss 206933.29687500\n",
      "epoch 7249 train_loss 10978114.60218857 val_loss 206933.29687500\n",
      "epoch 7250 train_loss 10978114.60211052 val_loss 206933.29687500\n",
      "epoch 7251 train_loss 10978114.60201737 val_loss 206933.27343750\n",
      "epoch 7252 train_loss 10978114.60193741 val_loss 206933.27343750\n",
      "epoch 7253 train_loss 10978114.60184669 val_loss 206933.27343750\n",
      "epoch 7254 train_loss 10978114.60181938 val_loss 206933.27343750\n",
      "epoch 7255 train_loss 10978114.60173706 val_loss 206933.27343750\n",
      "epoch 7256 train_loss 10978114.60165794 val_loss 206933.27343750\n",
      "epoch 7257 train_loss 10978114.60155785 val_loss 206933.27343750\n",
      "epoch 7258 train_loss 10978114.60145729 val_loss 206933.27343750\n",
      "epoch 7259 train_loss 10978114.60137497 val_loss 206933.27343750\n",
      "epoch 7260 train_loss 10978114.60125237 val_loss 206933.27343750\n",
      "epoch 7261 train_loss 10978114.60116753 val_loss 206933.27343750\n",
      "epoch 7262 train_loss 10978114.60107925 val_loss 206933.29687500\n",
      "epoch 7263 train_loss 10978114.60100243 val_loss 206933.29687500\n",
      "epoch 7264 train_loss 10978114.60088936 val_loss 206933.29687500\n",
      "epoch 7265 train_loss 10978114.60078400 val_loss 206933.29687500\n",
      "epoch 7266 train_loss 10978114.60071114 val_loss 206933.29687500\n",
      "epoch 7267 train_loss 10978114.60061951 val_loss 206933.29687500\n",
      "epoch 7268 train_loss 10978114.60052727 val_loss 206933.29687500\n",
      "epoch 7269 train_loss 10978114.60043617 val_loss 206933.29687500\n",
      "epoch 7270 train_loss 10978114.60036316 val_loss 206933.29687500\n",
      "epoch 7271 train_loss 10978114.60027504 val_loss 206933.29687500\n",
      "epoch 7272 train_loss 10978114.60017715 val_loss 206933.29687500\n",
      "epoch 7273 train_loss 10978114.60010002 val_loss 206933.29687500\n",
      "epoch 7274 train_loss 10978114.60000313 val_loss 206933.29687500\n",
      "epoch 7275 train_loss 10978114.59990578 val_loss 206933.29687500\n",
      "epoch 7276 train_loss 10978114.59982140 val_loss 206933.29687500\n",
      "epoch 7277 train_loss 10978114.59973618 val_loss 206933.29687500\n",
      "epoch 7278 train_loss 10978114.59963684 val_loss 206933.29687500\n",
      "epoch 7279 train_loss 10978114.59954453 val_loss 206933.29687500\n",
      "epoch 7280 train_loss 10978114.59944443 val_loss 206933.29687500\n",
      "epoch 7281 train_loss 10978114.59936089 val_loss 206933.29687500\n",
      "epoch 7282 train_loss 10978114.59925026 val_loss 206933.29687500\n",
      "epoch 7283 train_loss 10978114.59914970 val_loss 206933.29687500\n",
      "epoch 7284 train_loss 10978114.59912140 val_loss 206933.29687500\n",
      "epoch 7285 train_loss 10978114.59901840 val_loss 206933.29687500\n",
      "epoch 7286 train_loss 10978114.59892700 val_loss 206933.29687500\n",
      "epoch 7287 train_loss 10978114.59883987 val_loss 206933.29687500\n",
      "epoch 7288 train_loss 10978114.59876976 val_loss 206933.29687500\n",
      "epoch 7289 train_loss 10978114.59866516 val_loss 206933.29687500\n",
      "epoch 7290 train_loss 10978114.59856995 val_loss 206933.29687500\n",
      "epoch 7291 train_loss 10978114.59852089 val_loss 206933.29687500\n",
      "epoch 7292 train_loss 10978114.59841690 val_loss 206933.29687500\n",
      "epoch 7293 train_loss 10978114.59834831 val_loss 206933.29687500\n",
      "epoch 7294 train_loss 10978114.59825531 val_loss 206933.29687500\n",
      "epoch 7295 train_loss 10978114.59816200 val_loss 206933.29687500\n",
      "epoch 7296 train_loss 10978114.59808167 val_loss 206933.29687500\n",
      "epoch 7297 train_loss 10978114.59798691 val_loss 206933.29687500\n",
      "epoch 7298 train_loss 10978114.59789070 val_loss 206933.29687500\n",
      "epoch 7299 train_loss 10978114.59780991 val_loss 206933.29687500\n",
      "epoch 7300 train_loss 10978114.59772484 val_loss 206933.29687500\n",
      "epoch 7301 train_loss 10978114.59761444 val_loss 206933.29687500\n",
      "epoch 7302 train_loss 10978114.59754288 val_loss 206933.29687500\n",
      "epoch 7303 train_loss 10978114.59743843 val_loss 206933.29687500\n",
      "epoch 7304 train_loss 10978114.59735725 val_loss 206933.29687500\n",
      "epoch 7305 train_loss 10978114.59727127 val_loss 206933.29687500\n",
      "epoch 7306 train_loss 10978114.59716904 val_loss 206933.29687500\n",
      "epoch 7307 train_loss 10978114.59706222 val_loss 206933.29687500\n",
      "epoch 7308 train_loss 10978114.59698044 val_loss 206933.29687500\n",
      "epoch 7309 train_loss 10978114.59689880 val_loss 206933.29687500\n",
      "epoch 7310 train_loss 10978114.59679291 val_loss 206933.29687500\n",
      "epoch 7311 train_loss 10978114.59668961 val_loss 206933.29687500\n",
      "epoch 7312 train_loss 10978114.59660591 val_loss 206933.29687500\n",
      "epoch 7313 train_loss 10978114.59652885 val_loss 206933.29687500\n",
      "epoch 7314 train_loss 10978114.59644188 val_loss 206933.29687500\n",
      "epoch 7315 train_loss 10978114.59637421 val_loss 206933.29687500\n",
      "epoch 7316 train_loss 10978114.59627907 val_loss 206933.29687500\n",
      "epoch 7317 train_loss 10978114.59618446 val_loss 206933.29687500\n",
      "epoch 7318 train_loss 10978114.59610138 val_loss 206933.29687500\n",
      "epoch 7319 train_loss 10978114.59600922 val_loss 206933.29687500\n",
      "epoch 7320 train_loss 10978114.59592461 val_loss 206933.29687500\n",
      "epoch 7321 train_loss 10978114.59584328 val_loss 206933.29687500\n",
      "epoch 7322 train_loss 10978114.59573936 val_loss 206933.29687500\n",
      "epoch 7323 train_loss 10978114.59564903 val_loss 206933.29687500\n",
      "epoch 7324 train_loss 10978114.59556190 val_loss 206933.29687500\n",
      "epoch 7325 train_loss 10978114.59563477 val_loss 206933.29687500\n",
      "epoch 7326 train_loss 10978114.59555786 val_loss 206933.29687500\n",
      "epoch 7327 train_loss 10978114.59547844 val_loss 206933.29687500\n",
      "epoch 7328 train_loss 10978114.59535362 val_loss 206933.29687500\n",
      "epoch 7329 train_loss 10978114.59526054 val_loss 206933.29687500\n",
      "epoch 7330 train_loss 10978114.59517609 val_loss 206933.29687500\n",
      "epoch 7331 train_loss 10978114.59510101 val_loss 206933.29687500\n",
      "epoch 7332 train_loss 10978114.59500244 val_loss 206933.29687500\n",
      "epoch 7333 train_loss 10978114.59490898 val_loss 206933.29687500\n",
      "epoch 7334 train_loss 10978114.59482140 val_loss 206933.29687500\n",
      "epoch 7335 train_loss 10978114.59471405 val_loss 206933.29687500\n",
      "epoch 7336 train_loss 10978114.59461067 val_loss 206933.29687500\n",
      "epoch 7337 train_loss 10978114.59453331 val_loss 206933.29687500\n",
      "epoch 7338 train_loss 10978114.59444618 val_loss 206933.29687500\n",
      "epoch 7339 train_loss 10978114.59440193 val_loss 206933.29687500\n",
      "epoch 7340 train_loss 10978114.59429421 val_loss 206933.29687500\n",
      "epoch 7341 train_loss 10978114.59423813 val_loss 206933.29687500\n",
      "epoch 7342 train_loss 10978114.59414566 val_loss 206933.29687500\n",
      "epoch 7343 train_loss 10978114.59404770 val_loss 206933.29687500\n",
      "epoch 7344 train_loss 10978114.59395851 val_loss 206933.29687500\n",
      "epoch 7345 train_loss 10978114.59386337 val_loss 206933.29687500\n",
      "epoch 7346 train_loss 10978114.59375359 val_loss 206933.29687500\n",
      "epoch 7347 train_loss 10978114.59367302 val_loss 206933.29687500\n",
      "epoch 7348 train_loss 10978114.59357140 val_loss 206933.29687500\n",
      "epoch 7349 train_loss 10978114.59347588 val_loss 206933.29687500\n",
      "epoch 7350 train_loss 10978114.59338615 val_loss 206933.29687500\n",
      "epoch 7351 train_loss 10978114.59331078 val_loss 206933.29687500\n",
      "epoch 7352 train_loss 10978114.59321243 val_loss 206933.29687500\n",
      "epoch 7353 train_loss 10978114.59312096 val_loss 206933.29687500\n",
      "epoch 7354 train_loss 10978114.59301834 val_loss 206933.29687500\n",
      "epoch 7355 train_loss 10978114.59294243 val_loss 206933.29687500\n",
      "epoch 7356 train_loss 10978114.59287544 val_loss 206933.29687500\n",
      "epoch 7357 train_loss 10978114.59278969 val_loss 206933.29687500\n",
      "epoch 7358 train_loss 10978114.59269455 val_loss 206933.29687500\n",
      "epoch 7359 train_loss 10978114.59257233 val_loss 206933.29687500\n",
      "epoch 7360 train_loss 10978114.59250404 val_loss 206933.29687500\n",
      "epoch 7361 train_loss 10978114.59243980 val_loss 206933.29687500\n",
      "epoch 7362 train_loss 10978114.59234527 val_loss 206933.29687500\n",
      "epoch 7363 train_loss 10978114.59224838 val_loss 206933.29687500\n",
      "epoch 7364 train_loss 10978114.59216530 val_loss 206933.29687500\n",
      "epoch 7365 train_loss 10978114.59209519 val_loss 206933.29687500\n",
      "epoch 7366 train_loss 10978114.59200439 val_loss 206933.29687500\n",
      "epoch 7367 train_loss 10978114.59191849 val_loss 206933.29687500\n",
      "epoch 7368 train_loss 10978114.59181961 val_loss 206933.29687500\n",
      "epoch 7369 train_loss 10978114.59172424 val_loss 206933.29687500\n",
      "epoch 7370 train_loss 10978114.59163017 val_loss 206933.29687500\n",
      "epoch 7371 train_loss 10978114.59152931 val_loss 206933.29687500\n",
      "epoch 7372 train_loss 10978114.59145622 val_loss 206933.29687500\n",
      "epoch 7373 train_loss 10978114.59136215 val_loss 206933.29687500\n",
      "epoch 7374 train_loss 10978114.59125946 val_loss 206933.29687500\n",
      "epoch 7375 train_loss 10978114.59116081 val_loss 206933.29687500\n",
      "epoch 7376 train_loss 10978114.59107803 val_loss 206933.29687500\n",
      "epoch 7377 train_loss 10978114.59106392 val_loss 206933.29687500\n",
      "epoch 7378 train_loss 10978114.59097038 val_loss 206933.29687500\n",
      "epoch 7379 train_loss 10978114.59088417 val_loss 206933.29687500\n",
      "epoch 7380 train_loss 10978114.59078545 val_loss 206933.29687500\n",
      "epoch 7381 train_loss 10978114.59070664 val_loss 206933.29687500\n",
      "epoch 7382 train_loss 10978114.59060425 val_loss 206933.29687500\n",
      "epoch 7383 train_loss 10978114.59049881 val_loss 206933.29687500\n",
      "epoch 7384 train_loss 10978114.59041672 val_loss 206933.29687500\n",
      "epoch 7385 train_loss 10978114.59032227 val_loss 206933.29687500\n",
      "epoch 7386 train_loss 10978114.59022537 val_loss 206933.29687500\n",
      "epoch 7387 train_loss 10978114.59014572 val_loss 206933.29687500\n",
      "epoch 7388 train_loss 10978114.59007263 val_loss 206933.29687500\n",
      "epoch 7389 train_loss 10978114.58997589 val_loss 206933.29687500\n",
      "epoch 7390 train_loss 10978114.58987282 val_loss 206933.29687500\n",
      "epoch 7391 train_loss 10978114.58979439 val_loss 206933.29687500\n",
      "epoch 7392 train_loss 10978114.58970032 val_loss 206933.29687500\n",
      "epoch 7393 train_loss 10978114.58960297 val_loss 206933.29687500\n",
      "epoch 7394 train_loss 10978114.58949516 val_loss 206933.29687500\n",
      "epoch 7395 train_loss 10978114.58940918 val_loss 206933.29687500\n",
      "epoch 7396 train_loss 10978114.58932037 val_loss 206933.29687500\n",
      "epoch 7397 train_loss 10978114.58923233 val_loss 206933.29687500\n",
      "epoch 7398 train_loss 10978114.58915787 val_loss 206933.29687500\n",
      "epoch 7399 train_loss 10978114.58905769 val_loss 206933.29687500\n",
      "epoch 7400 train_loss 10978114.58896416 val_loss 206933.29687500\n",
      "epoch 7401 train_loss 10978114.58888306 val_loss 206933.29687500\n",
      "epoch 7402 train_loss 10978114.58879044 val_loss 206933.29687500\n",
      "epoch 7403 train_loss 10978114.58870254 val_loss 206933.29687500\n",
      "epoch 7404 train_loss 10978114.58861015 val_loss 206933.29687500\n",
      "epoch 7405 train_loss 10978114.58851303 val_loss 206933.29687500\n",
      "epoch 7406 train_loss 10978114.58842682 val_loss 206933.29687500\n",
      "epoch 7407 train_loss 10978114.58833748 val_loss 206933.29687500\n",
      "epoch 7408 train_loss 10978114.58823631 val_loss 206933.29687500\n",
      "epoch 7409 train_loss 10978114.58814850 val_loss 206933.29687500\n",
      "epoch 7410 train_loss 10978114.58805870 val_loss 206933.29687500\n",
      "epoch 7411 train_loss 10978114.58798584 val_loss 206933.29687500\n",
      "epoch 7412 train_loss 10978114.58789314 val_loss 206933.29687500\n",
      "epoch 7413 train_loss 10978114.58778786 val_loss 206933.29687500\n",
      "epoch 7414 train_loss 10978114.58774856 val_loss 206933.29687500\n",
      "epoch 7415 train_loss 10978114.58768547 val_loss 206933.29687500\n",
      "epoch 7416 train_loss 10978114.58759102 val_loss 206933.29687500\n",
      "epoch 7417 train_loss 10978114.58749542 val_loss 206933.29687500\n",
      "epoch 7418 train_loss 10978114.58740723 val_loss 206933.29687500\n",
      "epoch 7419 train_loss 10978114.58734596 val_loss 206933.29687500\n",
      "epoch 7420 train_loss 10978114.58726334 val_loss 206933.29687500\n",
      "epoch 7421 train_loss 10978114.58717522 val_loss 206933.29687500\n",
      "epoch 7422 train_loss 10978114.58706551 val_loss 206933.29687500\n",
      "epoch 7423 train_loss 10978114.58697884 val_loss 206933.29687500\n",
      "epoch 7424 train_loss 10978114.58688980 val_loss 206933.29687500\n",
      "epoch 7425 train_loss 10978114.58678764 val_loss 206933.29687500\n",
      "epoch 7426 train_loss 10978114.58673866 val_loss 206933.29687500\n",
      "epoch 7427 train_loss 10978114.58663612 val_loss 206933.29687500\n",
      "epoch 7428 train_loss 10978114.58658249 val_loss 206933.29687500\n",
      "epoch 7429 train_loss 10978114.58647850 val_loss 206933.29687500\n",
      "epoch 7430 train_loss 10978114.58639214 val_loss 206933.29687500\n",
      "epoch 7431 train_loss 10978114.58630684 val_loss 206933.29687500\n",
      "epoch 7432 train_loss 10978114.58621185 val_loss 206933.29687500\n",
      "epoch 7433 train_loss 10978114.58612381 val_loss 206933.29687500\n",
      "epoch 7434 train_loss 10978114.58604378 val_loss 206933.29687500\n",
      "epoch 7435 train_loss 10978114.58593956 val_loss 206933.29687500\n",
      "epoch 7436 train_loss 10978114.58583710 val_loss 206933.29687500\n",
      "epoch 7437 train_loss 10978114.58575508 val_loss 206933.29687500\n",
      "epoch 7438 train_loss 10978114.58565285 val_loss 206933.29687500\n",
      "epoch 7439 train_loss 10978114.58556404 val_loss 206933.29687500\n",
      "epoch 7440 train_loss 10978114.58547707 val_loss 206933.29687500\n",
      "epoch 7441 train_loss 10978114.58538437 val_loss 206933.29687500\n",
      "epoch 7442 train_loss 10978114.58529694 val_loss 206933.29687500\n",
      "epoch 7443 train_loss 10978114.58519478 val_loss 206933.29687500\n",
      "epoch 7444 train_loss 10978114.58510529 val_loss 206933.29687500\n",
      "epoch 7445 train_loss 10978114.58502029 val_loss 206933.29687500\n",
      "epoch 7446 train_loss 10978114.58493538 val_loss 206933.29687500\n",
      "epoch 7447 train_loss 10978114.58483452 val_loss 206933.29687500\n",
      "epoch 7448 train_loss 10978114.58474777 val_loss 206933.29687500\n",
      "epoch 7449 train_loss 10978114.58465393 val_loss 206933.29687500\n",
      "epoch 7450 train_loss 10978114.58455254 val_loss 206933.29687500\n",
      "epoch 7451 train_loss 10978114.58447914 val_loss 206933.29687500\n",
      "epoch 7452 train_loss 10978114.58438179 val_loss 206933.29687500\n",
      "epoch 7453 train_loss 10978114.58430512 val_loss 206933.29687500\n",
      "epoch 7454 train_loss 10978114.58421913 val_loss 206933.29687500\n",
      "epoch 7455 train_loss 10978114.58419754 val_loss 206933.29687500\n",
      "epoch 7456 train_loss 10978114.58411819 val_loss 206933.29687500\n",
      "epoch 7457 train_loss 10978114.58403458 val_loss 206933.29687500\n",
      "epoch 7458 train_loss 10978114.58390793 val_loss 206933.29687500\n",
      "epoch 7459 train_loss 10978114.58387215 val_loss 206933.29687500\n",
      "epoch 7460 train_loss 10978114.58380150 val_loss 206933.29687500\n",
      "epoch 7461 train_loss 10978114.58370491 val_loss 206933.29687500\n",
      "epoch 7462 train_loss 10978114.58362419 val_loss 206933.29687500\n",
      "epoch 7463 train_loss 10978114.58353020 val_loss 206933.29687500\n",
      "epoch 7464 train_loss 10978114.58343750 val_loss 206933.29687500\n",
      "epoch 7465 train_loss 10978114.58332993 val_loss 206933.29687500\n",
      "epoch 7466 train_loss 10978114.58329956 val_loss 206933.29687500\n",
      "epoch 7467 train_loss 10978114.58313888 val_loss 206933.29687500\n",
      "epoch 7468 train_loss 10978114.58304123 val_loss 206933.29687500\n",
      "epoch 7469 train_loss 10978114.58294403 val_loss 206933.29687500\n",
      "epoch 7470 train_loss 10978114.58285438 val_loss 206933.29687500\n",
      "epoch 7471 train_loss 10978114.58276886 val_loss 206933.29687500\n",
      "epoch 7472 train_loss 10978114.58266167 val_loss 206933.29687500\n",
      "epoch 7473 train_loss 10978114.58257896 val_loss 206933.29687500\n",
      "epoch 7474 train_loss 10978114.58249657 val_loss 206933.29687500\n",
      "epoch 7475 train_loss 10978114.58240868 val_loss 206933.29687500\n",
      "epoch 7476 train_loss 10978114.58232040 val_loss 206933.29687500\n",
      "epoch 7477 train_loss 10978114.58223961 val_loss 206933.29687500\n",
      "epoch 7478 train_loss 10978114.58213120 val_loss 206933.29687500\n",
      "epoch 7479 train_loss 10978114.58202080 val_loss 206933.29687500\n",
      "epoch 7480 train_loss 10978114.58194351 val_loss 206933.29687500\n",
      "epoch 7481 train_loss 10978114.58184074 val_loss 206933.29687500\n",
      "epoch 7482 train_loss 10978114.58174194 val_loss 206933.29687500\n",
      "epoch 7483 train_loss 10978114.58167824 val_loss 206933.29687500\n",
      "epoch 7484 train_loss 10978114.58154999 val_loss 206933.29687500\n",
      "epoch 7485 train_loss 10978114.58146385 val_loss 206933.29687500\n",
      "epoch 7486 train_loss 10978114.58135078 val_loss 206933.29687500\n",
      "epoch 7487 train_loss 10978114.58128761 val_loss 206933.29687500\n",
      "epoch 7488 train_loss 10978114.58125259 val_loss 206933.29687500\n",
      "epoch 7489 train_loss 10978114.58114250 val_loss 206933.29687500\n",
      "epoch 7490 train_loss 10978114.58102890 val_loss 206933.29687500\n",
      "epoch 7491 train_loss 10978114.58093727 val_loss 206933.29687500\n",
      "epoch 7492 train_loss 10978114.58096329 val_loss 206933.29687500\n",
      "epoch 7493 train_loss 10978114.58086960 val_loss 206933.29687500\n",
      "epoch 7494 train_loss 10978114.58080116 val_loss 206933.29687500\n",
      "epoch 7495 train_loss 10978114.58076653 val_loss 206933.29687500\n",
      "epoch 7496 train_loss 10978114.58068298 val_loss 206933.29687500\n",
      "epoch 7497 train_loss 10978114.58059082 val_loss 206933.29687500\n",
      "epoch 7498 train_loss 10978114.58048660 val_loss 206933.29687500\n",
      "epoch 7499 train_loss 10978114.58039062 val_loss 206933.29687500\n",
      "epoch 7500 train_loss 10978114.58032356 val_loss 206933.29687500\n",
      "epoch 7501 train_loss 10978114.58021805 val_loss 206933.29687500\n",
      "epoch 7502 train_loss 10978114.58013519 val_loss 206933.29687500\n",
      "epoch 7503 train_loss 10978114.58004067 val_loss 206933.29687500\n",
      "epoch 7504 train_loss 10978114.58002289 val_loss 206933.29687500\n",
      "epoch 7505 train_loss 10978114.57993340 val_loss 206933.29687500\n",
      "epoch 7506 train_loss 10978114.57984161 val_loss 206933.29687500\n",
      "epoch 7507 train_loss 10978114.57974838 val_loss 206933.29687500\n",
      "epoch 7508 train_loss 10978114.57963623 val_loss 206933.29687500\n",
      "epoch 7509 train_loss 10978114.57946480 val_loss 206933.29687500\n",
      "epoch 7510 train_loss 10978114.57936943 val_loss 206933.29687500\n",
      "epoch 7511 train_loss 10978114.57930084 val_loss 206933.29687500\n",
      "epoch 7512 train_loss 10978114.57920456 val_loss 206933.29687500\n",
      "epoch 7513 train_loss 10978114.57913223 val_loss 206933.29687500\n",
      "epoch 7514 train_loss 10978114.57907951 val_loss 206933.29687500\n",
      "epoch 7515 train_loss 10978114.57900032 val_loss 206933.29687500\n",
      "epoch 7516 train_loss 10978114.57890831 val_loss 206933.29687500\n",
      "epoch 7517 train_loss 10978114.57882713 val_loss 206933.29687500\n",
      "epoch 7518 train_loss 10978114.57872505 val_loss 206933.29687500\n",
      "epoch 7519 train_loss 10978114.57863762 val_loss 206933.29687500\n",
      "epoch 7520 train_loss 10978114.57852547 val_loss 206933.29687500\n",
      "epoch 7521 train_loss 10978114.57844688 val_loss 206933.29687500\n",
      "epoch 7522 train_loss 10978114.57834496 val_loss 206933.29687500\n",
      "epoch 7523 train_loss 10978114.57824295 val_loss 206933.29687500\n",
      "epoch 7524 train_loss 10978114.57823166 val_loss 206933.29687500\n",
      "epoch 7525 train_loss 10978114.57815620 val_loss 206933.29687500\n",
      "epoch 7526 train_loss 10978114.57804710 val_loss 206933.29687500\n",
      "epoch 7527 train_loss 10978114.57796089 val_loss 206933.29687500\n",
      "epoch 7528 train_loss 10978114.57789246 val_loss 206933.29687500\n",
      "epoch 7529 train_loss 10978114.57779762 val_loss 206933.29687500\n",
      "epoch 7530 train_loss 10978114.57770737 val_loss 206933.29687500\n",
      "epoch 7531 train_loss 10978114.57762032 val_loss 206933.29687500\n",
      "epoch 7532 train_loss 10978114.57754059 val_loss 206933.29687500\n",
      "epoch 7533 train_loss 10978114.57746422 val_loss 206933.29687500\n",
      "epoch 7534 train_loss 10978114.57737206 val_loss 206933.29687500\n",
      "epoch 7535 train_loss 10978114.57727951 val_loss 206933.29687500\n",
      "epoch 7536 train_loss 10978114.57718933 val_loss 206933.29687500\n",
      "epoch 7537 train_loss 10978114.57708702 val_loss 206933.29687500\n",
      "epoch 7538 train_loss 10978114.57700310 val_loss 206933.29687500\n",
      "epoch 7539 train_loss 10978114.57692337 val_loss 206933.29687500\n",
      "epoch 7540 train_loss 10978114.57689415 val_loss 206933.29687500\n",
      "epoch 7541 train_loss 10978114.57680679 val_loss 206933.29687500\n",
      "epoch 7542 train_loss 10978114.57673279 val_loss 206933.29687500\n",
      "epoch 7543 train_loss 10978114.57664230 val_loss 206933.29687500\n",
      "epoch 7544 train_loss 10978114.57653854 val_loss 206933.29687500\n",
      "epoch 7545 train_loss 10978114.57644135 val_loss 206933.29687500\n",
      "epoch 7546 train_loss 10978114.57636841 val_loss 206933.29687500\n",
      "epoch 7547 train_loss 10978114.57626701 val_loss 206933.29687500\n",
      "epoch 7548 train_loss 10978114.57619194 val_loss 206933.29687500\n",
      "epoch 7549 train_loss 10978114.57610176 val_loss 206933.29687500\n",
      "epoch 7550 train_loss 10978114.57599373 val_loss 206933.29687500\n",
      "epoch 7551 train_loss 10978114.57592575 val_loss 206933.29687500\n",
      "epoch 7552 train_loss 10978114.57585663 val_loss 206933.29687500\n",
      "epoch 7553 train_loss 10978114.57577126 val_loss 206933.29687500\n",
      "epoch 7554 train_loss 10978114.57566650 val_loss 206933.29687500\n",
      "epoch 7555 train_loss 10978114.57559059 val_loss 206933.29687500\n",
      "epoch 7556 train_loss 10978114.57549164 val_loss 206933.29687500\n",
      "epoch 7557 train_loss 10978114.57540596 val_loss 206933.29687500\n",
      "epoch 7558 train_loss 10978114.57532120 val_loss 206933.29687500\n",
      "epoch 7559 train_loss 10978114.57521896 val_loss 206933.29687500\n",
      "epoch 7560 train_loss 10978114.57512810 val_loss 206933.29687500\n",
      "epoch 7561 train_loss 10978114.57501724 val_loss 206933.29687500\n",
      "epoch 7562 train_loss 10978114.57496742 val_loss 206933.29687500\n",
      "epoch 7563 train_loss 10978114.57490913 val_loss 206933.29687500\n",
      "epoch 7564 train_loss 10978114.57483742 val_loss 206933.29687500\n",
      "epoch 7565 train_loss 10978114.57474083 val_loss 206933.29687500\n",
      "epoch 7566 train_loss 10978114.57464546 val_loss 206933.29687500\n",
      "epoch 7567 train_loss 10978114.57456978 val_loss 206933.29687500\n",
      "epoch 7568 train_loss 10978114.57445213 val_loss 206933.29687500\n",
      "epoch 7569 train_loss 10978114.57438156 val_loss 206933.29687500\n",
      "epoch 7570 train_loss 10978114.57427048 val_loss 206933.29687500\n",
      "epoch 7571 train_loss 10978114.57417198 val_loss 206933.29687500\n",
      "epoch 7572 train_loss 10978114.57409264 val_loss 206933.29687500\n",
      "epoch 7573 train_loss 10978114.57400551 val_loss 206933.29687500\n",
      "epoch 7574 train_loss 10978114.57393005 val_loss 206933.29687500\n",
      "epoch 7575 train_loss 10978114.57382118 val_loss 206933.29687500\n",
      "epoch 7576 train_loss 10978114.57372627 val_loss 206933.29687500\n",
      "epoch 7577 train_loss 10978114.57363876 val_loss 206933.29687500\n",
      "epoch 7578 train_loss 10978114.57354660 val_loss 206933.29687500\n",
      "epoch 7579 train_loss 10978114.57344482 val_loss 206933.29687500\n",
      "epoch 7580 train_loss 10978114.57335274 val_loss 206933.29687500\n",
      "epoch 7581 train_loss 10978114.57327797 val_loss 206933.29687500\n",
      "epoch 7582 train_loss 10978114.57315559 val_loss 206933.29687500\n",
      "epoch 7583 train_loss 10978114.57308006 val_loss 206933.29687500\n",
      "epoch 7584 train_loss 10978114.57298302 val_loss 206933.29687500\n",
      "epoch 7585 train_loss 10978114.57289688 val_loss 206933.29687500\n",
      "epoch 7586 train_loss 10978114.57280945 val_loss 206933.29687500\n",
      "epoch 7587 train_loss 10978114.57271599 val_loss 206933.29687500\n",
      "epoch 7588 train_loss 10978114.57262985 val_loss 206933.29687500\n",
      "epoch 7589 train_loss 10978114.57253387 val_loss 206933.29687500\n",
      "epoch 7590 train_loss 10978114.57244896 val_loss 206933.29687500\n",
      "epoch 7591 train_loss 10978114.57233345 val_loss 206933.29687500\n",
      "epoch 7592 train_loss 10978114.57227982 val_loss 206933.29687500\n",
      "epoch 7593 train_loss 10978114.57217575 val_loss 206933.29687500\n",
      "epoch 7594 train_loss 10978114.57209267 val_loss 206933.29687500\n",
      "epoch 7595 train_loss 10978114.57199555 val_loss 206933.29687500\n",
      "epoch 7596 train_loss 10978114.57191399 val_loss 206933.29687500\n",
      "epoch 7597 train_loss 10978114.57179810 val_loss 206933.29687500\n",
      "epoch 7598 train_loss 10978114.57172150 val_loss 206933.29687500\n",
      "epoch 7599 train_loss 10978114.57163139 val_loss 206933.29687500\n",
      "epoch 7600 train_loss 10978114.57152962 val_loss 206933.29687500\n",
      "epoch 7601 train_loss 10978114.57143204 val_loss 206933.29687500\n",
      "epoch 7602 train_loss 10978114.57137962 val_loss 206933.29687500\n",
      "epoch 7603 train_loss 10978114.57128502 val_loss 206933.29687500\n",
      "epoch 7604 train_loss 10978114.57120689 val_loss 206933.29687500\n",
      "epoch 7605 train_loss 10978114.57110794 val_loss 206933.29687500\n",
      "epoch 7606 train_loss 10978114.57102043 val_loss 206933.29687500\n",
      "epoch 7607 train_loss 10978114.57091423 val_loss 206933.29687500\n",
      "epoch 7608 train_loss 10978114.57082062 val_loss 206933.29687500\n",
      "epoch 7609 train_loss 10978114.57072868 val_loss 206933.29687500\n",
      "epoch 7610 train_loss 10978114.57066414 val_loss 206933.29687500\n",
      "epoch 7611 train_loss 10978114.57059578 val_loss 206933.29687500\n",
      "epoch 7612 train_loss 10978114.57051384 val_loss 206933.29687500\n",
      "epoch 7613 train_loss 10978114.57040665 val_loss 206933.29687500\n",
      "epoch 7614 train_loss 10978114.57034149 val_loss 206933.29687500\n",
      "epoch 7615 train_loss 10978114.57023613 val_loss 206933.29687500\n",
      "epoch 7616 train_loss 10978114.57019043 val_loss 206933.29687500\n",
      "epoch 7617 train_loss 10978114.57010422 val_loss 206933.29687500\n",
      "epoch 7618 train_loss 10978114.56999580 val_loss 206933.29687500\n",
      "epoch 7619 train_loss 10978114.56991448 val_loss 206933.29687500\n",
      "epoch 7620 train_loss 10978114.56981186 val_loss 206933.29687500\n",
      "epoch 7621 train_loss 10978114.56971535 val_loss 206933.29687500\n",
      "epoch 7622 train_loss 10978114.56961555 val_loss 206933.29687500\n",
      "epoch 7623 train_loss 10978114.56952919 val_loss 206933.29687500\n",
      "epoch 7624 train_loss 10978114.56944046 val_loss 206933.29687500\n",
      "epoch 7625 train_loss 10978114.56935661 val_loss 206933.29687500\n",
      "epoch 7626 train_loss 10978114.56931229 val_loss 206933.29687500\n",
      "epoch 7627 train_loss 10978114.56918976 val_loss 206933.29687500\n",
      "epoch 7628 train_loss 10978114.56912445 val_loss 206933.29687500\n",
      "epoch 7629 train_loss 10978114.56901703 val_loss 206933.29687500\n",
      "epoch 7630 train_loss 10978114.56892426 val_loss 206933.29687500\n",
      "epoch 7631 train_loss 10978114.56883171 val_loss 206933.29687500\n",
      "epoch 7632 train_loss 10978114.56876823 val_loss 206933.29687500\n",
      "epoch 7633 train_loss 10978114.56868622 val_loss 206933.29687500\n",
      "epoch 7634 train_loss 10978114.56859146 val_loss 206933.29687500\n",
      "epoch 7635 train_loss 10978114.56850746 val_loss 206933.29687500\n",
      "epoch 7636 train_loss 10978114.56840256 val_loss 206933.29687500\n",
      "epoch 7637 train_loss 10978114.56832932 val_loss 206933.29687500\n",
      "epoch 7638 train_loss 10978114.56822868 val_loss 206933.29687500\n",
      "epoch 7639 train_loss 10978114.56815811 val_loss 206933.29687500\n",
      "epoch 7640 train_loss 10978114.56806931 val_loss 206933.29687500\n",
      "epoch 7641 train_loss 10978114.56796066 val_loss 206933.29687500\n",
      "epoch 7642 train_loss 10978114.56787788 val_loss 206933.29687500\n",
      "epoch 7643 train_loss 10978114.56778564 val_loss 206933.29687500\n",
      "epoch 7644 train_loss 10978114.56770096 val_loss 206933.29687500\n",
      "epoch 7645 train_loss 10978114.56762527 val_loss 206933.29687500\n",
      "epoch 7646 train_loss 10978114.56754524 val_loss 206933.29687500\n",
      "epoch 7647 train_loss 10978114.56745209 val_loss 206933.29687500\n",
      "epoch 7648 train_loss 10978114.56734596 val_loss 206933.29687500\n",
      "epoch 7649 train_loss 10978114.56725449 val_loss 206933.29687500\n",
      "epoch 7650 train_loss 10978114.56714691 val_loss 206933.29687500\n",
      "epoch 7651 train_loss 10978114.56705322 val_loss 206933.29687500\n",
      "epoch 7652 train_loss 10978114.56696213 val_loss 206933.29687500\n",
      "epoch 7653 train_loss 10978114.56687363 val_loss 206933.29687500\n",
      "epoch 7654 train_loss 10978114.56678978 val_loss 206933.29687500\n",
      "epoch 7655 train_loss 10978114.56670242 val_loss 206933.29687500\n",
      "epoch 7656 train_loss 10978114.56661484 val_loss 206933.29687500\n",
      "epoch 7657 train_loss 10978114.56651543 val_loss 206933.29687500\n",
      "epoch 7658 train_loss 10978114.56642113 val_loss 206933.29687500\n",
      "epoch 7659 train_loss 10978114.56632660 val_loss 206933.29687500\n",
      "epoch 7660 train_loss 10978114.56623703 val_loss 206933.29687500\n",
      "epoch 7661 train_loss 10978114.56614746 val_loss 206933.29687500\n",
      "epoch 7662 train_loss 10978114.56604813 val_loss 206933.29687500\n",
      "epoch 7663 train_loss 10978114.56604050 val_loss 206933.29687500\n",
      "epoch 7664 train_loss 10978114.56594391 val_loss 206933.29687500\n",
      "epoch 7665 train_loss 10978114.56585159 val_loss 206933.29687500\n",
      "epoch 7666 train_loss 10978114.56575897 val_loss 206933.29687500\n",
      "epoch 7667 train_loss 10978114.56567093 val_loss 206933.29687500\n",
      "epoch 7668 train_loss 10978114.56558090 val_loss 206933.29687500\n",
      "epoch 7669 train_loss 10978114.56548683 val_loss 206933.29687500\n",
      "epoch 7670 train_loss 10978114.56539116 val_loss 206933.29687500\n",
      "epoch 7671 train_loss 10978114.56530708 val_loss 206933.29687500\n",
      "epoch 7672 train_loss 10978114.56521271 val_loss 206933.29687500\n",
      "epoch 7673 train_loss 10978114.56512108 val_loss 206933.29687500\n",
      "epoch 7674 train_loss 10978114.56502693 val_loss 206933.29687500\n",
      "epoch 7675 train_loss 10978114.56493210 val_loss 206933.29687500\n",
      "epoch 7676 train_loss 10978114.56484268 val_loss 206933.29687500\n",
      "epoch 7677 train_loss 10978114.56474846 val_loss 206933.29687500\n",
      "epoch 7678 train_loss 10978114.56467621 val_loss 206933.29687500\n",
      "epoch 7679 train_loss 10978114.56457901 val_loss 206933.29687500\n",
      "epoch 7680 train_loss 10978114.56447769 val_loss 206933.29687500\n",
      "epoch 7681 train_loss 10978114.56439415 val_loss 206933.29687500\n",
      "epoch 7682 train_loss 10978114.56428825 val_loss 206933.29687500\n",
      "epoch 7683 train_loss 10978114.56420280 val_loss 206933.29687500\n",
      "epoch 7684 train_loss 10978114.56414856 val_loss 206933.29687500\n",
      "epoch 7685 train_loss 10978114.56407661 val_loss 206933.29687500\n",
      "epoch 7686 train_loss 10978114.56399444 val_loss 206933.29687500\n",
      "epoch 7687 train_loss 10978114.56392136 val_loss 206933.29687500\n",
      "epoch 7688 train_loss 10978114.56381248 val_loss 206933.29687500\n",
      "epoch 7689 train_loss 10978114.56370850 val_loss 206933.29687500\n",
      "epoch 7690 train_loss 10978114.56363152 val_loss 206933.29687500\n",
      "epoch 7691 train_loss 10978114.56351036 val_loss 206933.29687500\n",
      "epoch 7692 train_loss 10978114.56342407 val_loss 206933.29687500\n",
      "epoch 7693 train_loss 10978114.56336052 val_loss 206933.29687500\n",
      "epoch 7694 train_loss 10978114.56330208 val_loss 206933.29687500\n",
      "epoch 7695 train_loss 10978114.56325150 val_loss 206933.29687500\n",
      "epoch 7696 train_loss 10978114.56315582 val_loss 206933.29687500\n",
      "epoch 7697 train_loss 10978114.56305389 val_loss 206933.29687500\n",
      "epoch 7698 train_loss 10978114.56297340 val_loss 206933.29687500\n",
      "epoch 7699 train_loss 10978114.56288444 val_loss 206933.29687500\n",
      "epoch 7700 train_loss 10978114.56278275 val_loss 206933.29687500\n",
      "epoch 7701 train_loss 10978114.56270439 val_loss 206933.29687500\n",
      "epoch 7702 train_loss 10978114.56260811 val_loss 206933.29687500\n",
      "epoch 7703 train_loss 10978114.56253784 val_loss 206933.29687500\n",
      "epoch 7704 train_loss 10978114.56243233 val_loss 206933.29687500\n",
      "epoch 7705 train_loss 10978114.56234436 val_loss 206933.29687500\n",
      "epoch 7706 train_loss 10978114.56224419 val_loss 206933.29687500\n",
      "epoch 7707 train_loss 10978114.56213486 val_loss 206933.29687500\n",
      "epoch 7708 train_loss 10978114.56205444 val_loss 206933.29687500\n",
      "epoch 7709 train_loss 10978114.56195732 val_loss 206933.29687500\n",
      "epoch 7710 train_loss 10978114.56188095 val_loss 206933.29687500\n",
      "epoch 7711 train_loss 10978114.56177422 val_loss 206933.29687500\n",
      "epoch 7712 train_loss 10978114.56167778 val_loss 206933.29687500\n",
      "epoch 7713 train_loss 10978114.56157860 val_loss 206933.29687500\n",
      "epoch 7714 train_loss 10978114.56151810 val_loss 206933.29687500\n",
      "epoch 7715 train_loss 10978114.56152649 val_loss 206933.29687500\n",
      "epoch 7716 train_loss 10978114.56144180 val_loss 206933.29687500\n",
      "epoch 7717 train_loss 10978114.56135658 val_loss 206933.29687500\n",
      "epoch 7718 train_loss 10978114.56127182 val_loss 206933.29687500\n",
      "epoch 7719 train_loss 10978114.56115662 val_loss 206933.29687500\n",
      "epoch 7720 train_loss 10978114.56108337 val_loss 206933.29687500\n",
      "epoch 7721 train_loss 10978114.56097687 val_loss 206933.29687500\n",
      "epoch 7722 train_loss 10978114.56088165 val_loss 206933.29687500\n",
      "epoch 7723 train_loss 10978114.56079407 val_loss 206933.29687500\n",
      "epoch 7724 train_loss 10978114.56069603 val_loss 206933.29687500\n",
      "epoch 7725 train_loss 10978114.56059601 val_loss 206933.29687500\n",
      "epoch 7726 train_loss 10978114.56052360 val_loss 206933.29687500\n",
      "epoch 7727 train_loss 10978114.56042702 val_loss 206933.29687500\n",
      "epoch 7728 train_loss 10978114.56032097 val_loss 206933.29687500\n",
      "epoch 7729 train_loss 10978114.56023720 val_loss 206933.29687500\n",
      "epoch 7730 train_loss 10978114.56015495 val_loss 206933.29687500\n",
      "epoch 7731 train_loss 10978114.56011292 val_loss 206933.29687500\n",
      "epoch 7732 train_loss 10978114.56001213 val_loss 206933.29687500\n",
      "epoch 7733 train_loss 10978114.55991341 val_loss 206933.29687500\n",
      "epoch 7734 train_loss 10978114.55983070 val_loss 206933.29687500\n",
      "epoch 7735 train_loss 10978114.55979492 val_loss 206933.29687500\n",
      "epoch 7736 train_loss 10978114.55973091 val_loss 206933.29687500\n",
      "epoch 7737 train_loss 10978114.55963722 val_loss 206933.29687500\n",
      "epoch 7738 train_loss 10978114.55954002 val_loss 206933.29687500\n",
      "epoch 7739 train_loss 10978114.55945114 val_loss 206933.29687500\n",
      "epoch 7740 train_loss 10978114.55936783 val_loss 206933.29687500\n",
      "epoch 7741 train_loss 10978114.55926193 val_loss 206933.29687500\n",
      "epoch 7742 train_loss 10978114.55917748 val_loss 206933.29687500\n",
      "epoch 7743 train_loss 10978114.55909317 val_loss 206933.29687500\n",
      "epoch 7744 train_loss 10978114.55899437 val_loss 206933.29687500\n",
      "epoch 7745 train_loss 10978114.55891045 val_loss 206933.29687500\n",
      "epoch 7746 train_loss 10978114.55880783 val_loss 206933.29687500\n",
      "epoch 7747 train_loss 10978114.55873032 val_loss 206933.29687500\n",
      "epoch 7748 train_loss 10978114.55863579 val_loss 206933.29687500\n",
      "epoch 7749 train_loss 10978114.55854019 val_loss 206933.29687500\n",
      "epoch 7750 train_loss 10978114.55845001 val_loss 206933.29687500\n",
      "epoch 7751 train_loss 10978114.55835548 val_loss 206933.29687500\n",
      "epoch 7752 train_loss 10978114.55827240 val_loss 206933.29687500\n",
      "epoch 7753 train_loss 10978114.55818092 val_loss 206933.29687500\n",
      "epoch 7754 train_loss 10978114.55807976 val_loss 206933.29687500\n",
      "epoch 7755 train_loss 10978114.55799469 val_loss 206933.29687500\n",
      "epoch 7756 train_loss 10978114.55789482 val_loss 206933.29687500\n",
      "epoch 7757 train_loss 10978114.55781059 val_loss 206933.29687500\n",
      "epoch 7758 train_loss 10978114.55769974 val_loss 206933.29687500\n",
      "epoch 7759 train_loss 10978114.55760849 val_loss 206933.29687500\n",
      "epoch 7760 train_loss 10978114.55750923 val_loss 206933.29687500\n",
      "epoch 7761 train_loss 10978114.55741447 val_loss 206933.29687500\n",
      "epoch 7762 train_loss 10978114.55732697 val_loss 206933.29687500\n",
      "epoch 7763 train_loss 10978114.55728127 val_loss 206933.29687500\n",
      "epoch 7764 train_loss 10978114.55718422 val_loss 206933.29687500\n",
      "epoch 7765 train_loss 10978114.55708405 val_loss 206933.29687500\n",
      "epoch 7766 train_loss 10978114.55699219 val_loss 206933.29687500\n",
      "epoch 7767 train_loss 10978114.55693825 val_loss 206933.29687500\n",
      "epoch 7768 train_loss 10978114.55684257 val_loss 206933.29687500\n",
      "epoch 7769 train_loss 10978114.55675232 val_loss 206933.29687500\n",
      "epoch 7770 train_loss 10978114.55664009 val_loss 206933.29687500\n",
      "epoch 7771 train_loss 10978114.55657028 val_loss 206933.29687500\n",
      "epoch 7772 train_loss 10978114.55648369 val_loss 206933.29687500\n",
      "epoch 7773 train_loss 10978114.55641754 val_loss 206933.29687500\n",
      "epoch 7774 train_loss 10978114.55638138 val_loss 206933.29687500\n",
      "epoch 7775 train_loss 10978114.55627281 val_loss 206933.29687500\n",
      "epoch 7776 train_loss 10978114.55618141 val_loss 206933.29687500\n",
      "epoch 7777 train_loss 10978114.55608322 val_loss 206933.29687500\n",
      "epoch 7778 train_loss 10978114.55599907 val_loss 206933.29687500\n",
      "epoch 7779 train_loss 10978114.55592293 val_loss 206933.29687500\n",
      "epoch 7780 train_loss 10978114.55585075 val_loss 206933.29687500\n",
      "epoch 7781 train_loss 10978114.55574623 val_loss 206933.29687500\n",
      "epoch 7782 train_loss 10978114.55566559 val_loss 206933.29687500\n",
      "epoch 7783 train_loss 10978114.55557457 val_loss 206933.29687500\n",
      "epoch 7784 train_loss 10978114.55548103 val_loss 206933.29687500\n",
      "epoch 7785 train_loss 10978114.55538864 val_loss 206933.29687500\n",
      "epoch 7786 train_loss 10978114.55529640 val_loss 206933.29687500\n",
      "epoch 7787 train_loss 10978114.55553642 val_loss 206933.29687500\n",
      "epoch 7788 train_loss 10978114.55545265 val_loss 206933.29687500\n",
      "epoch 7789 train_loss 10978114.55535835 val_loss 206933.29687500\n",
      "epoch 7790 train_loss 10978114.55527115 val_loss 206933.29687500\n",
      "epoch 7791 train_loss 10978114.55518341 val_loss 206933.29687500\n",
      "epoch 7792 train_loss 10978114.55510651 val_loss 206933.29687500\n",
      "epoch 7793 train_loss 10978114.55498642 val_loss 206933.29687500\n",
      "epoch 7794 train_loss 10978114.55489944 val_loss 206933.29687500\n",
      "epoch 7795 train_loss 10978114.55480400 val_loss 206933.29687500\n",
      "epoch 7796 train_loss 10978114.55471649 val_loss 206933.29687500\n",
      "epoch 7797 train_loss 10978114.55463730 val_loss 206933.29687500\n",
      "epoch 7798 train_loss 10978114.55453430 val_loss 206933.29687500\n",
      "epoch 7799 train_loss 10978114.55443665 val_loss 206933.29687500\n",
      "epoch 7800 train_loss 10978114.55435242 val_loss 206933.29687500\n",
      "epoch 7801 train_loss 10978114.55426735 val_loss 206933.29687500\n",
      "epoch 7802 train_loss 10978114.55419334 val_loss 206933.29687500\n",
      "epoch 7803 train_loss 10978114.55409752 val_loss 206933.29687500\n",
      "epoch 7804 train_loss 10978114.55399117 val_loss 206933.29687500\n",
      "epoch 7805 train_loss 10978114.55390839 val_loss 206933.29687500\n",
      "epoch 7806 train_loss 10978114.55381378 val_loss 206933.29687500\n",
      "epoch 7807 train_loss 10978114.55372566 val_loss 206933.29687500\n",
      "epoch 7808 train_loss 10978114.55363029 val_loss 206933.29687500\n",
      "epoch 7809 train_loss 10978114.55353821 val_loss 206933.29687500\n",
      "epoch 7810 train_loss 10978114.55344360 val_loss 206933.29687500\n",
      "epoch 7811 train_loss 10978114.55335152 val_loss 206933.29687500\n",
      "epoch 7812 train_loss 10978114.55325157 val_loss 206933.29687500\n",
      "epoch 7813 train_loss 10978114.55316742 val_loss 206933.29687500\n",
      "epoch 7814 train_loss 10978114.55308647 val_loss 206933.29687500\n",
      "epoch 7815 train_loss 10978114.55299370 val_loss 206933.29687500\n",
      "epoch 7816 train_loss 10978114.55290413 val_loss 206933.29687500\n",
      "epoch 7817 train_loss 10978114.55280525 val_loss 206933.29687500\n",
      "epoch 7818 train_loss 10978114.55267815 val_loss 206933.29687500\n",
      "epoch 7819 train_loss 10978114.55259453 val_loss 206933.29687500\n",
      "epoch 7820 train_loss 10978114.55252129 val_loss 206933.29687500\n",
      "epoch 7821 train_loss 10978114.55244400 val_loss 206933.29687500\n",
      "epoch 7822 train_loss 10978114.55232903 val_loss 206933.29687500\n",
      "epoch 7823 train_loss 10978114.55223297 val_loss 206933.29687500\n",
      "epoch 7824 train_loss 10978114.55217232 val_loss 206933.29687500\n",
      "epoch 7825 train_loss 10978114.55208893 val_loss 206933.29687500\n",
      "epoch 7826 train_loss 10978114.55198929 val_loss 206933.29687500\n",
      "epoch 7827 train_loss 10978114.55189316 val_loss 206933.29687500\n",
      "epoch 7828 train_loss 10978114.55180252 val_loss 206933.29687500\n",
      "epoch 7829 train_loss 10978114.55169395 val_loss 206933.29687500\n",
      "epoch 7830 train_loss 10978114.55164650 val_loss 206933.29687500\n",
      "epoch 7831 train_loss 10978114.55156158 val_loss 206933.29687500\n",
      "epoch 7832 train_loss 10978114.55146934 val_loss 206933.29687500\n",
      "epoch 7833 train_loss 10978114.55138428 val_loss 206933.29687500\n",
      "epoch 7834 train_loss 10978114.55130066 val_loss 206933.29687500\n",
      "epoch 7835 train_loss 10978114.55122185 val_loss 206933.29687500\n",
      "epoch 7836 train_loss 10978114.55114426 val_loss 206933.29687500\n",
      "epoch 7837 train_loss 10978114.55103409 val_loss 206933.29687500\n",
      "epoch 7838 train_loss 10978114.55094734 val_loss 206933.29687500\n",
      "epoch 7839 train_loss 10978114.55087212 val_loss 206933.29687500\n",
      "epoch 7840 train_loss 10978114.55076538 val_loss 206933.29687500\n",
      "epoch 7841 train_loss 10978114.55069328 val_loss 206933.29687500\n",
      "epoch 7842 train_loss 10978114.55060890 val_loss 206933.29687500\n",
      "epoch 7843 train_loss 10978114.55050606 val_loss 206933.29687500\n",
      "epoch 7844 train_loss 10978114.55044441 val_loss 206933.29687500\n",
      "epoch 7845 train_loss 10978114.55036041 val_loss 206933.29687500\n",
      "epoch 7846 train_loss 10978114.55026787 val_loss 206933.29687500\n",
      "epoch 7847 train_loss 10978114.55016464 val_loss 206933.29687500\n",
      "epoch 7848 train_loss 10978114.55008469 val_loss 206933.29687500\n",
      "epoch 7849 train_loss 10978114.54997269 val_loss 206933.29687500\n",
      "epoch 7850 train_loss 10978114.54987969 val_loss 206933.29687500\n",
      "epoch 7851 train_loss 10978114.54978279 val_loss 206933.29687500\n",
      "epoch 7852 train_loss 10978114.54970169 val_loss 206933.29687500\n",
      "epoch 7853 train_loss 10978114.54981949 val_loss 206933.29687500\n",
      "epoch 7854 train_loss 10978114.54970512 val_loss 206933.29687500\n",
      "epoch 7855 train_loss 10978114.54960846 val_loss 206933.29687500\n",
      "epoch 7856 train_loss 10978114.54952889 val_loss 206933.29687500\n",
      "epoch 7857 train_loss 10978114.54942169 val_loss 206933.29687500\n",
      "epoch 7858 train_loss 10978114.54935158 val_loss 206933.29687500\n",
      "epoch 7859 train_loss 10978114.54925705 val_loss 206933.29687500\n",
      "epoch 7860 train_loss 10978114.54917587 val_loss 206933.29687500\n",
      "epoch 7861 train_loss 10978114.54907074 val_loss 206933.29687500\n",
      "epoch 7862 train_loss 10978114.54898109 val_loss 206933.29687500\n",
      "epoch 7863 train_loss 10978114.54889091 val_loss 206933.30468750\n",
      "epoch 7864 train_loss 10978114.54878235 val_loss 206933.30468750\n",
      "epoch 7865 train_loss 10978114.54870857 val_loss 206933.30468750\n",
      "epoch 7866 train_loss 10978114.54859535 val_loss 206933.30468750\n",
      "epoch 7867 train_loss 10978114.54850838 val_loss 206933.29687500\n",
      "epoch 7868 train_loss 10978114.54841377 val_loss 206933.29687500\n",
      "epoch 7869 train_loss 10978114.54831886 val_loss 206933.29687500\n",
      "epoch 7870 train_loss 10978114.54824638 val_loss 206933.29687500\n",
      "epoch 7871 train_loss 10978114.54816215 val_loss 206933.29687500\n",
      "epoch 7872 train_loss 10978114.54806671 val_loss 206933.29687500\n",
      "epoch 7873 train_loss 10978114.54804359 val_loss 206933.29687500\n",
      "epoch 7874 train_loss 10978114.54793861 val_loss 206933.29687500\n",
      "epoch 7875 train_loss 10978114.54783707 val_loss 206933.29687500\n",
      "epoch 7876 train_loss 10978114.54774567 val_loss 206933.29687500\n",
      "epoch 7877 train_loss 10978114.54767174 val_loss 206933.29687500\n",
      "epoch 7878 train_loss 10978114.54756996 val_loss 206933.29687500\n",
      "epoch 7879 train_loss 10978114.54746529 val_loss 206933.29687500\n",
      "epoch 7880 train_loss 10978114.54737823 val_loss 206933.29687500\n",
      "epoch 7881 train_loss 10978114.54732910 val_loss 206933.29687500\n",
      "epoch 7882 train_loss 10978114.54722633 val_loss 206933.29687500\n",
      "epoch 7883 train_loss 10978114.54712097 val_loss 206933.29687500\n",
      "epoch 7884 train_loss 10978114.54705658 val_loss 206933.29687500\n",
      "epoch 7885 train_loss 10978114.54695457 val_loss 206933.29687500\n",
      "epoch 7886 train_loss 10978114.54687981 val_loss 206933.29687500\n",
      "epoch 7887 train_loss 10978114.54682480 val_loss 206933.29687500\n",
      "epoch 7888 train_loss 10978114.54674644 val_loss 206933.29687500\n",
      "epoch 7889 train_loss 10978114.54665947 val_loss 206933.29687500\n",
      "epoch 7890 train_loss 10978114.54657341 val_loss 206933.29687500\n",
      "epoch 7891 train_loss 10978114.54648285 val_loss 206933.29687500\n",
      "epoch 7892 train_loss 10978114.54638924 val_loss 206933.29687500\n",
      "epoch 7893 train_loss 10978114.54628090 val_loss 206933.29687500\n",
      "epoch 7894 train_loss 10978114.54618874 val_loss 206933.29687500\n",
      "epoch 7895 train_loss 10978114.54608231 val_loss 206933.29687500\n",
      "epoch 7896 train_loss 10978114.54600510 val_loss 206933.29687500\n",
      "epoch 7897 train_loss 10978114.54592186 val_loss 206933.29687500\n",
      "epoch 7898 train_loss 10978114.54582848 val_loss 206933.29687500\n",
      "epoch 7899 train_loss 10978114.54572983 val_loss 206933.29687500\n",
      "epoch 7900 train_loss 10978114.54565796 val_loss 206933.29687500\n",
      "epoch 7901 train_loss 10978114.54557198 val_loss 206933.29687500\n",
      "epoch 7902 train_loss 10978114.54549332 val_loss 206933.29687500\n",
      "epoch 7903 train_loss 10978114.54544571 val_loss 206933.29687500\n",
      "epoch 7904 train_loss 10978114.54535248 val_loss 206933.29687500\n",
      "epoch 7905 train_loss 10978114.54525902 val_loss 206933.29687500\n",
      "epoch 7906 train_loss 10978114.54516037 val_loss 206933.29687500\n",
      "epoch 7907 train_loss 10978114.54505493 val_loss 206933.29687500\n",
      "epoch 7908 train_loss 10978114.54496139 val_loss 206933.29687500\n",
      "epoch 7909 train_loss 10978114.54486710 val_loss 206933.29687500\n",
      "epoch 7910 train_loss 10978114.54478943 val_loss 206933.29687500\n",
      "epoch 7911 train_loss 10978114.54467606 val_loss 206933.29687500\n",
      "epoch 7912 train_loss 10978114.54458557 val_loss 206933.29687500\n",
      "epoch 7913 train_loss 10978114.54448906 val_loss 206933.29687500\n",
      "epoch 7914 train_loss 10978114.54440331 val_loss 206933.29687500\n",
      "epoch 7915 train_loss 10978114.54431366 val_loss 206933.29687500\n",
      "epoch 7916 train_loss 10978114.54420456 val_loss 206933.29687500\n",
      "epoch 7917 train_loss 10978114.54412331 val_loss 206933.29687500\n",
      "epoch 7918 train_loss 10978114.54401787 val_loss 206933.30468750\n",
      "epoch 7919 train_loss 10978114.54397652 val_loss 206933.30468750\n",
      "epoch 7920 train_loss 10978114.54387100 val_loss 206933.30468750\n",
      "epoch 7921 train_loss 10978114.54381500 val_loss 206933.30468750\n",
      "epoch 7922 train_loss 10978114.54371071 val_loss 206933.30468750\n",
      "epoch 7923 train_loss 10978114.54361870 val_loss 206933.30468750\n",
      "epoch 7924 train_loss 10978114.54352028 val_loss 206933.30468750\n",
      "epoch 7925 train_loss 10978114.54343956 val_loss 206933.30468750\n",
      "epoch 7926 train_loss 10978114.54335335 val_loss 206933.30468750\n",
      "epoch 7927 train_loss 10978114.54326866 val_loss 206933.30468750\n",
      "epoch 7928 train_loss 10978114.54316979 val_loss 206933.30468750\n",
      "epoch 7929 train_loss 10978114.54307861 val_loss 206933.30468750\n",
      "epoch 7930 train_loss 10978114.54298676 val_loss 206933.30468750\n",
      "epoch 7931 train_loss 10978114.54290970 val_loss 206933.30468750\n",
      "epoch 7932 train_loss 10978114.54281517 val_loss 206933.30468750\n",
      "epoch 7933 train_loss 10978114.54271172 val_loss 206933.30468750\n",
      "epoch 7934 train_loss 10978114.54260307 val_loss 206933.30468750\n",
      "epoch 7935 train_loss 10978114.54253586 val_loss 206933.30468750\n",
      "epoch 7936 train_loss 10978114.54241692 val_loss 206933.30468750\n",
      "epoch 7937 train_loss 10978114.54236549 val_loss 206933.30468750\n",
      "epoch 7938 train_loss 10978114.54227310 val_loss 206933.30468750\n",
      "epoch 7939 train_loss 10978114.54218033 val_loss 206933.30468750\n",
      "epoch 7940 train_loss 10978114.54217064 val_loss 206933.30468750\n",
      "epoch 7941 train_loss 10978114.54210037 val_loss 206933.30468750\n",
      "epoch 7942 train_loss 10978114.54201858 val_loss 206933.30468750\n",
      "epoch 7943 train_loss 10978114.54192223 val_loss 206933.30468750\n",
      "epoch 7944 train_loss 10978114.54182053 val_loss 206933.30468750\n",
      "epoch 7945 train_loss 10978114.54174049 val_loss 206933.30468750\n",
      "epoch 7946 train_loss 10978114.54165825 val_loss 206933.30468750\n",
      "epoch 7947 train_loss 10978114.54155502 val_loss 206933.30468750\n",
      "epoch 7948 train_loss 10978114.54147575 val_loss 206933.30468750\n",
      "epoch 7949 train_loss 10978114.54139038 val_loss 206933.30468750\n",
      "epoch 7950 train_loss 10978114.54129425 val_loss 206933.30468750\n",
      "epoch 7951 train_loss 10978114.54120506 val_loss 206933.30468750\n",
      "epoch 7952 train_loss 10978114.54109985 val_loss 206933.30468750\n",
      "epoch 7953 train_loss 10978114.54101082 val_loss 206933.30468750\n",
      "epoch 7954 train_loss 10978114.54095711 val_loss 206933.30468750\n",
      "epoch 7955 train_loss 10978114.54085350 val_loss 206933.30468750\n",
      "epoch 7956 train_loss 10978114.54077263 val_loss 206933.30468750\n",
      "epoch 7957 train_loss 10978114.54066627 val_loss 206933.30468750\n",
      "epoch 7958 train_loss 10978114.54057922 val_loss 206933.30468750\n",
      "epoch 7959 train_loss 10978114.54049309 val_loss 206933.30468750\n",
      "epoch 7960 train_loss 10978114.54039749 val_loss 206933.30468750\n",
      "epoch 7961 train_loss 10978114.54030792 val_loss 206933.30468750\n",
      "epoch 7962 train_loss 10978114.54021698 val_loss 206933.30468750\n",
      "epoch 7963 train_loss 10978114.54011749 val_loss 206933.30468750\n",
      "epoch 7964 train_loss 10978114.54001434 val_loss 206933.30468750\n",
      "epoch 7965 train_loss 10978114.53991966 val_loss 206933.30468750\n",
      "epoch 7966 train_loss 10978114.53984100 val_loss 206933.30468750\n",
      "epoch 7967 train_loss 10978114.53973747 val_loss 206933.30468750\n",
      "epoch 7968 train_loss 10978114.53964195 val_loss 206933.30468750\n",
      "epoch 7969 train_loss 10978114.53956245 val_loss 206933.30468750\n",
      "epoch 7970 train_loss 10978114.53946182 val_loss 206933.30468750\n",
      "epoch 7971 train_loss 10978114.53936668 val_loss 206933.30468750\n",
      "epoch 7972 train_loss 10978114.53928429 val_loss 206933.30468750\n",
      "epoch 7973 train_loss 10978114.53919334 val_loss 206933.30468750\n",
      "epoch 7974 train_loss 10978114.53912483 val_loss 206933.30468750\n",
      "epoch 7975 train_loss 10978114.53901024 val_loss 206933.30468750\n",
      "epoch 7976 train_loss 10978114.53891716 val_loss 206933.30468750\n",
      "epoch 7977 train_loss 10978114.53883522 val_loss 206933.30468750\n",
      "epoch 7978 train_loss 10978114.53879791 val_loss 206933.30468750\n",
      "epoch 7979 train_loss 10978114.53869812 val_loss 206933.30468750\n",
      "epoch 7980 train_loss 10978114.53860855 val_loss 206933.30468750\n",
      "epoch 7981 train_loss 10978114.53849907 val_loss 206933.30468750\n",
      "epoch 7982 train_loss 10978114.53840920 val_loss 206933.30468750\n",
      "epoch 7983 train_loss 10978114.53831383 val_loss 206933.30468750\n",
      "epoch 7984 train_loss 10978114.53824943 val_loss 206933.30468750\n",
      "epoch 7985 train_loss 10978114.53816483 val_loss 206933.30468750\n",
      "epoch 7986 train_loss 10978114.53806236 val_loss 206933.30468750\n",
      "epoch 7987 train_loss 10978114.53798401 val_loss 206933.30468750\n",
      "epoch 7988 train_loss 10978114.53790154 val_loss 206933.30468750\n",
      "epoch 7989 train_loss 10978114.53779648 val_loss 206933.30468750\n",
      "epoch 7990 train_loss 10978114.53772369 val_loss 206933.30468750\n",
      "epoch 7991 train_loss 10978114.53763168 val_loss 206933.30468750\n",
      "epoch 7992 train_loss 10978114.53754837 val_loss 206933.30468750\n",
      "epoch 7993 train_loss 10978114.53743034 val_loss 206933.30468750\n",
      "epoch 7994 train_loss 10978114.53735619 val_loss 206933.30468750\n",
      "epoch 7995 train_loss 10978114.53724037 val_loss 206933.30468750\n",
      "epoch 7996 train_loss 10978114.53715248 val_loss 206933.30468750\n",
      "epoch 7997 train_loss 10978114.53706322 val_loss 206933.30468750\n",
      "epoch 7998 train_loss 10978114.53698105 val_loss 206933.30468750\n",
      "epoch 7999 train_loss 10978114.53690529 val_loss 206933.30468750\n",
      "epoch 8000 train_loss 10978114.53679237 val_loss 206933.30468750\n",
      "epoch 8001 train_loss 10978114.53670883 val_loss 206933.30468750\n",
      "epoch 8002 train_loss 10978114.53661804 val_loss 206933.30468750\n",
      "epoch 8003 train_loss 10978114.53651833 val_loss 206933.30468750\n",
      "epoch 8004 train_loss 10978114.53642677 val_loss 206933.30468750\n",
      "epoch 8005 train_loss 10978114.53633636 val_loss 206933.30468750\n",
      "epoch 8006 train_loss 10978114.53624779 val_loss 206933.30468750\n",
      "epoch 8007 train_loss 10978114.53618614 val_loss 206933.30468750\n",
      "epoch 8008 train_loss 10978114.53610176 val_loss 206933.30468750\n",
      "epoch 8009 train_loss 10978114.53601532 val_loss 206933.30468750\n",
      "epoch 8010 train_loss 10978114.53596863 val_loss 206933.30468750\n",
      "epoch 8011 train_loss 10978114.53585495 val_loss 206933.30468750\n",
      "epoch 8012 train_loss 10978114.53577293 val_loss 206933.30468750\n",
      "epoch 8013 train_loss 10978114.53567665 val_loss 206933.30468750\n",
      "epoch 8014 train_loss 10978114.53557869 val_loss 206933.30468750\n",
      "epoch 8015 train_loss 10978114.53548775 val_loss 206933.30468750\n",
      "epoch 8016 train_loss 10978114.53539795 val_loss 206933.30468750\n",
      "epoch 8017 train_loss 10978114.53533684 val_loss 206933.30468750\n",
      "epoch 8018 train_loss 10978114.53525551 val_loss 206933.30468750\n",
      "epoch 8019 train_loss 10978114.53517189 val_loss 206933.30468750\n",
      "epoch 8020 train_loss 10978114.53506538 val_loss 206933.30468750\n",
      "epoch 8021 train_loss 10978114.53499405 val_loss 206933.30468750\n",
      "epoch 8022 train_loss 10978114.53491920 val_loss 206933.30468750\n",
      "epoch 8023 train_loss 10978114.53482048 val_loss 206933.30468750\n",
      "epoch 8024 train_loss 10978114.53472725 val_loss 206933.30468750\n",
      "epoch 8025 train_loss 10978114.53463119 val_loss 206933.30468750\n",
      "epoch 8026 train_loss 10978114.53453529 val_loss 206933.30468750\n",
      "epoch 8027 train_loss 10978114.53445763 val_loss 206933.30468750\n",
      "epoch 8028 train_loss 10978114.53435921 val_loss 206933.30468750\n",
      "epoch 8029 train_loss 10978114.53426392 val_loss 206933.30468750\n",
      "epoch 8030 train_loss 10978114.53417747 val_loss 206933.30468750\n",
      "epoch 8031 train_loss 10978114.53409943 val_loss 206933.30468750\n",
      "epoch 8032 train_loss 10978114.53400444 val_loss 206933.30468750\n",
      "epoch 8033 train_loss 10978114.53390655 val_loss 206933.30468750\n",
      "epoch 8034 train_loss 10978114.53382286 val_loss 206933.30468750\n",
      "epoch 8035 train_loss 10978114.53373718 val_loss 206933.30468750\n",
      "epoch 8036 train_loss 10978114.53364410 val_loss 206933.30468750\n",
      "epoch 8037 train_loss 10978114.53354920 val_loss 206933.30468750\n",
      "epoch 8038 train_loss 10978114.53346535 val_loss 206933.30468750\n",
      "epoch 8039 train_loss 10978114.53338982 val_loss 206933.30468750\n",
      "epoch 8040 train_loss 10978114.53328293 val_loss 206933.30468750\n",
      "epoch 8041 train_loss 10978114.53321373 val_loss 206933.30468750\n",
      "epoch 8042 train_loss 10978114.53319862 val_loss 206933.30468750\n",
      "epoch 8043 train_loss 10978114.53309921 val_loss 206933.30468750\n",
      "epoch 8044 train_loss 10978114.53300301 val_loss 206933.30468750\n",
      "epoch 8045 train_loss 10978114.53293259 val_loss 206933.30468750\n",
      "epoch 8046 train_loss 10978114.53284592 val_loss 206933.30468750\n",
      "epoch 8047 train_loss 10978114.53275047 val_loss 206933.30468750\n",
      "epoch 8048 train_loss 10978114.53265701 val_loss 206933.30468750\n",
      "epoch 8049 train_loss 10978114.53225456 val_loss 206933.30468750\n",
      "epoch 8050 train_loss 10978114.53215111 val_loss 206933.30468750\n",
      "epoch 8051 train_loss 10978114.53208168 val_loss 206933.30468750\n",
      "epoch 8052 train_loss 10978114.53198204 val_loss 206933.30468750\n",
      "epoch 8053 train_loss 10978114.53187317 val_loss 206933.30468750\n",
      "epoch 8054 train_loss 10978114.53179192 val_loss 206933.30468750\n",
      "epoch 8055 train_loss 10978114.53171051 val_loss 206933.30468750\n",
      "epoch 8056 train_loss 10978114.53162506 val_loss 206933.30468750\n",
      "epoch 8057 train_loss 10978114.53152588 val_loss 206933.30468750\n",
      "epoch 8058 train_loss 10978114.53145332 val_loss 206933.30468750\n",
      "epoch 8059 train_loss 10978114.53137001 val_loss 206933.30468750\n",
      "epoch 8060 train_loss 10978114.53156570 val_loss 206933.30468750\n",
      "epoch 8061 train_loss 10978114.53149406 val_loss 206933.30468750\n",
      "epoch 8062 train_loss 10978114.53147194 val_loss 206933.30468750\n",
      "epoch 8063 train_loss 10978114.53138290 val_loss 206933.30468750\n",
      "epoch 8064 train_loss 10978114.53127914 val_loss 206933.30468750\n",
      "epoch 8065 train_loss 10978114.53118118 val_loss 206933.30468750\n",
      "epoch 8066 train_loss 10978114.53107880 val_loss 206933.30468750\n",
      "epoch 8067 train_loss 10978114.53100861 val_loss 206933.30468750\n",
      "epoch 8068 train_loss 10978114.53090996 val_loss 206933.30468750\n",
      "epoch 8069 train_loss 10978114.53083130 val_loss 206933.30468750\n",
      "epoch 8070 train_loss 10978114.53073028 val_loss 206933.30468750\n",
      "epoch 8071 train_loss 10978114.53062950 val_loss 206933.30468750\n",
      "epoch 8072 train_loss 10978114.53055923 val_loss 206933.30468750\n",
      "epoch 8073 train_loss 10978114.53048424 val_loss 206933.30468750\n",
      "epoch 8074 train_loss 10978114.53039566 val_loss 206933.30468750\n",
      "epoch 8075 train_loss 10978114.53030815 val_loss 206933.30468750\n",
      "epoch 8076 train_loss 10978114.53020180 val_loss 206933.30468750\n",
      "epoch 8077 train_loss 10978114.53015274 val_loss 206933.30468750\n",
      "epoch 8078 train_loss 10978114.53005043 val_loss 206933.30468750\n",
      "epoch 8079 train_loss 10978114.52996010 val_loss 206933.30468750\n",
      "epoch 8080 train_loss 10978114.52985321 val_loss 206933.30468750\n",
      "epoch 8081 train_loss 10978114.52975449 val_loss 206933.30468750\n",
      "epoch 8082 train_loss 10978114.52966210 val_loss 206933.30468750\n",
      "epoch 8083 train_loss 10978114.52958359 val_loss 206933.30468750\n",
      "epoch 8084 train_loss 10978114.52949043 val_loss 206933.30468750\n",
      "epoch 8085 train_loss 10978114.52939125 val_loss 206933.30468750\n",
      "epoch 8086 train_loss 10978114.52933128 val_loss 206933.30468750\n",
      "epoch 8087 train_loss 10978114.52924454 val_loss 206933.30468750\n",
      "epoch 8088 train_loss 10978114.52915253 val_loss 206933.30468750\n",
      "epoch 8089 train_loss 10978114.52903824 val_loss 206933.30468750\n",
      "epoch 8090 train_loss 10978114.52895645 val_loss 206933.30468750\n",
      "epoch 8091 train_loss 10978114.52882797 val_loss 206933.30468750\n",
      "epoch 8092 train_loss 10978114.52874496 val_loss 206933.30468750\n",
      "epoch 8093 train_loss 10978114.52868950 val_loss 206933.30468750\n",
      "epoch 8094 train_loss 10978114.52856911 val_loss 206933.30468750\n",
      "epoch 8095 train_loss 10978114.52846634 val_loss 206933.30468750\n",
      "epoch 8096 train_loss 10978114.52841339 val_loss 206933.30468750\n",
      "epoch 8097 train_loss 10978114.52831719 val_loss 206933.30468750\n",
      "epoch 8098 train_loss 10978114.52823280 val_loss 206933.30468750\n",
      "epoch 8099 train_loss 10978114.52817116 val_loss 206933.30468750\n",
      "epoch 8100 train_loss 10978114.52806816 val_loss 206933.30468750\n",
      "epoch 8101 train_loss 10978114.52797508 val_loss 206933.30468750\n",
      "epoch 8102 train_loss 10978114.52790001 val_loss 206933.30468750\n",
      "epoch 8103 train_loss 10978114.52780952 val_loss 206933.30468750\n",
      "epoch 8104 train_loss 10978114.52763275 val_loss 206933.30468750\n",
      "epoch 8105 train_loss 10978114.52754112 val_loss 206933.30468750\n",
      "epoch 8106 train_loss 10978114.52745323 val_loss 206933.30468750\n",
      "epoch 8107 train_loss 10978114.52736862 val_loss 206933.30468750\n",
      "epoch 8108 train_loss 10978114.52728493 val_loss 206933.30468750\n",
      "epoch 8109 train_loss 10978114.52719620 val_loss 206933.30468750\n",
      "epoch 8110 train_loss 10978114.52710335 val_loss 206933.30468750\n",
      "epoch 8111 train_loss 10978114.52703079 val_loss 206933.30468750\n",
      "epoch 8112 train_loss 10978114.52695572 val_loss 206933.30468750\n",
      "epoch 8113 train_loss 10978114.52684029 val_loss 206933.30468750\n",
      "epoch 8114 train_loss 10978114.52676949 val_loss 206933.30468750\n",
      "epoch 8115 train_loss 10978114.52668617 val_loss 206933.30468750\n",
      "epoch 8116 train_loss 10978114.52659493 val_loss 206933.30468750\n",
      "epoch 8117 train_loss 10978114.52650642 val_loss 206933.30468750\n",
      "epoch 8118 train_loss 10978114.52639839 val_loss 206933.30468750\n",
      "epoch 8119 train_loss 10978114.52630218 val_loss 206933.30468750\n",
      "epoch 8120 train_loss 10978114.52621429 val_loss 206933.30468750\n",
      "epoch 8121 train_loss 10978114.52614876 val_loss 206933.30468750\n",
      "epoch 8122 train_loss 10978114.52605751 val_loss 206933.30468750\n",
      "epoch 8123 train_loss 10978114.52597290 val_loss 206933.30468750\n",
      "epoch 8124 train_loss 10978114.52587234 val_loss 206933.30468750\n",
      "epoch 8125 train_loss 10978114.52577904 val_loss 206933.30468750\n",
      "epoch 8126 train_loss 10978114.52567055 val_loss 206933.30468750\n",
      "epoch 8127 train_loss 10978114.52559937 val_loss 206933.30468750\n",
      "epoch 8128 train_loss 10978114.52550156 val_loss 206933.30468750\n",
      "epoch 8129 train_loss 10978114.52541740 val_loss 206933.30468750\n",
      "epoch 8130 train_loss 10978114.52534332 val_loss 206933.30468750\n",
      "epoch 8131 train_loss 10978114.52526215 val_loss 206933.30468750\n",
      "epoch 8132 train_loss 10978114.52516777 val_loss 206933.30468750\n",
      "epoch 8133 train_loss 10978114.52505699 val_loss 206933.30468750\n",
      "epoch 8134 train_loss 10978114.52497581 val_loss 206933.30468750\n",
      "epoch 8135 train_loss 10978114.52485855 val_loss 206933.30468750\n",
      "epoch 8136 train_loss 10978114.52479324 val_loss 206933.30468750\n",
      "epoch 8137 train_loss 10978114.52468666 val_loss 206933.30468750\n",
      "epoch 8138 train_loss 10978114.52461067 val_loss 206933.30468750\n",
      "epoch 8139 train_loss 10978114.52449860 val_loss 206933.30468750\n",
      "epoch 8140 train_loss 10978114.52440391 val_loss 206933.30468750\n",
      "epoch 8141 train_loss 10978114.52433449 val_loss 206933.30468750\n",
      "epoch 8142 train_loss 10978114.52424843 val_loss 206933.30468750\n",
      "epoch 8143 train_loss 10978114.52411972 val_loss 206933.30468750\n",
      "epoch 8144 train_loss 10978114.52405815 val_loss 206933.30468750\n",
      "epoch 8145 train_loss 10978114.52397842 val_loss 206933.30468750\n",
      "epoch 8146 train_loss 10978114.52386986 val_loss 206933.30468750\n",
      "epoch 8147 train_loss 10978114.52381180 val_loss 206933.30468750\n",
      "epoch 8148 train_loss 10978114.52371559 val_loss 206933.30468750\n",
      "epoch 8149 train_loss 10978114.52364708 val_loss 206933.30468750\n",
      "epoch 8150 train_loss 10978114.52358673 val_loss 206933.30468750\n",
      "epoch 8151 train_loss 10978114.52351074 val_loss 206933.30468750\n",
      "epoch 8152 train_loss 10978114.52340721 val_loss 206933.30468750\n",
      "epoch 8153 train_loss 10978114.52329819 val_loss 206933.30468750\n",
      "epoch 8154 train_loss 10978114.52321213 val_loss 206933.30468750\n",
      "epoch 8155 train_loss 10978114.52312347 val_loss 206933.30468750\n",
      "epoch 8156 train_loss 10978114.52303864 val_loss 206933.30468750\n",
      "epoch 8157 train_loss 10978114.52293633 val_loss 206933.30468750\n",
      "epoch 8158 train_loss 10978114.52285339 val_loss 206933.30468750\n",
      "epoch 8159 train_loss 10978114.52275070 val_loss 206933.30468750\n",
      "epoch 8160 train_loss 10978114.52266281 val_loss 206933.30468750\n",
      "epoch 8161 train_loss 10978114.52257103 val_loss 206933.30468750\n",
      "epoch 8162 train_loss 10978114.52248947 val_loss 206933.30468750\n",
      "epoch 8163 train_loss 10978114.52239365 val_loss 206933.30468750\n",
      "epoch 8164 train_loss 10978114.52229485 val_loss 206933.30468750\n",
      "epoch 8165 train_loss 10978114.52221001 val_loss 206933.30468750\n",
      "epoch 8166 train_loss 10978114.52214447 val_loss 206933.30468750\n",
      "epoch 8167 train_loss 10978114.52202408 val_loss 206933.30468750\n",
      "epoch 8168 train_loss 10978114.52193581 val_loss 206933.30468750\n",
      "epoch 8169 train_loss 10978114.52185173 val_loss 206933.30468750\n",
      "epoch 8170 train_loss 10978114.52176865 val_loss 206933.30468750\n",
      "epoch 8171 train_loss 10978114.52173271 val_loss 206933.30468750\n",
      "epoch 8172 train_loss 10978114.52165703 val_loss 206933.30468750\n",
      "epoch 8173 train_loss 10978114.52159210 val_loss 206933.30468750\n",
      "epoch 8174 train_loss 10978114.52150314 val_loss 206933.30468750\n",
      "epoch 8175 train_loss 10978114.52141479 val_loss 206933.30468750\n",
      "epoch 8176 train_loss 10978114.52131935 val_loss 206933.30468750\n",
      "epoch 8177 train_loss 10978114.52122215 val_loss 206933.30468750\n",
      "epoch 8178 train_loss 10978114.52114746 val_loss 206933.30468750\n",
      "epoch 8179 train_loss 10978114.52104790 val_loss 206933.30468750\n",
      "epoch 8180 train_loss 10978114.52095848 val_loss 206933.30468750\n",
      "epoch 8181 train_loss 10978114.52087273 val_loss 206933.30468750\n",
      "epoch 8182 train_loss 10978114.52074829 val_loss 206933.30468750\n",
      "epoch 8183 train_loss 10978114.52066544 val_loss 206933.30468750\n",
      "epoch 8184 train_loss 10978114.52056991 val_loss 206933.30468750\n",
      "epoch 8185 train_loss 10978114.52047607 val_loss 206933.30468750\n",
      "epoch 8186 train_loss 10978114.52041283 val_loss 206933.30468750\n",
      "epoch 8187 train_loss 10978114.52032097 val_loss 206933.30468750\n",
      "epoch 8188 train_loss 10978114.52023125 val_loss 206933.30468750\n",
      "epoch 8189 train_loss 10978114.52014305 val_loss 206933.30468750\n",
      "epoch 8190 train_loss 10978114.52003502 val_loss 206933.30468750\n",
      "epoch 8191 train_loss 10978114.51996040 val_loss 206933.30468750\n",
      "epoch 8192 train_loss 10978114.51986511 val_loss 206933.30468750\n",
      "epoch 8193 train_loss 10978114.51976265 val_loss 206933.30468750\n",
      "epoch 8194 train_loss 10978114.51968361 val_loss 206933.30468750\n",
      "epoch 8195 train_loss 10978114.51958336 val_loss 206933.30468750\n",
      "epoch 8196 train_loss 10978114.51950050 val_loss 206933.30468750\n",
      "epoch 8197 train_loss 10978114.51941162 val_loss 206933.30468750\n",
      "epoch 8198 train_loss 10978114.51933006 val_loss 206933.30468750\n",
      "epoch 8199 train_loss 10978114.51923698 val_loss 206933.30468750\n",
      "epoch 8200 train_loss 10978114.51914024 val_loss 206933.30468750\n",
      "epoch 8201 train_loss 10978114.51904014 val_loss 206933.30468750\n",
      "epoch 8202 train_loss 10978114.51895447 val_loss 206933.30468750\n",
      "epoch 8203 train_loss 10978114.51887062 val_loss 206933.30468750\n",
      "epoch 8204 train_loss 10978114.51879173 val_loss 206933.30468750\n",
      "epoch 8205 train_loss 10978114.51868584 val_loss 206933.30468750\n",
      "epoch 8206 train_loss 10978114.51860832 val_loss 206933.30468750\n",
      "epoch 8207 train_loss 10978114.51851715 val_loss 206933.30468750\n",
      "epoch 8208 train_loss 10978114.51841537 val_loss 206933.30468750\n",
      "epoch 8209 train_loss 10978114.51832733 val_loss 206933.30468750\n",
      "epoch 8210 train_loss 10978114.51822075 val_loss 206933.30468750\n",
      "epoch 8211 train_loss 10978114.51813370 val_loss 206933.30468750\n",
      "epoch 8212 train_loss 10978114.51804527 val_loss 206933.30468750\n",
      "epoch 8213 train_loss 10978114.51795029 val_loss 206933.30468750\n",
      "epoch 8214 train_loss 10978114.51794571 val_loss 206933.30468750\n",
      "epoch 8215 train_loss 10978114.51787651 val_loss 206933.30468750\n",
      "epoch 8216 train_loss 10978114.51779106 val_loss 206933.30468750\n",
      "epoch 8217 train_loss 10978114.51768181 val_loss 206933.30468750\n",
      "epoch 8218 train_loss 10978114.51767670 val_loss 206933.30468750\n",
      "epoch 8219 train_loss 10978114.51756935 val_loss 206933.30468750\n",
      "epoch 8220 train_loss 10978114.51747932 val_loss 206933.30468750\n",
      "epoch 8221 train_loss 10978114.51741341 val_loss 206933.30468750\n",
      "epoch 8222 train_loss 10978114.51732368 val_loss 206933.30468750\n",
      "epoch 8223 train_loss 10978114.51722923 val_loss 206933.30468750\n",
      "epoch 8224 train_loss 10978114.51713371 val_loss 206933.30468750\n",
      "epoch 8225 train_loss 10978114.51705185 val_loss 206933.30468750\n",
      "epoch 8226 train_loss 10978114.51699203 val_loss 206933.30468750\n",
      "epoch 8227 train_loss 10978114.51691543 val_loss 206933.30468750\n",
      "epoch 8228 train_loss 10978114.51682236 val_loss 206933.30468750\n",
      "epoch 8229 train_loss 10978114.51671288 val_loss 206933.30468750\n",
      "epoch 8230 train_loss 10978114.51662567 val_loss 206933.30468750\n",
      "epoch 8231 train_loss 10978114.51652573 val_loss 206933.30468750\n",
      "epoch 8232 train_loss 10978114.51644119 val_loss 206933.30468750\n",
      "epoch 8233 train_loss 10978114.51635284 val_loss 206933.30468750\n",
      "epoch 8234 train_loss 10978114.51628136 val_loss 206933.30468750\n",
      "epoch 8235 train_loss 10978114.51620094 val_loss 206933.30468750\n",
      "epoch 8236 train_loss 10978114.51609360 val_loss 206933.30468750\n",
      "epoch 8237 train_loss 10978114.51600525 val_loss 206933.30468750\n",
      "epoch 8238 train_loss 10978114.51590965 val_loss 206933.30468750\n",
      "epoch 8239 train_loss 10978114.51581200 val_loss 206933.30468750\n",
      "epoch 8240 train_loss 10978114.51571724 val_loss 206933.30468750\n",
      "epoch 8241 train_loss 10978114.51561485 val_loss 206933.30468750\n",
      "epoch 8242 train_loss 10978114.51552269 val_loss 206933.30468750\n",
      "epoch 8243 train_loss 10978114.51544014 val_loss 206933.30468750\n",
      "epoch 8244 train_loss 10978114.51534676 val_loss 206933.30468750\n",
      "epoch 8245 train_loss 10978114.51528915 val_loss 206933.30468750\n",
      "epoch 8246 train_loss 10978114.51521523 val_loss 206933.30468750\n",
      "epoch 8247 train_loss 10978114.51511986 val_loss 206933.30468750\n",
      "epoch 8248 train_loss 10978114.51505623 val_loss 206933.30468750\n",
      "epoch 8249 train_loss 10978114.51495529 val_loss 206933.30468750\n",
      "epoch 8250 train_loss 10978114.51485146 val_loss 206933.30468750\n",
      "epoch 8251 train_loss 10978114.51477242 val_loss 206933.30468750\n",
      "epoch 8252 train_loss 10978114.51467529 val_loss 206933.30468750\n",
      "epoch 8253 train_loss 10978114.51457230 val_loss 206933.30468750\n",
      "epoch 8254 train_loss 10978114.51447327 val_loss 206933.30468750\n",
      "epoch 8255 train_loss 10978114.51438927 val_loss 206933.30468750\n",
      "epoch 8256 train_loss 10978114.51430168 val_loss 206933.30468750\n",
      "epoch 8257 train_loss 10978114.51418205 val_loss 206933.30468750\n",
      "epoch 8258 train_loss 10978114.51409988 val_loss 206933.30468750\n",
      "epoch 8259 train_loss 10978114.51400719 val_loss 206933.30468750\n",
      "epoch 8260 train_loss 10978114.51390259 val_loss 206933.30468750\n",
      "epoch 8261 train_loss 10978114.51385040 val_loss 206933.30468750\n",
      "epoch 8262 train_loss 10978114.51373375 val_loss 206933.30468750\n",
      "epoch 8263 train_loss 10978114.51364227 val_loss 206933.30468750\n",
      "epoch 8264 train_loss 10978114.51360031 val_loss 206933.30468750\n",
      "epoch 8265 train_loss 10978114.51353393 val_loss 206933.30468750\n",
      "epoch 8266 train_loss 10978114.51346321 val_loss 206933.30468750\n",
      "epoch 8267 train_loss 10978114.51336342 val_loss 206933.30468750\n",
      "epoch 8268 train_loss 10978114.51328102 val_loss 206933.30468750\n",
      "epoch 8269 train_loss 10978114.51322311 val_loss 206933.30468750\n",
      "epoch 8270 train_loss 10978114.51314201 val_loss 206933.30468750\n",
      "epoch 8271 train_loss 10978114.51303627 val_loss 206933.30468750\n",
      "epoch 8272 train_loss 10978114.51294724 val_loss 206933.30468750\n",
      "epoch 8273 train_loss 10978114.51281090 val_loss 206933.30468750\n",
      "epoch 8274 train_loss 10978114.51272820 val_loss 206933.30468750\n",
      "epoch 8275 train_loss 10978114.51263985 val_loss 206933.30468750\n",
      "epoch 8276 train_loss 10978114.51259110 val_loss 206933.30468750\n",
      "epoch 8277 train_loss 10978114.51248856 val_loss 206933.30468750\n",
      "epoch 8278 train_loss 10978114.51238754 val_loss 206933.30468750\n",
      "epoch 8279 train_loss 10978114.51232216 val_loss 206933.30468750\n",
      "epoch 8280 train_loss 10978114.51223961 val_loss 206933.30468750\n",
      "epoch 8281 train_loss 10978114.51212128 val_loss 206933.30468750\n",
      "epoch 8282 train_loss 10978114.51204246 val_loss 206933.30468750\n",
      "epoch 8283 train_loss 10978114.51195518 val_loss 206933.30468750\n",
      "epoch 8284 train_loss 10978114.51186180 val_loss 206933.30468750\n",
      "epoch 8285 train_loss 10978114.51175682 val_loss 206933.30468750\n",
      "epoch 8286 train_loss 10978114.51170029 val_loss 206933.30468750\n",
      "epoch 8287 train_loss 10978114.51160538 val_loss 206933.30468750\n",
      "epoch 8288 train_loss 10978114.51151115 val_loss 206933.30468750\n",
      "epoch 8289 train_loss 10978114.51144005 val_loss 206933.30468750\n",
      "epoch 8290 train_loss 10978114.51133507 val_loss 206933.30468750\n",
      "epoch 8291 train_loss 10978114.51124611 val_loss 206933.30468750\n",
      "epoch 8292 train_loss 10978114.51114075 val_loss 206933.30468750\n",
      "epoch 8293 train_loss 10978114.51105736 val_loss 206933.30468750\n",
      "epoch 8294 train_loss 10978114.51093872 val_loss 206933.30468750\n",
      "epoch 8295 train_loss 10978114.51085792 val_loss 206933.30468750\n",
      "epoch 8296 train_loss 10978114.51077110 val_loss 206933.30468750\n",
      "epoch 8297 train_loss 10978114.51067291 val_loss 206933.30468750\n",
      "epoch 8298 train_loss 10978114.51062248 val_loss 206933.30468750\n",
      "epoch 8299 train_loss 10978114.51052032 val_loss 206933.30468750\n",
      "epoch 8300 train_loss 10978114.51045433 val_loss 206933.30468750\n",
      "epoch 8301 train_loss 10978114.51034874 val_loss 206933.30468750\n",
      "epoch 8302 train_loss 10978114.51042870 val_loss 206933.30468750\n",
      "epoch 8303 train_loss 10978114.51032806 val_loss 206933.30468750\n",
      "epoch 8304 train_loss 10978114.51024544 val_loss 206933.31250000\n",
      "epoch 8305 train_loss 10978114.51014915 val_loss 206933.31250000\n",
      "epoch 8306 train_loss 10978114.51003395 val_loss 206933.31250000\n",
      "epoch 8307 train_loss 10978114.50995087 val_loss 206933.31250000\n",
      "epoch 8308 train_loss 10978114.50987213 val_loss 206933.31250000\n",
      "epoch 8309 train_loss 10978114.50977699 val_loss 206933.31250000\n",
      "epoch 8310 train_loss 10978114.50969635 val_loss 206933.31250000\n",
      "epoch 8311 train_loss 10978114.50964058 val_loss 206933.31250000\n",
      "epoch 8312 train_loss 10978114.50955704 val_loss 206933.31250000\n",
      "epoch 8313 train_loss 10978114.50944389 val_loss 206933.31250000\n",
      "epoch 8314 train_loss 10978114.50938194 val_loss 206933.31250000\n",
      "epoch 8315 train_loss 10978114.50927048 val_loss 206933.31250000\n",
      "epoch 8316 train_loss 10978114.50918770 val_loss 206933.31250000\n",
      "epoch 8317 train_loss 10978114.50909645 val_loss 206933.31250000\n",
      "epoch 8318 train_loss 10978114.50902252 val_loss 206933.31250000\n",
      "epoch 8319 train_loss 10978114.50890717 val_loss 206933.31250000\n",
      "epoch 8320 train_loss 10978114.50883446 val_loss 206933.31250000\n",
      "epoch 8321 train_loss 10978114.50871803 val_loss 206933.31250000\n",
      "epoch 8322 train_loss 10978114.50863670 val_loss 206933.31250000\n",
      "epoch 8323 train_loss 10978114.50854706 val_loss 206933.31250000\n",
      "epoch 8324 train_loss 10978114.50848038 val_loss 206933.31250000\n",
      "epoch 8325 train_loss 10978114.50838608 val_loss 206933.31250000\n",
      "epoch 8326 train_loss 10978114.50829262 val_loss 206933.31250000\n",
      "epoch 8327 train_loss 10978114.50822929 val_loss 206933.31250000\n",
      "epoch 8328 train_loss 10978114.50816566 val_loss 206933.31250000\n",
      "epoch 8329 train_loss 10978114.50809273 val_loss 206933.31250000\n",
      "epoch 8330 train_loss 10978114.50799339 val_loss 206933.31250000\n",
      "epoch 8331 train_loss 10978114.50789383 val_loss 206933.31250000\n",
      "epoch 8332 train_loss 10978114.50780052 val_loss 206933.31250000\n",
      "epoch 8333 train_loss 10978114.50770996 val_loss 206933.31250000\n",
      "epoch 8334 train_loss 10978114.50762459 val_loss 206933.31250000\n",
      "epoch 8335 train_loss 10978114.50752106 val_loss 206933.31250000\n",
      "epoch 8336 train_loss 10978114.50743477 val_loss 206933.31250000\n",
      "epoch 8337 train_loss 10978114.50734940 val_loss 206933.31250000\n",
      "epoch 8338 train_loss 10978114.50726303 val_loss 206933.31250000\n",
      "epoch 8339 train_loss 10978114.50715340 val_loss 206933.31250000\n",
      "epoch 8340 train_loss 10978114.50706688 val_loss 206933.31250000\n",
      "epoch 8341 train_loss 10978114.50698799 val_loss 206933.31250000\n",
      "epoch 8342 train_loss 10978114.50689316 val_loss 206933.31250000\n",
      "epoch 8343 train_loss 10978114.50680054 val_loss 206933.31250000\n",
      "epoch 8344 train_loss 10978114.50672295 val_loss 206933.31250000\n",
      "epoch 8345 train_loss 10978114.50662140 val_loss 206933.31250000\n",
      "epoch 8346 train_loss 10978114.50652847 val_loss 206933.31250000\n",
      "epoch 8347 train_loss 10978114.50643341 val_loss 206933.31250000\n",
      "epoch 8348 train_loss 10978114.50634071 val_loss 206933.31250000\n",
      "epoch 8349 train_loss 10978114.50623985 val_loss 206933.31250000\n",
      "epoch 8350 train_loss 10978114.50615105 val_loss 206933.31250000\n",
      "epoch 8351 train_loss 10978114.50605804 val_loss 206933.31250000\n",
      "epoch 8352 train_loss 10978114.50598221 val_loss 206933.31250000\n",
      "epoch 8353 train_loss 10978114.50586899 val_loss 206933.31250000\n",
      "epoch 8354 train_loss 10978114.50579391 val_loss 206933.31250000\n",
      "epoch 8355 train_loss 10978114.50569405 val_loss 206933.31250000\n",
      "epoch 8356 train_loss 10978114.50559540 val_loss 206933.31250000\n",
      "epoch 8357 train_loss 10978114.50550484 val_loss 206933.31250000\n",
      "epoch 8358 train_loss 10978114.50540649 val_loss 206933.31250000\n",
      "epoch 8359 train_loss 10978114.50530045 val_loss 206933.31250000\n",
      "epoch 8360 train_loss 10978114.50525711 val_loss 206933.31250000\n",
      "epoch 8361 train_loss 10978114.50516647 val_loss 206933.31250000\n",
      "epoch 8362 train_loss 10978114.50507736 val_loss 206933.31250000\n",
      "epoch 8363 train_loss 10978114.50500107 val_loss 206933.31250000\n",
      "epoch 8364 train_loss 10978114.50491188 val_loss 206933.31250000\n",
      "epoch 8365 train_loss 10978114.50482887 val_loss 206933.31250000\n",
      "epoch 8366 train_loss 10978114.50474976 val_loss 206933.31250000\n",
      "epoch 8367 train_loss 10978114.50473358 val_loss 206933.31250000\n",
      "epoch 8368 train_loss 10978114.50462616 val_loss 206933.31250000\n",
      "epoch 8369 train_loss 10978114.50454414 val_loss 206933.31250000\n",
      "epoch 8370 train_loss 10978114.50445770 val_loss 206933.31250000\n",
      "epoch 8371 train_loss 10978114.50435806 val_loss 206933.31250000\n",
      "epoch 8372 train_loss 10978114.50425262 val_loss 206933.31250000\n",
      "epoch 8373 train_loss 10978114.50421318 val_loss 206933.31250000\n",
      "epoch 8374 train_loss 10978114.50410591 val_loss 206933.31250000\n",
      "epoch 8375 train_loss 10978114.50401848 val_loss 206933.31250000\n",
      "epoch 8376 train_loss 10978114.50393845 val_loss 206933.31250000\n",
      "epoch 8377 train_loss 10978114.50383888 val_loss 206933.31250000\n",
      "epoch 8378 train_loss 10978114.50374527 val_loss 206933.31250000\n",
      "epoch 8379 train_loss 10978114.50365028 val_loss 206933.31250000\n",
      "epoch 8380 train_loss 10978114.50360375 val_loss 206933.31250000\n",
      "epoch 8381 train_loss 10978114.50349266 val_loss 206933.31250000\n",
      "epoch 8382 train_loss 10978114.50339996 val_loss 206933.31250000\n",
      "epoch 8383 train_loss 10978114.50333565 val_loss 206933.31250000\n",
      "epoch 8384 train_loss 10978114.50324654 val_loss 206933.31250000\n",
      "epoch 8385 train_loss 10978114.50312355 val_loss 206933.31250000\n",
      "epoch 8386 train_loss 10978114.50303131 val_loss 206933.31250000\n",
      "epoch 8387 train_loss 10978114.50293800 val_loss 206933.31250000\n",
      "epoch 8388 train_loss 10978114.50283577 val_loss 206933.31250000\n",
      "epoch 8389 train_loss 10978114.50275826 val_loss 206933.31250000\n",
      "epoch 8390 train_loss 10978114.50267494 val_loss 206933.31250000\n",
      "epoch 8391 train_loss 10978114.50259689 val_loss 206933.31250000\n",
      "epoch 8392 train_loss 10978114.50249893 val_loss 206933.31250000\n",
      "epoch 8393 train_loss 10978114.50241150 val_loss 206933.31250000\n",
      "epoch 8394 train_loss 10978114.50230347 val_loss 206933.31250000\n",
      "epoch 8395 train_loss 10978114.50220741 val_loss 206933.31250000\n",
      "epoch 8396 train_loss 10978114.50212257 val_loss 206933.31250000\n",
      "epoch 8397 train_loss 10978114.50205917 val_loss 206933.31250000\n",
      "epoch 8398 train_loss 10978114.50197143 val_loss 206933.31250000\n",
      "epoch 8399 train_loss 10978114.50186028 val_loss 206933.31250000\n",
      "epoch 8400 train_loss 10978114.50177574 val_loss 206933.31250000\n",
      "epoch 8401 train_loss 10978114.50167908 val_loss 206933.31250000\n",
      "epoch 8402 train_loss 10978114.50158096 val_loss 206933.31250000\n",
      "epoch 8403 train_loss 10978114.50153389 val_loss 206933.31250000\n",
      "epoch 8404 train_loss 10978114.50143570 val_loss 206933.31250000\n",
      "epoch 8405 train_loss 10978114.50135536 val_loss 206933.31250000\n",
      "epoch 8406 train_loss 10978114.50127258 val_loss 206933.31250000\n",
      "epoch 8407 train_loss 10978114.50119392 val_loss 206933.31250000\n",
      "epoch 8408 train_loss 10978114.50110008 val_loss 206933.31250000\n",
      "epoch 8409 train_loss 10978114.50099014 val_loss 206933.31250000\n",
      "epoch 8410 train_loss 10978114.50092697 val_loss 206933.31250000\n",
      "epoch 8411 train_loss 10978114.50084213 val_loss 206933.31250000\n",
      "epoch 8412 train_loss 10978114.50073173 val_loss 206933.31250000\n",
      "epoch 8413 train_loss 10978114.50065186 val_loss 206933.31250000\n",
      "epoch 8414 train_loss 10978114.50053421 val_loss 206933.31250000\n",
      "epoch 8415 train_loss 10978114.50045723 val_loss 206933.31250000\n",
      "epoch 8416 train_loss 10978114.50038444 val_loss 206933.31250000\n",
      "epoch 8417 train_loss 10978114.50029915 val_loss 206933.31250000\n",
      "epoch 8418 train_loss 10978114.50020111 val_loss 206933.31250000\n",
      "epoch 8419 train_loss 10978114.50010132 val_loss 206933.31250000\n",
      "epoch 8420 train_loss 10978114.50002754 val_loss 206933.31250000\n",
      "epoch 8421 train_loss 10978114.49993317 val_loss 206933.31250000\n",
      "epoch 8422 train_loss 10978114.49984878 val_loss 206933.31250000\n",
      "epoch 8423 train_loss 10978114.49974609 val_loss 206933.31250000\n",
      "epoch 8424 train_loss 10978114.49963417 val_loss 206933.31250000\n",
      "epoch 8425 train_loss 10978114.49954681 val_loss 206933.31250000\n",
      "epoch 8426 train_loss 10978114.49946838 val_loss 206933.31250000\n",
      "epoch 8427 train_loss 10978114.49937035 val_loss 206933.31250000\n",
      "epoch 8428 train_loss 10978114.49929512 val_loss 206933.31250000\n",
      "epoch 8429 train_loss 10978114.49919846 val_loss 206933.31250000\n",
      "epoch 8430 train_loss 10978114.49910667 val_loss 206933.31250000\n",
      "epoch 8431 train_loss 10978114.49899345 val_loss 206933.31250000\n",
      "epoch 8432 train_loss 10978114.49890785 val_loss 206933.31250000\n",
      "epoch 8433 train_loss 10978114.49881195 val_loss 206933.31250000\n",
      "epoch 8434 train_loss 10978114.49871033 val_loss 206933.31250000\n",
      "epoch 8435 train_loss 10978114.49864403 val_loss 206933.31250000\n",
      "epoch 8436 train_loss 10978114.49855652 val_loss 206933.31250000\n",
      "epoch 8437 train_loss 10978114.49845520 val_loss 206933.31250000\n",
      "epoch 8438 train_loss 10978114.49835701 val_loss 206933.31250000\n",
      "epoch 8439 train_loss 10978114.49827209 val_loss 206933.31250000\n",
      "epoch 8440 train_loss 10978114.49817909 val_loss 206933.31250000\n",
      "epoch 8441 train_loss 10978114.49808029 val_loss 206933.31250000\n",
      "epoch 8442 train_loss 10978114.49800888 val_loss 206933.31250000\n",
      "epoch 8443 train_loss 10978114.49790474 val_loss 206933.31250000\n",
      "epoch 8444 train_loss 10978114.49784431 val_loss 206933.31250000\n",
      "epoch 8445 train_loss 10978114.49774200 val_loss 206933.31250000\n",
      "epoch 8446 train_loss 10978114.49763977 val_loss 206933.31250000\n",
      "epoch 8447 train_loss 10978114.49755592 val_loss 206933.31250000\n",
      "epoch 8448 train_loss 10978114.49746490 val_loss 206933.31250000\n",
      "epoch 8449 train_loss 10978114.49736580 val_loss 206933.31250000\n",
      "epoch 8450 train_loss 10978114.49730347 val_loss 206933.31250000\n",
      "epoch 8451 train_loss 10978114.49722404 val_loss 206933.31250000\n",
      "epoch 8452 train_loss 10978114.49712898 val_loss 206933.31250000\n",
      "epoch 8453 train_loss 10978114.49702484 val_loss 206933.31250000\n",
      "epoch 8454 train_loss 10978114.49692543 val_loss 206933.31250000\n",
      "epoch 8455 train_loss 10978114.49683632 val_loss 206933.31250000\n",
      "epoch 8456 train_loss 10978114.49673912 val_loss 206933.31250000\n",
      "epoch 8457 train_loss 10978114.49664284 val_loss 206933.31250000\n",
      "epoch 8458 train_loss 10978114.49655128 val_loss 206933.31250000\n",
      "epoch 8459 train_loss 10978114.49646675 val_loss 206933.31250000\n",
      "epoch 8460 train_loss 10978114.49635345 val_loss 206933.31250000\n",
      "epoch 8461 train_loss 10978114.49630768 val_loss 206933.31250000\n",
      "epoch 8462 train_loss 10978114.49620140 val_loss 206933.31250000\n",
      "epoch 8463 train_loss 10978114.49609276 val_loss 206933.31250000\n",
      "epoch 8464 train_loss 10978114.49599838 val_loss 206933.31250000\n",
      "epoch 8465 train_loss 10978114.49591583 val_loss 206933.31250000\n",
      "epoch 8466 train_loss 10978114.49582306 val_loss 206933.31250000\n",
      "epoch 8467 train_loss 10978114.49574989 val_loss 206933.31250000\n",
      "epoch 8468 train_loss 10978114.49567627 val_loss 206933.31250000\n",
      "epoch 8469 train_loss 10978114.49559082 val_loss 206933.31250000\n",
      "epoch 8470 train_loss 10978114.49549172 val_loss 206933.31250000\n",
      "epoch 8471 train_loss 10978114.49539108 val_loss 206933.31250000\n",
      "epoch 8472 train_loss 10978114.49537331 val_loss 206933.31250000\n",
      "epoch 8473 train_loss 10978114.49528748 val_loss 206933.31250000\n",
      "epoch 8474 train_loss 10978114.49519012 val_loss 206933.31250000\n",
      "epoch 8475 train_loss 10978114.49509720 val_loss 206933.31250000\n",
      "epoch 8476 train_loss 10978114.49501427 val_loss 206933.31250000\n",
      "epoch 8477 train_loss 10978114.49492813 val_loss 206933.31250000\n",
      "epoch 8478 train_loss 10978114.49485237 val_loss 206933.31250000\n",
      "epoch 8479 train_loss 10978114.49475166 val_loss 206933.31250000\n",
      "epoch 8480 train_loss 10978114.49466125 val_loss 206933.31250000\n",
      "epoch 8481 train_loss 10978114.49464088 val_loss 206933.31250000\n",
      "epoch 8482 train_loss 10978114.49454788 val_loss 206933.31250000\n",
      "epoch 8483 train_loss 10978114.49445740 val_loss 206933.31250000\n",
      "epoch 8484 train_loss 10978114.49435371 val_loss 206933.31250000\n",
      "epoch 8485 train_loss 10978114.49427490 val_loss 206933.31250000\n",
      "epoch 8486 train_loss 10978114.49419136 val_loss 206933.31250000\n",
      "epoch 8487 train_loss 10978114.49410065 val_loss 206933.31250000\n",
      "epoch 8488 train_loss 10978114.49400780 val_loss 206933.31250000\n",
      "epoch 8489 train_loss 10978114.49393478 val_loss 206933.31250000\n",
      "epoch 8490 train_loss 10978114.49383736 val_loss 206933.31250000\n",
      "epoch 8491 train_loss 10978114.49374062 val_loss 206933.31250000\n",
      "epoch 8492 train_loss 10978114.49365944 val_loss 206933.31250000\n",
      "epoch 8493 train_loss 10978114.49356667 val_loss 206933.31250000\n",
      "epoch 8494 train_loss 10978114.49346207 val_loss 206933.31250000\n",
      "epoch 8495 train_loss 10978114.49337295 val_loss 206933.31250000\n",
      "epoch 8496 train_loss 10978114.49327110 val_loss 206933.31250000\n",
      "epoch 8497 train_loss 10978114.49317879 val_loss 206933.31250000\n",
      "epoch 8498 train_loss 10978114.49308289 val_loss 206933.31250000\n",
      "epoch 8499 train_loss 10978114.49299438 val_loss 206933.31250000\n",
      "epoch 8500 train_loss 10978114.49294159 val_loss 206933.31250000\n",
      "epoch 8501 train_loss 10978114.49286324 val_loss 206933.31250000\n",
      "epoch 8502 train_loss 10978114.49278107 val_loss 206933.31250000\n",
      "epoch 8503 train_loss 10978114.49269478 val_loss 206933.31250000\n",
      "epoch 8504 train_loss 10978114.49258850 val_loss 206933.31250000\n",
      "epoch 8505 train_loss 10978114.49247932 val_loss 206933.31250000\n",
      "epoch 8506 train_loss 10978114.49240166 val_loss 206933.31250000\n",
      "epoch 8507 train_loss 10978114.49231903 val_loss 206933.31250000\n",
      "epoch 8508 train_loss 10978114.49230904 val_loss 206933.31250000\n",
      "epoch 8509 train_loss 10978114.49219399 val_loss 206933.31250000\n",
      "epoch 8510 train_loss 10978114.49211723 val_loss 206933.31250000\n",
      "epoch 8511 train_loss 10978114.49201752 val_loss 206933.31250000\n",
      "epoch 8512 train_loss 10978114.49192749 val_loss 206933.31250000\n",
      "epoch 8513 train_loss 10978114.49182823 val_loss 206933.31250000\n",
      "epoch 8514 train_loss 10978114.49174942 val_loss 206933.31250000\n",
      "epoch 8515 train_loss 10978114.49164490 val_loss 206933.31250000\n",
      "epoch 8516 train_loss 10978114.49154762 val_loss 206933.31250000\n",
      "epoch 8517 train_loss 10978114.49145988 val_loss 206933.31250000\n",
      "epoch 8518 train_loss 10978114.49137581 val_loss 206933.31250000\n",
      "epoch 8519 train_loss 10978114.49136986 val_loss 206933.31250000\n",
      "epoch 8520 train_loss 10978114.49126625 val_loss 206933.31250000\n",
      "epoch 8521 train_loss 10978114.49116508 val_loss 206933.31250000\n",
      "epoch 8522 train_loss 10978114.49118279 val_loss 206933.31250000\n",
      "epoch 8523 train_loss 10978114.49108139 val_loss 206933.31250000\n",
      "epoch 8524 train_loss 10978114.49091980 val_loss 206933.31250000\n",
      "epoch 8525 train_loss 10978114.49083031 val_loss 206933.31250000\n",
      "epoch 8526 train_loss 10978114.49073090 val_loss 206933.31250000\n",
      "epoch 8527 train_loss 10978114.49063683 val_loss 206933.31250000\n",
      "epoch 8528 train_loss 10978114.49053909 val_loss 206933.31250000\n",
      "epoch 8529 train_loss 10978114.49053925 val_loss 206933.31250000\n",
      "epoch 8530 train_loss 10978114.49043808 val_loss 206933.31250000\n",
      "epoch 8531 train_loss 10978114.49035439 val_loss 206933.31250000\n",
      "epoch 8532 train_loss 10978114.49026917 val_loss 206933.31250000\n",
      "epoch 8533 train_loss 10978114.49018837 val_loss 206933.31250000\n",
      "epoch 8534 train_loss 10978114.49009109 val_loss 206933.31250000\n",
      "epoch 8535 train_loss 10978114.49007843 val_loss 206933.31250000\n",
      "epoch 8536 train_loss 10978114.48998741 val_loss 206933.31250000\n",
      "epoch 8537 train_loss 10978114.48986900 val_loss 206933.31250000\n",
      "epoch 8538 train_loss 10978114.48983078 val_loss 206933.31250000\n",
      "epoch 8539 train_loss 10978114.48973236 val_loss 206933.31250000\n",
      "epoch 8540 train_loss 10978114.48964150 val_loss 206933.31250000\n",
      "epoch 8541 train_loss 10978114.48953308 val_loss 206933.31250000\n",
      "epoch 8542 train_loss 10978114.48945297 val_loss 206933.31250000\n",
      "epoch 8543 train_loss 10978114.48935661 val_loss 206933.31250000\n",
      "epoch 8544 train_loss 10978114.48925758 val_loss 206933.31250000\n",
      "epoch 8545 train_loss 10978114.48917236 val_loss 206933.31250000\n",
      "epoch 8546 train_loss 10978114.48908051 val_loss 206933.31250000\n",
      "epoch 8547 train_loss 10978114.48900269 val_loss 206933.31250000\n",
      "epoch 8548 train_loss 10978114.48890457 val_loss 206933.31250000\n",
      "epoch 8549 train_loss 10978114.48881821 val_loss 206933.31250000\n",
      "epoch 8550 train_loss 10978114.48872864 val_loss 206933.31250000\n",
      "epoch 8551 train_loss 10978114.48867630 val_loss 206933.31250000\n",
      "epoch 8552 train_loss 10978114.48855866 val_loss 206933.31250000\n",
      "epoch 8553 train_loss 10978114.48848267 val_loss 206933.31250000\n",
      "epoch 8554 train_loss 10978114.48837303 val_loss 206933.31250000\n",
      "epoch 8555 train_loss 10978114.48828056 val_loss 206933.31250000\n",
      "epoch 8556 train_loss 10978114.48819878 val_loss 206933.31250000\n",
      "epoch 8557 train_loss 10978114.48812340 val_loss 206933.31250000\n",
      "epoch 8558 train_loss 10978114.48802116 val_loss 206933.31250000\n",
      "epoch 8559 train_loss 10978114.48795006 val_loss 206933.31250000\n",
      "epoch 8560 train_loss 10978114.48785866 val_loss 206933.31250000\n",
      "epoch 8561 train_loss 10978114.48776070 val_loss 206933.31250000\n",
      "epoch 8562 train_loss 10978114.48766731 val_loss 206933.31250000\n",
      "epoch 8563 train_loss 10978114.48758652 val_loss 206933.31250000\n",
      "epoch 8564 train_loss 10978114.48747482 val_loss 206933.31250000\n",
      "epoch 8565 train_loss 10978114.48737846 val_loss 206933.31250000\n",
      "epoch 8566 train_loss 10978114.48727646 val_loss 206933.31250000\n",
      "epoch 8567 train_loss 10978114.48722328 val_loss 206933.31250000\n",
      "epoch 8568 train_loss 10978114.48712753 val_loss 206933.31250000\n",
      "epoch 8569 train_loss 10978114.48703423 val_loss 206933.31250000\n",
      "epoch 8570 train_loss 10978114.48693596 val_loss 206933.31250000\n",
      "epoch 8571 train_loss 10978114.48684997 val_loss 206933.31250000\n",
      "epoch 8572 train_loss 10978114.48676384 val_loss 206933.31250000\n",
      "epoch 8573 train_loss 10978114.48667892 val_loss 206933.31250000\n",
      "epoch 8574 train_loss 10978114.48658005 val_loss 206933.31250000\n",
      "epoch 8575 train_loss 10978114.48648949 val_loss 206933.31250000\n",
      "epoch 8576 train_loss 10978114.48630485 val_loss 206933.31250000\n",
      "epoch 8577 train_loss 10978114.48621933 val_loss 206933.31250000\n",
      "epoch 8578 train_loss 10978114.48614342 val_loss 206933.31250000\n",
      "epoch 8579 train_loss 10978114.48602760 val_loss 206933.31250000\n",
      "epoch 8580 train_loss 10978114.48592339 val_loss 206933.31250000\n",
      "epoch 8581 train_loss 10978114.48592445 val_loss 206933.31250000\n",
      "epoch 8582 train_loss 10978114.48583229 val_loss 206933.31250000\n",
      "epoch 8583 train_loss 10978114.48573914 val_loss 206933.31250000\n",
      "epoch 8584 train_loss 10978114.48562843 val_loss 206933.31250000\n",
      "epoch 8585 train_loss 10978114.48553833 val_loss 206933.31250000\n",
      "epoch 8586 train_loss 10978114.48548477 val_loss 206933.31250000\n",
      "epoch 8587 train_loss 10978114.48539574 val_loss 206933.31250000\n",
      "epoch 8588 train_loss 10978114.48532074 val_loss 206933.31250000\n",
      "epoch 8589 train_loss 10978114.48522591 val_loss 206933.31250000\n",
      "epoch 8590 train_loss 10978114.48515800 val_loss 206933.31250000\n",
      "epoch 8591 train_loss 10978114.48504456 val_loss 206933.31250000\n",
      "epoch 8592 train_loss 10978114.48494392 val_loss 206933.31250000\n",
      "epoch 8593 train_loss 10978114.48485481 val_loss 206933.31250000\n",
      "epoch 8594 train_loss 10978114.48476105 val_loss 206933.31250000\n",
      "epoch 8595 train_loss 10978114.48466133 val_loss 206933.31250000\n",
      "epoch 8596 train_loss 10978114.48457451 val_loss 206933.31250000\n",
      "epoch 8597 train_loss 10978114.48465927 val_loss 206933.31250000\n",
      "epoch 8598 train_loss 10978114.48454819 val_loss 206933.31250000\n",
      "epoch 8599 train_loss 10978114.48445923 val_loss 206933.31250000\n",
      "epoch 8600 train_loss 10978114.48438232 val_loss 206933.31250000\n",
      "epoch 8601 train_loss 10978114.48427467 val_loss 206933.31250000\n",
      "epoch 8602 train_loss 10978114.48420883 val_loss 206933.31250000\n",
      "epoch 8603 train_loss 10978114.48414810 val_loss 206933.31250000\n",
      "epoch 8604 train_loss 10978114.48401970 val_loss 206933.31250000\n",
      "epoch 8605 train_loss 10978114.48398697 val_loss 206933.31250000\n",
      "epoch 8606 train_loss 10978114.48388786 val_loss 206933.31250000\n",
      "epoch 8607 train_loss 10978114.48379700 val_loss 206933.31250000\n",
      "epoch 8608 train_loss 10978114.48370018 val_loss 206933.31250000\n",
      "epoch 8609 train_loss 10978114.48361328 val_loss 206933.31250000\n",
      "epoch 8610 train_loss 10978114.48351898 val_loss 206933.31250000\n",
      "epoch 8611 train_loss 10978114.48341629 val_loss 206933.31250000\n",
      "epoch 8612 train_loss 10978114.48332603 val_loss 206933.31250000\n",
      "epoch 8613 train_loss 10978114.48323906 val_loss 206933.31250000\n",
      "epoch 8614 train_loss 10978114.48315392 val_loss 206933.31250000\n",
      "epoch 8615 train_loss 10978114.48307152 val_loss 206933.31250000\n",
      "epoch 8616 train_loss 10978114.48298645 val_loss 206933.31250000\n",
      "epoch 8617 train_loss 10978114.48289146 val_loss 206933.31250000\n",
      "epoch 8618 train_loss 10978114.48278259 val_loss 206933.31250000\n",
      "epoch 8619 train_loss 10978114.48268242 val_loss 206933.31250000\n",
      "epoch 8620 train_loss 10978114.48260292 val_loss 206933.31250000\n",
      "epoch 8621 train_loss 10978114.48249870 val_loss 206933.31250000\n",
      "epoch 8622 train_loss 10978114.48239899 val_loss 206933.31250000\n",
      "epoch 8623 train_loss 10978114.48230049 val_loss 206933.31250000\n",
      "epoch 8624 train_loss 10978114.48219131 val_loss 206933.31250000\n",
      "epoch 8625 train_loss 10978114.48212891 val_loss 206933.31250000\n",
      "epoch 8626 train_loss 10978114.48202103 val_loss 206933.31250000\n",
      "epoch 8627 train_loss 10978114.48194466 val_loss 206933.31250000\n",
      "epoch 8628 train_loss 10978114.48186508 val_loss 206933.31250000\n",
      "epoch 8629 train_loss 10978114.48175934 val_loss 206933.31250000\n",
      "epoch 8630 train_loss 10978114.48168098 val_loss 206933.31250000\n",
      "epoch 8631 train_loss 10978114.48159248 val_loss 206933.31250000\n",
      "epoch 8632 train_loss 10978114.48150269 val_loss 206933.31250000\n",
      "epoch 8633 train_loss 10978114.48140144 val_loss 206933.31250000\n",
      "epoch 8634 train_loss 10978114.48133057 val_loss 206933.31250000\n",
      "epoch 8635 train_loss 10978114.48122780 val_loss 206933.31250000\n",
      "epoch 8636 train_loss 10978114.48112572 val_loss 206933.31250000\n",
      "epoch 8637 train_loss 10978114.48102814 val_loss 206933.31250000\n",
      "epoch 8638 train_loss 10978114.48095505 val_loss 206933.31250000\n",
      "epoch 8639 train_loss 10978114.48086250 val_loss 206933.31250000\n",
      "epoch 8640 train_loss 10978114.48078682 val_loss 206933.31250000\n",
      "epoch 8641 train_loss 10978114.48067093 val_loss 206933.31250000\n",
      "epoch 8642 train_loss 10978114.48060822 val_loss 206933.31250000\n",
      "epoch 8643 train_loss 10978114.48050781 val_loss 206933.31250000\n",
      "epoch 8644 train_loss 10978114.48043777 val_loss 206933.31250000\n",
      "epoch 8645 train_loss 10978114.48034637 val_loss 206933.31250000\n",
      "epoch 8646 train_loss 10978114.48026924 val_loss 206933.31250000\n",
      "epoch 8647 train_loss 10978114.48017204 val_loss 206933.31250000\n",
      "epoch 8648 train_loss 10978114.48007980 val_loss 206933.31250000\n",
      "epoch 8649 train_loss 10978114.47999870 val_loss 206933.31250000\n",
      "epoch 8650 train_loss 10978114.47988686 val_loss 206933.31250000\n",
      "epoch 8651 train_loss 10978114.47979027 val_loss 206933.31250000\n",
      "epoch 8652 train_loss 10978114.47969223 val_loss 206933.31250000\n",
      "epoch 8653 train_loss 10978114.47962189 val_loss 206933.31250000\n",
      "epoch 8654 train_loss 10978114.47952042 val_loss 206933.31250000\n",
      "epoch 8655 train_loss 10978114.47942551 val_loss 206933.31250000\n",
      "epoch 8656 train_loss 10978114.47934616 val_loss 206933.31250000\n",
      "epoch 8657 train_loss 10978114.47926315 val_loss 206933.31250000\n",
      "epoch 8658 train_loss 10978114.47915581 val_loss 206933.31250000\n",
      "epoch 8659 train_loss 10978114.47904182 val_loss 206933.31250000\n",
      "epoch 8660 train_loss 10978114.47894485 val_loss 206933.31250000\n",
      "epoch 8661 train_loss 10978114.47886444 val_loss 206933.31250000\n",
      "epoch 8662 train_loss 10978114.47877983 val_loss 206933.31250000\n",
      "epoch 8663 train_loss 10978114.47869057 val_loss 206933.31250000\n",
      "epoch 8664 train_loss 10978114.47858315 val_loss 206933.31250000\n",
      "epoch 8665 train_loss 10978114.47849335 val_loss 206933.31250000\n",
      "epoch 8666 train_loss 10978114.47840477 val_loss 206933.31250000\n",
      "epoch 8667 train_loss 10978114.47831741 val_loss 206933.31250000\n",
      "epoch 8668 train_loss 10978114.47821655 val_loss 206933.31250000\n",
      "epoch 8669 train_loss 10978114.47811836 val_loss 206933.31250000\n",
      "epoch 8670 train_loss 10978114.47804070 val_loss 206933.31250000\n",
      "epoch 8671 train_loss 10978114.47795464 val_loss 206933.31250000\n",
      "epoch 8672 train_loss 10978114.47784653 val_loss 206933.31250000\n",
      "epoch 8673 train_loss 10978114.47777962 val_loss 206933.31250000\n",
      "epoch 8674 train_loss 10978114.47769005 val_loss 206933.31250000\n",
      "epoch 8675 train_loss 10978114.47759316 val_loss 206933.31250000\n",
      "epoch 8676 train_loss 10978114.47749466 val_loss 206933.31250000\n",
      "epoch 8677 train_loss 10978114.47740555 val_loss 206933.31250000\n",
      "epoch 8678 train_loss 10978114.47730797 val_loss 206933.31250000\n",
      "epoch 8679 train_loss 10978114.47720512 val_loss 206933.31250000\n",
      "epoch 8680 train_loss 10978114.47711617 val_loss 206933.31250000\n",
      "epoch 8681 train_loss 10978114.47703613 val_loss 206933.31250000\n",
      "epoch 8682 train_loss 10978114.47697510 val_loss 206933.31250000\n",
      "epoch 8683 train_loss 10978114.47685997 val_loss 206933.31250000\n",
      "epoch 8684 train_loss 10978114.47676750 val_loss 206933.31250000\n",
      "epoch 8685 train_loss 10978114.47667671 val_loss 206933.31250000\n",
      "epoch 8686 train_loss 10978114.47659142 val_loss 206933.31250000\n",
      "epoch 8687 train_loss 10978114.47651543 val_loss 206933.31250000\n",
      "epoch 8688 train_loss 10978114.47642899 val_loss 206933.31250000\n",
      "epoch 8689 train_loss 10978114.47632866 val_loss 206933.31250000\n",
      "epoch 8690 train_loss 10978114.47621460 val_loss 206933.31250000\n",
      "epoch 8691 train_loss 10978114.47612953 val_loss 206933.31250000\n",
      "epoch 8692 train_loss 10978114.47611565 val_loss 206933.31250000\n",
      "epoch 8693 train_loss 10978114.47601242 val_loss 206933.31250000\n",
      "epoch 8694 train_loss 10978114.47592262 val_loss 206933.31250000\n",
      "epoch 8695 train_loss 10978114.47585426 val_loss 206933.31250000\n",
      "epoch 8696 train_loss 10978114.47577728 val_loss 206933.31250000\n",
      "epoch 8697 train_loss 10978114.47567696 val_loss 206933.31250000\n",
      "epoch 8698 train_loss 10978114.47559189 val_loss 206933.31250000\n",
      "epoch 8699 train_loss 10978114.47548599 val_loss 206933.31250000\n",
      "epoch 8700 train_loss 10978114.47538475 val_loss 206933.31250000\n",
      "epoch 8701 train_loss 10978114.47534363 val_loss 206933.31250000\n",
      "epoch 8702 train_loss 10978114.47524429 val_loss 206933.31250000\n",
      "epoch 8703 train_loss 10978114.47515282 val_loss 206933.31250000\n",
      "epoch 8704 train_loss 10978114.47503563 val_loss 206933.31250000\n",
      "epoch 8705 train_loss 10978114.47498619 val_loss 206933.31250000\n",
      "epoch 8706 train_loss 10978114.47490326 val_loss 206933.31250000\n",
      "epoch 8707 train_loss 10978114.47484680 val_loss 206933.31250000\n",
      "epoch 8708 train_loss 10978114.47476715 val_loss 206933.31250000\n",
      "epoch 8709 train_loss 10978114.47469772 val_loss 206933.31250000\n",
      "epoch 8710 train_loss 10978114.47460373 val_loss 206933.31250000\n",
      "epoch 8711 train_loss 10978114.47450600 val_loss 206933.31250000\n",
      "epoch 8712 train_loss 10978114.47441963 val_loss 206933.31250000\n",
      "epoch 8713 train_loss 10978114.47432327 val_loss 206933.31250000\n",
      "epoch 8714 train_loss 10978114.47423538 val_loss 206933.31250000\n",
      "epoch 8715 train_loss 10978114.47411095 val_loss 206933.31250000\n",
      "epoch 8716 train_loss 10978114.47406342 val_loss 206933.31250000\n",
      "epoch 8717 train_loss 10978114.47398750 val_loss 206933.31250000\n",
      "epoch 8718 train_loss 10978114.47391396 val_loss 206933.31250000\n",
      "epoch 8719 train_loss 10978114.47383133 val_loss 206933.31250000\n",
      "epoch 8720 train_loss 10978114.47375534 val_loss 206933.31250000\n",
      "epoch 8721 train_loss 10978114.47363197 val_loss 206933.31250000\n",
      "epoch 8722 train_loss 10978114.47355919 val_loss 206933.31250000\n",
      "epoch 8723 train_loss 10978114.47345741 val_loss 206933.31250000\n",
      "epoch 8724 train_loss 10978114.47340996 val_loss 206933.31250000\n",
      "epoch 8725 train_loss 10978114.47330879 val_loss 206933.31250000\n",
      "epoch 8726 train_loss 10978114.47337692 val_loss 206933.31250000\n",
      "epoch 8727 train_loss 10978114.47329224 val_loss 206933.31250000\n",
      "epoch 8728 train_loss 10978114.47318649 val_loss 206933.31250000\n",
      "epoch 8729 train_loss 10978114.47310494 val_loss 206933.31250000\n",
      "epoch 8730 train_loss 10978114.47302780 val_loss 206933.31250000\n",
      "epoch 8731 train_loss 10978114.47295288 val_loss 206933.31250000\n",
      "epoch 8732 train_loss 10978114.47284111 val_loss 206933.31250000\n",
      "epoch 8733 train_loss 10978114.47276024 val_loss 206933.31250000\n",
      "epoch 8734 train_loss 10978114.47267220 val_loss 206933.31250000\n",
      "epoch 8735 train_loss 10978114.47256149 val_loss 206933.31250000\n",
      "epoch 8736 train_loss 10978114.47249329 val_loss 206933.31250000\n",
      "epoch 8737 train_loss 10978114.47239677 val_loss 206933.31250000\n",
      "epoch 8738 train_loss 10978114.47231056 val_loss 206933.31250000\n",
      "epoch 8739 train_loss 10978114.47220108 val_loss 206933.31250000\n",
      "epoch 8740 train_loss 10978114.47210792 val_loss 206933.31250000\n",
      "epoch 8741 train_loss 10978114.47203987 val_loss 206933.31250000\n",
      "epoch 8742 train_loss 10978114.47194161 val_loss 206933.31250000\n",
      "epoch 8743 train_loss 10978114.47183098 val_loss 206933.31250000\n",
      "epoch 8744 train_loss 10978114.47174171 val_loss 206933.31250000\n",
      "epoch 8745 train_loss 10978114.47165718 val_loss 206933.31250000\n",
      "epoch 8746 train_loss 10978114.47154594 val_loss 206933.31250000\n",
      "epoch 8747 train_loss 10978114.47147507 val_loss 206933.31250000\n",
      "epoch 8748 train_loss 10978114.47138451 val_loss 206933.31250000\n",
      "epoch 8749 train_loss 10978114.47129768 val_loss 206933.31250000\n",
      "epoch 8750 train_loss 10978114.47120926 val_loss 206933.31250000\n",
      "epoch 8751 train_loss 10978114.47113388 val_loss 206933.31250000\n",
      "epoch 8752 train_loss 10978114.47104004 val_loss 206933.31250000\n",
      "epoch 8753 train_loss 10978114.47096649 val_loss 206933.31250000\n",
      "epoch 8754 train_loss 10978114.47090134 val_loss 206933.31250000\n",
      "epoch 8755 train_loss 10978114.47080689 val_loss 206933.31250000\n",
      "epoch 8756 train_loss 10978114.47073258 val_loss 206933.31250000\n",
      "epoch 8757 train_loss 10978114.47065949 val_loss 206933.31250000\n",
      "epoch 8758 train_loss 10978114.47056961 val_loss 206933.31250000\n",
      "epoch 8759 train_loss 10978114.47047493 val_loss 206933.31250000\n",
      "epoch 8760 train_loss 10978114.47037209 val_loss 206933.31250000\n",
      "epoch 8761 train_loss 10978114.47029976 val_loss 206933.31250000\n",
      "epoch 8762 train_loss 10978114.47021912 val_loss 206933.31250000\n",
      "epoch 8763 train_loss 10978114.47012260 val_loss 206933.31250000\n",
      "epoch 8764 train_loss 10978114.47000145 val_loss 206933.31250000\n",
      "epoch 8765 train_loss 10978114.46992035 val_loss 206933.31250000\n",
      "epoch 8766 train_loss 10978114.46983589 val_loss 206933.31250000\n",
      "epoch 8767 train_loss 10978114.46973610 val_loss 206933.31250000\n",
      "epoch 8768 train_loss 10978114.46964409 val_loss 206933.31250000\n",
      "epoch 8769 train_loss 10978114.46955994 val_loss 206933.31250000\n",
      "epoch 8770 train_loss 10978114.46946442 val_loss 206933.31250000\n",
      "epoch 8771 train_loss 10978114.46937340 val_loss 206933.31250000\n",
      "epoch 8772 train_loss 10978114.46927414 val_loss 206933.31250000\n",
      "epoch 8773 train_loss 10978114.46919472 val_loss 206933.31250000\n",
      "epoch 8774 train_loss 10978114.46907631 val_loss 206933.31250000\n",
      "epoch 8775 train_loss 10978114.46900414 val_loss 206933.31250000\n",
      "epoch 8776 train_loss 10978114.46890999 val_loss 206933.31250000\n",
      "epoch 8777 train_loss 10978114.46882584 val_loss 206933.31250000\n",
      "epoch 8778 train_loss 10978114.46872421 val_loss 206933.31250000\n",
      "epoch 8779 train_loss 10978114.46863648 val_loss 206933.31250000\n",
      "epoch 8780 train_loss 10978114.46855446 val_loss 206933.31250000\n",
      "epoch 8781 train_loss 10978114.46843697 val_loss 206933.31250000\n",
      "epoch 8782 train_loss 10978114.46834259 val_loss 206933.31250000\n",
      "epoch 8783 train_loss 10978114.46825272 val_loss 206933.31250000\n",
      "epoch 8784 train_loss 10978114.46817047 val_loss 206933.31250000\n",
      "epoch 8785 train_loss 10978114.46807854 val_loss 206933.31250000\n",
      "epoch 8786 train_loss 10978114.46798256 val_loss 206933.31250000\n",
      "epoch 8787 train_loss 10978114.46789040 val_loss 206933.31250000\n",
      "epoch 8788 train_loss 10978114.46779633 val_loss 206933.31250000\n",
      "epoch 8789 train_loss 10978114.46771080 val_loss 206933.31250000\n",
      "epoch 8790 train_loss 10978114.46763794 val_loss 206933.31250000\n",
      "epoch 8791 train_loss 10978114.46758217 val_loss 206933.31250000\n",
      "epoch 8792 train_loss 10978114.46748070 val_loss 206933.31250000\n",
      "epoch 8793 train_loss 10978114.46740181 val_loss 206933.31250000\n",
      "epoch 8794 train_loss 10978114.46730812 val_loss 206933.31250000\n",
      "epoch 8795 train_loss 10978114.46720642 val_loss 206933.31250000\n",
      "epoch 8796 train_loss 10978114.46711121 val_loss 206933.31250000\n",
      "epoch 8797 train_loss 10978114.46700501 val_loss 206933.31250000\n",
      "epoch 8798 train_loss 10978114.46692093 val_loss 206933.31250000\n",
      "epoch 8799 train_loss 10978114.46682358 val_loss 206933.31250000\n",
      "epoch 8800 train_loss 10978114.46674973 val_loss 206933.31250000\n",
      "epoch 8801 train_loss 10978114.46665901 val_loss 206933.31250000\n",
      "epoch 8802 train_loss 10978114.46656151 val_loss 206933.31250000\n",
      "epoch 8803 train_loss 10978114.46648514 val_loss 206933.31250000\n",
      "epoch 8804 train_loss 10978114.46639885 val_loss 206933.31250000\n",
      "epoch 8805 train_loss 10978114.46631157 val_loss 206933.31250000\n",
      "epoch 8806 train_loss 10978114.46619644 val_loss 206933.31250000\n",
      "epoch 8807 train_loss 10978114.46611031 val_loss 206933.31250000\n",
      "epoch 8808 train_loss 10978114.46601799 val_loss 206933.31250000\n",
      "epoch 8809 train_loss 10978114.46591759 val_loss 206933.31250000\n",
      "epoch 8810 train_loss 10978114.46587357 val_loss 206933.31250000\n",
      "epoch 8811 train_loss 10978114.46577156 val_loss 206933.31250000\n",
      "epoch 8812 train_loss 10978114.46569893 val_loss 206933.31250000\n",
      "epoch 8813 train_loss 10978114.46558624 val_loss 206933.31250000\n",
      "epoch 8814 train_loss 10978114.46549622 val_loss 206933.31250000\n",
      "epoch 8815 train_loss 10978114.46541916 val_loss 206933.31250000\n",
      "epoch 8816 train_loss 10978114.46533081 val_loss 206933.31250000\n",
      "epoch 8817 train_loss 10978114.46522598 val_loss 206933.31250000\n",
      "epoch 8818 train_loss 10978114.46511970 val_loss 206933.31250000\n",
      "epoch 8819 train_loss 10978114.46503364 val_loss 206933.31250000\n",
      "epoch 8820 train_loss 10978114.46493629 val_loss 206933.31250000\n",
      "epoch 8821 train_loss 10978114.46486885 val_loss 206933.31250000\n",
      "epoch 8822 train_loss 10978114.46492294 val_loss 206933.31250000\n",
      "epoch 8823 train_loss 10978114.46484535 val_loss 206933.31250000\n",
      "epoch 8824 train_loss 10978114.46473671 val_loss 206933.31250000\n",
      "epoch 8825 train_loss 10978114.46466583 val_loss 206933.31250000\n",
      "epoch 8826 train_loss 10978114.46456360 val_loss 206933.31250000\n",
      "epoch 8827 train_loss 10978114.46446426 val_loss 206933.31250000\n",
      "epoch 8828 train_loss 10978114.46435860 val_loss 206933.31250000\n",
      "epoch 8829 train_loss 10978114.46428062 val_loss 206933.31250000\n",
      "epoch 8830 train_loss 10978114.46420349 val_loss 206933.31250000\n",
      "epoch 8831 train_loss 10978114.46408485 val_loss 206933.31250000\n",
      "epoch 8832 train_loss 10978114.46400986 val_loss 206933.31250000\n",
      "epoch 8833 train_loss 10978114.46390884 val_loss 206933.31250000\n",
      "epoch 8834 train_loss 10978114.46382629 val_loss 206933.31250000\n",
      "epoch 8835 train_loss 10978114.46373756 val_loss 206933.31250000\n",
      "epoch 8836 train_loss 10978114.46366058 val_loss 206933.31250000\n",
      "epoch 8837 train_loss 10978114.46357254 val_loss 206933.31250000\n",
      "epoch 8838 train_loss 10978114.46355476 val_loss 206933.31250000\n",
      "epoch 8839 train_loss 10978114.46346588 val_loss 206933.31250000\n",
      "epoch 8840 train_loss 10978114.46338127 val_loss 206933.31250000\n",
      "epoch 8841 train_loss 10978114.46328560 val_loss 206933.31250000\n",
      "epoch 8842 train_loss 10978114.46319710 val_loss 206933.31250000\n",
      "epoch 8843 train_loss 10978114.46309898 val_loss 206933.32812500\n",
      "epoch 8844 train_loss 10978114.46300224 val_loss 206933.32812500\n",
      "epoch 8845 train_loss 10978114.46290436 val_loss 206933.32812500\n",
      "epoch 8846 train_loss 10978114.46281120 val_loss 206933.32812500\n",
      "epoch 8847 train_loss 10978114.46272491 val_loss 206933.32812500\n",
      "epoch 8848 train_loss 10978114.46261543 val_loss 206933.32812500\n",
      "epoch 8849 train_loss 10978114.46253052 val_loss 206933.32812500\n",
      "epoch 8850 train_loss 10978114.46243034 val_loss 206933.32812500\n",
      "epoch 8851 train_loss 10978114.46236259 val_loss 206933.32812500\n",
      "epoch 8852 train_loss 10978114.46226959 val_loss 206933.32812500\n",
      "epoch 8853 train_loss 10978114.46220100 val_loss 206933.32812500\n",
      "epoch 8854 train_loss 10978114.46210106 val_loss 206933.32812500\n",
      "epoch 8855 train_loss 10978114.46200058 val_loss 206933.32812500\n",
      "epoch 8856 train_loss 10978114.46189804 val_loss 206933.32812500\n",
      "epoch 8857 train_loss 10978114.46182243 val_loss 206933.32812500\n",
      "epoch 8858 train_loss 10978114.46171272 val_loss 206933.32812500\n",
      "epoch 8859 train_loss 10978114.46163666 val_loss 206933.32812500\n",
      "epoch 8860 train_loss 10978114.46154823 val_loss 206933.32812500\n",
      "epoch 8861 train_loss 10978114.46144936 val_loss 206933.32812500\n",
      "epoch 8862 train_loss 10978114.46134598 val_loss 206933.32812500\n",
      "epoch 8863 train_loss 10978114.46127693 val_loss 206933.32812500\n",
      "epoch 8864 train_loss 10978114.46120644 val_loss 206933.32812500\n",
      "epoch 8865 train_loss 10978114.46111580 val_loss 206933.32812500\n",
      "epoch 8866 train_loss 10978114.46099419 val_loss 206933.32812500\n",
      "epoch 8867 train_loss 10978114.46089951 val_loss 206933.32812500\n",
      "epoch 8868 train_loss 10978114.46084610 val_loss 206933.32812500\n",
      "epoch 8869 train_loss 10978114.46073914 val_loss 206933.32812500\n",
      "epoch 8870 train_loss 10978114.46065720 val_loss 206933.32812500\n",
      "epoch 8871 train_loss 10978114.46055893 val_loss 206933.32812500\n",
      "epoch 8872 train_loss 10978114.46046760 val_loss 206933.32812500\n",
      "epoch 8873 train_loss 10978114.46035088 val_loss 206933.32812500\n",
      "epoch 8874 train_loss 10978114.46025963 val_loss 206933.32812500\n",
      "epoch 8875 train_loss 10978114.46016807 val_loss 206933.32812500\n",
      "epoch 8876 train_loss 10978114.46005989 val_loss 206933.32812500\n",
      "epoch 8877 train_loss 10978114.45996544 val_loss 206933.32812500\n",
      "epoch 8878 train_loss 10978114.45987854 val_loss 206933.32812500\n",
      "epoch 8879 train_loss 10978114.45980583 val_loss 206933.32812500\n",
      "epoch 8880 train_loss 10978114.45971016 val_loss 206933.32812500\n",
      "epoch 8881 train_loss 10978114.45966721 val_loss 206933.32812500\n",
      "epoch 8882 train_loss 10978114.45956787 val_loss 206933.32812500\n",
      "epoch 8883 train_loss 10978114.45947029 val_loss 206933.32812500\n",
      "epoch 8884 train_loss 10978114.45937080 val_loss 206933.32812500\n",
      "epoch 8885 train_loss 10978114.45927856 val_loss 206933.32812500\n",
      "epoch 8886 train_loss 10978114.45919457 val_loss 206933.32812500\n",
      "epoch 8887 train_loss 10978114.45908798 val_loss 206933.32812500\n",
      "epoch 8888 train_loss 10978114.45899925 val_loss 206933.32812500\n",
      "epoch 8889 train_loss 10978114.45890320 val_loss 206933.32812500\n",
      "epoch 8890 train_loss 10978114.45885033 val_loss 206933.32812500\n",
      "epoch 8891 train_loss 10978114.45877136 val_loss 206933.32812500\n",
      "epoch 8892 train_loss 10978114.45866264 val_loss 206933.32812500\n",
      "epoch 8893 train_loss 10978114.45858719 val_loss 206933.32812500\n",
      "epoch 8894 train_loss 10978114.45846878 val_loss 206933.32812500\n",
      "epoch 8895 train_loss 10978114.45840141 val_loss 206933.32812500\n",
      "epoch 8896 train_loss 10978114.45831413 val_loss 206933.32812500\n",
      "epoch 8897 train_loss 10978114.45820938 val_loss 206933.32812500\n",
      "epoch 8898 train_loss 10978114.45811272 val_loss 206933.32812500\n",
      "epoch 8899 train_loss 10978114.45803154 val_loss 206933.32812500\n",
      "epoch 8900 train_loss 10978114.45793015 val_loss 206933.32812500\n",
      "epoch 8901 train_loss 10978114.45784050 val_loss 206933.32812500\n",
      "epoch 8902 train_loss 10978114.45774971 val_loss 206933.32812500\n",
      "epoch 8903 train_loss 10978114.45765099 val_loss 206933.32812500\n",
      "epoch 8904 train_loss 10978114.45758926 val_loss 206933.32812500\n",
      "epoch 8905 train_loss 10978114.45750572 val_loss 206933.32812500\n",
      "epoch 8906 train_loss 10978114.45741554 val_loss 206933.32812500\n",
      "epoch 8907 train_loss 10978114.45738014 val_loss 206933.32812500\n",
      "epoch 8908 train_loss 10978114.45729172 val_loss 206933.32812500\n",
      "epoch 8909 train_loss 10978114.45720375 val_loss 206933.32812500\n",
      "epoch 8910 train_loss 10978114.45713097 val_loss 206933.32812500\n",
      "epoch 8911 train_loss 10978114.45703156 val_loss 206933.32812500\n",
      "epoch 8912 train_loss 10978114.45693863 val_loss 206933.32812500\n",
      "epoch 8913 train_loss 10978114.45684723 val_loss 206933.32812500\n",
      "epoch 8914 train_loss 10978114.45674912 val_loss 206933.32812500\n",
      "epoch 8915 train_loss 10978114.45662720 val_loss 206933.32812500\n",
      "epoch 8916 train_loss 10978114.45656776 val_loss 206933.32812500\n",
      "epoch 8917 train_loss 10978114.45647011 val_loss 206933.32812500\n",
      "epoch 8918 train_loss 10978114.45636406 val_loss 206933.32812500\n",
      "epoch 8919 train_loss 10978114.45628532 val_loss 206933.32812500\n",
      "epoch 8920 train_loss 10978114.45618881 val_loss 206933.32812500\n",
      "epoch 8921 train_loss 10978114.45610184 val_loss 206933.32812500\n",
      "epoch 8922 train_loss 10978114.45600258 val_loss 206933.32812500\n",
      "epoch 8923 train_loss 10978114.45591858 val_loss 206933.32812500\n",
      "epoch 8924 train_loss 10978114.45581810 val_loss 206933.32812500\n",
      "epoch 8925 train_loss 10978114.45572670 val_loss 206933.32812500\n",
      "epoch 8926 train_loss 10978114.45566513 val_loss 206933.32812500\n",
      "epoch 8927 train_loss 10978114.45555489 val_loss 206933.32812500\n",
      "epoch 8928 train_loss 10978114.45547478 val_loss 206933.32812500\n",
      "epoch 8929 train_loss 10978114.45539467 val_loss 206933.32812500\n",
      "epoch 8930 train_loss 10978114.45528412 val_loss 206933.32812500\n",
      "epoch 8931 train_loss 10978114.45519752 val_loss 206933.32812500\n",
      "epoch 8932 train_loss 10978114.45511330 val_loss 206933.32812500\n",
      "epoch 8933 train_loss 10978114.45502678 val_loss 206933.32812500\n",
      "epoch 8934 train_loss 10978114.45499107 val_loss 206933.32812500\n",
      "epoch 8935 train_loss 10978114.45487816 val_loss 206933.32812500\n",
      "epoch 8936 train_loss 10978114.45477928 val_loss 206933.32812500\n",
      "epoch 8937 train_loss 10978114.45472008 val_loss 206933.32812500\n",
      "epoch 8938 train_loss 10978114.45464012 val_loss 206933.32812500\n",
      "epoch 8939 train_loss 10978114.45457710 val_loss 206933.32812500\n",
      "epoch 8940 train_loss 10978114.45448067 val_loss 206933.32812500\n",
      "epoch 8941 train_loss 10978114.45439621 val_loss 206933.32812500\n",
      "epoch 8942 train_loss 10978114.45431694 val_loss 206933.32812500\n",
      "epoch 8943 train_loss 10978114.45421822 val_loss 206933.32812500\n",
      "epoch 8944 train_loss 10978114.45412087 val_loss 206933.32812500\n",
      "epoch 8945 train_loss 10978114.45400948 val_loss 206933.32812500\n",
      "epoch 8946 train_loss 10978114.45393646 val_loss 206933.32812500\n",
      "epoch 8947 train_loss 10978114.45382095 val_loss 206933.32812500\n",
      "epoch 8948 train_loss 10978114.45374596 val_loss 206933.32812500\n",
      "epoch 8949 train_loss 10978114.45364334 val_loss 206933.32812500\n",
      "epoch 8950 train_loss 10978114.45354660 val_loss 206933.32812500\n",
      "epoch 8951 train_loss 10978114.45345337 val_loss 206933.32812500\n",
      "epoch 8952 train_loss 10978114.45337158 val_loss 206933.32812500\n",
      "epoch 8953 train_loss 10978114.45327194 val_loss 206933.32812500\n",
      "epoch 8954 train_loss 10978114.45317062 val_loss 206933.32812500\n",
      "epoch 8955 train_loss 10978114.45309425 val_loss 206933.32812500\n",
      "epoch 8956 train_loss 10978114.45299866 val_loss 206933.32812500\n",
      "epoch 8957 train_loss 10978114.45290985 val_loss 206933.32812500\n",
      "epoch 8958 train_loss 10978114.45279671 val_loss 206933.32812500\n",
      "epoch 8959 train_loss 10978114.45270523 val_loss 206933.32812500\n",
      "epoch 8960 train_loss 10978114.45261932 val_loss 206933.32812500\n",
      "epoch 8961 train_loss 10978114.45251083 val_loss 206933.32812500\n",
      "epoch 8962 train_loss 10978114.45244301 val_loss 206933.32812500\n",
      "epoch 8963 train_loss 10978114.45233841 val_loss 206933.32812500\n",
      "epoch 8964 train_loss 10978114.45224495 val_loss 206933.32812500\n",
      "epoch 8965 train_loss 10978114.45214233 val_loss 206933.32812500\n",
      "epoch 8966 train_loss 10978114.45205559 val_loss 206933.32812500\n",
      "epoch 8967 train_loss 10978114.45197121 val_loss 206933.32812500\n",
      "epoch 8968 train_loss 10978114.45185028 val_loss 206933.32812500\n",
      "epoch 8969 train_loss 10978114.45175896 val_loss 206933.32812500\n",
      "epoch 8970 train_loss 10978114.45169510 val_loss 206933.32812500\n",
      "epoch 8971 train_loss 10978114.45159935 val_loss 206933.32812500\n",
      "epoch 8972 train_loss 10978114.45147759 val_loss 206933.32812500\n",
      "epoch 8973 train_loss 10978114.45139961 val_loss 206933.32812500\n",
      "epoch 8974 train_loss 10978114.45130959 val_loss 206933.32812500\n",
      "epoch 8975 train_loss 10978114.45120933 val_loss 206933.32812500\n",
      "epoch 8976 train_loss 10978114.45111816 val_loss 206933.32812500\n",
      "epoch 8977 train_loss 10978114.45110603 val_loss 206933.32812500\n",
      "epoch 8978 train_loss 10978114.45104050 val_loss 206933.32812500\n",
      "epoch 8979 train_loss 10978114.45094917 val_loss 206933.32812500\n",
      "epoch 8980 train_loss 10978114.45091660 val_loss 206933.32812500\n",
      "epoch 8981 train_loss 10978114.45083763 val_loss 206933.32812500\n",
      "epoch 8982 train_loss 10978114.45072899 val_loss 206933.32812500\n",
      "epoch 8983 train_loss 10978114.45063919 val_loss 206933.32812500\n",
      "epoch 8984 train_loss 10978114.45053909 val_loss 206933.32812500\n",
      "epoch 8985 train_loss 10978114.45045990 val_loss 206933.32812500\n",
      "epoch 8986 train_loss 10978114.45034973 val_loss 206933.32812500\n",
      "epoch 8987 train_loss 10978114.45025627 val_loss 206933.32812500\n",
      "epoch 8988 train_loss 10978114.45018692 val_loss 206933.32812500\n",
      "epoch 8989 train_loss 10978114.45008392 val_loss 206933.32812500\n",
      "epoch 8990 train_loss 10978114.44999558 val_loss 206933.32812500\n",
      "epoch 8991 train_loss 10978114.44988411 val_loss 206933.32812500\n",
      "epoch 8992 train_loss 10978114.44982353 val_loss 206933.32812500\n",
      "epoch 8993 train_loss 10978114.44971779 val_loss 206933.32812500\n",
      "epoch 8994 train_loss 10978114.44963623 val_loss 206933.32812500\n",
      "epoch 8995 train_loss 10978114.44958824 val_loss 206933.32812500\n",
      "epoch 8996 train_loss 10978114.44948006 val_loss 206933.32812500\n",
      "epoch 8997 train_loss 10978114.44943901 val_loss 206933.32812500\n",
      "epoch 8998 train_loss 10978114.44939102 val_loss 206933.32812500\n",
      "epoch 8999 train_loss 10978114.44930008 val_loss 206933.32812500\n",
      "epoch 9000 train_loss 10978114.44919869 val_loss 206933.32812500\n",
      "epoch 9001 train_loss 10978114.44911110 val_loss 206933.32812500\n",
      "epoch 9002 train_loss 10978114.44901977 val_loss 206933.32812500\n",
      "epoch 9003 train_loss 10978114.44891136 val_loss 206933.32812500\n",
      "epoch 9004 train_loss 10978114.44881325 val_loss 206933.32812500\n",
      "epoch 9005 train_loss 10978114.44873085 val_loss 206933.32812500\n",
      "epoch 9006 train_loss 10978114.44868065 val_loss 206933.32812500\n",
      "epoch 9007 train_loss 10978114.44857765 val_loss 206933.32812500\n",
      "epoch 9008 train_loss 10978114.44851662 val_loss 206933.32812500\n",
      "epoch 9009 train_loss 10978114.44839859 val_loss 206933.32812500\n",
      "epoch 9010 train_loss 10978114.44830170 val_loss 206933.32812500\n",
      "epoch 9011 train_loss 10978114.44822006 val_loss 206933.32812500\n",
      "epoch 9012 train_loss 10978114.44811790 val_loss 206933.32812500\n",
      "epoch 9013 train_loss 10978114.44803665 val_loss 206933.32812500\n",
      "epoch 9014 train_loss 10978114.44792267 val_loss 206933.32812500\n",
      "epoch 9015 train_loss 10978114.44783485 val_loss 206933.32812500\n",
      "epoch 9016 train_loss 10978114.44773422 val_loss 206933.32812500\n",
      "epoch 9017 train_loss 10978114.44763062 val_loss 206933.32812500\n",
      "epoch 9018 train_loss 10978114.44753647 val_loss 206933.32812500\n",
      "epoch 9019 train_loss 10978114.44744820 val_loss 206933.32812500\n",
      "epoch 9020 train_loss 10978114.44734955 val_loss 206933.32812500\n",
      "epoch 9021 train_loss 10978114.44727020 val_loss 206933.32812500\n",
      "epoch 9022 train_loss 10978114.44717461 val_loss 206933.32812500\n",
      "epoch 9023 train_loss 10978114.44708023 val_loss 206933.32812500\n",
      "epoch 9024 train_loss 10978114.44697044 val_loss 206933.32812500\n",
      "epoch 9025 train_loss 10978114.44688850 val_loss 206933.32812500\n",
      "epoch 9026 train_loss 10978114.44680107 val_loss 206933.32812500\n",
      "epoch 9027 train_loss 10978114.44672012 val_loss 206933.32812500\n",
      "epoch 9028 train_loss 10978114.44668976 val_loss 206933.32812500\n",
      "epoch 9029 train_loss 10978114.44659302 val_loss 206933.32812500\n",
      "epoch 9030 train_loss 10978114.44650673 val_loss 206933.32812500\n",
      "epoch 9031 train_loss 10978114.44641647 val_loss 206933.32812500\n",
      "epoch 9032 train_loss 10978114.44641724 val_loss 206933.32812500\n",
      "epoch 9033 train_loss 10978114.44631035 val_loss 206933.32812500\n",
      "epoch 9034 train_loss 10978114.44622856 val_loss 206933.32812500\n",
      "epoch 9035 train_loss 10978114.44613396 val_loss 206933.32812500\n",
      "epoch 9036 train_loss 10978114.44604248 val_loss 206933.32812500\n",
      "epoch 9037 train_loss 10978114.44597412 val_loss 206933.32812500\n",
      "epoch 9038 train_loss 10978114.44590271 val_loss 206933.32812500\n",
      "epoch 9039 train_loss 10978114.44577850 val_loss 206933.32812500\n",
      "epoch 9040 train_loss 10978114.44568863 val_loss 206933.32812500\n",
      "epoch 9041 train_loss 10978114.44560417 val_loss 206933.32812500\n",
      "epoch 9042 train_loss 10978114.44548599 val_loss 206933.32812500\n",
      "epoch 9043 train_loss 10978114.44539963 val_loss 206933.32812500\n",
      "epoch 9044 train_loss 10978114.44530823 val_loss 206933.32812500\n",
      "epoch 9045 train_loss 10978114.44521935 val_loss 206933.32812500\n",
      "epoch 9046 train_loss 10978114.44512657 val_loss 206933.32812500\n",
      "epoch 9047 train_loss 10978114.44502647 val_loss 206933.32812500\n",
      "epoch 9048 train_loss 10978114.44494003 val_loss 206933.32812500\n",
      "epoch 9049 train_loss 10978114.44484627 val_loss 206933.32812500\n",
      "epoch 9050 train_loss 10978114.44475151 val_loss 206933.32812500\n",
      "epoch 9051 train_loss 10978114.44466949 val_loss 206933.32812500\n",
      "epoch 9052 train_loss 10978114.44462273 val_loss 206933.32812500\n",
      "epoch 9053 train_loss 10978114.44453819 val_loss 206933.32812500\n",
      "epoch 9054 train_loss 10978114.44445099 val_loss 206933.32812500\n",
      "epoch 9055 train_loss 10978114.44433929 val_loss 206933.32812500\n",
      "epoch 9056 train_loss 10978114.44424004 val_loss 206933.32812500\n",
      "epoch 9057 train_loss 10978114.44414711 val_loss 206933.32812500\n",
      "epoch 9058 train_loss 10978114.44405868 val_loss 206933.32812500\n",
      "epoch 9059 train_loss 10978114.44396469 val_loss 206933.32812500\n",
      "epoch 9060 train_loss 10978114.44386284 val_loss 206933.32812500\n",
      "epoch 9061 train_loss 10978114.44377052 val_loss 206933.32812500\n",
      "epoch 9062 train_loss 10978114.44367172 val_loss 206933.32812500\n",
      "epoch 9063 train_loss 10978114.44357147 val_loss 206933.32812500\n",
      "epoch 9064 train_loss 10978114.44350517 val_loss 206933.32812500\n",
      "epoch 9065 train_loss 10978114.44341194 val_loss 206933.32812500\n",
      "epoch 9066 train_loss 10978114.44333931 val_loss 206933.32812500\n",
      "epoch 9067 train_loss 10978114.44324585 val_loss 206933.32812500\n",
      "epoch 9068 train_loss 10978114.44316376 val_loss 206933.32812500\n",
      "epoch 9069 train_loss 10978114.44305428 val_loss 206933.32812500\n",
      "epoch 9070 train_loss 10978114.44297165 val_loss 206933.32812500\n",
      "epoch 9071 train_loss 10978114.44286636 val_loss 206933.32812500\n",
      "epoch 9072 train_loss 10978114.44276970 val_loss 206933.32812500\n",
      "epoch 9073 train_loss 10978114.44268326 val_loss 206933.32812500\n",
      "epoch 9074 train_loss 10978114.44258995 val_loss 206933.32812500\n",
      "epoch 9075 train_loss 10978114.44250679 val_loss 206933.32812500\n",
      "epoch 9076 train_loss 10978114.44242607 val_loss 206933.32812500\n",
      "epoch 9077 train_loss 10978114.44230972 val_loss 206933.32812500\n",
      "epoch 9078 train_loss 10978114.44222076 val_loss 206933.32812500\n",
      "epoch 9079 train_loss 10978114.44210533 val_loss 206933.32812500\n",
      "epoch 9080 train_loss 10978114.44203865 val_loss 206933.32812500\n",
      "epoch 9081 train_loss 10978114.44194267 val_loss 206933.32812500\n",
      "epoch 9082 train_loss 10978114.44187004 val_loss 206933.32812500\n",
      "epoch 9083 train_loss 10978114.44176750 val_loss 206933.32812500\n",
      "epoch 9084 train_loss 10978114.44166817 val_loss 206933.32812500\n",
      "epoch 9085 train_loss 10978114.44156532 val_loss 206933.32812500\n",
      "epoch 9086 train_loss 10978114.44148323 val_loss 206933.32812500\n",
      "epoch 9087 train_loss 10978114.44139854 val_loss 206933.32812500\n",
      "epoch 9088 train_loss 10978114.44128487 val_loss 206933.32812500\n",
      "epoch 9089 train_loss 10978114.44122261 val_loss 206933.32812500\n",
      "epoch 9090 train_loss 10978114.44114967 val_loss 206933.32812500\n",
      "epoch 9091 train_loss 10978114.44104057 val_loss 206933.32812500\n",
      "epoch 9092 train_loss 10978114.44094124 val_loss 206933.32812500\n",
      "epoch 9093 train_loss 10978114.44087830 val_loss 206933.32812500\n",
      "epoch 9094 train_loss 10978114.44076256 val_loss 206933.32812500\n",
      "epoch 9095 train_loss 10978114.44068687 val_loss 206933.32812500\n",
      "epoch 9096 train_loss 10978114.44058998 val_loss 206933.32812500\n",
      "epoch 9097 train_loss 10978114.44050881 val_loss 206933.32812500\n",
      "epoch 9098 train_loss 10978114.44041855 val_loss 206933.32812500\n",
      "epoch 9099 train_loss 10978114.44034103 val_loss 206933.32812500\n",
      "epoch 9100 train_loss 10978114.44024513 val_loss 206933.32812500\n",
      "epoch 9101 train_loss 10978114.44016312 val_loss 206933.32812500\n",
      "epoch 9102 train_loss 10978114.44005035 val_loss 206933.32812500\n",
      "epoch 9103 train_loss 10978114.43996422 val_loss 206933.32812500\n",
      "epoch 9104 train_loss 10978114.43987953 val_loss 206933.32812500\n",
      "epoch 9105 train_loss 10978114.43977600 val_loss 206933.32812500\n",
      "epoch 9106 train_loss 10978114.43971214 val_loss 206933.32812500\n",
      "epoch 9107 train_loss 10978114.43959755 val_loss 206933.32812500\n",
      "epoch 9108 train_loss 10978114.43952583 val_loss 206933.32812500\n",
      "epoch 9109 train_loss 10978114.43941750 val_loss 206933.32812500\n",
      "epoch 9110 train_loss 10978114.43934448 val_loss 206933.32812500\n",
      "epoch 9111 train_loss 10978114.43924973 val_loss 206933.32812500\n",
      "epoch 9112 train_loss 10978114.43914795 val_loss 206933.32812500\n",
      "epoch 9113 train_loss 10978114.43906616 val_loss 206933.32812500\n",
      "epoch 9114 train_loss 10978114.43897736 val_loss 206933.32812500\n",
      "epoch 9115 train_loss 10978114.43887894 val_loss 206933.32812500\n",
      "epoch 9116 train_loss 10978114.43877960 val_loss 206933.32812500\n",
      "epoch 9117 train_loss 10978114.43872627 val_loss 206933.32812500\n",
      "epoch 9118 train_loss 10978114.43864571 val_loss 206933.32812500\n",
      "epoch 9119 train_loss 10978114.43854698 val_loss 206933.32812500\n",
      "epoch 9120 train_loss 10978114.43845436 val_loss 206933.32812500\n",
      "epoch 9121 train_loss 10978114.43836586 val_loss 206933.32812500\n",
      "epoch 9122 train_loss 10978114.43828980 val_loss 206933.32812500\n",
      "epoch 9123 train_loss 10978114.43819939 val_loss 206933.32812500\n",
      "epoch 9124 train_loss 10978114.43807838 val_loss 206933.32812500\n",
      "epoch 9125 train_loss 10978114.43800186 val_loss 206933.32812500\n",
      "epoch 9126 train_loss 10978114.43789177 val_loss 206933.32812500\n",
      "epoch 9127 train_loss 10978114.43779533 val_loss 206933.32812500\n",
      "epoch 9128 train_loss 10978114.43774315 val_loss 206933.32812500\n",
      "epoch 9129 train_loss 10978114.43766060 val_loss 206933.32812500\n",
      "epoch 9130 train_loss 10978114.43756271 val_loss 206933.32812500\n",
      "epoch 9131 train_loss 10978114.43746773 val_loss 206933.32812500\n",
      "epoch 9132 train_loss 10978114.43740295 val_loss 206933.32812500\n",
      "epoch 9133 train_loss 10978114.43730911 val_loss 206933.32812500\n",
      "epoch 9134 train_loss 10978114.43721077 val_loss 206933.32812500\n",
      "epoch 9135 train_loss 10978114.43710670 val_loss 206933.32812500\n",
      "epoch 9136 train_loss 10978114.43701347 val_loss 206933.32812500\n",
      "epoch 9137 train_loss 10978114.43691040 val_loss 206933.32812500\n",
      "epoch 9138 train_loss 10978114.43680923 val_loss 206933.32812500\n",
      "epoch 9139 train_loss 10978114.43671333 val_loss 206933.32812500\n",
      "epoch 9140 train_loss 10978114.43664459 val_loss 206933.32812500\n",
      "epoch 9141 train_loss 10978114.43657631 val_loss 206933.32812500\n",
      "epoch 9142 train_loss 10978114.43652672 val_loss 206933.32812500\n",
      "epoch 9143 train_loss 10978114.43643951 val_loss 206933.32812500\n",
      "epoch 9144 train_loss 10978114.43633377 val_loss 206933.32812500\n",
      "epoch 9145 train_loss 10978114.43624947 val_loss 206933.32812500\n",
      "epoch 9146 train_loss 10978114.43617058 val_loss 206933.32812500\n",
      "epoch 9147 train_loss 10978114.43606300 val_loss 206933.32812500\n",
      "epoch 9148 train_loss 10978114.43596222 val_loss 206933.32812500\n",
      "epoch 9149 train_loss 10978114.43586975 val_loss 206933.32812500\n",
      "epoch 9150 train_loss 10978114.43578392 val_loss 206933.32812500\n",
      "epoch 9151 train_loss 10978114.43569656 val_loss 206933.32812500\n",
      "epoch 9152 train_loss 10978114.43562561 val_loss 206933.32812500\n",
      "epoch 9153 train_loss 10978114.43551140 val_loss 206933.32812500\n",
      "epoch 9154 train_loss 10978114.43541725 val_loss 206933.32812500\n",
      "epoch 9155 train_loss 10978114.43532211 val_loss 206933.32812500\n",
      "epoch 9156 train_loss 10978114.43523460 val_loss 206933.32812500\n",
      "epoch 9157 train_loss 10978114.43514984 val_loss 206933.32812500\n",
      "epoch 9158 train_loss 10978114.43507675 val_loss 206933.32812500\n",
      "epoch 9159 train_loss 10978114.43497375 val_loss 206933.32812500\n",
      "epoch 9160 train_loss 10978114.43493691 val_loss 206933.32812500\n",
      "epoch 9161 train_loss 10978114.43484383 val_loss 206933.32812500\n",
      "epoch 9162 train_loss 10978114.43473572 val_loss 206933.32812500\n",
      "epoch 9163 train_loss 10978114.43463341 val_loss 206933.32812500\n",
      "epoch 9164 train_loss 10978114.43455162 val_loss 206933.32812500\n",
      "epoch 9165 train_loss 10978114.43446304 val_loss 206933.32812500\n",
      "epoch 9166 train_loss 10978114.43446037 val_loss 206933.32812500\n",
      "epoch 9167 train_loss 10978114.43436989 val_loss 206933.32812500\n",
      "epoch 9168 train_loss 10978114.43427383 val_loss 206933.32812500\n",
      "epoch 9169 train_loss 10978114.43414932 val_loss 206933.32812500\n",
      "epoch 9170 train_loss 10978114.43406448 val_loss 206933.32812500\n",
      "epoch 9171 train_loss 10978114.43397087 val_loss 206933.32812500\n",
      "epoch 9172 train_loss 10978114.43388756 val_loss 206933.32812500\n",
      "epoch 9173 train_loss 10978114.43380920 val_loss 206933.32812500\n",
      "epoch 9174 train_loss 10978114.43371292 val_loss 206933.32812500\n",
      "epoch 9175 train_loss 10978114.43365112 val_loss 206933.32812500\n",
      "epoch 9176 train_loss 10978114.43357719 val_loss 206933.32812500\n",
      "epoch 9177 train_loss 10978114.43358955 val_loss 206933.32812500\n",
      "epoch 9178 train_loss 10978114.43348106 val_loss 206933.32812500\n",
      "epoch 9179 train_loss 10978114.43337502 val_loss 206933.32812500\n",
      "epoch 9180 train_loss 10978114.43329140 val_loss 206933.32812500\n",
      "epoch 9181 train_loss 10978114.43319672 val_loss 206933.32812500\n",
      "epoch 9182 train_loss 10978114.43310509 val_loss 206933.32812500\n",
      "epoch 9183 train_loss 10978114.43300255 val_loss 206933.32812500\n",
      "epoch 9184 train_loss 10978114.43289421 val_loss 206933.32812500\n",
      "epoch 9185 train_loss 10978114.43281189 val_loss 206933.32812500\n",
      "epoch 9186 train_loss 10978114.43270157 val_loss 206933.32812500\n",
      "epoch 9187 train_loss 10978114.43262833 val_loss 206933.32812500\n",
      "epoch 9188 train_loss 10978114.43254936 val_loss 206933.32812500\n",
      "epoch 9189 train_loss 10978114.43248367 val_loss 206933.32812500\n",
      "epoch 9190 train_loss 10978114.43237511 val_loss 206933.32812500\n",
      "epoch 9191 train_loss 10978114.43228340 val_loss 206933.32812500\n",
      "epoch 9192 train_loss 10978114.43218964 val_loss 206933.32812500\n",
      "epoch 9193 train_loss 10978114.43209434 val_loss 206933.32812500\n",
      "epoch 9194 train_loss 10978114.43198738 val_loss 206933.32812500\n",
      "epoch 9195 train_loss 10978114.43193634 val_loss 206933.32812500\n",
      "epoch 9196 train_loss 10978114.43184540 val_loss 206933.32812500\n",
      "epoch 9197 train_loss 10978114.43173965 val_loss 206933.32812500\n",
      "epoch 9198 train_loss 10978114.43166412 val_loss 206933.32812500\n",
      "epoch 9199 train_loss 10978114.43156532 val_loss 206933.32812500\n",
      "epoch 9200 train_loss 10978114.43145897 val_loss 206933.32812500\n",
      "epoch 9201 train_loss 10978114.43138092 val_loss 206933.32812500\n",
      "epoch 9202 train_loss 10978114.43131020 val_loss 206933.32812500\n",
      "epoch 9203 train_loss 10978114.43120109 val_loss 206933.32812500\n",
      "epoch 9204 train_loss 10978114.43111496 val_loss 206933.32812500\n",
      "epoch 9205 train_loss 10978114.43101845 val_loss 206933.32812500\n",
      "epoch 9206 train_loss 10978114.43093506 val_loss 206933.32812500\n",
      "epoch 9207 train_loss 10978114.43083137 val_loss 206933.32812500\n",
      "epoch 9208 train_loss 10978114.43074318 val_loss 206933.32812500\n",
      "epoch 9209 train_loss 10978114.43064735 val_loss 206933.32812500\n",
      "epoch 9210 train_loss 10978114.43057365 val_loss 206933.32812500\n",
      "epoch 9211 train_loss 10978114.43047936 val_loss 206933.32812500\n",
      "epoch 9212 train_loss 10978114.43037018 val_loss 206933.32812500\n",
      "epoch 9213 train_loss 10978114.43027832 val_loss 206933.32812500\n",
      "epoch 9214 train_loss 10978114.43017410 val_loss 206933.32812500\n",
      "epoch 9215 train_loss 10978114.43008217 val_loss 206933.32812500\n",
      "epoch 9216 train_loss 10978114.43006035 val_loss 206933.32812500\n",
      "epoch 9217 train_loss 10978114.42996002 val_loss 206933.32812500\n",
      "epoch 9218 train_loss 10978114.42987770 val_loss 206933.32812500\n",
      "epoch 9219 train_loss 10978114.42977699 val_loss 206933.32812500\n",
      "epoch 9220 train_loss 10978114.42968437 val_loss 206933.32812500\n",
      "epoch 9221 train_loss 10978114.42957619 val_loss 206933.32812500\n",
      "epoch 9222 train_loss 10978114.42951271 val_loss 206933.32812500\n",
      "epoch 9223 train_loss 10978114.42942253 val_loss 206933.32812500\n",
      "epoch 9224 train_loss 10978114.42932785 val_loss 206933.32812500\n",
      "epoch 9225 train_loss 10978114.42929291 val_loss 206933.32812500\n",
      "epoch 9226 train_loss 10978114.42921394 val_loss 206933.32812500\n",
      "epoch 9227 train_loss 10978114.42911987 val_loss 206933.32812500\n",
      "epoch 9228 train_loss 10978114.42906807 val_loss 206933.32812500\n",
      "epoch 9229 train_loss 10978114.42896713 val_loss 206933.32812500\n",
      "epoch 9230 train_loss 10978114.42890160 val_loss 206933.32812500\n",
      "epoch 9231 train_loss 10978114.42881462 val_loss 206933.32812500\n",
      "epoch 9232 train_loss 10978114.42869369 val_loss 206933.32812500\n",
      "epoch 9233 train_loss 10978114.42860977 val_loss 206933.32812500\n",
      "epoch 9234 train_loss 10978114.42852142 val_loss 206933.33593750\n",
      "epoch 9235 train_loss 10978114.42842484 val_loss 206933.33593750\n",
      "epoch 9236 train_loss 10978114.42832863 val_loss 206933.33593750\n",
      "epoch 9237 train_loss 10978114.42823707 val_loss 206933.33593750\n",
      "epoch 9238 train_loss 10978114.42812958 val_loss 206933.33593750\n",
      "epoch 9239 train_loss 10978114.42805489 val_loss 206933.33593750\n",
      "epoch 9240 train_loss 10978114.42796249 val_loss 206933.33593750\n",
      "epoch 9241 train_loss 10978114.42794785 val_loss 206933.33593750\n",
      "epoch 9242 train_loss 10978114.42782448 val_loss 206933.33593750\n",
      "epoch 9243 train_loss 10978114.42775368 val_loss 206933.33593750\n",
      "epoch 9244 train_loss 10978114.42767326 val_loss 206933.33593750\n",
      "epoch 9245 train_loss 10978114.42758019 val_loss 206933.33593750\n",
      "epoch 9246 train_loss 10978114.42748352 val_loss 206933.32812500\n",
      "epoch 9247 train_loss 10978114.42740112 val_loss 206933.32812500\n",
      "epoch 9248 train_loss 10978114.42730888 val_loss 206933.32812500\n",
      "epoch 9249 train_loss 10978114.42722527 val_loss 206933.32812500\n",
      "epoch 9250 train_loss 10978114.42711227 val_loss 206933.32812500\n",
      "epoch 9251 train_loss 10978114.42702728 val_loss 206933.32812500\n",
      "epoch 9252 train_loss 10978114.42694527 val_loss 206933.32812500\n",
      "epoch 9253 train_loss 10978114.42684563 val_loss 206933.32812500\n",
      "epoch 9254 train_loss 10978114.42676681 val_loss 206933.32812500\n",
      "epoch 9255 train_loss 10978114.42665543 val_loss 206933.32812500\n",
      "epoch 9256 train_loss 10978114.42656769 val_loss 206933.32812500\n",
      "epoch 9257 train_loss 10978114.42655418 val_loss 206933.32812500\n",
      "epoch 9258 train_loss 10978114.42646568 val_loss 206933.32812500\n",
      "epoch 9259 train_loss 10978114.42639725 val_loss 206933.32812500\n",
      "epoch 9260 train_loss 10978114.42629539 val_loss 206933.32812500\n",
      "epoch 9261 train_loss 10978114.42619278 val_loss 206933.32812500\n",
      "epoch 9262 train_loss 10978114.42609589 val_loss 206933.32812500\n",
      "epoch 9263 train_loss 10978114.42603127 val_loss 206933.32812500\n",
      "epoch 9264 train_loss 10978114.42591621 val_loss 206933.32812500\n",
      "epoch 9265 train_loss 10978114.42582626 val_loss 206933.32812500\n",
      "epoch 9266 train_loss 10978114.42571655 val_loss 206933.32812500\n",
      "epoch 9267 train_loss 10978114.42561836 val_loss 206933.32812500\n",
      "epoch 9268 train_loss 10978114.42555710 val_loss 206933.32812500\n",
      "epoch 9269 train_loss 10978114.42549988 val_loss 206933.32812500\n",
      "epoch 9270 train_loss 10978114.42540245 val_loss 206933.32812500\n",
      "epoch 9271 train_loss 10978114.42530556 val_loss 206933.32812500\n",
      "epoch 9272 train_loss 10978114.42524841 val_loss 206933.32812500\n",
      "epoch 9273 train_loss 10978114.42516579 val_loss 206933.32812500\n",
      "epoch 9274 train_loss 10978114.42505821 val_loss 206933.32812500\n",
      "epoch 9275 train_loss 10978114.42497414 val_loss 206933.32812500\n",
      "epoch 9276 train_loss 10978114.42488861 val_loss 206933.32812500\n",
      "epoch 9277 train_loss 10978114.42480873 val_loss 206933.32812500\n",
      "epoch 9278 train_loss 10978114.42469856 val_loss 206933.32812500\n",
      "epoch 9279 train_loss 10978114.42461685 val_loss 206933.33593750\n",
      "epoch 9280 train_loss 10978114.42451675 val_loss 206933.33593750\n",
      "epoch 9281 train_loss 10978114.42443001 val_loss 206933.33593750\n",
      "epoch 9282 train_loss 10978114.42434364 val_loss 206933.33593750\n",
      "epoch 9283 train_loss 10978114.42428345 val_loss 206933.33593750\n",
      "epoch 9284 train_loss 10978114.42419441 val_loss 206933.33593750\n",
      "epoch 9285 train_loss 10978114.42411415 val_loss 206933.33593750\n",
      "epoch 9286 train_loss 10978114.42401405 val_loss 206933.33593750\n",
      "epoch 9287 train_loss 10978114.42392609 val_loss 206933.33593750\n",
      "epoch 9288 train_loss 10978114.42380432 val_loss 206933.33593750\n",
      "epoch 9289 train_loss 10978114.42372635 val_loss 206933.33593750\n",
      "epoch 9290 train_loss 10978114.42362091 val_loss 206933.33593750\n",
      "epoch 9291 train_loss 10978114.42353981 val_loss 206933.33593750\n",
      "epoch 9292 train_loss 10978114.42344093 val_loss 206933.33593750\n",
      "epoch 9293 train_loss 10978114.42333717 val_loss 206933.33593750\n",
      "epoch 9294 train_loss 10978114.42326256 val_loss 206933.33593750\n",
      "epoch 9295 train_loss 10978114.42315781 val_loss 206933.33593750\n",
      "epoch 9296 train_loss 10978114.42306122 val_loss 206933.33593750\n",
      "epoch 9297 train_loss 10978114.42297066 val_loss 206933.33593750\n",
      "epoch 9298 train_loss 10978114.42290756 val_loss 206933.33593750\n",
      "epoch 9299 train_loss 10978114.42280029 val_loss 206933.33593750\n",
      "epoch 9300 train_loss 10978114.42270348 val_loss 206933.33593750\n",
      "epoch 9301 train_loss 10978114.42262794 val_loss 206933.33593750\n",
      "epoch 9302 train_loss 10978114.42252159 val_loss 206933.33593750\n",
      "epoch 9303 train_loss 10978114.42243080 val_loss 206933.33593750\n",
      "epoch 9304 train_loss 10978114.42235100 val_loss 206933.33593750\n",
      "epoch 9305 train_loss 10978114.42225655 val_loss 206933.33593750\n",
      "epoch 9306 train_loss 10978114.42217026 val_loss 206933.33593750\n",
      "epoch 9307 train_loss 10978114.42207130 val_loss 206933.33593750\n",
      "epoch 9308 train_loss 10978114.42199493 val_loss 206933.33593750\n",
      "epoch 9309 train_loss 10978114.42192612 val_loss 206933.33593750\n",
      "epoch 9310 train_loss 10978114.42183884 val_loss 206933.33593750\n",
      "epoch 9311 train_loss 10978114.42174446 val_loss 206933.33593750\n",
      "epoch 9312 train_loss 10978114.42165359 val_loss 206933.33593750\n",
      "epoch 9313 train_loss 10978114.42156143 val_loss 206933.33593750\n",
      "epoch 9314 train_loss 10978114.42145973 val_loss 206933.33593750\n",
      "epoch 9315 train_loss 10978114.42137657 val_loss 206933.33593750\n",
      "epoch 9316 train_loss 10978114.42126373 val_loss 206933.33593750\n",
      "epoch 9317 train_loss 10978114.42117828 val_loss 206933.33593750\n",
      "epoch 9318 train_loss 10978114.42109695 val_loss 206933.33593750\n",
      "epoch 9319 train_loss 10978114.42099838 val_loss 206933.33593750\n",
      "epoch 9320 train_loss 10978114.42090775 val_loss 206933.33593750\n",
      "epoch 9321 train_loss 10978114.42079452 val_loss 206933.33593750\n",
      "epoch 9322 train_loss 10978114.42079536 val_loss 206933.33593750\n",
      "epoch 9323 train_loss 10978114.42070534 val_loss 206933.33593750\n",
      "epoch 9324 train_loss 10978114.42062271 val_loss 206933.33593750\n",
      "epoch 9325 train_loss 10978114.42052124 val_loss 206933.33593750\n",
      "epoch 9326 train_loss 10978114.42046783 val_loss 206933.33593750\n",
      "epoch 9327 train_loss 10978114.42038025 val_loss 206933.33593750\n",
      "epoch 9328 train_loss 10978114.42029678 val_loss 206933.33593750\n",
      "epoch 9329 train_loss 10978114.42020088 val_loss 206933.33593750\n",
      "epoch 9330 train_loss 10978114.42009789 val_loss 206933.33593750\n",
      "epoch 9331 train_loss 10978114.42000503 val_loss 206933.33593750\n",
      "epoch 9332 train_loss 10978114.41992004 val_loss 206933.33593750\n",
      "epoch 9333 train_loss 10978114.41983528 val_loss 206933.33593750\n",
      "epoch 9334 train_loss 10978114.41972977 val_loss 206933.33593750\n",
      "epoch 9335 train_loss 10978114.41963760 val_loss 206933.33593750\n",
      "epoch 9336 train_loss 10978114.41953507 val_loss 206933.33593750\n",
      "epoch 9337 train_loss 10978114.41943870 val_loss 206933.33593750\n",
      "epoch 9338 train_loss 10978114.41933708 val_loss 206933.33593750\n",
      "epoch 9339 train_loss 10978114.41924805 val_loss 206933.33593750\n",
      "epoch 9340 train_loss 10978114.41917107 val_loss 206933.33593750\n",
      "epoch 9341 train_loss 10978114.41910645 val_loss 206933.33593750\n",
      "epoch 9342 train_loss 10978114.41901504 val_loss 206933.33593750\n",
      "epoch 9343 train_loss 10978114.41891838 val_loss 206933.33593750\n",
      "epoch 9344 train_loss 10978114.41882484 val_loss 206933.33593750\n",
      "epoch 9345 train_loss 10978114.41873756 val_loss 206933.33593750\n",
      "epoch 9346 train_loss 10978114.41863525 val_loss 206933.33593750\n",
      "epoch 9347 train_loss 10978114.41856224 val_loss 206933.33593750\n",
      "epoch 9348 train_loss 10978114.41848015 val_loss 206933.33593750\n",
      "epoch 9349 train_loss 10978114.41837891 val_loss 206933.33593750\n",
      "epoch 9350 train_loss 10978114.41828857 val_loss 206933.33593750\n",
      "epoch 9351 train_loss 10978114.41822342 val_loss 206933.33593750\n",
      "epoch 9352 train_loss 10978114.41812065 val_loss 206933.33593750\n",
      "epoch 9353 train_loss 10978114.41803123 val_loss 206933.33593750\n",
      "epoch 9354 train_loss 10978114.41791885 val_loss 206933.33593750\n",
      "epoch 9355 train_loss 10978114.41783462 val_loss 206933.33593750\n",
      "epoch 9356 train_loss 10978114.41775711 val_loss 206933.33593750\n",
      "epoch 9357 train_loss 10978114.41765480 val_loss 206933.33593750\n",
      "epoch 9358 train_loss 10978114.41757538 val_loss 206933.33593750\n",
      "epoch 9359 train_loss 10978114.41745697 val_loss 206933.33593750\n",
      "epoch 9360 train_loss 10978114.41736496 val_loss 206933.33593750\n",
      "epoch 9361 train_loss 10978114.41726479 val_loss 206933.33593750\n",
      "epoch 9362 train_loss 10978114.41715744 val_loss 206933.33593750\n",
      "epoch 9363 train_loss 10978114.41706719 val_loss 206933.33593750\n",
      "epoch 9364 train_loss 10978114.41697639 val_loss 206933.33593750\n",
      "epoch 9365 train_loss 10978114.41689033 val_loss 206933.33593750\n",
      "epoch 9366 train_loss 10978114.41680702 val_loss 206933.33593750\n",
      "epoch 9367 train_loss 10978114.41672600 val_loss 206933.33593750\n",
      "epoch 9368 train_loss 10978114.41663437 val_loss 206933.33593750\n",
      "epoch 9369 train_loss 10978114.41652725 val_loss 206933.33593750\n",
      "epoch 9370 train_loss 10978114.41644035 val_loss 206933.33593750\n",
      "epoch 9371 train_loss 10978114.41634880 val_loss 206933.33593750\n",
      "epoch 9372 train_loss 10978114.41625549 val_loss 206933.33593750\n",
      "epoch 9373 train_loss 10978114.41615196 val_loss 206933.33593750\n",
      "epoch 9374 train_loss 10978114.41604790 val_loss 206933.33593750\n",
      "epoch 9375 train_loss 10978114.41596580 val_loss 206933.33593750\n",
      "epoch 9376 train_loss 10978114.41586517 val_loss 206933.33593750\n",
      "epoch 9377 train_loss 10978114.41577362 val_loss 206933.33593750\n",
      "epoch 9378 train_loss 10978114.41569138 val_loss 206933.33593750\n",
      "epoch 9379 train_loss 10978114.41568436 val_loss 206933.33593750\n",
      "epoch 9380 train_loss 10978114.41557449 val_loss 206933.33593750\n",
      "epoch 9381 train_loss 10978114.41553856 val_loss 206933.33593750\n",
      "epoch 9382 train_loss 10978114.41543579 val_loss 206933.33593750\n",
      "epoch 9383 train_loss 10978114.41537239 val_loss 206933.33593750\n",
      "epoch 9384 train_loss 10978114.41528068 val_loss 206933.33593750\n",
      "epoch 9385 train_loss 10978114.41516914 val_loss 206933.33593750\n",
      "epoch 9386 train_loss 10978114.41508644 val_loss 206933.33593750\n",
      "epoch 9387 train_loss 10978114.41496803 val_loss 206933.33593750\n",
      "epoch 9388 train_loss 10978114.41489288 val_loss 206933.33593750\n",
      "epoch 9389 train_loss 10978114.41483322 val_loss 206933.33593750\n",
      "epoch 9390 train_loss 10978114.41464638 val_loss 206933.33593750\n",
      "epoch 9391 train_loss 10978114.41454277 val_loss 206933.33593750\n",
      "epoch 9392 train_loss 10978114.41444534 val_loss 206933.33593750\n",
      "epoch 9393 train_loss 10978114.41438072 val_loss 206933.33593750\n",
      "epoch 9394 train_loss 10978114.41425835 val_loss 206933.33593750\n",
      "epoch 9395 train_loss 10978114.41418167 val_loss 206933.33593750\n",
      "epoch 9396 train_loss 10978114.41409889 val_loss 206933.33593750\n",
      "epoch 9397 train_loss 10978114.41397240 val_loss 206933.33593750\n",
      "epoch 9398 train_loss 10978114.41388756 val_loss 206933.33593750\n",
      "epoch 9399 train_loss 10978114.41380005 val_loss 206933.33593750\n",
      "epoch 9400 train_loss 10978114.41371262 val_loss 206933.33593750\n",
      "epoch 9401 train_loss 10978114.41360741 val_loss 206933.33593750\n",
      "epoch 9402 train_loss 10978114.41351448 val_loss 206933.33593750\n",
      "epoch 9403 train_loss 10978114.41343300 val_loss 206933.33593750\n",
      "epoch 9404 train_loss 10978114.41335869 val_loss 206933.33593750\n",
      "epoch 9405 train_loss 10978114.41325371 val_loss 206933.33593750\n",
      "epoch 9406 train_loss 10978114.41317024 val_loss 206933.33593750\n",
      "epoch 9407 train_loss 10978114.41308090 val_loss 206933.33593750\n",
      "epoch 9408 train_loss 10978114.41299240 val_loss 206933.33593750\n",
      "epoch 9409 train_loss 10978114.41290703 val_loss 206933.33593750\n",
      "epoch 9410 train_loss 10978114.41282921 val_loss 206933.33593750\n",
      "epoch 9411 train_loss 10978114.41273987 val_loss 206933.33593750\n",
      "epoch 9412 train_loss 10978114.41264122 val_loss 206933.33593750\n",
      "epoch 9413 train_loss 10978114.41255219 val_loss 206933.33593750\n",
      "epoch 9414 train_loss 10978114.41245590 val_loss 206933.33593750\n",
      "epoch 9415 train_loss 10978114.41238991 val_loss 206933.33593750\n",
      "epoch 9416 train_loss 10978114.41238777 val_loss 206933.33593750\n",
      "epoch 9417 train_loss 10978114.41229004 val_loss 206933.33593750\n",
      "epoch 9418 train_loss 10978114.41220032 val_loss 206933.33593750\n",
      "epoch 9419 train_loss 10978114.41210571 val_loss 206933.33593750\n",
      "epoch 9420 train_loss 10978114.41203926 val_loss 206933.33593750\n",
      "epoch 9421 train_loss 10978114.41195778 val_loss 206933.33593750\n",
      "epoch 9422 train_loss 10978114.41184524 val_loss 206933.33593750\n",
      "epoch 9423 train_loss 10978114.41176750 val_loss 206933.33593750\n",
      "epoch 9424 train_loss 10978114.41168015 val_loss 206933.33593750\n",
      "epoch 9425 train_loss 10978114.41161461 val_loss 206933.33593750\n",
      "epoch 9426 train_loss 10978114.41152573 val_loss 206933.33593750\n",
      "epoch 9427 train_loss 10978114.41142479 val_loss 206933.33593750\n",
      "epoch 9428 train_loss 10978114.41135185 val_loss 206933.33593750\n",
      "epoch 9429 train_loss 10978114.41125481 val_loss 206933.33593750\n",
      "epoch 9430 train_loss 10978114.41114830 val_loss 206933.33593750\n",
      "epoch 9431 train_loss 10978114.41104370 val_loss 206933.33593750\n",
      "epoch 9432 train_loss 10978114.41095619 val_loss 206933.33593750\n",
      "epoch 9433 train_loss 10978114.41086594 val_loss 206933.33593750\n",
      "epoch 9434 train_loss 10978114.41077568 val_loss 206933.33593750\n",
      "epoch 9435 train_loss 10978114.41071037 val_loss 206933.33593750\n",
      "epoch 9436 train_loss 10978114.41060791 val_loss 206933.33593750\n",
      "epoch 9437 train_loss 10978114.41051575 val_loss 206933.33593750\n",
      "epoch 9438 train_loss 10978114.41043243 val_loss 206933.33593750\n",
      "epoch 9439 train_loss 10978114.41036705 val_loss 206933.33593750\n",
      "epoch 9440 train_loss 10978114.41027100 val_loss 206933.33593750\n",
      "epoch 9441 train_loss 10978114.41018570 val_loss 206933.33593750\n",
      "epoch 9442 train_loss 10978114.41008774 val_loss 206933.33593750\n",
      "epoch 9443 train_loss 10978114.41000900 val_loss 206933.33593750\n",
      "epoch 9444 train_loss 10978114.40992615 val_loss 206933.33593750\n",
      "epoch 9445 train_loss 10978114.40982422 val_loss 206933.33593750\n",
      "epoch 9446 train_loss 10978114.40972076 val_loss 206933.33593750\n",
      "epoch 9447 train_loss 10978114.40964096 val_loss 206933.33593750\n",
      "epoch 9448 train_loss 10978114.40954895 val_loss 206933.33593750\n",
      "epoch 9449 train_loss 10978114.40948860 val_loss 206933.33593750\n",
      "epoch 9450 train_loss 10978114.40937912 val_loss 206933.33593750\n",
      "epoch 9451 train_loss 10978114.40928474 val_loss 206933.33593750\n",
      "epoch 9452 train_loss 10978114.40920578 val_loss 206933.33593750\n",
      "epoch 9453 train_loss 10978114.40910606 val_loss 206933.33593750\n",
      "epoch 9454 train_loss 10978114.40901367 val_loss 206933.33593750\n",
      "epoch 9455 train_loss 10978114.40891617 val_loss 206933.33593750\n",
      "epoch 9456 train_loss 10978114.40883080 val_loss 206933.33593750\n",
      "epoch 9457 train_loss 10978114.40873756 val_loss 206933.33593750\n",
      "epoch 9458 train_loss 10978114.40863129 val_loss 206933.33593750\n",
      "epoch 9459 train_loss 10978114.40854576 val_loss 206933.33593750\n",
      "epoch 9460 train_loss 10978114.40844345 val_loss 206933.33593750\n",
      "epoch 9461 train_loss 10978114.40836754 val_loss 206933.33593750\n",
      "epoch 9462 train_loss 10978114.40827255 val_loss 206933.33593750\n",
      "epoch 9463 train_loss 10978114.40817993 val_loss 206933.33593750\n",
      "epoch 9464 train_loss 10978114.40808212 val_loss 206933.33593750\n",
      "epoch 9465 train_loss 10978114.40806603 val_loss 206933.33593750\n",
      "epoch 9466 train_loss 10978114.40798508 val_loss 206933.33593750\n",
      "epoch 9467 train_loss 10978114.40788437 val_loss 206933.33593750\n",
      "epoch 9468 train_loss 10978114.40778923 val_loss 206933.33593750\n",
      "epoch 9469 train_loss 10978114.40768120 val_loss 206933.33593750\n",
      "epoch 9470 train_loss 10978114.40758827 val_loss 206933.33593750\n",
      "epoch 9471 train_loss 10978114.40750847 val_loss 206933.33593750\n",
      "epoch 9472 train_loss 10978114.40741852 val_loss 206933.33593750\n",
      "epoch 9473 train_loss 10978114.40733574 val_loss 206933.33593750\n",
      "epoch 9474 train_loss 10978114.40722595 val_loss 206933.33593750\n",
      "epoch 9475 train_loss 10978114.40714577 val_loss 206933.33593750\n",
      "epoch 9476 train_loss 10978114.40704979 val_loss 206933.33593750\n",
      "epoch 9477 train_loss 10978114.40695213 val_loss 206933.33593750\n",
      "epoch 9478 train_loss 10978114.40683777 val_loss 206933.33593750\n",
      "epoch 9479 train_loss 10978114.40675835 val_loss 206933.33593750\n",
      "epoch 9480 train_loss 10978114.40668152 val_loss 206933.33593750\n",
      "epoch 9481 train_loss 10978114.40659317 val_loss 206933.33593750\n",
      "epoch 9482 train_loss 10978114.40649056 val_loss 206933.33593750\n",
      "epoch 9483 train_loss 10978114.40639801 val_loss 206933.33593750\n",
      "epoch 9484 train_loss 10978114.40637497 val_loss 206933.33593750\n",
      "epoch 9485 train_loss 10978114.40626587 val_loss 206933.33593750\n",
      "epoch 9486 train_loss 10978114.40617691 val_loss 206933.33593750\n",
      "epoch 9487 train_loss 10978114.40607376 val_loss 206933.33593750\n",
      "epoch 9488 train_loss 10978114.40599716 val_loss 206933.33593750\n",
      "epoch 9489 train_loss 10978114.40590813 val_loss 206933.33593750\n",
      "epoch 9490 train_loss 10978114.40585327 val_loss 206933.33593750\n",
      "epoch 9491 train_loss 10978114.40578735 val_loss 206933.33593750\n",
      "epoch 9492 train_loss 10978114.40566887 val_loss 206933.33593750\n",
      "epoch 9493 train_loss 10978114.40557602 val_loss 206933.33593750\n",
      "epoch 9494 train_loss 10978114.40548775 val_loss 206933.33593750\n",
      "epoch 9495 train_loss 10978114.40555977 val_loss 206933.33593750\n",
      "epoch 9496 train_loss 10978114.40546593 val_loss 206933.33593750\n",
      "epoch 9497 train_loss 10978114.40537033 val_loss 206933.33593750\n",
      "epoch 9498 train_loss 10978114.40528297 val_loss 206933.33593750\n",
      "epoch 9499 train_loss 10978114.40517967 val_loss 206933.33593750\n",
      "epoch 9500 train_loss 10978114.40508835 val_loss 206933.33593750\n",
      "epoch 9501 train_loss 10978114.40500793 val_loss 206933.33593750\n",
      "epoch 9502 train_loss 10978114.40492798 val_loss 206933.33593750\n",
      "epoch 9503 train_loss 10978114.40482124 val_loss 206933.33593750\n",
      "epoch 9504 train_loss 10978114.40472153 val_loss 206933.33593750\n",
      "epoch 9505 train_loss 10978114.40463806 val_loss 206933.33593750\n",
      "epoch 9506 train_loss 10978114.40452400 val_loss 206933.33593750\n",
      "epoch 9507 train_loss 10978114.40443092 val_loss 206933.33593750\n",
      "epoch 9508 train_loss 10978114.40434570 val_loss 206933.33593750\n",
      "epoch 9509 train_loss 10978114.40424667 val_loss 206933.33593750\n",
      "epoch 9510 train_loss 10978114.40416321 val_loss 206933.33593750\n",
      "epoch 9511 train_loss 10978114.40411797 val_loss 206933.33593750\n",
      "epoch 9512 train_loss 10978114.40401840 val_loss 206933.33593750\n",
      "epoch 9513 train_loss 10978114.40395454 val_loss 206933.33593750\n",
      "epoch 9514 train_loss 10978114.40384094 val_loss 206933.33593750\n",
      "epoch 9515 train_loss 10978114.40374741 val_loss 206933.33593750\n",
      "epoch 9516 train_loss 10978114.40368034 val_loss 206933.33593750\n",
      "epoch 9517 train_loss 10978114.40356728 val_loss 206933.33593750\n",
      "epoch 9518 train_loss 10978114.40349319 val_loss 206933.33593750\n",
      "epoch 9519 train_loss 10978114.40342026 val_loss 206933.33593750\n",
      "epoch 9520 train_loss 10978114.40333649 val_loss 206933.33593750\n",
      "epoch 9521 train_loss 10978114.40323212 val_loss 206933.33593750\n",
      "epoch 9522 train_loss 10978114.40311859 val_loss 206933.33593750\n",
      "epoch 9523 train_loss 10978114.40302918 val_loss 206933.33593750\n",
      "epoch 9524 train_loss 10978114.40294113 val_loss 206933.33593750\n",
      "epoch 9525 train_loss 10978114.40283394 val_loss 206933.33593750\n",
      "epoch 9526 train_loss 10978114.40280708 val_loss 206933.33593750\n",
      "epoch 9527 train_loss 10978114.40270424 val_loss 206933.33593750\n",
      "epoch 9528 train_loss 10978114.40260635 val_loss 206933.33593750\n",
      "epoch 9529 train_loss 10978114.40252754 val_loss 206933.33593750\n",
      "epoch 9530 train_loss 10978114.40243492 val_loss 206933.33593750\n",
      "epoch 9531 train_loss 10978114.40232521 val_loss 206933.33593750\n",
      "epoch 9532 train_loss 10978114.40226097 val_loss 206933.33593750\n",
      "epoch 9533 train_loss 10978114.40218468 val_loss 206933.33593750\n",
      "epoch 9534 train_loss 10978114.40206741 val_loss 206933.33593750\n",
      "epoch 9535 train_loss 10978114.40198944 val_loss 206933.33593750\n",
      "epoch 9536 train_loss 10978114.40189751 val_loss 206933.33593750\n",
      "epoch 9537 train_loss 10978114.40181702 val_loss 206933.33593750\n",
      "epoch 9538 train_loss 10978114.40170074 val_loss 206933.33593750\n",
      "epoch 9539 train_loss 10978114.40160965 val_loss 206933.33593750\n",
      "epoch 9540 train_loss 10978114.40151810 val_loss 206933.33593750\n",
      "epoch 9541 train_loss 10978114.40143829 val_loss 206933.33593750\n",
      "epoch 9542 train_loss 10978114.40134254 val_loss 206933.33593750\n",
      "epoch 9543 train_loss 10978114.40124382 val_loss 206933.33593750\n",
      "epoch 9544 train_loss 10978114.40114449 val_loss 206933.33593750\n",
      "epoch 9545 train_loss 10978114.40104355 val_loss 206933.33593750\n",
      "epoch 9546 train_loss 10978114.40097336 val_loss 206933.33593750\n",
      "epoch 9547 train_loss 10978114.40086044 val_loss 206933.33593750\n",
      "epoch 9548 train_loss 10978114.40076378 val_loss 206933.33593750\n",
      "epoch 9549 train_loss 10978114.40067299 val_loss 206933.33593750\n",
      "epoch 9550 train_loss 10978114.40056381 val_loss 206933.33593750\n",
      "epoch 9551 train_loss 10978114.40049156 val_loss 206933.33593750\n",
      "epoch 9552 train_loss 10978114.40038963 val_loss 206933.33593750\n",
      "epoch 9553 train_loss 10978114.40032860 val_loss 206933.33593750\n",
      "epoch 9554 train_loss 10978114.40024742 val_loss 206933.33593750\n",
      "epoch 9555 train_loss 10978114.40015289 val_loss 206933.33593750\n",
      "epoch 9556 train_loss 10978114.40005318 val_loss 206933.33593750\n",
      "epoch 9557 train_loss 10978114.39996414 val_loss 206933.33593750\n",
      "epoch 9558 train_loss 10978114.39985916 val_loss 206933.33593750\n",
      "epoch 9559 train_loss 10978114.39976440 val_loss 206933.33593750\n",
      "epoch 9560 train_loss 10978114.39967636 val_loss 206933.33593750\n",
      "epoch 9561 train_loss 10978114.39959030 val_loss 206933.33593750\n",
      "epoch 9562 train_loss 10978114.39949272 val_loss 206933.33593750\n",
      "epoch 9563 train_loss 10978114.39939018 val_loss 206933.33593750\n",
      "epoch 9564 train_loss 10978114.39930542 val_loss 206933.33593750\n",
      "epoch 9565 train_loss 10978114.39925377 val_loss 206933.33593750\n",
      "epoch 9566 train_loss 10978114.39915291 val_loss 206933.33593750\n",
      "epoch 9567 train_loss 10978114.39906471 val_loss 206933.33593750\n",
      "epoch 9568 train_loss 10978114.39896858 val_loss 206933.33593750\n",
      "epoch 9569 train_loss 10978114.39888550 val_loss 206933.33593750\n",
      "epoch 9570 train_loss 10978114.39882690 val_loss 206933.33593750\n",
      "epoch 9571 train_loss 10978114.39872688 val_loss 206933.33593750\n",
      "epoch 9572 train_loss 10978114.39867233 val_loss 206933.33593750\n",
      "epoch 9573 train_loss 10978114.39858185 val_loss 206933.33593750\n",
      "epoch 9574 train_loss 10978114.39848747 val_loss 206933.33593750\n",
      "epoch 9575 train_loss 10978114.39841141 val_loss 206933.33593750\n",
      "epoch 9576 train_loss 10978114.39832184 val_loss 206933.33593750\n",
      "epoch 9577 train_loss 10978114.39822311 val_loss 206933.33593750\n",
      "epoch 9578 train_loss 10978114.39813835 val_loss 206933.33593750\n",
      "epoch 9579 train_loss 10978114.39804482 val_loss 206933.33593750\n",
      "epoch 9580 train_loss 10978114.39793839 val_loss 206933.33593750\n",
      "epoch 9581 train_loss 10978114.39784538 val_loss 206933.33593750\n",
      "epoch 9582 train_loss 10978114.39776573 val_loss 206933.33593750\n",
      "epoch 9583 train_loss 10978114.39768585 val_loss 206933.33593750\n",
      "epoch 9584 train_loss 10978114.39757667 val_loss 206933.33593750\n",
      "epoch 9585 train_loss 10978114.39751289 val_loss 206933.33593750\n",
      "epoch 9586 train_loss 10978114.39741432 val_loss 206933.33593750\n",
      "epoch 9587 train_loss 10978114.39729683 val_loss 206933.33593750\n",
      "epoch 9588 train_loss 10978114.39722664 val_loss 206933.33593750\n",
      "epoch 9589 train_loss 10978114.39712410 val_loss 206933.33593750\n",
      "epoch 9590 train_loss 10978114.39702446 val_loss 206933.33593750\n",
      "epoch 9591 train_loss 10978114.39691864 val_loss 206933.33593750\n",
      "epoch 9592 train_loss 10978114.39683350 val_loss 206933.33593750\n",
      "epoch 9593 train_loss 10978114.39674347 val_loss 206933.33593750\n",
      "epoch 9594 train_loss 10978114.39664887 val_loss 206933.33593750\n",
      "epoch 9595 train_loss 10978114.39656181 val_loss 206933.33593750\n",
      "epoch 9596 train_loss 10978114.39646309 val_loss 206933.33593750\n",
      "epoch 9597 train_loss 10978114.39637283 val_loss 206933.33593750\n",
      "epoch 9598 train_loss 10978114.39628105 val_loss 206933.33593750\n",
      "epoch 9599 train_loss 10978114.39619522 val_loss 206933.33593750\n",
      "epoch 9600 train_loss 10978114.39610909 val_loss 206933.33593750\n",
      "epoch 9601 train_loss 10978114.39600441 val_loss 206933.33593750\n",
      "epoch 9602 train_loss 10978114.39594544 val_loss 206933.33593750\n",
      "epoch 9603 train_loss 10978114.39586044 val_loss 206933.33593750\n",
      "epoch 9604 train_loss 10978114.39583626 val_loss 206933.33593750\n",
      "epoch 9605 train_loss 10978114.39574028 val_loss 206933.33593750\n",
      "epoch 9606 train_loss 10978114.39564758 val_loss 206933.33593750\n",
      "epoch 9607 train_loss 10978114.39556297 val_loss 206933.33593750\n",
      "epoch 9608 train_loss 10978114.39554237 val_loss 206933.33593750\n",
      "epoch 9609 train_loss 10978114.39544868 val_loss 206933.33593750\n",
      "epoch 9610 train_loss 10978114.39533935 val_loss 206933.33593750\n",
      "epoch 9611 train_loss 10978114.39526543 val_loss 206933.33593750\n",
      "epoch 9612 train_loss 10978114.39516808 val_loss 206933.33593750\n",
      "epoch 9613 train_loss 10978114.39507965 val_loss 206933.33593750\n",
      "epoch 9614 train_loss 10978114.39498962 val_loss 206933.33593750\n",
      "epoch 9615 train_loss 10978114.39493164 val_loss 206933.33593750\n",
      "epoch 9616 train_loss 10978114.39485222 val_loss 206933.33593750\n",
      "epoch 9617 train_loss 10978114.39476265 val_loss 206933.33593750\n",
      "epoch 9618 train_loss 10978114.39468925 val_loss 206933.33593750\n",
      "epoch 9619 train_loss 10978114.39459763 val_loss 206933.33593750\n",
      "epoch 9620 train_loss 10978114.39447685 val_loss 206933.33593750\n",
      "epoch 9621 train_loss 10978114.39440361 val_loss 206933.33593750\n",
      "epoch 9622 train_loss 10978114.39428078 val_loss 206933.33593750\n",
      "epoch 9623 train_loss 10978114.39422386 val_loss 206933.33593750\n",
      "epoch 9624 train_loss 10978114.39413338 val_loss 206933.33593750\n",
      "epoch 9625 train_loss 10978114.39411278 val_loss 206933.33593750\n",
      "epoch 9626 train_loss 10978114.39400154 val_loss 206933.33593750\n",
      "epoch 9627 train_loss 10978114.39389603 val_loss 206933.33593750\n",
      "epoch 9628 train_loss 10978114.39380966 val_loss 206933.33593750\n",
      "epoch 9629 train_loss 10978114.39373115 val_loss 206933.33593750\n",
      "epoch 9630 train_loss 10978114.39363152 val_loss 206933.33593750\n",
      "epoch 9631 train_loss 10978114.39353744 val_loss 206933.33593750\n",
      "epoch 9632 train_loss 10978114.39347198 val_loss 206933.33593750\n",
      "epoch 9633 train_loss 10978114.39336777 val_loss 206933.33593750\n",
      "epoch 9634 train_loss 10978114.39330292 val_loss 206933.33593750\n",
      "epoch 9635 train_loss 10978114.39320198 val_loss 206933.33593750\n",
      "epoch 9636 train_loss 10978114.39310646 val_loss 206933.33593750\n",
      "epoch 9637 train_loss 10978114.39302094 val_loss 206933.33593750\n",
      "epoch 9638 train_loss 10978114.39292603 val_loss 206933.33593750\n",
      "epoch 9639 train_loss 10978114.39284836 val_loss 206933.33593750\n",
      "epoch 9640 train_loss 10978114.39273346 val_loss 206933.33593750\n",
      "epoch 9641 train_loss 10978114.39263908 val_loss 206933.33593750\n",
      "epoch 9642 train_loss 10978114.39254158 val_loss 206933.33593750\n",
      "epoch 9643 train_loss 10978114.39244568 val_loss 206933.33593750\n",
      "epoch 9644 train_loss 10978114.39241684 val_loss 206933.33593750\n",
      "epoch 9645 train_loss 10978114.39235413 val_loss 206933.33593750\n",
      "epoch 9646 train_loss 10978114.39227608 val_loss 206933.33593750\n",
      "epoch 9647 train_loss 10978114.39217506 val_loss 206933.33593750\n",
      "epoch 9648 train_loss 10978114.39207306 val_loss 206933.33593750\n",
      "epoch 9649 train_loss 10978114.39198357 val_loss 206933.33593750\n",
      "epoch 9650 train_loss 10978114.39190170 val_loss 206933.33593750\n",
      "epoch 9651 train_loss 10978114.39177872 val_loss 206933.33593750\n",
      "epoch 9652 train_loss 10978114.39173813 val_loss 206933.33593750\n",
      "epoch 9653 train_loss 10978114.39165154 val_loss 206933.33593750\n",
      "epoch 9654 train_loss 10978114.39154999 val_loss 206933.33593750\n",
      "epoch 9655 train_loss 10978114.39145340 val_loss 206933.33593750\n",
      "epoch 9656 train_loss 10978114.39135666 val_loss 206933.33593750\n",
      "epoch 9657 train_loss 10978114.39128487 val_loss 206933.33593750\n",
      "epoch 9658 train_loss 10978114.39118042 val_loss 206933.33593750\n",
      "epoch 9659 train_loss 10978114.39111526 val_loss 206933.33593750\n",
      "epoch 9660 train_loss 10978114.39109490 val_loss 206933.33593750\n",
      "epoch 9661 train_loss 10978114.39100502 val_loss 206933.33593750\n",
      "epoch 9662 train_loss 10978114.39091400 val_loss 206933.33593750\n",
      "epoch 9663 train_loss 10978114.39082085 val_loss 206933.33593750\n",
      "epoch 9664 train_loss 10978114.39073112 val_loss 206933.33593750\n",
      "epoch 9665 train_loss 10978114.39064858 val_loss 206933.33593750\n",
      "epoch 9666 train_loss 10978114.39054062 val_loss 206933.33593750\n",
      "epoch 9667 train_loss 10978114.39045647 val_loss 206933.33593750\n",
      "epoch 9668 train_loss 10978114.39053978 val_loss 206933.33593750\n",
      "epoch 9669 train_loss 10978114.39044418 val_loss 206933.33593750\n",
      "epoch 9670 train_loss 10978114.39035515 val_loss 206933.33593750\n",
      "epoch 9671 train_loss 10978114.39028061 val_loss 206933.33593750\n",
      "epoch 9672 train_loss 10978114.39017059 val_loss 206933.33593750\n",
      "epoch 9673 train_loss 10978114.39007248 val_loss 206933.33593750\n",
      "epoch 9674 train_loss 10978114.39001869 val_loss 206933.33593750\n",
      "epoch 9675 train_loss 10978114.38991798 val_loss 206933.33593750\n",
      "epoch 9676 train_loss 10978114.38983360 val_loss 206933.33593750\n",
      "epoch 9677 train_loss 10978114.38973381 val_loss 206933.33593750\n",
      "epoch 9678 train_loss 10978114.38963654 val_loss 206933.33593750\n",
      "epoch 9679 train_loss 10978114.38954834 val_loss 206933.33593750\n",
      "epoch 9680 train_loss 10978114.38945664 val_loss 206933.33593750\n",
      "epoch 9681 train_loss 10978114.38935371 val_loss 206933.33593750\n",
      "epoch 9682 train_loss 10978114.38925072 val_loss 206933.33593750\n",
      "epoch 9683 train_loss 10978114.38911964 val_loss 206933.33593750\n",
      "epoch 9684 train_loss 10978114.38902664 val_loss 206933.33593750\n",
      "epoch 9685 train_loss 10978114.38894249 val_loss 206933.33593750\n",
      "epoch 9686 train_loss 10978114.38887619 val_loss 206933.33593750\n",
      "epoch 9687 train_loss 10978114.38880035 val_loss 206933.33593750\n",
      "epoch 9688 train_loss 10978114.38870873 val_loss 206933.33593750\n",
      "epoch 9689 train_loss 10978114.38861176 val_loss 206933.33593750\n",
      "epoch 9690 train_loss 10978114.38851616 val_loss 206933.33593750\n",
      "epoch 9691 train_loss 10978114.38842964 val_loss 206933.33593750\n",
      "epoch 9692 train_loss 10978114.38833885 val_loss 206933.33593750\n",
      "epoch 9693 train_loss 10978114.38823723 val_loss 206933.33593750\n",
      "epoch 9694 train_loss 10978114.38815361 val_loss 206933.33593750\n",
      "epoch 9695 train_loss 10978114.38806953 val_loss 206933.33593750\n",
      "epoch 9696 train_loss 10978114.38798737 val_loss 206933.33593750\n",
      "epoch 9697 train_loss 10978114.38790390 val_loss 206933.33593750\n",
      "epoch 9698 train_loss 10978114.38781837 val_loss 206933.33593750\n",
      "epoch 9699 train_loss 10978114.38771721 val_loss 206933.33593750\n",
      "epoch 9700 train_loss 10978114.38762054 val_loss 206933.33593750\n",
      "epoch 9701 train_loss 10978114.38753311 val_loss 206933.33593750\n",
      "epoch 9702 train_loss 10978114.38744102 val_loss 206933.33593750\n",
      "epoch 9703 train_loss 10978114.38734306 val_loss 206933.33593750\n",
      "epoch 9704 train_loss 10978114.38725052 val_loss 206933.33593750\n",
      "epoch 9705 train_loss 10978114.38715248 val_loss 206933.33593750\n",
      "epoch 9706 train_loss 10978114.38708626 val_loss 206933.33593750\n",
      "epoch 9707 train_loss 10978114.38697464 val_loss 206933.33593750\n",
      "epoch 9708 train_loss 10978114.38688301 val_loss 206933.33593750\n",
      "epoch 9709 train_loss 10978114.38680153 val_loss 206933.33593750\n",
      "epoch 9710 train_loss 10978114.38668846 val_loss 206933.33593750\n",
      "epoch 9711 train_loss 10978114.38661057 val_loss 206933.33593750\n",
      "epoch 9712 train_loss 10978114.38651840 val_loss 206933.33593750\n",
      "epoch 9713 train_loss 10978114.38645119 val_loss 206933.33593750\n",
      "epoch 9714 train_loss 10978114.38633774 val_loss 206933.33593750\n",
      "epoch 9715 train_loss 10978114.38622620 val_loss 206933.33593750\n",
      "epoch 9716 train_loss 10978114.38615227 val_loss 206933.33593750\n",
      "epoch 9717 train_loss 10978114.38605598 val_loss 206933.33593750\n",
      "epoch 9718 train_loss 10978114.38595184 val_loss 206933.33593750\n",
      "epoch 9719 train_loss 10978114.38587204 val_loss 206933.33593750\n",
      "epoch 9720 train_loss 10978114.38579140 val_loss 206933.33593750\n",
      "epoch 9721 train_loss 10978114.38567863 val_loss 206933.33593750\n",
      "epoch 9722 train_loss 10978114.38560349 val_loss 206933.33593750\n",
      "epoch 9723 train_loss 10978114.38554031 val_loss 206933.33593750\n",
      "epoch 9724 train_loss 10978114.38541885 val_loss 206933.33593750\n",
      "epoch 9725 train_loss 10978114.38534554 val_loss 206933.33593750\n",
      "epoch 9726 train_loss 10978114.38525360 val_loss 206933.33593750\n",
      "epoch 9727 train_loss 10978114.38523277 val_loss 206933.33593750\n",
      "epoch 9728 train_loss 10978114.38514160 val_loss 206933.33593750\n",
      "epoch 9729 train_loss 10978114.38504257 val_loss 206933.33593750\n",
      "epoch 9730 train_loss 10978114.38497826 val_loss 206933.33593750\n",
      "epoch 9731 train_loss 10978114.38486977 val_loss 206933.33593750\n",
      "epoch 9732 train_loss 10978114.38478142 val_loss 206933.33593750\n",
      "epoch 9733 train_loss 10978114.38468063 val_loss 206933.33593750\n",
      "epoch 9734 train_loss 10978114.38459435 val_loss 206933.33593750\n",
      "epoch 9735 train_loss 10978114.38449196 val_loss 206933.33593750\n",
      "epoch 9736 train_loss 10978114.38447838 val_loss 206933.33593750\n",
      "epoch 9737 train_loss 10978114.38438156 val_loss 206933.33593750\n",
      "epoch 9738 train_loss 10978114.38427422 val_loss 206933.33593750\n",
      "epoch 9739 train_loss 10978114.38419334 val_loss 206933.33593750\n",
      "epoch 9740 train_loss 10978114.38410790 val_loss 206933.33593750\n",
      "epoch 9741 train_loss 10978114.38401222 val_loss 206933.35156250\n",
      "epoch 9742 train_loss 10978114.38393402 val_loss 206933.35156250\n",
      "epoch 9743 train_loss 10978114.38383820 val_loss 206933.35156250\n",
      "epoch 9744 train_loss 10978114.38374611 val_loss 206933.35156250\n",
      "epoch 9745 train_loss 10978114.38364914 val_loss 206933.35156250\n",
      "epoch 9746 train_loss 10978114.38354973 val_loss 206933.35156250\n",
      "epoch 9747 train_loss 10978114.38345375 val_loss 206933.35156250\n",
      "epoch 9748 train_loss 10978114.38335587 val_loss 206933.35156250\n",
      "epoch 9749 train_loss 10978114.38327820 val_loss 206933.35156250\n",
      "epoch 9750 train_loss 10978114.38318977 val_loss 206933.35156250\n",
      "epoch 9751 train_loss 10978114.38309105 val_loss 206933.35156250\n",
      "epoch 9752 train_loss 10978114.38301155 val_loss 206933.35156250\n",
      "epoch 9753 train_loss 10978114.38289856 val_loss 206933.35156250\n",
      "epoch 9754 train_loss 10978114.38280434 val_loss 206933.35156250\n",
      "epoch 9755 train_loss 10978114.38271721 val_loss 206933.35156250\n",
      "epoch 9756 train_loss 10978114.38261879 val_loss 206933.35156250\n",
      "epoch 9757 train_loss 10978114.38254211 val_loss 206933.35156250\n",
      "epoch 9758 train_loss 10978114.38244377 val_loss 206933.35156250\n",
      "epoch 9759 train_loss 10978114.38235428 val_loss 206933.35156250\n",
      "epoch 9760 train_loss 10978114.38225021 val_loss 206933.35156250\n",
      "epoch 9761 train_loss 10978114.38217552 val_loss 206933.35156250\n",
      "epoch 9762 train_loss 10978114.38211273 val_loss 206933.35156250\n",
      "epoch 9763 train_loss 10978114.38201942 val_loss 206933.35156250\n",
      "epoch 9764 train_loss 10978114.38194817 val_loss 206933.35156250\n",
      "epoch 9765 train_loss 10978114.38186691 val_loss 206933.35156250\n",
      "epoch 9766 train_loss 10978114.38174934 val_loss 206933.35156250\n",
      "epoch 9767 train_loss 10978114.38166115 val_loss 206933.35156250\n",
      "epoch 9768 train_loss 10978114.38156677 val_loss 206933.35156250\n",
      "epoch 9769 train_loss 10978114.38147820 val_loss 206933.35156250\n",
      "epoch 9770 train_loss 10978114.38137306 val_loss 206933.35156250\n",
      "epoch 9771 train_loss 10978114.38130531 val_loss 206933.35156250\n",
      "epoch 9772 train_loss 10978114.38122452 val_loss 206933.35156250\n",
      "epoch 9773 train_loss 10978114.38114464 val_loss 206933.35156250\n",
      "epoch 9774 train_loss 10978114.38105141 val_loss 206933.35156250\n",
      "epoch 9775 train_loss 10978114.38096001 val_loss 206933.35156250\n",
      "epoch 9776 train_loss 10978114.38086197 val_loss 206933.35156250\n",
      "epoch 9777 train_loss 10978114.38074730 val_loss 206933.35156250\n",
      "epoch 9778 train_loss 10978114.38070366 val_loss 206933.35156250\n",
      "epoch 9779 train_loss 10978114.38060608 val_loss 206933.35156250\n",
      "epoch 9780 train_loss 10978114.38048981 val_loss 206933.35156250\n",
      "epoch 9781 train_loss 10978114.38041786 val_loss 206933.35156250\n",
      "epoch 9782 train_loss 10978114.38036324 val_loss 206933.35156250\n",
      "epoch 9783 train_loss 10978114.38025742 val_loss 206933.35156250\n",
      "epoch 9784 train_loss 10978114.38015709 val_loss 206933.35156250\n",
      "epoch 9785 train_loss 10978114.38005775 val_loss 206933.35156250\n",
      "epoch 9786 train_loss 10978114.38002144 val_loss 206933.35156250\n",
      "epoch 9787 train_loss 10978114.37992439 val_loss 206933.35156250\n",
      "epoch 9788 train_loss 10978114.37983849 val_loss 206933.35156250\n",
      "epoch 9789 train_loss 10978114.37973061 val_loss 206933.35156250\n",
      "epoch 9790 train_loss 10978114.37963608 val_loss 206933.35156250\n",
      "epoch 9791 train_loss 10978114.37953178 val_loss 206933.35156250\n",
      "epoch 9792 train_loss 10978114.37944611 val_loss 206933.35156250\n",
      "epoch 9793 train_loss 10978114.37935272 val_loss 206933.35156250\n",
      "epoch 9794 train_loss 10978114.37929764 val_loss 206933.35156250\n",
      "epoch 9795 train_loss 10978114.37919044 val_loss 206933.35156250\n",
      "epoch 9796 train_loss 10978114.37909714 val_loss 206933.35156250\n",
      "epoch 9797 train_loss 10978114.37901222 val_loss 206933.35156250\n",
      "epoch 9798 train_loss 10978114.37889000 val_loss 206933.35156250\n",
      "epoch 9799 train_loss 10978114.37880470 val_loss 206933.35156250\n",
      "epoch 9800 train_loss 10978114.37873184 val_loss 206933.35156250\n",
      "epoch 9801 train_loss 10978114.37864227 val_loss 206933.35156250\n",
      "epoch 9802 train_loss 10978114.37853096 val_loss 206933.35156250\n",
      "epoch 9803 train_loss 10978114.37843788 val_loss 206933.35156250\n",
      "epoch 9804 train_loss 10978114.37833664 val_loss 206933.35156250\n",
      "epoch 9805 train_loss 10978114.37824356 val_loss 206933.35156250\n",
      "epoch 9806 train_loss 10978114.37814995 val_loss 206933.35156250\n",
      "epoch 9807 train_loss 10978114.37808205 val_loss 206933.35156250\n",
      "epoch 9808 train_loss 10978114.37795380 val_loss 206933.35156250\n",
      "epoch 9809 train_loss 10978114.37787315 val_loss 206933.35156250\n",
      "epoch 9810 train_loss 10978114.37777290 val_loss 206933.35156250\n",
      "epoch 9811 train_loss 10978114.37767944 val_loss 206933.35156250\n",
      "epoch 9812 train_loss 10978114.37757752 val_loss 206933.35156250\n",
      "epoch 9813 train_loss 10978114.37748856 val_loss 206933.35156250\n",
      "epoch 9814 train_loss 10978114.37740311 val_loss 206933.35156250\n",
      "epoch 9815 train_loss 10978114.37731964 val_loss 206933.35156250\n",
      "epoch 9816 train_loss 10978114.37723465 val_loss 206933.35156250\n",
      "epoch 9817 train_loss 10978114.37714577 val_loss 206933.35156250\n",
      "epoch 9818 train_loss 10978114.37705940 val_loss 206933.35156250\n",
      "epoch 9819 train_loss 10978114.37695374 val_loss 206933.35156250\n",
      "epoch 9820 train_loss 10978114.37685898 val_loss 206933.35156250\n",
      "epoch 9821 train_loss 10978114.37679924 val_loss 206933.35156250\n",
      "epoch 9822 train_loss 10978114.37669251 val_loss 206933.35156250\n",
      "epoch 9823 train_loss 10978114.37659660 val_loss 206933.35156250\n",
      "epoch 9824 train_loss 10978114.37652641 val_loss 206933.35156250\n",
      "epoch 9825 train_loss 10978114.37644203 val_loss 206933.35156250\n",
      "epoch 9826 train_loss 10978114.37635040 val_loss 206933.35156250\n",
      "epoch 9827 train_loss 10978114.37625504 val_loss 206933.35156250\n",
      "epoch 9828 train_loss 10978114.37618660 val_loss 206933.35156250\n",
      "epoch 9829 train_loss 10978114.37607414 val_loss 206933.35156250\n",
      "epoch 9830 train_loss 10978114.37598877 val_loss 206933.35156250\n",
      "epoch 9831 train_loss 10978114.37591896 val_loss 206933.35156250\n",
      "epoch 9832 train_loss 10978114.37582512 val_loss 206933.35156250\n",
      "epoch 9833 train_loss 10978114.37572227 val_loss 206933.35156250\n",
      "epoch 9834 train_loss 10978114.37563751 val_loss 206933.35156250\n",
      "epoch 9835 train_loss 10978114.37554329 val_loss 206933.35156250\n",
      "epoch 9836 train_loss 10978114.37544151 val_loss 206933.35156250\n",
      "epoch 9837 train_loss 10978114.37533958 val_loss 206933.35156250\n",
      "epoch 9838 train_loss 10978114.37524223 val_loss 206933.35156250\n",
      "epoch 9839 train_loss 10978114.37515862 val_loss 206933.35156250\n",
      "epoch 9840 train_loss 10978114.37505684 val_loss 206933.35156250\n",
      "epoch 9841 train_loss 10978114.37498077 val_loss 206933.35156250\n",
      "epoch 9842 train_loss 10978114.37488121 val_loss 206933.35156250\n",
      "epoch 9843 train_loss 10978114.37478088 val_loss 206933.35156250\n",
      "epoch 9844 train_loss 10978114.37467567 val_loss 206933.35156250\n",
      "epoch 9845 train_loss 10978114.37459473 val_loss 206933.35156250\n",
      "epoch 9846 train_loss 10978114.37450325 val_loss 206933.35156250\n",
      "epoch 9847 train_loss 10978114.37440910 val_loss 206933.35156250\n",
      "epoch 9848 train_loss 10978114.37433502 val_loss 206933.35156250\n",
      "epoch 9849 train_loss 10978114.37426346 val_loss 206933.35156250\n",
      "epoch 9850 train_loss 10978114.37421745 val_loss 206933.35156250\n",
      "epoch 9851 train_loss 10978114.37412682 val_loss 206933.35156250\n",
      "epoch 9852 train_loss 10978114.37401382 val_loss 206933.35156250\n",
      "epoch 9853 train_loss 10978114.37398216 val_loss 206933.35156250\n",
      "epoch 9854 train_loss 10978114.37390945 val_loss 206933.35156250\n",
      "epoch 9855 train_loss 10978114.37381020 val_loss 206933.35156250\n",
      "epoch 9856 train_loss 10978114.37371872 val_loss 206933.35156250\n",
      "epoch 9857 train_loss 10978114.37365639 val_loss 206933.35156250\n",
      "epoch 9858 train_loss 10978114.37355644 val_loss 206933.35156250\n",
      "epoch 9859 train_loss 10978114.37346207 val_loss 206933.35156250\n",
      "epoch 9860 train_loss 10978114.37339714 val_loss 206933.35156250\n",
      "epoch 9861 train_loss 10978114.37329628 val_loss 206933.35156250\n",
      "epoch 9862 train_loss 10978114.37325058 val_loss 206933.35156250\n",
      "epoch 9863 train_loss 10978114.37317444 val_loss 206933.35156250\n",
      "epoch 9864 train_loss 10978114.37305443 val_loss 206933.35156250\n",
      "epoch 9865 train_loss 10978114.37297203 val_loss 206933.35156250\n",
      "epoch 9866 train_loss 10978114.37291336 val_loss 206933.35156250\n",
      "epoch 9867 train_loss 10978114.37282593 val_loss 206933.35156250\n",
      "epoch 9868 train_loss 10978114.37271591 val_loss 206933.35156250\n",
      "epoch 9869 train_loss 10978114.37262672 val_loss 206933.35156250\n",
      "epoch 9870 train_loss 10978114.37254623 val_loss 206933.35156250\n",
      "epoch 9871 train_loss 10978114.37244011 val_loss 206933.35156250\n",
      "epoch 9872 train_loss 10978114.37235512 val_loss 206933.35156250\n",
      "epoch 9873 train_loss 10978114.37224678 val_loss 206933.35156250\n",
      "epoch 9874 train_loss 10978114.37216164 val_loss 206933.35156250\n",
      "epoch 9875 train_loss 10978114.37206390 val_loss 206933.35156250\n",
      "epoch 9876 train_loss 10978114.37197433 val_loss 206933.35156250\n",
      "epoch 9877 train_loss 10978114.37191193 val_loss 206933.36718750\n",
      "epoch 9878 train_loss 10978114.37181190 val_loss 206933.36718750\n",
      "epoch 9879 train_loss 10978114.37172928 val_loss 206933.36718750\n",
      "epoch 9880 train_loss 10978114.37162895 val_loss 206933.36718750\n",
      "epoch 9881 train_loss 10978114.37153885 val_loss 206933.36718750\n",
      "epoch 9882 train_loss 10978114.37144005 val_loss 206933.36718750\n",
      "epoch 9883 train_loss 10978114.37133591 val_loss 206933.36718750\n",
      "epoch 9884 train_loss 10978114.37124245 val_loss 206933.36718750\n",
      "epoch 9885 train_loss 10978114.37117859 val_loss 206933.36718750\n",
      "epoch 9886 train_loss 10978114.37105354 val_loss 206933.36718750\n",
      "epoch 9887 train_loss 10978114.37098038 val_loss 206933.36718750\n",
      "epoch 9888 train_loss 10978114.37090263 val_loss 206933.36718750\n",
      "epoch 9889 train_loss 10978114.37079071 val_loss 206933.36718750\n",
      "epoch 9890 train_loss 10978114.37070419 val_loss 206933.36718750\n",
      "epoch 9891 train_loss 10978114.37065483 val_loss 206933.36718750\n",
      "epoch 9892 train_loss 10978114.37056297 val_loss 206933.36718750\n",
      "epoch 9893 train_loss 10978114.37048653 val_loss 206933.36718750\n",
      "epoch 9894 train_loss 10978114.37038933 val_loss 206933.36718750\n",
      "epoch 9895 train_loss 10978114.37029297 val_loss 206933.36718750\n",
      "epoch 9896 train_loss 10978114.37019287 val_loss 206933.36718750\n",
      "epoch 9897 train_loss 10978114.37012672 val_loss 206933.36718750\n",
      "epoch 9898 train_loss 10978114.37004074 val_loss 206933.36718750\n",
      "epoch 9899 train_loss 10978114.36991707 val_loss 206933.36718750\n",
      "epoch 9900 train_loss 10978114.36982224 val_loss 206933.36718750\n",
      "epoch 9901 train_loss 10978114.36973259 val_loss 206933.36718750\n",
      "epoch 9902 train_loss 10978114.36969368 val_loss 206933.36718750\n",
      "epoch 9903 train_loss 10978114.36961166 val_loss 206933.36718750\n",
      "epoch 9904 train_loss 10978114.36955696 val_loss 206933.36718750\n",
      "epoch 9905 train_loss 10978114.36946671 val_loss 206933.36718750\n",
      "epoch 9906 train_loss 10978114.36936348 val_loss 206933.36718750\n",
      "epoch 9907 train_loss 10978114.36926437 val_loss 206933.36718750\n",
      "epoch 9908 train_loss 10978114.36918648 val_loss 206933.36718750\n",
      "epoch 9909 train_loss 10978114.36910667 val_loss 206933.36718750\n",
      "epoch 9910 train_loss 10978114.36900307 val_loss 206933.36718750\n",
      "epoch 9911 train_loss 10978114.36891029 val_loss 206933.36718750\n",
      "epoch 9912 train_loss 10978114.36878822 val_loss 206933.36718750\n",
      "epoch 9913 train_loss 10978114.36870827 val_loss 206933.36718750\n",
      "epoch 9914 train_loss 10978114.36860558 val_loss 206933.36718750\n",
      "epoch 9915 train_loss 10978114.36852402 val_loss 206933.36718750\n",
      "epoch 9916 train_loss 10978114.36845024 val_loss 206933.36718750\n",
      "epoch 9917 train_loss 10978114.36835327 val_loss 206933.36718750\n",
      "epoch 9918 train_loss 10978114.36825142 val_loss 206933.36718750\n",
      "epoch 9919 train_loss 10978114.36815758 val_loss 206933.36718750\n",
      "epoch 9920 train_loss 10978114.36804443 val_loss 206933.36718750\n",
      "epoch 9921 train_loss 10978114.36796692 val_loss 206933.36718750\n",
      "epoch 9922 train_loss 10978114.36789703 val_loss 206933.36718750\n",
      "epoch 9923 train_loss 10978114.36780670 val_loss 206933.36718750\n",
      "epoch 9924 train_loss 10978114.36774940 val_loss 206933.36718750\n",
      "epoch 9925 train_loss 10978114.36764923 val_loss 206933.36718750\n",
      "epoch 9926 train_loss 10978114.36759041 val_loss 206933.36718750\n",
      "epoch 9927 train_loss 10978114.36746353 val_loss 206933.36718750\n",
      "epoch 9928 train_loss 10978114.36737511 val_loss 206933.36718750\n",
      "epoch 9929 train_loss 10978114.36727623 val_loss 206933.36718750\n",
      "epoch 9930 train_loss 10978114.36721275 val_loss 206933.36718750\n",
      "epoch 9931 train_loss 10978114.36711266 val_loss 206933.36718750\n",
      "epoch 9932 train_loss 10978114.36701248 val_loss 206933.36718750\n",
      "epoch 9933 train_loss 10978114.36691917 val_loss 206933.36718750\n",
      "epoch 9934 train_loss 10978114.36682640 val_loss 206933.36718750\n",
      "epoch 9935 train_loss 10978114.36675003 val_loss 206933.36718750\n",
      "epoch 9936 train_loss 10978114.36666168 val_loss 206933.36718750\n",
      "epoch 9937 train_loss 10978114.36656761 val_loss 206933.36718750\n",
      "epoch 9938 train_loss 10978114.36646103 val_loss 206933.36718750\n",
      "epoch 9939 train_loss 10978114.36640457 val_loss 206933.36718750\n",
      "epoch 9940 train_loss 10978114.36629204 val_loss 206933.36718750\n",
      "epoch 9941 train_loss 10978114.36621162 val_loss 206933.36718750\n",
      "epoch 9942 train_loss 10978114.36611565 val_loss 206933.36718750\n",
      "epoch 9943 train_loss 10978114.36603088 val_loss 206933.36718750\n",
      "epoch 9944 train_loss 10978114.36594078 val_loss 206933.36718750\n",
      "epoch 9945 train_loss 10978114.36584846 val_loss 206933.36718750\n",
      "epoch 9946 train_loss 10978114.36574356 val_loss 206933.36718750\n",
      "epoch 9947 train_loss 10978114.36566086 val_loss 206933.36718750\n",
      "epoch 9948 train_loss 10978114.36553871 val_loss 206933.36718750\n",
      "epoch 9949 train_loss 10978114.36548393 val_loss 206933.36718750\n",
      "epoch 9950 train_loss 10978114.36539558 val_loss 206933.36718750\n",
      "epoch 9951 train_loss 10978114.36529838 val_loss 206933.36718750\n",
      "epoch 9952 train_loss 10978114.36520798 val_loss 206933.36718750\n",
      "epoch 9953 train_loss 10978114.36511040 val_loss 206933.36718750\n",
      "epoch 9954 train_loss 10978114.36501297 val_loss 206933.36718750\n",
      "epoch 9955 train_loss 10978114.36491211 val_loss 206933.36718750\n",
      "epoch 9956 train_loss 10978114.36479515 val_loss 206933.36718750\n",
      "epoch 9957 train_loss 10978114.36471847 val_loss 206933.36718750\n",
      "epoch 9958 train_loss 10978114.36462875 val_loss 206933.36718750\n",
      "epoch 9959 train_loss 10978114.36452004 val_loss 206933.36718750\n",
      "epoch 9960 train_loss 10978114.36453713 val_loss 206933.36718750\n",
      "epoch 9961 train_loss 10978114.36443390 val_loss 206933.36718750\n",
      "epoch 9962 train_loss 10978114.36436089 val_loss 206933.36718750\n",
      "epoch 9963 train_loss 10978114.36427689 val_loss 206933.36718750\n",
      "epoch 9964 train_loss 10978114.36419228 val_loss 206933.36718750\n",
      "epoch 9965 train_loss 10978114.36408562 val_loss 206933.36718750\n",
      "epoch 9966 train_loss 10978114.36399040 val_loss 206933.36718750\n",
      "epoch 9967 train_loss 10978114.36393372 val_loss 206933.36718750\n",
      "epoch 9968 train_loss 10978114.36385475 val_loss 206933.36718750\n",
      "epoch 9969 train_loss 10978114.36374779 val_loss 206933.36718750\n",
      "epoch 9970 train_loss 10978114.36365746 val_loss 206933.36718750\n",
      "epoch 9971 train_loss 10978114.36356850 val_loss 206933.36718750\n",
      "epoch 9972 train_loss 10978114.36347969 val_loss 206933.36718750\n",
      "epoch 9973 train_loss 10978114.36338425 val_loss 206933.36718750\n",
      "epoch 9974 train_loss 10978114.36331123 val_loss 206933.36718750\n",
      "epoch 9975 train_loss 10978114.36320747 val_loss 206933.36718750\n",
      "epoch 9976 train_loss 10978114.36310898 val_loss 206933.36718750\n",
      "epoch 9977 train_loss 10978114.36300636 val_loss 206933.36718750\n",
      "epoch 9978 train_loss 10978114.36291122 val_loss 206933.36718750\n",
      "epoch 9979 train_loss 10978114.36281868 val_loss 206933.36718750\n",
      "epoch 9980 train_loss 10978114.36273071 val_loss 206933.36718750\n",
      "epoch 9981 train_loss 10978114.36262825 val_loss 206933.36718750\n",
      "epoch 9982 train_loss 10978114.36256882 val_loss 206933.36718750\n",
      "epoch 9983 train_loss 10978114.36246254 val_loss 206933.36718750\n",
      "epoch 9984 train_loss 10978114.36238136 val_loss 206933.36718750\n",
      "epoch 9985 train_loss 10978114.36228317 val_loss 206933.36718750\n",
      "epoch 9986 train_loss 10978114.36220650 val_loss 206933.36718750\n",
      "epoch 9987 train_loss 10978114.36213448 val_loss 206933.36718750\n",
      "epoch 9988 train_loss 10978114.36203644 val_loss 206933.36718750\n",
      "epoch 9989 train_loss 10978114.36194946 val_loss 206933.36718750\n",
      "epoch 9990 train_loss 10978114.36184280 val_loss 206933.36718750\n",
      "epoch 9991 train_loss 10978114.36175156 val_loss 206933.36718750\n",
      "epoch 9992 train_loss 10978114.36169151 val_loss 206933.36718750\n",
      "epoch 9993 train_loss 10978114.36160637 val_loss 206933.36718750\n",
      "epoch 9994 train_loss 10978114.36147965 val_loss 206933.36718750\n",
      "epoch 9995 train_loss 10978114.36140305 val_loss 206933.36718750\n",
      "epoch 9996 train_loss 10978114.36129127 val_loss 206933.36718750\n",
      "epoch 9997 train_loss 10978114.36119728 val_loss 206933.36718750\n",
      "epoch 9998 train_loss 10978114.36110870 val_loss 206933.36718750\n",
      "epoch 9999 train_loss 10978114.36101982 val_loss 206933.36718750\n",
      "預測 : tensor([204.9367], device='cuda:0') 正解 : 730\n",
      "預測 : tensor([204.9368], device='cuda:0') 正解 : 731\n",
      "預測 : tensor([204.9368], device='cuda:0') 正解 : 732\n",
      "預測 : tensor([204.9369], device='cuda:0') 正解 : 733\n",
      "預測 : tensor([204.9369], device='cuda:0') 正解 : 734\n",
      "預測 : tensor([204.9370], device='cuda:0') 正解 : 735\n",
      "預測 : tensor([204.9370], device='cuda:0') 正解 : 736\n",
      "預測 : tensor([204.9370], device='cuda:0') 正解 : 737\n",
      "預測 : tensor([204.9371], device='cuda:0') 正解 : 738\n",
      "預測 : tensor([204.9371], device='cuda:0') 正解 : 739\n",
      "預測 : tensor([204.9371], device='cuda:0') 正解 : 740\n",
      "預測 : tensor([204.9372], device='cuda:0') 正解 : 741\n",
      "預測 : tensor([204.9372], device='cuda:0') 正解 : 742\n",
      "預測 : tensor([204.9373], device='cuda:0') 正解 : 743\n",
      "預測 : tensor([204.9373], device='cuda:0') 正解 : 744\n",
      "預測 : tensor([204.9373], device='cuda:0') 正解 : 745\n",
      "預測 : tensor([204.9374], device='cuda:0') 正解 : 746\n",
      "預測 : tensor([204.9374], device='cuda:0') 正解 : 747\n",
      "預測 : tensor([204.9374], device='cuda:0') 正解 : 748\n",
      "預測 : tensor([204.9375], device='cuda:0') 正解 : 749\n",
      "預測 : tensor([204.9375], device='cuda:0') 正解 : 750\n",
      "預測 : tensor([204.9375], device='cuda:0') 正解 : 751\n",
      "預測 : tensor([204.9376], device='cuda:0') 正解 : 752\n",
      "預測 : tensor([204.9376], device='cuda:0') 正解 : 753\n",
      "預測 : tensor([204.9377], device='cuda:0') 正解 : 754\n",
      "預測 : tensor([204.9377], device='cuda:0') 正解 : 755\n",
      "預測 : tensor([204.9377], device='cuda:0') 正解 : 756\n",
      "預測 : tensor([204.9377], device='cuda:0') 正解 : 757\n",
      "預測 : tensor([204.9378], device='cuda:0') 正解 : 758\n",
      "預測 : tensor([204.9378], device='cuda:0') 正解 : 759\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 30 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m             ans \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     51\u001b[0m         loss \u001b[39m=\u001b[39m criterion(output, target)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 53\u001b[0m         predicted_value \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m     56\u001b[0m accuracy \u001b[39m=\u001b[39m correct_predictions \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(test_data)\n\u001b[1;32m     57\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTest Accuracy: \u001b[39m\u001b[39m{\u001b[39;00maccuracy\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 30 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "# 模型訓練\n",
    "\n",
    "#for epoch in tqdm(range(1000)):\n",
    "for epoch in range(10000):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    time = 0\n",
    "    for sequence, target in train_data:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        sequence = sequence.to(device)\n",
    "        # print(sequence.shape)\n",
    "        # print(sequence.dtype)\n",
    "        # print(sequence.type())\n",
    "        target = target.to(device)\n",
    "        # print(target.shape)\n",
    "        # print(target.dtype)\n",
    "        # print(target.type())\n",
    "        output = model(sequence)\n",
    "        #print('model :', output.view(-1)[0])\n",
    "        #print('true :', target.view(-1)[0])\n",
    "        \n",
    "        # 計算損失\n",
    "        loss = criterion(output.view(-1), target.view(-1)).to(device)\n",
    "\n",
    "        # 反向傳播與參數更新\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        time += 1\n",
    "    #print('結束1')  \n",
    "    val_loss = get_val_loss(model, valid_data, criterion)\n",
    "    #print('結束2')  \n",
    "    print('epoch {:03d} train_loss {:.8f} val_loss {:.8f}'.format(epoch, total_loss/time, val_loss))\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "\n",
    "# 模型測試\n",
    "model.eval()\n",
    "correct_predictions = 0\n",
    "ans = 730\n",
    "with torch.no_grad():\n",
    "    for sequence, target in test_data:\n",
    "        sequence = sequence.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(sequence)\n",
    "        for i in output:\n",
    "            print('預測 :', i, '正解 :', ans)\n",
    "            ans += 1\n",
    "        loss = criterion(output, target).to(device)\n",
    "    \n",
    "        predicted_value = output.view(-1).item()\n",
    "       \n",
    "\n",
    "accuracy = correct_predictions / len(test_data)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
