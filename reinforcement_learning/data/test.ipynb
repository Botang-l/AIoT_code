{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用 DEFAULT 作為超參數\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from Memory import *\n",
    "from Model import *\n",
    "from Environment import *\n",
    "from Strategy import *\n",
    "from util import *\n",
    "from args import *\n",
    "from Environment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net = torch.load('model/policy_net.pth')\n",
    "target_net = torch.load('model/target_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最終決策 policy net:\n",
      "----------\n",
      "tensor([[6.7245, 6.8179]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[6.8206, 6.8930]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[6.8974, 6.9682]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[6.9728, 7.0444]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.0475, 7.1207]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.0915, 6.9449]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.0542, 7.1680]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.1319, 7.0914]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.0730, 7.2118]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.1800, 7.1507]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.1189, 7.2582]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.2229, 7.1769]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.1546, 7.3002]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.2680, 7.2501]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.2117, 7.3531]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.3251, 7.3034]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.2614, 7.4039]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.3743, 7.3637]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.3123, 7.4560]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.4261, 7.4163]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.3629, 7.5075]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.4763, 7.4669]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.4128, 7.5559]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.5275, 7.5175]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.4776, 7.6116]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.5832, 7.5650]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.5330, 7.6679]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.6417, 7.6223]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.5876, 7.7221]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.6957, 7.6779]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.6446, 7.7797]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.7525, 7.7356]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.7002, 7.8358]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.8095, 7.7929]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.7557, 7.8918]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.8666, 7.8502]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.8117, 7.9495]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.9236, 7.9075]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.8814, 8.0178]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.9930, 7.9813]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[7.9463, 8.0824]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.0603, 8.0463]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.0128, 8.1490]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.1323, 8.1164]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.0813, 8.2180]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.1999, 8.1821]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.1497, 8.2864]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.2675, 8.2478]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.2175, 8.3534]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.3350, 8.3135]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.2853, 8.4203]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.4026, 8.3791]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.3530, 8.4873]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.4702, 8.4448]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.4297, 8.5609]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.5377, 8.5105]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.5196, 8.6444]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.6182, 8.5857]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.6023, 8.7266]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.7079, 8.6679]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.6786, 8.8079]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.7977, 8.7501]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.7577, 8.8909]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.8896, 8.8522]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.8396, 8.9750]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.9682, 8.9395]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[8.9221, 9.0565]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9.0461, 9.0215]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9.0047, 9.1380]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9.1256, 9.1005]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9.0872, 9.2195]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9.2072, 9.1783]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9.1698, 9.3010]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9.2888, 9.2562]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9.2523, 9.3825]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9.3704, 9.3342]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9.3327, 9.4620]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9.4530, 9.4139]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9.4066, 9.5339]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9.5356, 9.4937]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9.4989, 9.6294]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9.6183, 9.5735]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9.5962, 9.7310]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9.7179, 9.6784]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9.6949, 9.8290]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9.8166, 9.7815]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9.7948, 9.9241]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9.9148, 9.8840]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 9.8947, 10.0193]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[10.0167,  9.9886]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 9.9945, 10.1144]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[10.1201, 10.0940]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[10.1036, 10.2218]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[10.2235, 10.1994]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[10.2178, 10.3360]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[10.3310, 10.3104]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[10.3320, 10.4502]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[10.4487, 10.4348]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[10.4446, 10.5623]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[10.5664, 10.5564]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[10.5490, 10.6631]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Total Reward : 4.380000000000006\n",
      "[1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print('最終決策 policy net:')\n",
    "# Initialize the environment and get it's state\n",
    "state, _ = env.reset()\n",
    "#env.displayPosition()\n",
    "print('-'*10)\n",
    "state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "for t in count():\n",
    "    if(t > 100):\n",
    "        break\n",
    "    action = policy_net(state).max(1)[1].view(1, 1)\n",
    "    print(policy_net(state))\n",
    "    observation, reward, terminated, truncated, _ = env.step(action.item())\n",
    "    reward = torch.tensor([reward], device=device)\n",
    "    done = terminated or truncated\n",
    "    if terminated:\n",
    "        state = None\n",
    "    else:\n",
    "        state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            total_reward.append(env.TotalReward())\n",
    "            #plot_durations(total_reward)\n",
    "            break     \n",
    "env.displayTotalReward() \n",
    "print(env.actionlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最終決策 target net:\n",
      "----------\n",
      "tensor([[8., 0.]], device='cuda:0')\n",
      "tensor([[6.7314, 6.8235]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[9., 1.]], device='cuda:0')\n",
      "tensor([[6.8282, 6.8990]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[10.,  2.]], device='cuda:0')\n",
      "tensor([[6.9059, 6.9747]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[11.,  3.]], device='cuda:0')\n",
      "tensor([[6.9819, 7.0511]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12.,  4.]], device='cuda:0')\n",
      "tensor([[7.0573, 7.1276]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13.,  5.]], device='cuda:0')\n",
      "tensor([[7.0974, 6.9380]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12.,  6.]], device='cuda:0')\n",
      "tensor([[7.0636, 7.1743]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13.,  7.]], device='cuda:0')\n",
      "tensor([[7.1388, 7.0881]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12.,  8.]], device='cuda:0')\n",
      "tensor([[7.0829, 7.2180]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13.,  9.]], device='cuda:0')\n",
      "tensor([[7.1852, 7.1448]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 10.]], device='cuda:0')\n",
      "tensor([[7.1269, 7.2623]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 11.]], device='cuda:0')\n",
      "tensor([[7.2284, 7.1715]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 12.]], device='cuda:0')\n",
      "tensor([[7.1610, 7.3027]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 13.]], device='cuda:0')\n",
      "tensor([[7.2723, 7.2448]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 14.]], device='cuda:0')\n",
      "tensor([[7.2175, 7.3551]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 15.]], device='cuda:0')\n",
      "tensor([[7.3288, 7.2970]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 16.]], device='cuda:0')\n",
      "tensor([[7.2684, 7.4083]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 17.]], device='cuda:0')\n",
      "tensor([[7.3795, 7.3611]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 18.]], device='cuda:0')\n",
      "tensor([[7.3193, 7.4606]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 19.]], device='cuda:0')\n",
      "tensor([[7.4313, 7.4138]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 20.]], device='cuda:0')\n",
      "tensor([[7.3698, 7.5122]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 21.]], device='cuda:0')\n",
      "tensor([[7.4814, 7.4644]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 22.]], device='cuda:0')\n",
      "tensor([[7.4197, 7.5608]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 23.]], device='cuda:0')\n",
      "tensor([[7.5325, 7.5151]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 24.]], device='cuda:0')\n",
      "tensor([[7.4845, 7.6167]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 25.]], device='cuda:0')\n",
      "tensor([[7.5881, 7.5626]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 26.]], device='cuda:0')\n",
      "tensor([[7.5400, 7.6732]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 27.]], device='cuda:0')\n",
      "tensor([[7.6470, 7.6210]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 28.]], device='cuda:0')\n",
      "tensor([[7.5945, 7.7273]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 29.]], device='cuda:0')\n",
      "tensor([[7.7011, 7.6770]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 30.]], device='cuda:0')\n",
      "tensor([[7.6515, 7.7850]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 31.]], device='cuda:0')\n",
      "tensor([[7.7574, 7.7332]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 32.]], device='cuda:0')\n",
      "tensor([[7.7071, 7.8413]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 33.]], device='cuda:0')\n",
      "tensor([[7.8143, 7.7905]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 34.]], device='cuda:0')\n",
      "tensor([[7.7626, 7.8974]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 35.]], device='cuda:0')\n",
      "tensor([[7.8713, 7.8477]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 36.]], device='cuda:0')\n",
      "tensor([[7.8180, 7.9544]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 37.]], device='cuda:0')\n",
      "tensor([[7.9283, 7.9050]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 38.]], device='cuda:0')\n",
      "tensor([[7.8880, 8.0234]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 39.]], device='cuda:0')\n",
      "tensor([[7.9971, 7.9779]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 40.]], device='cuda:0')\n",
      "tensor([[7.9530, 8.0880]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 41.]], device='cuda:0')\n",
      "tensor([[8.0649, 8.0440]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 42.]], device='cuda:0')\n",
      "tensor([[8.0192, 8.1543]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 43.]], device='cuda:0')\n",
      "tensor([[8.1365, 8.1135]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 44.]], device='cuda:0')\n",
      "tensor([[8.0878, 8.2234]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 45.]], device='cuda:0')\n",
      "tensor([[8.2041, 8.1790]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 46.]], device='cuda:0')\n",
      "tensor([[8.1562, 8.2916]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 47.]], device='cuda:0')\n",
      "tensor([[8.2717, 8.2446]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 48.]], device='cuda:0')\n",
      "tensor([[8.2240, 8.3586]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 49.]], device='cuda:0')\n",
      "tensor([[8.3392, 8.3101]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 50.]], device='cuda:0')\n",
      "tensor([[8.2918, 8.4256]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 51.]], device='cuda:0')\n",
      "tensor([[8.4068, 8.3757]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 52.]], device='cuda:0')\n",
      "tensor([[8.3596, 8.4926]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 53.]], device='cuda:0')\n",
      "tensor([[8.4743, 8.4412]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 54.]], device='cuda:0')\n",
      "tensor([[8.4372, 8.5669]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 55.]], device='cuda:0')\n",
      "tensor([[8.5419, 8.5068]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 56.]], device='cuda:0')\n",
      "tensor([[8.5273, 8.6505]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 57.]], device='cuda:0')\n",
      "tensor([[8.6233, 8.5826]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 58.]], device='cuda:0')\n",
      "tensor([[8.6113, 8.7332]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 59.]], device='cuda:0')\n",
      "tensor([[8.7132, 8.6647]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 60.]], device='cuda:0')\n",
      "tensor([[8.6877, 8.8147]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 61.]], device='cuda:0')\n",
      "tensor([[8.8031, 8.7468]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 62.]], device='cuda:0')\n",
      "tensor([[8.7665, 8.8975]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 63.]], device='cuda:0')\n",
      "tensor([[8.8948, 8.8468]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 64.]], device='cuda:0')\n",
      "tensor([[8.8490, 8.9831]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 65.]], device='cuda:0')\n",
      "tensor([[8.9750, 8.9365]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 66.]], device='cuda:0')\n",
      "tensor([[8.9317, 9.0649]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 67.]], device='cuda:0')\n",
      "tensor([[9.0529, 9.0193]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 68.]], device='cuda:0')\n",
      "tensor([[9.0144, 9.1466]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 69.]], device='cuda:0')\n",
      "tensor([[9.1325, 9.0984]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 70.]], device='cuda:0')\n",
      "tensor([[9.0971, 9.2284]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 71.]], device='cuda:0')\n",
      "tensor([[9.2142, 9.1764]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 72.]], device='cuda:0')\n",
      "tensor([[9.1798, 9.3101]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 73.]], device='cuda:0')\n",
      "tensor([[9.2959, 9.2544]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 74.]], device='cuda:0')\n",
      "tensor([[9.2625, 9.3919]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 75.]], device='cuda:0')\n",
      "tensor([[9.3775, 9.3323]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 76.]], device='cuda:0')\n",
      "tensor([[9.3430, 9.4712]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 77.]], device='cuda:0')\n",
      "tensor([[9.4598, 9.4113]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 78.]], device='cuda:0')\n",
      "tensor([[9.4170, 9.5433]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 79.]], device='cuda:0')\n",
      "tensor([[9.5425, 9.4911]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 80.]], device='cuda:0')\n",
      "tensor([[9.5089, 9.6374]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 81.]], device='cuda:0')\n",
      "tensor([[9.6252, 9.5709]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 82.]], device='cuda:0')\n",
      "tensor([[9.6059, 9.7375]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 83.]], device='cuda:0')\n",
      "tensor([[9.7248, 9.6758]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 84.]], device='cuda:0')\n",
      "tensor([[9.7051, 9.8367]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 85.]], device='cuda:0')\n",
      "tensor([[9.8242, 9.7798]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 86.]], device='cuda:0')\n",
      "tensor([[9.8051, 9.9320]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 87.]], device='cuda:0')\n",
      "tensor([[9.9224, 9.8823]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 88.]], device='cuda:0')\n",
      "tensor([[ 9.9051, 10.0273]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 89.]], device='cuda:0')\n",
      "tensor([[10.0244,  9.9869]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 90.]], device='cuda:0')\n",
      "tensor([[10.0052, 10.1227]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 91.]], device='cuda:0')\n",
      "tensor([[10.1278, 10.0924]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 92.]], device='cuda:0')\n",
      "tensor([[10.1144, 10.2303]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 93.]], device='cuda:0')\n",
      "tensor([[10.2313, 10.1979]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 94.]], device='cuda:0')\n",
      "tensor([[10.2286, 10.3445]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 95.]], device='cuda:0')\n",
      "tensor([[10.3408, 10.3113]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 96.]], device='cuda:0')\n",
      "tensor([[10.3429, 10.4589]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 97.]], device='cuda:0')\n",
      "tensor([[10.4568, 10.4333]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[12., 98.]], device='cuda:0')\n",
      "tensor([[10.4558, 10.5713]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[13., 99.]], device='cuda:0')\n",
      "tensor([[10.5750, 10.5560]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 12., 100.]], device='cuda:0')\n",
      "tensor([[10.5604, 10.6724]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 13., 101.]], device='cuda:0')\n",
      "Total Reward : 4.380000000000006\n",
      "[1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print('最終決策 target net:')\n",
    "# Initialize the environment and get it's state\n",
    "state, _ = env.reset()\n",
    "#env.displayPosition()\n",
    "print('-'*10)\n",
    "state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "for t in count():\n",
    "    print(state)\n",
    "    if(t > 100):\n",
    "        break\n",
    "    action = target_net(state).max(1)[1].view(1, 1)\n",
    "    print(target_net(state))\n",
    "    observation, reward, terminated, truncated, _ = env.step(action.item())\n",
    "    reward = torch.tensor([reward], device=device)\n",
    "    done = terminated or truncated\n",
    "    if terminated:\n",
    "        state = None\n",
    "    else:\n",
    "        state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            total_reward.append(env.TotalReward())\n",
    "            #plot_durations(total_reward)\n",
    "            break\n",
    "env.displayTotalReward()\n",
    "print(env.actionlist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
